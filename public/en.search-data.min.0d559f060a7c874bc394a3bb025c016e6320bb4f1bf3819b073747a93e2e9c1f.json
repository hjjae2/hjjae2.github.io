[{"id":0,"href":"/docs/AWS/OpenSearch/01.-%EA%B0%9C%EC%9A%94/","title":"01. 개요","section":"08. Opensearch","content":" OpenSearch # ES의 라이센스가 변경되면서, AWS 커뮤니티에서 개발/관리하는 (AWS 기반의)ES 프로젝트가 생겨났다. (참고 : 히스토리)\n해당 (ES)라이선스는 오픈 소스가 아니며 사용자에게 동일한 자유를 제공하지 않습니다. 오픈 소스 커뮤니티와 고객이 계속해서 안전하고 고품질에 완전한 오픈 소스 검색과 분석 제품군을 사용할 수 있도록 AWS는 커뮤니티 주도적이며 오픈 소스 Elasticsearch 및 Kibana의 ALv2 라이선스 갈래인 OpenSearch 프로젝트를 도입했습니다.\n이 AWS Elasticsearch 의 후속 서비스가 AWS OpenSearch 이다.\nISM (Index Statement Management, 인덱스 관리) # ISM(Index Statement Management)을 통해, 커스텀한 관리 정책(custom management policies)을 정의할 수 있다.\n(이 정책을 통해) 주기적으로 실행하는 task를 자동화할 수 있다. (이 정책을) 인덱스, 인덱스 패턴에 적용시킬 수 있다. 인덱스를 관리하기 위해 외부의 프로세스(예를 들어, 크론 스크립트?)를 만들었는데, ISM 덕분에 더 이상 이런 것들이 필요하지 않게 되는 것이다.\nPolicy # 하나의 정책은 하나의 default state 와 인덱스가 전환(transition)할 state 리스트를 가지고 있다.\n각 state 내에서는, 수항핼 작업(actions)들과 전환(transitions) + 전환을 트리거할 조건(conditions)들을 정의할 수 있다.\n정책(policy)을 인덱스(index)에 연결(attach)하면, ISM은 30~48분마다 action을 실행하고, condition을 체크하고, 인덱스의 state를 transition하는 Job을 생성한다.\n이 Job은 기본적으로 매 30분마다 동작하지만, +0~60%(즉 최대 48분 까지) jitter가 더해진다. 이유는 인덱스에 동시에 많은 작업 활동들이 급증하지 않도록 하기 위해서이다. (클러스터 상태가 빨간색이면 ISM 은 Job을 실행하지 않는다.)\nISM은 OpenSearch / Elasticsearch 6.8 이상의 버전에서 동작한다.\n예시 # 일정 기간 후에 오래된 인덱스를 주기적으로 삭제할 수 있다. 인덱스 30일 후에 read_only 상태로 이동한 후, 90일 이후에 삭제하는 정책을 정의할 수 있다.\n참고 # AWS Elasticsearch Amazon OpenSearch Service Java High Level Rest Client "},{"id":1,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-01.-%EA%B0%80%EB%B3%80%EC%84%B1%EC%9D%84-%EC%A0%9C%ED%95%9C%ED%95%98%EB%9D%BC/","title":"아이템 01. 가변성을 제한하라","section":"이펙티브 코틀린","content":" 아이템 01. 가변성을 제한하라. # val # val 은 읽기 전용 프로퍼티지만, immutable 을 의미하는 것은 아니다. setter 를 제공하지 않을 뿐이다. (혼동하지 말 것)\nimmutable 이 필요하다면 final 키워드를 사용한다.\n컬렉션 다운캐스팅 # 컬렉션 다운캐스팅은 계약을 위반하고, 추상화를 무시하는 행위다.\n아래는 컬렉션 다운캐스팅의 간단한 예시이다.\nval list = listOf(1,2,3) if (list is MutableList) { list.add(4) } JVM에서 listOf 는 자바의 List 인터페이스를 구현한 Array.ArrayList 객체를 리턴한다.\n자바의 List 인터페이스는 add, set 과 같은 메서드를 제공하니까 코틀린에서 MutableList 로 변경될 수 있다.\n하지만 Arrays.ArrayList 이런 연산을 구현하고 있지 않아 오류가 발생한다.\n즉, 위 코드의 문제는 플랫폼이나 내부 구현 버전(예를 들어, java/kotlin 언어의 버전 업그레이드)마다 결과가 달라질 수 있다.\n\u0026quot; \u0026lsquo;시스템 해킹\u0026rsquo;을 시도해서 다운캐스팅을 할 때 문제가 됩니다. 실제로 코틀린 프로젝트를 진행할 때, 이는 허용해서는 안 되는 큰 문제입니다. \u0026ldquo;\nimmutable 객체로부터 mutable 객체가 필요한 경우 # immutable 객체에 write 작업이 필요한 경우,\n복제(copy)를 통해서 새로운 mutable 객체를 만들어 반환,사용한다. 새로운 객체를 만들어 반환,사용한다. 다른 종류의 변경 가능 지점 # 변경 가능한 컬렉션을 사용할 때 다음과 같은 조합으로 사용할 수 있다.\nval + mutable 컬렉션 var + immutable 컬렉션 var + mutable 컬렉션 사용/비교하지 않는다. (다른 종류의 변경 가능 지점) 예시 1. val + mutable 컬렉션 # val list = mutableListOf\u0026lt;Int\u0026gt;() list.add(1) println(list) // [1] list += 2 // list.plusAssign(2)로 변경된다. println(list) // [1, 2] (다른 종류의 변경 가능 지점) 예시 2. var + immutable 컬렉션 # var list = listOf\u0026lt;Int\u0026gt;() list = list + 1 println(list) // [1] list += 2 // list.plus(2)로 변경된다. println(list) // [1, 2] 기준 특징 val + mutable 컬렉션 변경 지점/코드가 컬렉션 구현 내부에 있다. 멀티스레드 처리가 이루어질 경우, 내부적으로 적절한 동기화가 되어 있는지 확실하게 알 수 없으므로 위험하다. var + immutable 컬렉션 변경 지점/코드가 우리 코드에 있다. 멀티스레드 처리 안정성이 더 좋다고 할 수 있다. (즉, 우리가 직접 제어하기 편하다.) 예시 1: (우리가 관리하는 코드라면) 값이 변경될 때 Delegates.observable를 사용해서 log를 추가하거나 이벤트를 발행하거나 등의 추가적인 행위를 쉽게 덧붙일 수 있다. 예시 2. setter 를 private 으로 만들 수 있다. \u0026ldquo;물론 잘못 만들면 일부 요소가 손실될 수 있다\u0026rdquo; 고 설명한다. \u0026rdquo; mutable 컬렉션에도 observable 하게 만들 수 있지만 추가적인 구현이 필요하다. 따라서 mutable 프로퍼티에 immutable 컬렉션을 사용하는 것이 더 쉽다. \u0026ldquo;\n(Q) 내부적으로 구현된 컬렉션이 어떤 타입인지 정확히 알고 있다면 구현된 컬렉션을 사용하는 것이 더 좋지 않을까?\n사용자가 개발한 코드에 오류가 발생하기 더 쉽지 않을까?\n변경 가능 지점 노출하지 말기 # (한 줄 요약) mutable 객체를 외부에 노출하는 것은 굉장히 위험하다.\nmutable 객체를 외부에 노출하고 싶다면 아래와 같이 처리할 수 있다.\n(1) 방어적 복제(copy) (2) immutable 반환 요약 # val, final 혼동하지 말 것 컬렉션 다운캐스팅 하지말 것 쓰기가 필요한 컬렉션을 프로퍼티로 가질 때 var + immutable 컬렉션 조합으로 사용하자. 최근에 관련해서 고민한 부분이 있었는데 도움이 됐다.\n"},{"id":2,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-02.-%EB%B3%80%EC%88%98%EC%9D%98-%EC%8A%A4%EC%BD%94%ED%94%84%EB%A5%BC-%EC%B5%9C%EC%86%8C%ED%95%98%ED%95%98%EB%9D%BC/","title":"아이템 02. 변수의 스코프를 최소하하라","section":"이펙티브 코틀린","content":" 변수의 스코프를 최소화하라 # 프로퍼티보다는 지역 변수를 사용하는 것이 좋다. 최대한 좁은 스코프를 갖게 변수를 사용한다. (예를 들어, 블록 내에서만 변수가 사용된다면 블록 내에서만 변수를 사용하는 것이 좋다.) 스코프를 좁게 만들어야 하는 가장 중요한 이유는 코드를 추적하고 관리하기 쉽기 때문이다.\n변수를 정의할 때 초기화되는 것이 가장 좋다. (코틀린의) if, when, try-catch, Elvis 표현식, 구조분해 선언 등을 활용하여 변수 정의-초기화를 최대한 함께 처리할 수 있다.\n캡처링 # 위의 예시 처럼 변수 선언 위치에 따라 결과가 달라지는 경우도 있다.\n가변성을 피하고 스코프를 좁게 만들면 이런 문제를 간단하게 피할 수 있다.\n\u0026quot; 람다에서 변수를 캡처한다는 것을 꼭 기억하세요. \u0026ldquo;\n캡처링 부분은 좀 더 찾아보자.\n"},{"id":3,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-03.-%EC%B5%9C%EB%8C%80%ED%95%9C-%ED%94%8C%EB%9E%AB%ED%8F%BC-%ED%83%80%EC%9E%85%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%98%EC%A7%80-%EB%A7%90%EB%9D%BC/","title":"아이템 03. 최대한 플랫폼 타입을 사용하지 말라","section":"이펙티브 코틀린","content":" 최대한 플랫폼 타입을 사용하지 말라 # 코틀린은 자바 등의 다른 프로그래밍 언어에서 넘어온 타입들을 특수하게 다룬다. 이 타입을 플랫폼 타입(platform type) 이라고 부른다.\n플랫폼 타입은 ! 기호를 붙여서 표기한다. 예를 들면, String! 과 같다.\n플랫폼 타입은 코틀린에서 non-nullable, nullable, platform type 변수로 받아 사용할 수 있다.\n// 자바 public User getUser() { ... } // 코틀린 val user = getUser() // User! val user = getUser() // User val user = getUser() // User? 단, nullable 문제를 잘 해결해야되겠다. 즉, nullable, non-nullable 을 가능한 표기하여 사용하는 것이 좋다.\n자바의 경우 다음과 같이 여러 어노테이션을 지원하고 있다.\n|지원처|어노테이션| |JSR-305|javax.annotation @Nullable, @CheckForNull, @Nonnull| |Lombok|@NonNull| |JetBrains|@Nullable, @NotNull| |JavaX|javax.annotation @Nullable, @CheckForNull, @Nonnull| |ReactiveX|io.reactivex.annotations @Nullable, @NonNull| |\u0026hellip;|\u0026hellip;|\n자바의 경우 어노테이션 @Nullable, @NotNull 등을 사용한다.\n대체적으로 JSR-305 의 @ParametersAreNonnullByDefault 어노테이션 등을 활용하면, 자바에서도 디폴트로 파라미터가 널이 아니라는 것을 보장할 수 있다.\n플랫폼 타입은 안전하지 않으므로 최대한 빨리 제거한다. # 위에서 본 코드를 다시 살펴보면 코틀린은 플랫폼 타입을 (변수에)유지한 채 계속해서 가져갈 수 있다. 이는 지양해야 한다.\n플랫폼 타입은 안전하지 않으므로 최대한 빨리 제거하는 것이 좋다.\n// 자바 public User getUser() { ... } // 코틀린 val user = getUser() // User! val user = getUser() // User val user = getUser() // User? 플랫폼 타입을 유지한다는 것은 NPE를 전파하는 행위일 것이다.\n요약 # 코틀린 단에서 플랫폼 타입은 빠르게 제거한다. 플랫폼 타입 사용 시 inferred 타입(추론된 타입)의 사용은 지양한다. (코틀린 처럼 언어 레벨에서 지원하지 않아도) nullable, non-nullable 을 구분하여/표기하여 사용하는 것은 지향한다. "},{"id":4,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-04.-inferred-%ED%83%80%EC%9E%85%EC%9C%BC%EB%A1%9C-%EB%A6%AC%ED%84%B4%ED%95%98%EC%A7%80-%EB%A7%90%EB%9D%BC/","title":"아이템 04. Inferred 타입으로 리턴하지 말라","section":"이펙티브 코틀린","content":" inferred 타입으로 리턴하지 말라 # 타입 추론은 코틀린의 대표적인 특징이다. 다만, 타입 추론을 사용할 때 몇 가지 위험한 부분들이 있다.\n(assign 구문에서) 타입 추론 시 슈퍼클래스 또는 인터페이스로 설정되지 않는다. # (assign 구문에서) 타입 추론 시 정확하게 오른쪽에 있는 피연산자에 맞게 설정된다.\n슈퍼클래스, 혹은 인터페이스로 설정되지 않는다.\nopen class Animal class Zebra: Animal() fun main() { var animal = Zebra() // animal 타입은 Zebra animal = Animal() // 오류 : Type mismatch } 타입을 명시하면 아래와 같다.\nopen class Animal class Zebra: Animal() fun main() { var animal: Animal = Zebra() // animal 타입은 Animal animal = Animal() // OK } 리턴 타입은 꼭 명시한다. (공개된 API에서 리턴 타입을 제거하지 말자.) # 다음의 예시를 살펴보자.\ninterface CarFactory { fun produce(): Car } val DEFAULT_CAR: Car = Fiat126P() // Fiat126P 가 디폴트라고 가정하자. 이후 시간이 지나 다음과 같이 코드를 수정했다.\n\u0026quot; DEFAULT_CAR는 Car 로 명시적으로 지정되어 있으므로 따로 필요 없다고 판단해서, 함수의 리턴 타입을 제거했다고 합시다. \u0026ldquo;\ninterface CarFactory { fun produce() = DEFAULT_CAR } 또 시간이 지나 다음과 같이 코드를 수정했다.\nval DEFAULT_CAR = Fiat126P() 이제 문제가 발생한다. CarFactory.produce()는 Fiat126P 만 생성할 수 있다.\n즉, fun produce() = DEFAULT_CAR 수정 시 리턴 타입이 제거된 것이 가장 큰 문제로 볼 수 있겠다.\n요약 # (public)공개된 API(인터페이스, 외부 API 등)에는 리턴 타입을 명시한다.\n"},{"id":5,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-05.-%EC%98%88%EC%99%B8%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%B4-%EC%BD%94%EB%93%9C%EC%97%90-%EC%A0%9C%ED%95%9C%EC%9D%84-%EA%B1%B8%EC%96%B4%EB%9D%BC/","title":"아이템 05. 예외를 활용해 코드에 제한을 걸어라","section":"이펙티브 코틀린","content":" 예외를 활용해 코드에 제한을 걸어라 # \u0026quot; 확실하게 어떤 기능으로(형태로) 동작해야 하는 코드가 있다면, 예외를 활용해 제한을 걸어주는 것이 좋습니다. \u0026ldquo;\n예외(제한)을 통해 가독성, 빠른 실패의 이점을 취할 수 있겠다.\n코틀린에서는 제한을 걸 때 아래 기능을 사용할 수 있다.\n기능 설명 require argument 를 대상으로 한다. argument에 제한을 건다. check 상태를 대상으로 한다. 상태를 확인(제한)할 때 사용할 수 있다. assert 말 그대로 assertion assert 블록은 테스트 모드에서만 작동한다. (?, 밑에 내용을 살펴보면 코틀린/JVM에서만 테스트 코드가 아닌 곳에서 사용할 수 있다고 한다.) ?: return, throw 와 함께 활용한다. require # fun hello(name: String) { require(name.isNotBlank()) { \u0026#34;$name은 빈 문자열이 될 수 없어요.\u0026#34; } } 보통 함수(메서드)의 맨 앞에 배치된다. (= 무의식중에 대부분이 이렇게 사용할 것이다.)\nrequire 는 조건을 만족하지 못할 때 IllegalArgumentException 을 발생시킨다.\n즉, argument를 위한 기능이라는 것을 알 수 있다.\ncheck # fun write(): T { check(isOpen) ... } check 는 조건을 만족하지 못할 때 IllegalStateException 을 발생시킨다.\n즉, state 를 위한 기능이라는 것을 알 수 있다.\ncheck 함수도 아래와 같이 argument 를 체크하기 위해 사용할 수도 있다.\nfun hello(name: String) { check(name.isNotBlank()) { \u0026#34;$name은 빈 문자열이 될 수 없어요.\u0026#34; } } 하지만 check 함수는 require 함수와 비슷하지만, 상태가 올바른지 확인할 때 사용해야한다. (require 도 마찬가지다.)\nassert 계열 함수 # @Test fun `테스트 코드`() { val stack = Stack(20) { it } val ret = stack.pop(10) assertEquals(10, ret.size) } fun pop(num: Int = 1): List\u0026lt;T\u0026gt; { // ... assert(ret.size == num) return ret } 위 코드는 코틀린/JVM에서만 활성화된다. (-ea JVAM 옵션을 활성화해야 확인할 수 있다.)\n/** * Throws an [AssertionError] calculated by [lazyMessage] if the [value] is false * and runtime assertions have been enabled on the JVM using the *-ea* JVM option. */ @kotlin.internal.InlineOnly public inline fun assert(value: Boolean, lazyMessage: () -\u0026gt; Any) { if (_Assertions.ENABLED) { if (!value) { val message = lazyMessage() throw AssertionError(message) } } } ?: # fun send(name: String?) { val receiverName = name ?: \u0026#34;알 수 없는 수신자\u0026#34; ... } ?: + return/throw 구문은 굉장히 많이 사용되는 관용적인 방법이다. 적극적으로 활용해보는 것을 권장한다.\n(추가적으로 권장하는 것) 함수의 앞부분에 넣어서 잘 보이게 만드는 것이 좋다.\n요약 # 기능 설명 require argument check state assert assertion ?: ?: + return/throw "},{"id":6,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-06.-%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%A0%95%EC%9D%98-%EC%98%A4%EB%A5%98%EB%B3%B4%EB%8B%A4%EB%8A%94-%ED%91%9C%EC%A4%80-%EC%98%A4%EB%A5%98%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%9D%BC/","title":"아이템 06. 사용자 정의 오류보다는 표준 오류를 사용하라","section":"이펙티브 코틀린","content":" 사용자 정의 오류보다는 표준 오류를 사용하라 # 가능하다면, 직접 오류를 정의(커스텀 Exception)하는 것보다는 최대한 표준 라이브러리의 오류를 사용하는 것이 좋다. 표준 라이브러리의 사용은 범용성↑ 을 의미한다. (많은 개발자가 이미 알고 있다.)\n잘 만들어진 규약을 재사용하는 것은 코드(API)를 더 쉽게 만드는 것이라고 볼 수 있다.\n일반적으로 사용되는 Exception # 일반적으로 많이 사용되는 Exception 몇 가지를 살펴본다.\nException 설명 IllegalArgumentException 생략 IllegalStateException 생략 IndexOutOfBoundsException 생략 ConcurrentModificationException 동시 수정(concurrent modification)을 금지했으나, 발생한 경우 UnsupportedOperationException 사용자가 사용하려는 메서드가 현재는 사용할 수 없는 상태(지원되지 않는 상태) 단, 기본적으로 사용할 수 없는 메서드는 코드(클래스)에 없는 것이 좋다. (사용할 수 없다면 미래에 작성해야 하겠다. 단, 추상 메서드등을 작성해야 할 때, 의도적으로 클라이언트에게 메시지를 전달할 때와 같이 불가피한 경우도 있겠다.) NoSuchElementException 사용자가 사용하려는 요소가 존재하지 않는 상태 예를 들어, 내부에 요소가 없는 Iterable 에 next()를 호출했을 때 "},{"id":7,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-07.-%EA%B2%B0%EA%B3%BC-%EB%B6%80%EC%A1%B1%EC%9D%B4-%EB%B0%9C%EC%83%9D%ED%95%A0-%EA%B2%BD%EC%9A%B0-null%EA%B3%BC-Failure%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%9D%BC/","title":"아이템 07. 결과 부족이 발생할 경우 Null과 Failure를 사용하라","section":"이펙티브 코틀린","content":" 결과 부족이 발생할 경우 null과 Failure를 사용하라 # 함수가 원하는 결과를 만들어 낼 수 없는 경우가 있다. 이런 상황을 처리하는 메커니즘은 크게 두 가지가 있다.\nnull 또는 Failure를 나타내는 seald 클래스 예외 throw 위 두 가지는 중요한 차이점이 있다.\nException (예외) # 예외는 정보를 전달하는 방법으로 사용해서는 안된다. 예외는 잘못된 특별한 상황을 나타내고 처리해야 한다.\nimmutable 컬렉션의 경우 명시적으로 Exception 을 사용하지 않던가\u0026hellip;🤔 어떻게 보느냐가 중요할 것 같다. 메시지 전달을 포함하여 잘못된 상황을 처리하는 것이기도 하니까.\n예외는 예외적인 상황(예상하지 못한 상황)이 발생했을 때 사용하는 것이 좋다.\n이유는 다음과 같다.\n많은 개발자가 전파된 예외를 제대로 처리하지 않는다. (추적하지 못한다.) 코틀린의 모든 예외는 unchecked 예외이다. (중요) 따라서, 사용자가 예외를 제대로 처리하지 않을 수도 있으며, 이런 내용들이 문서에 제대로 드러나지 않기도 한다. 예외는 예외적인 상황을 위해 만들어졌다. 명시적인 테스트만큼 빠르게 동작하지 않는다. (= 빠른 실패를 말하는건가? 🤔 ) try-catch 블록 내부에 코드를 배치하면, 컴파일러가 할 수 있는 최적화가 제한된다. (중요) null, Failure(= seald 클래스) # 반면, null, Failure 는 예상되는 오류를 표현할 때 굉장히 좋다. 명시적이고, 효율적이며, 간단한 방법으로 처리할 수 있다. 이렇게 처리되는 오류는 다루기 쉽고, 놓치기 어렵다.\nnull 값과 sealed 클래스의 차이점은 다음과 같이 정리할 수 있다.\n추가적인 정보를 전달해야 한다면 sealed 클래스를 사용하고, 그렇지 않다면 null을 사용한다.\n결론 # 충분히 예측할 수 있는 범위의 오류는 null과 Failure를 사용하고,\n예측하기 어려운 예외적인 범위의 오류는 예외를 throw해서 처리하는 것이 좋다.\n요약 # :star: 코틀린은 모두 unchecked 예외다. (제대로 처리되지 않고 전파되기 쉽다.)\nException null, Failure 놓치기 쉽다. 놓치기 어렵다. 애플리케이션을 중지시킬 수 있다. 애플리케이션을 중지시키지 않는다. 예상하지 못한 경우다. (= 예외적인 경우다.) 예상할 수 있는 경우다. "},{"id":8,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-08.-%EC%A0%81%EC%A0%88%ED%95%98%EA%B2%8C-null%EC%9D%84-%EC%B2%98%EB%A6%AC%ED%95%98%EB%9D%BC/","title":"아이템 08. 적절하게 Null을 처리하라","section":"이펙티브 코틀린","content":" 적절하게 null을 처리하라 # null은 \u0026lsquo;값이 부족하다(lack of value)\u0026lsquo;를 의미한다. 프로퍼티가 null이 라는 것은 값이 제대로 설정되지 않았다거나, 제거됐다는 것을 의미한다.\nnullable 은 최대한 명확하게 처리해야한다. (String.toIntOrNull(), Iterable\u0026lt;T\u0026gt;.firstOrNull(() -\u0026gt; Boolean))\n기본적으로 nullable 타입은 3 가지 방법으로 처리한다.\n?., ?:, 스마트 캐스팅 등을 활용해서 처리한다. 오류를 throw 한다. (함수, 프로퍼티 리팩터링하여) non-nullable로 변경한다. null 안전하게 처리 # safe call (?., ?:), 스마트 캐스팅을 활용해서 null 을 안전하게 처리할 수 있다.\n오류 throw # throw, !!, requireNotNull, checkNotNull 등을 활용해서 명시적으로 non-null 을 표기하고, 예외를 발생시킬 수 있다.\n!! 은 사용하기 쉽지만, 좋은 해결 방법은 아니다. !!은 예외가 발생할 때 어떤 설명도 없는 제네릭 예외(generic exception)이 발생한다. (명시적 오류가 generic exception보다 더 많은 정보를 제공한다.)\n!!은 null이 나오지 않는다는 것이 거의 확실한 상황에서 많이 사용된다. (!!을 남용하지 말자.)\n\u0026quot; 코틀린을 대상으로 설계된 API를 활용한다면, !!연산자를 사용하는 것을 이상하게 생각해야 합니다. 일반적으로 !! 연산자 사용을 피해야 합니다. 이러한 제안은 코틀린 커뮤니티 전체에서 널리 승인되고 있는 제안입니다. \u0026ldquo;\nnon-nullable # nullability는 어떻게든 처리해야 하므로 비용이 발생한다. 필요한 경우가 아니라면 nullability 자체를 피하는 것이 좋다.\nnullability 에 따라 (구분되는)함수를 만들어 사용/제공할 수 있다. 어떤 값이 클래스 생성 이후에 확실하게 설정된다는 보장이 있다면, lateinit, Delegates.notNull 를 사용한다. 빈 컬렉션 대신 null 을 리턴하지 않는다. nullable enum 과 None enum 은 완전히 다르다. (= nullable enum 보다 None enum 사용을 권장) lateinit 프로퍼티 # lateinit 한정자는 프로퍼티가 이후에 설정될 것임을 명시하는 한정자다. lateinit은 프로퍼티를 처음 사용하기 전에 반드시 초기화될 것이라고 예상되는 상황에서 활용한다.\nclass UserControllerTest { private lateinit var dao: UserDao @BeforeEach fun init() { dao = mockk() ... } } 물론 lateinit 사용도 비용이 발생한다. 초기화 전에 해당 변수를 사용하면 예외가 발생한다. 무서워할 수 있지만, 어떻게 보면 이것은 \u0026lsquo;빠른 실패\u0026rsquo;로 오히려 좋은 것이다.\nDelegates.notNull # lateinit을 사용할 수 없는 경우도 있다. JVM에서 Int, Long, Double, Boolean과 같은 기본 타입과 연결된 타입은 사용할 수 없다. 이런 경우 lateinit 보다 약간 느리지만, Delegates.notNull 을 사용한다.\n:star: 새롭게 알게 된 내용 : JVM에서 Int, Long, Double, Boolean과 같은 기본 타입과 연결된 타입은 사용할 수 없다.\nclass DoctorActivity: Activity() { private var doctorId: Int by Delegates.notNull() private var fromNotification: Boolean by Delegates.notNull() override fun onCreate(savedInstanceState: Bundle?) { ... doctorId = ... fromNotification = ... } } 다음과 같이 프로퍼티 위임(property delegation)을 사용할 수도 있다.\nclass DoctorActivity: Activity() { private var doctorId: Int by arg(DOCTOR_ID_ARG) private var fromNotification: Boolean by arg(FROM_NOTIFICATION_ARG) } \u0026rdquo; 프로퍼티 위임을 사용하면, nullability로 발생하는 여러 가지 문제를 안전하게 처리할 수 있다. (아이템 21에서 자세하게 다룰 예정) \u0026ldquo;\n"},{"id":9,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-09.-use%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EC%97%AC-%EB%A6%AC%EC%86%8C%EC%8A%A4%EB%A5%BC-%EB%8B%AB%EC%95%84%EB%9D%BC/","title":"아이템 09. Use를 사용하여 리소스를 닫아라","section":"이펙티브 코틀린","content":" use를 사용하여 리소스를 닫아라 # java 의 try-with-resources 와 동일한 기능이겠다.\n코틀린에서는 java의 try-with-resources 와 같은 기능으로 use, useLines 등을 사용할 수 있다.\n모든 Closable 객체에 사용할 수 있다.\nfun countCharactersInFile(path: String): Int { val reader = BufferedReader(FileReader(path)) reader.use { return reader.lineSequence().sumBy { it.length } } } fun countCharactersInFile(path: String): Int { BufferedReader(FileReader(path)).use { return reader.lineSequence().sumBy { it.length } } } fun countCharactersInFile(path: String): Int { File(path).useLines { lines -\u0026gt; return lines.sumBy { it. length } } } useLines(파일을 한 줄씩 처리)의 경우 메모리에 파일의 내용을 한 줄씩만 유지하므로, 대용량 파일도 적절하게 처리할 수 있다. 다만 파일의 줄을 한 번만 사용할 수 있다는 단점이 있다.\n요약 # use를 사용하여 Closeable/AutoCloseable 을 구현한 모든 객체를 쉽고 안전하게 처리할 수 있다. 파일을 처리할 때 파일을 한 줄씩 읽어 들이는 useLines를 사용하는 것이 좋다. "},{"id":10,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-10.-%EB%8B%A8%EC%9C%84-%ED%85%8C%EC%8A%A4%ED%8A%B8%EB%A5%BC-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%9D%BC/","title":"아이템 10. 단위 테스트를 만들어라","section":"이펙티브 코틀린","content":" 단위 테스트를 만들어라 # 이 아이템의 내용은 생략\n"},{"id":11,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-11.-%EA%B0%80%EB%8F%85%EC%84%B1%EC%9D%84-%EB%AA%A9%ED%91%9C%EB%A1%9C-%EC%84%A4%EA%B3%84%ED%95%98%EB%9D%BC/","title":"아이템 11. 가독성을 목표로 설계하라","section":"이펙티브 코틀린","content":" 코틀린은 간결성을 목표로 설계된 프로그래밍 언어가 아니라, 가독성을 좋게 하는 데 목표를 두고 설계된 프로그래밍 언어입니다.\n간결성과 가독성을 혼동하지 말자. (책에서 말하는)간결성은 \u0026lsquo;짧음\u0026rsquo;과 조금 더 관계가 있다. 가독성은 \u0026lsquo;읽기 좋음\u0026rsquo;과 관계가 있다.\n가독성을 목표로 설계하라 # 프로그래밍은 쓰기보다 읽기가 중요하다. (e.g. \u0026quot; 개발자가 코드를 작성하는 데는 1분 걸리지만, 이를 읽는 데는 10분이 걸린다. \u0026ldquo;)\n인식 부하 감소 # 사용 빈도가 적은 관용구는 코드를 복잡하게 만든다. 이런 관용구들을 한 문장 내부에 조합해서 사용하면 복잡성은 훨씬 빠르게 증가한다.\n// A if(person != null \u0026amp;\u0026amp; person.isAdult) { view.showPerson(person) } else { view.showError() } // B person?.takeIf { it.isAdult } ?.let(view::showPerson) ?: view.showError() 기본적으로 \u0026lsquo;인지 부하\u0026rsquo;를 줄이는 방향으로 코드를 작성하자.\n뇌는 짧은 코드를 빠르게 읽을 수 있지만, 익숙한 코드는 더 빠르게 읽을 수 있다. 👍\n극단적이 되지 않기 # students.filter { it.result \u0026gt;= 50 } .joinToString(separator = \u0026#34;\\n\u0026#34;) { \u0026#34;${it.name} ${it.surname}, ${it.result}\u0026#34; } .let(::print) var obj = FileInputStream(\u0026#34;/file.gz\u0026#34;) .let(::BufferedInputStream) .let(::ZipInputStream) .let(::ObjectInputStream) .readObject() as SomeObject 위 코드는 디버그하기 어렵고, 경험이 적은 코틀린 개발자는 이해하기 어렵다. 따라서 비용이 발생한다.\n하지만 이 비용은 지불할만한 가치가 있으므로 사용해도 괜찮다.\n문제가 되는 경우는 지불할 만한 가치가 없는 코드에 비용을 지불하는 경우(= 정당한 이유 없이 복잡성을 추가할 때)이다.\n"},{"id":12,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-12.-%EC%97%B0%EC%82%B0%EC%9E%90-%EC%98%A4%EB%B2%84%EB%A1%9C%EB%93%9C%EB%A5%BC-%ED%95%A0-%EB%95%8C%EB%8A%94-%EC%9D%98%EB%AF%B8%EC%97%90-%EB%A7%9E%EA%B2%8C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%9D%BC/","title":"아이템 12. 연산자 오버로드를 할 때는 의미에 맞게 사용하라","section":"이펙티브 코틀린","content":" 연산자 오버로드를 할 때는 의미에 맞게 사용하라 # 연산자 오버로딩은 그 이름의 의미에 맞게 사용하자. 적절하게 사용하지 못할 것 같다면, 오버로딩을 하지 않는 것이 좋다. (이때는 일반 함수를 쓰자)\n연산자 같은 형태로 사용하고 싶다면 infix 확장 함수, Top-Level 함수를 활용할 수 있다.\n"},{"id":13,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-13.-Unit%EC%9D%84-%EB%A6%AC%ED%84%B4%ED%95%98%EC%A7%80-%EB%A7%90%EB%9D%BC/","title":"아이템 13. Unit?을 리턴하지 말라","section":"이펙티브 코틀린","content":" Unit? 을 리턴하지 말라 # fun keyIsCorrect(key: String): Boolean = //... if(!keyIsCorrect(key)) { // 로직 } fun keyIsCorrect(key: String): Unit? = //... keyIsCorrect(key) ?: // 로직 위 코드를 보면, Unit? 의 경우에도 ?:, ?.let 등을 활용해 Boolean 처럼 쓸 수 있다.\n하지만 이 형태는 좋지 않다. 예측하기 어려운 오류를 만들어 낼 수 있다.\n예시\ngetData()?.let { view.showData(it) } ?: view.showError() 위 코드에서 getData 가 null 이 아니고, showData(it)가 null 인 상황이면 showData, showError 가 모두 호출된다. (= 예측하기 어려운 코드다.)\n\u0026quot; Unit?을 쉽게 읽을 수 있는 경우는 거의 보지 못했다. \u0026ldquo;\n요약 # Unit? 사용보다 Boolean 사용하는 형태로 변경하는 것이 좋다. Unit? 을 리턴하거나, 이를 기반으로 연산하지 않는 것이 좋다. "},{"id":14,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-14.-%EB%B3%80%EC%88%98-%ED%83%80%EC%9E%85%EC%9D%B4-%EB%AA%85%ED%99%95%ED%95%98%EC%A7%80-%EC%95%8A%EC%9D%80-%EA%B2%BD%EC%9A%B0-%ED%99%95%EC%8B%A4%ED%95%98%EA%B2%8C-%EC%A7%80%EC%A0%95%ED%95%98%EB%9D%BC/","title":"아이템 14. 변수 타입이 명확하지 않은 경우 확실하게 지정하라","section":"이펙티브 코틀린","content":" 변수 타입이 명확하지 않은 경우 확실하게 지정하라 # 코틀린의 타입 추론 시스템은 매우 편리하다.\n하지만 타입을 명확하게 보여주지 않는 것은 좋지 않다.\n// data 의 타입이 무엇인지 바로 알 수 없다. val data = getSomeData() // 다음과 같이 표현하는 것이 좋다. val data: UserData = getSomeData() 가독성을 위해 코드를 작성/설계할 때는 읽는 사람에게 중요한 정보를 숨겨선 안된다. 가독성 향상 이외에 안전을 위해서라도 타입을 지정하는 것이 좋다.\n함수 정의를 보면 되지 않나? = 비용이다. 코드 정의로 쉽게 이동할 수 없는 웹(깃헙, 깃랩 등)환경에서 코드를 읽을 수도 있다. 이런 경우 읽기 더 힘들어 질 것이다.\n타입을 무조건 지정하라는 것이 아니다. 상황에 맞게 사용하자.\n"},{"id":15,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-15.-%EB%A6%AC%EC%8B%9C%EB%B2%84%EB%A5%BC-%EB%AA%85%EC%8B%9C%EC%A0%81%EC%9C%BC%EB%A1%9C-%EC%B0%B8%EC%A1%B0%ED%95%98%EB%9D%BC/","title":"아이템 15. 리시버를 명시적으로 참조하라","section":"이펙티브 코틀린","content":" 리시버를 명시적으로 참조하라 # 여러 개의 리시버 # 스코프 내부에 둘 이상의 리시버가 있는 경우, 리시버를 명시적으로 나타내면 좋다. 즉 리시버가 헷갈릴 수 있는 경우, 명시적으로 표현하자.\n또, 리시버가 중첩되는 경우 목적에 맞는 함수를 잘 구분해서 쓰자. (e.g. let, apply, also, with, run)\nclass Node(val name: String) { fun makeChild(childName: String) { create(\u0026#34;$name.$childName\u0026#34;).apply { print(\u0026#34;Created ${this?.name} in ${this@Node.name}\u0026#34;) // this@Node와 같이 label 을 활용할 수 있다. } } } label 없이 리시버 사용하면, 가장 가까운 리시버를 의미한다.\nDSL 마커 # \u0026quot; 코틀린 DSL을 사용할 때는 여러 리시버를 가진 요소들이 중첩되더라도, 리시버를 명시적으로 붙이지 않습니다. DSL은 원래 그렇게 사용하도록 설계되었기 때문입니다. \u0026ldquo;\n@DslMarker\n:thinking:\n요약 # 짧게 적을 수 있다는 이유만으로 리시버(표현)을 제거하지 말자. 헷갈릴 수 있는 경우 명시적으로 표현하자. "},{"id":16,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-16.-%ED%94%84%EB%A1%9C%ED%8D%BC%ED%8B%B0%EB%8A%94-%EB%8F%99%EC%9E%91%EC%9D%B4-%EC%95%84%EB%8B%88%EB%9D%BC-%EC%83%81%ED%83%9C%EB%A5%BC-%EB%82%98%ED%83%80%EB%82%B4%EC%95%BC-%ED%95%9C%EB%8B%A4/","title":"아이템 16. 프로퍼티는 동작이 아니라 상태를 나타내야 한다","section":"이펙티브 코틀린","content":" 프로퍼티는 동작이 아니라 상태를 나타내야 한다. # 코틀린의 프로퍼티는 자바의 필드랑 비슷해 보이지만, 서로 완전히 다른 개념이다.\n둘 다 데이터를 저장한다는 점은 같다. 하지만 프로퍼티에는 더 많은 기능이 있다.\n프로퍼티 # 사용자 정의 getter/setter 가질 수 있다. val 프로퍼티에는 백킹 필드가 만들어지지 않는다. 필드가 필요 없다. 프로퍼티는 개념적으로 \u0026lsquo;접근자\u0026rsquo;를 나타낸다. 따라서 코틀린에서는 인터페이스에서도 프로퍼티를 정의할 수 있다. (아래 \u0026lsquo;예시 1\u0026rsquo; 참고) 위임(property delegate)할 수 있다. 프로퍼티는 본질적으로 함수이다. 확장 프로퍼티를 만들 수 있다. 프로퍼티를 함수 대신 사용할 수도 있지만, 그렇다고 완전히 대체해서 사용하는 것은 좋지 않다. (아래 \u0026lsquo;예시 2\u0026rsquo; 참고) // 예시 1. 인터페이스에서도 프로퍼티를 정의할 수 있다. interface Person { val name: String // getName() (getter) } // 예시 2. 함수를 완전히 대체하는 것은 좋지 않다. // 이유 : 관습적으로 게터에 알고리즘, (무거운)계산 등의 로직이 들어갈 것이라고 생각하지 않는다. val Tree\u0026lt;Int\u0026gt;.sum: Int get() = when(this) { is Leaf -\u0026gt; value is Node -\u0026gt; left.sum + right.sum } 원칙적으로 프로퍼티는 상태(state)를 표현하거나 설정하기 위한 목적으로만 사용하는 것이 좋다. 다른 로직 등을 포함하지 않는 것이 좋다.\nㄴ 이런 관점에서는 \u0026lsquo;필드\u0026rsquo;처럼 사용되는 것 같다.\n\u0026quot; 많은 사람은 경험적으로 프로퍼티는 상태 집합을 나타내고, 함수는 행동을 나타낸다고 생각한다. \u0026ldquo;\n이전 장에서 본 인식 부하 감소(인지 부하 감소) 내용을 기억해보면, 충분히 이해된다.\n"},{"id":17,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-17.-%EC%9D%B4%EB%A6%84-%EC%9E%88%EB%8A%94-%EC%95%84%EA%B7%9C%EB%A8%BC%ED%8A%B8%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%9D%BC/","title":"아이템 17. 이름 있는 아규먼트를 사용하라","section":"이펙티브 코틀린","content":" 이름 있는 아규먼트를 사용하라 # 장점은 다음과 같다.\n이름을 기반으로 값이 무엇을 나타내는지 알 수 있다. 파라미터 입력 순서와 상관 없으므로 안전하다. 함수 타입 파라미터 # 함수 타입 파라미터는 마지막 위치에 배치하는 것이 좋다.\n:thinking: (책에서 이렇게 말한)이유가 무엇인지?\n참고로, 코틀린에서는 마지막에 위치한 함수 타입의 경우 람다를 이용할 수 있다.\n"},{"id":18,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-18.-%EC%BD%94%EB%94%A9-%EC%BB%A8%EB%B2%A4%EC%85%98%EC%9D%84-%EC%A7%80%EC%BC%9C%EB%9D%BC/","title":"아이템 18. 코딩 컨벤션을 지켜라","section":"이펙티브 코틀린","content":" 코딩 컨벤션을 지켜라 # 코드는 마치 한 사람이 작성한 것 처럼 작성돼야 한다.\n코딩 컨벤션을 지켜야 하는 이유는 다음과 같다.\n이해하기 쉽다. (인지 부하 감소) 코드 병합, 리팩터링이 쉬워진다. IntelliJ 의 경우 Code Style - Kotlin - Predefined style/Kotlin style guide 를 이용할 수 있다. (= 공식 코딩 컨벤션 스타일)\n"},{"id":19,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-19.-knowledge%EB%A5%BC-%EB%B0%98%EB%B3%B5%ED%95%98%EC%97%AC-%EC%82%AC%EC%9A%A9%ED%95%98%EC%A7%80-%EB%A7%90%EB%9D%BC/","title":"아이템 19. Knowledge를 반복하여 사용하지 말라","section":"이펙티브 코틀린","content":" knowledge를 반복하여 사용하지 말라 # \u0026quot; 프로젝트에서 이미 있던 코드를 복사해서 붙여넣고 있다면, 무언가가 잘못된 것이다. \u0026quot;\n규모가 작은 것들(예를 들어, 함수, 단일 클래스 등)은 재사용할 수 있게 잘 추출해서 정리하고 있다. 다만, 최근에 규모가 큰 것(패키지 단위)에 대해서 복붙한 경험이 있다. 공통 모듈로 분리할 수 있었지만 깊이 있게 고민하지 않고 넘어갔다. :thinking:\nDRY, WET 안티패턴(We Enjoy Typing, Waste Everyone\u0026rsquo;s Time or Write Everthing Twice), SSOT(Single Source of Truth)\nWET 패턴, 흥미롭다.\n언제 코드를 반복해도 될까? # 어떤 프로젝트에서 독립적인 2개의 애플리케이션을 만들고 있다고 가정해보자. 빌드 설정이 비슷할 것이므로, 이를 추출해서 공통으로 작성할 수도 있겠다.\n하지만 두 애플리케이션은 독립적이므로 각각 필요한 변경 사항이 필요할 수 있다. (e.g., 한 애플리케이션의 구성만 변경해야 할 때)\n이처럼 신중하지 못한 추출은 변경을 더 어렵게 만들어 버린다.\n두 코드가 같은 knowledge 를 나타내는지, 다른 knowledge 를 나타내는지는 \u0026ldquo;함께 변경될 가능성이 높은가? 따로 변경될 가능성이 높은가?\u0026rdquo;(= 해당 코드의 라이프사이클이 같은가?) 를 고민해보면 좋겠다.\n서로 다른 곳(부서, 사용처)에서 사용하는 knowledge는 독립적으로 변경할 가능성이 많다. 따라서 비슷한 처리를 하더라도 완전히 다른 knowlede 로 취급하는 것이 좋다. (위 내용은 실제로 경험한 적이 있어서 공감된다.)\n다른 knowledge는 분리해두는 것이 좋다. 그렇지 않으면 (공통으로 사용해서는 안되는 코드를)공통으로 만들어 재사용하려는 유혹이 발생할 수 있다. (공감된다.)\n단일 책임 원칙 # \u0026quot; 클래스를 변경하는 이유는 단 한가지여야 한다. \u0026ldquo;\n:star: :star: :star: \u0026ldquo;단일 책임을 가져야 한다.\u0026rdquo; = \u0026ldquo;클래스를 변경하는 이유는 한가지여야 한다.\u0026rdquo;\n\u0026rdquo; 두 액터(actor, 변화를 만들어 내는 존재)가 같은 클래스를 변경하는 일은 없어야 한다. \u0026ldquo;\n"},{"id":20,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-20.-%EC%9D%BC%EB%B0%98%EC%A0%81%EC%9D%B8-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%84-%EB%B0%98%EB%B3%B5%ED%95%B4%EC%84%9C-%EA%B5%AC%ED%98%84%ED%95%98%EC%A7%80-%EB%A7%90%EB%9D%BC/","title":"아이템 20. 일반적인 알고리즘을 반복해서 구현하지 말라","section":"이펙티브 코틀린","content":" 일반적인 알고리즘을 반복해서 구현하지 말라 # 여기서 말하는 알고리즘은 특정 프로젝트에 국한된 것이 아니라 정말 일반적인(수학 연산과 같은)것들을 말한다.\n(깨알 TIP) 아래 코드는 권장되지 않는 코드다. 팩토리 메서드를 활용하거나 기본 생성자를 활용하는 것이 좋다.\nitem.sources.forEach { var sourceEntity = SourceEntity() sourceEntity.id = it.id sourceEntity.category = it.category ... } 널리 알려진, 일반적으로 모두 이해할 수 있는 것들은(수학 연산과 같은), 꼭 여러 번 재사용되지 않는다고 해도 공통으로 추출하는 것이 좋다. 예를 들면 아래와 같다.\n// 잘 알려진 수학적 개념이고, 대부분 예측할 수 있다. fun Iterable\u0026lt;Int\u0026gt;.product() = fold(1) { acc, i -\u0026gt; acc * i } 알고리즘을 추출할 때 다음과 같은 방법이 있다.\nTop-level 함수 프로퍼티 위임 클래스 확장 함수 함수는 상태(state)를 유지하지 않으므로, 행위를 나타내기 좋다. Top-level 함수와 비교해서, 확장 함수는 구체적인 타입이 있는 객체에만 사용을 제한할 수 있기에 좋다. 수정할 객체를 아규먼트로 받는 것(= 일반적인 함수)보다 확장 리시버(= 확장 함수?)로 사용하는 것이 가독성 측면에서 좋다. 확장 함수는 객체를 사용할 때 자동 완성 기능과 같은 제안이 이뤄지므로 쉽게 함수를 찾아, 사용할 수 있다. 프로퍼티 위임 예시는 한번 보면 좋겠다.\n\u0026quot; 특정 알고리즘을 반복해서 사용해야 하는 경우 프로젝트 내부에 직접 정의하기 바랍니다. 일반적으로 이런 알고리즘들은 확장 함수로 정의하는 것이 좋습니다. \u0026ldquo;\n(깨알 TIP) 공통 알고리즘 추출 시 확장 함수가 잘 쓰인다.\n"},{"id":21,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-21.-%EC%9D%BC%EB%B0%98%EC%A0%81%EC%9D%B8-%ED%94%84%EB%A1%9C%ED%8D%BC%ED%8B%B0-%ED%8C%A8%ED%84%B4%EC%9D%80-%ED%94%84%EB%A1%9C%ED%8D%BC%ED%8B%B0-%EC%9C%84%EC%9E%84%EC%9C%BC%EB%A1%9C-%EB%A7%8C%EB%93%A4%EC%96%B4%EB%9D%BC/","title":"아이템 21. 일반적인 프로퍼티 패턴은 프로퍼티 위임으로 만들어라","section":"이펙티브 코틀린","content":" 일반적인 프로퍼티 패턴은 프로퍼티 위임으로 만들어라 # 프로퍼티 위임을 사용하면 일반적인 프로퍼티 행위를 추출해서 재사용할 수 있다. 또, 프로퍼티 위임 메커니즘을 통해 다양한 패턴들을 만들 수 있다.\n프로퍼티 위임은 프로퍼티 패턴을 추출하는 일반적인 방법이라 많이 사용되고 있다.\nlazy, observable, 뷰, 리소스 바인딩, 의존성 주입, 데이터 바인딩 등의 사용 예시가 있겠다.\n// 예시 : lazy val value by lazy { createValue() } // 예시 : observable var items: List\u0026lt;Item\u0026gt; by Delegates.observable(listof()) { _, _, _ -\u0026gt; notifyDataSetChanged() } // 예시 : 뷰, 리소스 바인딩 (안드로이드) private val button: Button by bindView(R.id.button) private val textSize by bindDimension(R.dimen.font_size) private val doctor: Doctor by argExtra(DOCTOR_ARG) // 예시 : 의존성 주입 (Koin) private val presenter: MainPresenter by inject() private val repository: NetworkRepository by inject() private val vm: MainViewModel by viewModel() // 예시 : 데이터 바인딩 private val port by bindConfiguration(\u0026#34;port\u0026#34;) private val token: String by preferences.bind(TOKEN_KEY) 커스텀 프로퍼티 위임 만들어보기 # 프로퍼티 위임은 다른 객체의 메서드를 활용해서 프로퍼티의 접근자(getter/setter)를 만드는 방식이다.\n게터, 세터 사용 시 로그를 출력하는 예시가 있다고 가정해보자.\nvar token: String? = null get() { print(\u0026#34;token returned value $field\u0026#34;) return field } set(value) { print(\u0026#34;token changed from $field to $value\u0026#34;) field = value } var attempts: Int = 0 get() { print(\u0026#34;attempts returned value $field\u0026#34;) return field } set(value) { print(\u0026#34;attempts changed from $field to $value\u0026#34;) field = value } 위 코드를 프로퍼티 위임을 통해 개선해보자. (확장 함수로 만들 수도 있다.)\nvar token: String? by LoggingProperty(null) var attempts: Int by LoggingProperty(0) // 위에서 말한 *다른 객체의 메서드를 사용한다* 는 부분을 기억하자. // 확장 함수로 만들어도 된다. private class LoggingProperty\u0026lt;T\u0026gt;(var value: T) { operator fun getValue( thisRef: Any?, prop: KProperty\u0026lt;*\u0026gt; ): T { print(\u0026#34;${prop.name} returned value $value\u0026#34;) return value } operator fun setValue( thisRef: Any?, prop: KProperty\u0026lt;*\u0026gt;, newValue: T ) { val name = prop.name print(\u0026#34;$name changed from $value to $newValue\u0026#34;) value = newValue } } private class LoggingProperty\u0026lt;T\u0026gt;(var value: T) { operator fun getValue( thisRef: ) } getValue, setValue 메서드가 여러 개 있어도 무방하다. (오버로딩 형태로 생각해면 될까 싶다.)\n위의 코드 중 by가 어떻게 컴파일되는지 살펴보자.\n// var token: String? by LoggingProperty(null) // var attempts: Int by LoggingProperty(0) @JvmField private val \u0026#39;token$delegate\u0026#39; = LoggingProperty\u0026lt;String?\u0026gt;(null) var token: String? get() = \u0026#39;token$delegate\u0026#39;.getValue(thisRef = this, prop = ::token) set(value) { \u0026#39;token$delegate\u0026#39;.setValue( thisRef = this, prop = ::token, newValue = value ) } val 의 경우, getValue 가 필요하다. var 의 경우, getValue, setValue 가 필요하다. 그 외 예시 # val map: Map\u0026lt;String, Any\u0026gt; = mapOf( \u0026#34;name\u0026#34; to \u0026#34;Marcin\u0026#34;, \u0026#34;programmer\u0026#34; to true ) val name by map print(name) // Marcin 위 코드는 코틀린 stdlib 에 확장 함수가 정의되어 있기에 사용할 수 있는 코드다.\ninline operator fun \u0026lt;V, V1 : V\u0026gt; Map\u0026lt;in String, V\u0026gt;.getValue(thisRef: Any?, property: KProperty\u0026lt;*\u0026gt;): V1 = getOrImplicitDefault(property.name) as V1 코틀린 stdlib의 다음과 같은 프로퍼티 위임을 알아 두면 좋다.\nlazy Delegates.observable Delegates.vetoable Delegates.notNull 굉장히 범용적으로 사용되는 델리게이터들이다.\n참고 : https://kotlinlang.org/api/latest/jvm/stdlib/kotlin.properties/-delegates/\n참고 : notNull # var max: Int by Delegates.notNull() // println(max) // will fail with IllegalStateException max = 10 println(max) // 10 참고 : observable # var observed = false var max: Int by Delegates.observable(0) { property, oldValue, newValue -\u0026gt; observed = true } println(max) // 0 println(\u0026#34;observed is ${observed}\u0026#34;) // false max = 10 println(max) // 10 println(\u0026#34;observed is ${observed}\u0026#34;) // true 참고 : vetoable # 값 변경 시 특정 조건에 따라 변경을 취소할 수 있다.\ninline fun \u0026lt;T\u0026gt; vetoable( initialValue: T, crossinline onChange: (property: KProperty\u0026lt;*\u0026gt;, oldValue: T, newValue: T) -\u0026gt; Boolean ): ReadWriteProperty\u0026lt;Any?, T\u0026gt; (source) var max: Int by Delegates.vetoable(0) { property, oldValue, newValue -\u0026gt; newValue \u0026gt; oldValue } println(max) // 0 max = 10 println(max) // 10 max = 5 println(max) // 10 "},{"id":22,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-22.-%EC%9D%BC%EB%B0%98%EC%A0%81%EC%9D%B8-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98%EC%9D%84-%EA%B5%AC%ED%98%84%ED%95%A0-%EB%95%8C-%EC%A0%9C%EB%84%A4%EB%A6%AD%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%98%EB%9D%BC/","title":"아이템 22. 일반적인 알고리즘을 구현할 때 제네릭을 사용하라","section":"이펙티브 코틀린","content":" 일반적인 알고리즘을 구현할 때 제네릭을 사용하라 # 타입 아규먼트를 사용하면 함수에 타입을 전달할 수 있다. 타입 아규먼트를 사용하는 함수를 제네릭 함수라고 부른다.\n\u0026quot; 제네릭은 List 또는 Set 처럼 구체적인 타입으로 컬렉션을 만들 수 있게 클래스와 인터페이스에 도입된 기능입니다. \u0026ldquo;\n제네릭 제한 # 구체적인 타입의 서브타입만 허용하도록 제한할 수도 있다.\n// 콜론 뒤에 상위 타입 명시 `T: Comparable\u0026lt;T\u0026gt;` fun \u0026lt;T : Comparable\u0026lt;T\u0026gt;\u0026gt; Iterable\u0026lt;T\u0026gt;.sorted(): List\u0026lt;T\u0026gt; { ... 많이 사용하는 제한 타입으로 Any 가 있다. 이는 nullable 이 아닌 타입을 명시할 때 사용한다.\n의미가 있나 싶었는데, nullable 을 체크하는 목적으로 사용한다고 한다. :thumbsup:\ninline fun \u0026lt;T, R : Any\u0026gt; Iterable\u0026lt;T\u0026gt;.mapNotNull( transform: (T) -\u0026gt; R? ): List\u0026lt;R\u0026gt; { ... } 드물지만 둘 이상의 제한을 걸 수도 있다.\nfun \u0026lt;T: Animal\u0026gt; pet(animal: T) where T: GoodTempered { ... } // 또는 fun \u0026lt;T\u0026gt; pet(animal: T) where T: Animal, T: GoodTempered { ... } where-clause # where-clause 관련해서는 아래 문서를 참고해보자.\n참고 : Generic constraints\n요약 # 제네릭을 이용해서 type-safe 코드를 작성하자.\n"},{"id":23,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-23.-%ED%83%80%EC%9E%85-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%EC%9D%98-%EC%84%80%EB%8F%84%EC%9E%89%EC%9D%84-%ED%94%BC%ED%95%98%EB%9D%BC/","title":"아이템 23. 타입 파라미터의 섀도잉을 피하라","section":"이펙티브 코틀린","content":" 타입 파라미터의 섀도잉을 피하라 # interface Tree class Birch: Tree class Spruce: Tree class Forest\u0026lt;T: Tree\u0026gt; { fun \u0026lt;T: Tree\u0026gt; addTree(tree: T) { // ... } } Forest와 addTree의 타입 파라미터는 독립적이다. (관계가 없다.)\nval forest = Forest\u0026lt;Birch\u0026gt;() forest.addTree(Birch()) forest.addTree(Spruce()) (아마도 대부분의 경우) 위 코드는 개발자가 의도한 것이 아닐 것이다. 따라서 오류가 발생한다는 것을 알아차리기 쉽지 않다.\n[수정 1] 다음과 같이 작성하는 것이 올바를 것이다.\nclass Forest\u0026lt;T: Tree\u0026gt; { fun addTree(tree: T) { // 클래스의 타입 파라미터를 사용하도록 수정한다. // ... } } val forest = Forest\u0026lt;Birch\u0026gt;() forest.addTree(Birch()) forest.addTree(Spruce()) // ERROR [수정 2] 만약 독립적인 타입 파라미터를 의도한 것이라면 \u0026lsquo;이름\u0026rsquo;을 다르게 짓는 것이 좋았을 것이다.\nclass Forest\u0026lt;T: Tree\u0026gt; { fun \u0026lt;ST: T\u0026gt; addTree(tree: ST) { } } 요약 # 타입 파라미터의 섀도잉을 피하자.\n"},{"id":24,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-24.-%EC%A0%9C%EB%84%A4%EB%A6%AD-%ED%83%80%EC%9E%85%EA%B3%BC-variance-%ED%95%9C%EC%A0%95%EC%9E%90%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%98%EB%9D%BC/","title":"아이템 24. 제네릭 타입과 Variance 한정자를 활용하라","section":"이펙티브 코틀린","content":" 제네릭 타입과 variance 한정자를 활용하라 # class Cup\u0026lt;T\u0026gt; 위 코드에서 (타입 파라미터)T는 variacne 한정자(out 또는 in)가 없으므로, invariant(불공변성)이다.\ninvariant 는 제네릭 타입으로 만들어지는 타입들이 서로 아무 관계가 없다는 것을 의미한다. (e.g., Cup\u0026lt;Coffee\u0026gt;, Cup\u0026lt;Int\u0026gt;, Cup\u0026lt;Any\u0026gt;, Cup\u0026lt;Nothing\u0026gt;)\n만약 제네릭 타입으로 만들어지는 타입에 관련성을 원한다면, variance 한정자(out 또는 in)를 사용한다.\nvariance 설명 out covariance (공변성) in contravariant(반변성) out (covariance) # class Cup\u0026lt;out T\u0026gt; open class Dog class Puppy: Dog() fun main(args: Array\u0026lt;String\u0026gt;) { val a: Cup\u0026lt;Dog\u0026gt; = Cup\u0026lt;Puppy\u0026gt;() // OK val b: Cup\u0026lt;Puppy\u0026gt; = Cup\u0026lt;Dog\u0026gt;() // ERROR } in (contravariant) # class Cup\u0026lt;in T\u0026gt; open class Dog class Puppy: Dog() fun main(args: Array\u0026lt;String\u0026gt;) { val a: Cup\u0026lt;Dog\u0026gt; = Cup\u0026lt;Puppy\u0026gt;() // ERROR val b: Cup\u0026lt;Puppy\u0026gt; = Cup\u0026lt;Dog\u0026gt;() // OK } variant, invariant 정리 # 함수 타입 # 함수타입은 파라미터 타입과 리턴 타입에 따라 서로 어떤 관계를 갖는다.\n예를 들어, 다음 (Int) -\u0026gt; Any 와 같은 함수 타입이 있다고 가정하자.\nfun printProcessedNumber(transition: (Int) -\u0026gt; Any) { print(transition(42)) } (Int) -\u0026gt; Any 타입의 함수는 아래 형태로도 동작한다.\n(Int) -\u0026gt; Number (Number) -\u0026gt; Any (Number) -\u0026gt; Number (Number) -\u0026gt; Int 코틀린 함수 타입의 모든 파라미터 타입(위 예시에서 Int)은 contravariant 이다.\n코틀린 함수 타입의 모든 리턴 타입(위 예시에서 Any)은 covariant 이다.\nfun main(args: Array\u0026lt;String\u0026gt;) { val numberToInt: (Number) -\u0026gt; Int = { it.toInt() } val numberHash: (Any) -\u0026gt; Number = { it.hashCode() } val intToInt: (Int) -\u0026gt; Int = { it } printProcessedNumber(numberToInt) // OK printProcessedNumber(numberHash) // OK printProcessedNumber(intToInt) // ERROR } fun printProcessedNumber(transition: (Number) -\u0026gt; Any) { println(transition(42)) } 함수 타입을 사용할 때는 위처럼 자동으로 variance 한정자가 사용된다. :star: :star:\n\u0026quot; 코틀린에서 자주 사용되는 것으로는 covariant(out 한정자)를 가진 List 가 있습니다. 이는 variance 한정자가 붙지 않은 MutableList와 다릅니다. 왜 MutableList보다 List를 더 많이 사용하는지, 그리고 어떤 부분이 다른 것인지는 variance 한정자의 안정성과 관련된 내용을 이해하면 알 수 있습니다. \u0026ldquo;\nvariance 한정자의 안정성 # 자바의 배열은 covariant(out) 이다.\n많은 출처에 따르면, 이렇게 만들어진 이유가 배열을 기반으로 제네릭 연산자는 정렬 함수 등을 만들기 위해서라고 한다.\n그런데 covariant 속성으로 인한 결함이 있다.\n아래 코드는 컴파일 중에는 아무 문제가 없지만, 런타임 시 오류가 발생한다.\nInteger[] numbers = {1, 4, 2, 1}; Object[] objects = numbers; objects[2] = \u0026#34;B\u0026#34; // ERROR 코틀린은 이 결함을 해결하기 위해 Array(IntArray, CharArray 등)를 invariant 로 만들었다.\n따라서, Array\u0026lt;Int\u0026gt; 를 Array\u0026lt;Any\u0026gt; 등으로 바꿀 수 없다.\n예시를 봐야 할듯.\n이 아이템은 좀 찾아볼 것\n"},{"id":25,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-25.-%EA%B3%B5%ED%86%B5-%EB%AA%A8%EB%93%88%EC%9D%84-%EC%B6%94%EC%B6%9C%ED%95%B4%EC%84%9C-%EC%97%AC%EB%9F%AC-%ED%94%8C%EB%9E%AB%ED%8F%BC%EC%97%90%EC%84%9C-%EC%9E%AC%EC%82%AC%EC%9A%A9%ED%95%98%EB%9D%BC/","title":"아이템 25. 공통 모듈을 추출해서 여러 플랫폼에서 재사용하라","section":"이펙티브 코틀린","content":" 공통 모듈을 추출해서 여러 플랫폼에서 재사용하라 # 함께 사용하기 # 코틀린/JVM 을 사용한 백엔드 개발 : Spring, Ktor 등 코틀린/JVM 을 사용한 데스크톱(애플리케이션) 개발 : TornatoFX 등 코틀린/JVM 을 사용한 안드로이드 개발 : Android SDK 등 코틀린/JS 을 사용한 프론트 개발 : React 등 코틀린/네이티브 을 사용한 IOS 개발 코틀린/네이티브 을 사용한 라즈베리파이, 리눅스, macOS 프로그램 개발 "},{"id":26,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-26.-%ED%95%A8%EC%88%98-%EB%82%B4%EB%B6%80%EC%9D%98-%EC%B6%94%EC%83%81%ED%99%94-%EB%A0%88%EB%B2%A8%EC%9D%84-%ED%86%B5%EC%9D%BC%ED%95%98%EB%9D%BC/","title":"아이템 26. 함수 내부의 추상화 레벨을 통일하라","section":"이펙티브 코틀린","content":" \u0026quot; 컴퓨터 과학에서 추상화는 복잡한 자료, 모듈, 시스템 등으로부터 핵심적인 개념 또는 기능을 간추려 내는 것을 말한다. \u0026hellip; 조금 간단하게 표현하면, 추상화는 복잡성을 숨기기 위해 사용되는 방식을 의미한다. \u0026ldquo;\n인터페이스는 클래스라는 복잡한 것에서 메서드, 프로퍼티만 추출해서 간단하게 만들었으므로 클래스의 추상화라고 볼 수 있다.\n추상화를 하려면 무엇을 감추고 무엇을 노출해야 하는지 결정해야 한다. (잘 결정하지 못하면 추상화 능력이 떨어진다고 볼 수 있다.)\n일반적으로 프로그래밍에서는 다음과 같은 목적으로 추상화를 사용한다.\n복잡성을 숨기기 위해 코드를 체계화 하기 위해 만드는 사람에게 변화의 자유를 주기 위해 = 쉽게 확장할 수 있고, 수정할 수 있도록 하기 위해 함수 내부의 추상화 레벨을 통일하라 # 계층이 잘 분리되면 좋은 점은 다음과 같다.\n어떤 계층에서 작업할 때, 그 아래 계층은 (완제품을 사용하는 것 처럼)살펴볼 필요 없다. 즉, 해당 계층에 대해서만 작업/생각하면 된다. 추상화 레벨 # 애플리케이션 \u0026lt;-- 높은 레벨 : 단순함↑ 제어력↓ | 프로그래밍언어 | 어셈블러 | 하드웨어 | 물리장치 \u0026lt;-- 낮은 레벨 : 단순함↓ 제어력↑ 추상화 레벨 통일 # (위의) 컴퓨터 과학과 마찬가지로 코드도 추상화를 통해 계층처럼 만들어 사용할 수 있을 것이다. 이를 위한 기본적인 도구가 함수다.\n함수도 높은 레벨, 낮은 레벨을 구분해서 사용해야 한다는 원칙이 바로 추상화 레벨 통일 원칙(Single Level of Abstraction, SLA) 이다.\nfun makeCoffee() { // 높은 레벨의 함수 boilWater() // 낮은 레벨의 함수 brewCoffee() pourCoffee() pourMilk() } 위의 예시는 추상화를 통해 가독성을 크게 향상시켰다고 볼 수 있다.\n위의 예시처럼 함수는 간단해야 한다. 어떤 함수가 크다면, 일부분을 추출해 별도의 함수로 추상화하는 것이 좋다.\n\u0026rdquo; 함수는 작아야 하며, 최소한의 책임만을 가져야 한다. \u0026ldquo;\n프로그램 아키텍처의 추상 레벨 # (아키텍처 관점에서) 추상화를 구분하는 이유는 서브시스템의 세부 사항을 숨김으로써 상호 운영성과 플랫폼 독립성을 얻기 위함이다.\n이는 문제 중심으로 프로그래밍한다는 이야기와 같다. :thinking:\n높은 레벨의 문제 중심 | 낮은 레벨의 문제 중심 | 낮은 레벨 구현 구조 | 프로그래밍 언어 구조와 도구 | 운영 체제 연산과 머신 명령 이러한 개념은 모듈 시스템을 설계할 때도 아주 중요하다. 모듈을 분리하면 계층 고유의 요소를 숨길 수 있다.\n예를 들어, 애플리케이션을 만들 때 입/출력을 나타내는 모듈은 \u0026lsquo;낮은 레벨의 모듈\u0026rsquo;이다.\n반대로 비즈니스 로직을 나타내는 모듈은 \u0026lsquo;높은 레벨의 모듈\u0026rsquo;이다.\n계층이 잘 분리된 프로젝트를 계층화가 잘 되었다고 말할 수 있다.\n요약 # 함수, 클래스, 모듈, 문제 해결 등 다양한 관점에서, 다양한 방식으로 추상화를 분리할 수 있다. 각각의 레이어(레벨)이 너무 커지지 않도록 주의해야 한다. 작고 최소한의 책임만 갖는 것이 좋다. (\u0026lsquo;함수\u0026rsquo; 분리도 추상화 행위라고 볼 수 있었던 것이다. :thinking:) "},{"id":27,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-27.-%EB%B3%80%ED%99%94%EB%A1%9C%EB%B6%80%ED%84%B0-%EC%BD%94%EB%93%9C%EB%A5%BC-%EB%B3%B4%ED%98%B8%ED%95%98%EB%A0%A4%EB%A9%B4-%EC%B6%94%EC%83%81%ED%99%94%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%9D%BC/","title":"아이템 27. 변화로부터 코드를 보호하려면 추상화를 사용하라","section":"이펙티브 코틀린","content":" 변화로부터 코드를 보호하려면 추상화를 사용하라 # \u0026quot; 함수와 클래스 등의 추상화로 실질적인 코드를 숨기면, 사용자가 세부 사항을 알지 못해도 괜찮다는 장점이 있습니다. 그리고 이후에 실질적인 코드를 원하는대로 수정할 수도 있습니다. \u0026ldquo;\n\u0026rdquo; 추상화는 더 많은 자유를 주지만, 이를 정의하고, 사용하고, 이해하는 것이 조금 어려워질 수 있습니다. \u0026ldquo;\n추상화 사례 1. 상수 # 리터럴은 아무것도 설명하지 않는다.\n리터럴을 상수 프로퍼티로 변경하면 해당 값에 의미를 부여할 수 있다. 그래서 두 번 이상 사용되는 값은 상수 프로퍼티(변수)로 만드는 것이 좋다.\n추상화 사례 2. 함수 # Context.toast(), Context.snackbar() -\u0026gt; Context.showMessage() 로의 변경 예시\n메시지의 출력 방법이 중요한 것이 아니고, 메시지를 출력하는 의도를 표현했다. = 세부 사항은 숨기고 범용적인 이름을 사용했다.\n의미 있는 이름은 굉장히 중요하다.\n추상화 사례 3. 클래스 # 클래스가 함수보다 강력한 이유는 \u0026lsquo;상태\u0026rsquo;를 가질 수 있고, 많은 함수를 가질 수 있다는 점이다.\n\u0026rdquo; 더 많은 자유를 얻으려면, 더 추상적이게 만들면 됩니다. (바로 인터페이스 뒤에 클래스를 숨기는 방법입니다. \u0026ldquo;\n추상화 사례 4. 인터페이스 # \u0026rdquo; 라이브러리를 만드는 사람은 내부 클래스의 가시성을 제한하고, 인터페이스를 통해 이를 노출하는 코드를 많이 사용합니다. 이렇게 하면 사용자가 내부 클래스를 직접 사용하지 못하므로, 라이브러리를 만드는 사람은 인터페이스만 유지한다면 별도의 걱정 없이 자신이 원하는 형태로 변경할 수 있습니다. \u0026ldquo;\n인터페이스 뒤에 객체를 숨김으로써 실질적인 구현을 추상화하고, 사용자가 추상화된 것(인터페이스)에 의존하게 만들 수 있다. = 결합성(coupling)을 줄일 수 있다.\n추상화의 문제 # 추상화는 자유를 주지만, 코드를 이해하고 수정하기 어렵게 만든다.\n즉, 추상화도 비용이 발생한다. 극단적으로 모든 것을 추상화해서는 안된다.\n어느 정도 숨기면 개발이 쉬워지는 것도 맞지만 너무 많은 것을 숨기면 결과를 이해하기 힘들어진다.\n추상화는 거의 무한하게 할 수 있지만, 어느 순간부터 득보다 실이 많아진다.\n이를 풍자한 \u0026lsquo;FizzBuzz Enterprise Edition\u0026rsquo; 이라는 프로젝트가 있다. 원래는 10줄도 필요하지 않은 코드가, 책 집필 시점 기준 61개의 클래스와 26개의 인터페이스로 작성됐다고 한다.\n어떻게 균형을 맞춰야 할까? # 진리의 케바케인 것 같다.\n팀의 크기, 팀의 경험, 프로젝트의 크기, 도메인 특징/지식 등에 따라 달라질 것이다.\n많은 개발자가 참여하는 프로젝트는 이후 객체 생성, 사용 방법을 변경하기 어렵다. 따라서 되도록 추상화를 고려하는 것이 좋다. 테스트를 하거나, 다른 애플리케이션을 기반으로 새로운 애플리케이션을 만든다면 추상화를 사용하는 것이 좋다. 프로젝트가 작고 실험적이라면, 추상화를 하지 않아도 괜찮겠다. 문제가 발생하면 빠르게 수정하면 된다. 요약 # 추상화는 가독성↑ 코드 유지보수(변경)↑ 중복↓ 비용↑ 의 특징이 있다고 볼 수 있겠다. 추상화는 단순히 중복을 제거하기 위한 것이 아니다. 추상화는 코드를 변경할 때 도움이 된다. 추상화를 사용하는 것은 어렵지만, 이를 배우고 이해해야 한다. 장점과 단점을 비교하여 프로젝트 내에서 균형을 찾아야 한다. "},{"id":28,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-28.-API-%EC%95%88%EC%A0%84%EC%84%B1%EC%9D%84-%ED%99%95%EC%9D%B8%ED%95%98%EB%9D%BC/","title":"아이템 28. API 안전성을 확인하라","section":"이펙티브 코틀린","content":" API 안전성을 확인하라 # API 또는 API의 일부가 불안정하다면, 작성자/개발자가 이를 명확하게 알려줘야 한다.\n일반적으로 버전을 활용해서 라이브러리, 모듈의 안전성을 나타낸다.\n많은 버저닝 시스템이 있지만 일반적으로 사용되는 것은 **시멘틱 버저닝(Semantic Versioning, SemVer)**이다.\n시멘틱 버저닝의 표기법은 {MAJOR}.{MINOR}.{PATCH} 이다. 각각의 부분은 0 이상의 정수로 구성되고, 변경 마다 1씩 증가시킨다.\n구분 설명 비고 MAJOR 호환되지 않는 수준의 API 변경 MAJOR 증가 시, MINOR, PATCH 는 0으로 초기화한다. MINOR 이전 변경과 호환되는 기능 추가 MINOR 증가 시, PATCH 는 0으로 초기화한다. PATCH 간단한 버그 수정 사전 배포, 빌드 메타데이터 등은 추가적인 레이블을 활용할 수 있다. (← SNAPSHOT, EXPERIMENTAL 과 같은 것을 의미하는 것 같다.)\nMAJOR 버전이 0인 경우(0.y.z)는 초기 개발 전용 버전을 의미한다. 언제든지 변경될 수 있으며, 안정적이지 않음을 의미한다.\n오랜 시간 동안 MAJOR가 0이거나 실험적 기능(@Experimental)으로 유지하는 것을 두려워해서는 안된다. 속도는 느릴 수 있지만 더 좋은 API를 설계하기 위해서라면 충분히 유지하는 것이 좋다.\n@Deprecated # 안정적인 API의 일부를 변경해야 한다면, @Deprecated 어노테이션을 활용할 수 있다.\n@Deprecated(\u0026#34;~~~\u0026#34;, ReplaceWith=\u0026#34;~~~\u0026#34;) fun OOO() {} 단, Deprecated 로 마킹했더라도 사용자가 이 변경에 적응할 시간이 필요하다.\n완벽하게 제거하기 위해서는 꽤 오랜 시간이 걸린다. (몇 년이 걸릴 수 있다.)\n충분한 시간이 지난 뒤 Major 배포 업그레이드와 함께 Deprecated 기능을 제거한다.\n요약 # 구분 설명 비고 MAJOR 호환되지 않는 수준의 API 변경 MAJOR 증가 시, MINOR, PATCH 는 0으로 초기화한다. MINOR 이전 변경과 호환되는 기능 추가 MINOR 증가 시, PATCH 는 0으로 초기화한다. PATCH 간단한 버그 수정 Deprecated 기능을 제거하는 것 = Major 버전업이 필요한 것으로? :thinking:\n"},{"id":29,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-29.-%EC%99%B8%EB%B6%80-API%EB%A5%BC-%EB%9E%A9wrap%ED%95%B4%EC%84%9C-%EC%82%AC%EC%9A%A9%ED%95%98%EB%9D%BC/","title":"아이템 29. 외부 API를 랩(wrap)해서 사용하라","section":"이펙티브 코틀린","content":" 외부 API를 랩(wrap)해서 사용하라 # \u0026quot; API 설계자가 안전하지 않다고 하거나 API 설계자가 안전하다고 해도 우리가 그것을 제대로 신뢰할 수 없다면, 해당 API는 불안정한 것입니다. \u0026ldquo;\n불안정한, 신뢰할 수 없는 API를 사용하는 것은 위험하다. 어쩔 수 없이 이런 API를 활용해야 한다면, 최대한 우리의 제품(로직)과 직접적인 결합을 만들지 않는 것이 좋다.\n그래서 많은 프로젝트가 (잠재적으로 불안한 API에 대해서) 랩(wrap)해서 사용한다.\n랩해서 사용하면 다음과 같은 장,단점이 있다.\n장점 단점 - (해당 API에) 문제 발생 시, 래퍼(wrapper)만 변경하면 되므로 API 변경에 쉽게 대응할 수 있다.(다른 API로 쉽게 교체할 수도 있겠다.)\n- (우리)프로젝트의 스타일에 맞춰 API 형태를 조정할 수 있다. - 필요하다면 쉽게 기능/동작을 추가하거나 수정할 수 있다. - 래퍼를 추가로 작성/관리해줘야 한다. 모든 외부 API를 래핑하라는 것은 아니다. 래핑을 고려해볼 수 있다는 것을 기억하자.\n래핑해서 사용하는 것은 나름 익숙하게 해왔던 것 같다.\n"},{"id":30,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/%EC%95%84%EC%9D%B4%ED%85%9C-50.-%EC%BB%AC%EB%A0%89%EC%85%98-%EC%B2%98%EB%A6%AC-%EB%8B%A8%EA%B3%84-%EC%88%98%EB%A5%BC-%EC%A0%9C%ED%95%9C%ED%95%98%EB%9D%BC/","title":"아이템 50. 컬렉션 처리 단계 수를 제한하라","section":"이펙티브 코틀린","content":" 컬렉션 처리 단계 수를 제한하라 # 모든 컬렉션 처리 메서드는 비용이 발생한다.\n\u0026quot; 표준 컬렉션 처리는 내부적으로 요소들을 활용해 반복문을 돌며, 계산을 위해 추가적인 컬렉션을 만들어 사용합니다. 시퀀스 처리도 시퀀스 전체를 wrap하는 객체가 만들어지며, 조작을 위해서 또 다른 추가적인 객체를 만들어 냅니다. 두 처리 모두 요소의 수가 많다면, 꽤 큰 비용이 들어갑니다. \u0026ldquo;\n따라서 적절한 메서드를 활용해서, 컬렉션 처리 단계 수를 적절하게 제한하는 것이 좋다.\nclass Student(val name: String?) // 작동은 합니다. fun List\u0026lt;Student\u0026gt;.getNames(): List\u0026lt;String\u0026gt; = this .map { it.name } .filter { it != null } .map { it!! } // 더 좋습니다. fun List\u0026lt;Student\u0026gt;.getNames(): List\u0026lt;String\u0026gt; = this .map { it.name } .filterNotNull() // 가장 좋습니다. fun List\u0026lt;Student\u0026gt;.getNames(): List\u0026lt;String\u0026gt; = this .mapNotNull { it.name } \u0026rdquo; 사실 컬렉션 처리와 관련해서 비효율적인 코드를 작성하는 이유는 그것이 필요 없다고 생각해서가 아니라, 어떤 메서드가 있는지 몰라서인 경우가 많습니다. \u0026ldquo;\n공감된다.\n쓸만한 함수 예시 # filterNotNull mapNotNull joinToString filterIsInstance() filter (책 확인) sortedWith(comparedBy()) listOfNotNull(\u0026hellip;) filterIndexed 요약 # 컬렉션 처리는 \u0026lsquo;전체 컬렉션에 대한 반복\u0026rsquo;, \u0026lsquo;중간 컬렉션 생성\u0026rsquo;이라는 비용이 발생한다.\n적절한 컬렉션 처리 함수를 통해 처리 단계를 줄일 수 있다.\n단계를 줄이자.\n"},{"id":31,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-01.-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8%EC%99%80-%EC%9E%90%EB%B0%94%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8%EC%9D%98-%EA%B4%80%EA%B3%84-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/","title":"아이템 01. 타입스크립트와 자바스크립트의 관계 이해하기","section":"이펙티브 타입스크립트","content":" \u0026quot; 타입스크립트는 인터프리터 언어로 실행되는 것도 아니고, (Java, C 같이)저수준 언어로 컴파일 되는 것도 아닙니다. 또 다른 고수준 언어인 \u0026lsquo;자바스크립트\u0026rsquo;로 컴파일되며, 실행 역시 타입스크립트가 아닌 자바스크립트로 이루어집니다. 그래서 타입스크립트와 자바스크립트의 관계는 필연적이며, 이 밀접한 관계 때문에 혼란스러운 일이 벌어지기도 합니다. \u0026quot; (1장 소개말 중)\n아이템 1. 타입스크립트와 자바스크립트의 관계 이해하기 # 타입스크립트는 자바스크립트의 상위 집합 모든 \u0026lsquo;자바스크립트\u0026rsquo; 는 \u0026lsquo;타입스크립트\u0026rsquo; 이다. (참) 모든 \u0026lsquo;타입스크립트\u0026rsquo; 는 \u0026lsquo;자바스크립트\u0026rsquo; 이다. (거짓) 타입스크립트 중에는 자바스크립트가 아닌 프로그램이 존재한다고 한다. |---------------------| | ts | | |------| | | | js | | | |------| | | | |---------------------| 타입스크립트는 자바스크립트의 상위집합이기 때문에, js 파일의 코드는 이미 타입스크립트라고 할 수 있다.\n종류 확장자 자바스크립트 .js, .jsx 타입스크립트 .ts, .tsx main.js → main.ts 변경해도 된다. 이러한 특성은 기존 자바스크립트 코드를 타입스크립트로 마이그레이션하는 것에 엄청난 이점을 줄 수 있다.\n자바스크립트에서 타입구문을 사용하는 순간부터 타입스크립트 영역으로 들어가게 된다.\n// 다음 코드를 javascript 를 구동하는 노드(node) 같은 프로그램에서 실행 시 오류가 발생한다. function greet(who: string) { console.log(\u0026#39;Hello, \u0026#39;, who); } // [오류 내용] // function greet(who: string) // ^ // SyntaxError: Unexpected token : 타입스크립트 컴파일러는 타입스크립트뿐만 아니라 일반 자바스크립트 프로그램에도 유용하다. 타입스크립트는 타입 구문(타입 선언) 없이도 다양한 오류를 잡을 수 있다. 여기에 타입 구문을 추가한다면 훨씬 더 많은 오류를 찾아낼 수 있게 되는 것이다.\n// 다음 코드는 오류가 발생한다. let city = \u0026#39;new york city\u0026#39;; console.log(city.toUppercase()); // [오류 내용] // TypeError: city.toUppercase is not a function (타입 구문이 없어도) 위 코드를 \u0026lsquo;타입스크립트의 타입 체커\u0026rsquo;를 이용하면 다음과 같이 문제점을 빠르게 찾아낼 수 있다.\nlet city = \u0026#39;new york city\u0026#39;; console.log(city.toUppercase()); // ~~~~~~~~ \u0026#39;toUppercase\u0026#39; 속성이 \u0026#39;string\u0026#39; 형식에 없습니다. // \u0026#39;toUpperCase\u0026#39;을(를) 사용하시겠습니까? 타입스크립트는 초깃값으로부터 타입을 추론한다. 타입스크립트의 타입 추론은 중요한 부분이다. (3장에서 자세히) 내가 생각한 핵심은 다음과 같다. \u0026quot; 타입스크립트에게 타입을 선언하여 개발자의 \u0026lsquo;의도\u0026rsquo;를 전달한다. \u0026lsquo;의도\u0026rsquo;를 정확히 전달할 수록 타입스크립트가 정확하게 확인해주는 것이다. 이러한 \u0026lsquo;의도\u0026rsquo; 전달을 자바, 코틀린 등 기존에 사용한 컴파일 언어에서 꾸준히 해온 것이다. \u0026ldquo;\n타입 시스템의 목표 중 하나는 런타임에 오류를 발생시킬 코드를 미리 찾아내는 것이다. 다만, 타입 체커가 모든 오류를 찾아내지는 않는다.\n타입스크립트는 자바스크립트 런타임 동작을 모델링한다. (설계한다?) 따라서, 런타임 오류를 발생시키는 코드를 찾아내려고 한다. 하지만, 모든 오류를 찾아내리라 기대하면 안된다. 타입 체커를 통과하면서 런타임 오류를 발생시키는 코드는 충분히 존재 가능하다.\n기존 자바스크립트의 \u0026lsquo;엄격하지 않는 특징\u0026rsquo;을 선호한다면, 타입스크립트를 선택하는 것을 고민해봐야 한다. 이것은 온전히 (개발자의)취향의 차이이다.\n"},{"id":32,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-02.-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8-%EC%84%A4%EC%A0%95-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/","title":"아이템 02. 타입스크립트 설정 이해하기","section":"이펙티브 타입스크립트","content":" 아이템 2. 타입스크립트 설정 이해하기 # 타입스크립트 컴파일러(타입 체커)는 매우 많은 설정을 가지고 있다.\n설정 방법 예시 커맨드 라인 (cli) tsc --noImplicitAny program.ts 파일 (file) tsconfig.json 참고 : tsc --init 통해 파일 생성 가능하다. 중요/권장 설정 : noImplicitAny\n타입을 미리 정의하여 사용할 것인지 설정하는 것\n값 설명 true 타입을 미리 정의해야 한다. 타입스크립트는 타입 정보를 설정/체크할 때 가장 효과적이기 때문에, 되도록 true 설정을 권장한다. false (기존 자바스크립트와 같이) 타입을 미리 정의하지 않아도 된다. 주의! 이 경우 any 타입으로 추론/간주된다. 자바스크립트에서 타입스크립트로 전환할 때와 같은 상황에서만 설정하는 것을 권장한다. 중요/권장 설정 : strictNullChecks\n타입에 null, undefined 가 허용될 수 있도록 할 것인지 설정하는 것\nstrictNullChecks 설정은 트레이드오프가 있다. 오류 검증 / 확인 : ↑ 코드 작성(생산성) : ↓ 값 설명 true null, undefined 를 허용하지 않는다. 예를 들어, 다음 코드는 오류를 발생시킨다. const x: number = null; // 오류 : ~ 'null' 형식은 'number' 형식에 할당할 수 없습니다. null 을 허용하기 위해서는 다음과 같이 명시적으로 작성해야한다. `const x: number false null, undefined 를 허용한다. 예를 들어, 다음 코드는 오류를 발생시키지 않는다. const x: number = null; // 정상 흔히 봐왔던 에러 메시지 : \u0026ldquo;undefined는 객체가 아닙니다\u0026rdquo; \u0026quot; strictNullChecks 는 noImplcitAny 가 먼저 설정되어야 한다. \u0026ldquo;\n중요 설정 : strict (모드)\nnoImplicitAny, strictNullChecks 등의 엄격한 체크를 설정하고 싶다면 strict 설정한다.\n\u0026rdquo; stirct 설정 시 대부분의 오류를 잡아낼 수 있다. \u0026ldquo;\n내가 생각한 핵심은 다음과 같다. 타입스크립트를 사용하려는 이유, 타입스크립트로 넘어가려는 이유를 생각해보면 위 내용의 \u0026lsquo;엄격한 설정\u0026rsquo;들을 설정해주는 것이 맞지 않을까?\n\u0026lsquo;엄격함\u0026rsquo; 보단 \u0026lsquo;조금 더 편리한 코드 작성\u0026rsquo;을 추구한다면 기존의 자바스크립트를 사용해도 괜찮지 않을까?\n\u0026ldquo;이것은 온전히 (개발자의)취향의 차이이다.\u0026rdquo; (1장 중)\n"},{"id":33,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-03.-%EC%BD%94%EB%93%9C-%EC%83%9D%EC%84%B1%EA%B3%BC-%ED%83%80%EC%9E%85%EC%9D%B4-%EA%B4%80%EA%B3%84%EC%97%86%EC%9D%8C%EC%9D%84-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/","title":"아이템 03. 코드 생성과 타입이 관계없음을 이해하기","section":"이펙티브 타입스크립트","content":" 아이템 3. 코드 생성과 타입이 관계없음을 이해하기 # 타입스크립트는 두 가지 역할(트랜스파일, 컴파일)을 수행한다. # 1. 최신 타입스크립트/자바스크립트를 (브라우저에서 동작할 수 있도록) 구버전의 자바스크립트로 트랜스파일(transpile)한다. 2. 코드의 타입 오류를 체크한다.\n트랜스파일, 타입 체크는 완벽히 독립적이다. 트랜스파일이 잘못되어도 타입 체크는 실행될 수 있다. 타입 체크가 잘못되어도 트랜스파일은 실행될 수 있다. 타입 오류가 있는 코드도 컴파일(트랜스파일)이 가능하다. # » cat test.ts let x = \u0026#39;hello\u0026#39;; x = 1234; » tsc test.ts test.ts:2:1 - error TS2322: Type \u0026#39;number\u0026#39; is not assignable to type \u0026#39;string\u0026#39;. 2 x = 1234; ~ Found 1 error in test.ts:2 » cat test.js var x = \u0026#39;hello\u0026#39;; x = 1234; » 타입스크립트에서 (타입 체크의)오류는 C, 자바에서의 경고(warning)와 비슷하다. noEmitOnError 옵션을 통해 오류가 있을 때 컴파일 결과물이 생성되지 않도록 설정할 수 있다. 기본 값 : false (= 오류가 있어도 컴파일 결과물을 생성한다.) 런타임에는 타입 체크가 불가능하다. # 타입스크립트의 타입은 \u0026lsquo;제거 가능(erasable)\u0026lsquo;하다.\n자바스크립트로 트랜스파일되는 과정에서 모든 인터페이스, 타입, 타입 구문은 제거된다. 따라서, 아래와 같은 코드는 의도한대로 실행되지 않는다.\n/** File : test.ts */ interface Square { width: number; } interface Rectangle extends Square { height: number; } type Shape = Square | Rectangle; function calculateArea(shape: Shape) { if(shape instanceof Rectangle) { return shape.width * shape.height; } else { return shape.width * shape.width; } } » tsc test.ts test.ts:10:25 - error TS2693: \u0026#39;Rectangle\u0026#39; only refers to a type, but is being used as a value here. 10 if(shape instanceof Rectangle) { ~~~~~~~~~ test.ts:11:36 - error TS2339: Property \u0026#39;height\u0026#39; does not exist on type \u0026#39;Shape\u0026#39;. Property \u0026#39;height\u0026#39; does not exist on type \u0026#39;Square\u0026#39;. 11 return shape.width * shape.height; ~~~~~~ Found 2 errors in the same file, starting at: test.ts:10 » cat test.js function calculateArea(shape) { if (shape instanceof Rectangle) { return shape.width * shape.height; } else { return shape.width * shape.width; } } 타입은 모두 제거되었다.\n런타임에 \u0026lsquo;타입 정보\u0026rsquo;를 유지하기 위해서는 아래와 같은 방법을 사용할 수 있다.\n런타임 시 속성 체크 태그 기법 (타입 정보 보유) 클래스 사용 1. 런타임 시 속성 체크\nfunction calculateArea(shape: Shape) { if(\u0026#39;height\u0026#39; in shape) { return shape.width * shape.height; } else { return shape.width * shape.width; } } » tsc test.ts » cat test.js function calculateArea(shape) { if (\u0026#39;height\u0026#39; in shape) { return shape.width * shape.height; } else { return shape.width * shape.width; } } 2. 태그 기법 (타입 정보 보유)\ninterface Square { kind: \u0026#39;square\u0026#39;; width: number; } interface Rectangle extends Square { kind: \u0026#39;rectangle\u0026#39;; height: number; } type Shape = Square | Rectangle; function calculateArea(shape: Shape) { if(shape.kind === \u0026#39;rectangle\u0026#39;) { return shape.width * shape.height; } else { return shape.width * shape.width; } } 3. 클래스 사용\n인터페이스는 \u0026lsquo;타입\u0026rsquo;으로만 사용 가능하지만, 클래스는 \u0026lsquo;타입\u0026rsquo;, \u0026lsquo;값\u0026rsquo;으로 모두 사용 가능하다.\n즉, 타입(런타임 접근 불가)와 값(런타임 접근 가능)을 둘 다 사용하는 기법\nclass Square { constructor(public width: number) {} } class Rectangle extends Square { constructor(public width: number, public height: number) { super(width); } } type Shape = Square | Rectangle; function calculateArea(shape: Shape) { if(shape instanceof Rectangle) { return shape.width * shape.height; } else { return shape.width * shape.width; } } \u0026lsquo;타입 연산\u0026rsquo;은 런타임에 영향을 주지 않는다. # (아래 예시) 변환된 .js 에서는 타입에 대한 코드가 모두 제거되었다. 즉 런타임 시에 아무런 영향을 주지 않는다.\nfunction asNumber(val: number | string): number { return val as number; } » tsc test.ts » cat test.js function asNumber(val) { return val; } (의도한대로 작성하기 위해서는) 아래와 같이 작성할 수 있다.\nfunction asNumber(val: number | string): number { return typeof(val) === \u0026#39;string\u0026#39; ? Number(val) : val; } » tsc test.js » cat test.js function asNumber(val) { return typeof (val) === \u0026#39;string\u0026#39; ? Number(val) : val; } 런타임 타입은 선언된 타입과 다를 수 있다. # 아래 코드의 default 케이스는 실행될 수 있다.\n(default 케이스에 대해서) (일반적으로) 타입스크립트는 실행되지 못하는 죽은(dead)코드를 찾아내지만, 여기서는 strict 모드를 설정하더라도 찾아내지 못한다.\nfunction setLightSwitch(value: boolean) { switch (value) { case true: turnLightOn(); break; case false: turhLightOff(); break; default: console.log(\u0026#34;???\u0026#34;); } } 트랜스파일 후 런타임 시에 value: boolean 에서 boolean 은 제거된다. 따라서 아래와 같이 호출될 수도 있다.\nsetLightSwitch(\u0026#34;ON\u0026#34;); 즉, 선언된 타입과 런타임 타입이 맞지 않을 수 있다. (이 부분을 명심해야 한다.)\n타입스크립트 타입으로는 함수를 \u0026lsquo;오버로드\u0026rsquo;할 수 없다. # 선언된 타입은 트랜스파일 후에는 모두 제거되기 때문에 당연한 결과일 것이다.\n아래 예시를 살펴보자. 트랜스파일 후 선언된 타입은 모두 제거되었다.\nfunction add(a: number, b: number) { console.log(a + b); } function add(a: string, b: string) { console.log(a + b); } » tsc test.js » cat test.js function add(a, b) { console.log(a + b); } function add(a, b) { console.log(a + b); } 타입스크립트가 함수 오버로딩 기능을 지원하는 것은 \u0026lsquo;타입\u0026rsquo; 수준에서만 의미하는 것이다. (\u0026hellip;?)\n예를 들면 아래와 같이 선언문은 여러 개를 작성할 수 있지만, 구현체는 오직 하나뿐이다. (\u0026hellip;?)\nfunction add(a: number, b: number): number; function add(a: string, b: string): string; function add(a, b) { return a + b; } » tsc test.js » cat test.js function add(a, b) { return a + b; } add 에 대한 두 개의 선언문은 타입 정보를 제공할 뿐이다. 선언문은 자바스크립트로 트랜스파일 될 때 제거된다. (구현체만 남는다.)\n타입스크립트 타입은 런타임 성능에 영향을 주지 않는다. # 타입은 자바스크립트로 변환되는 시점에 모두 제거되기 때문에, 런타임에서는 (성능을 포함하여)아무런 영향을 주지 않는다.\n\u0026lsquo;런타임\u0026rsquo; 오버헤드(성능 저하)가 없는 대신, \u0026lsquo;빌드타임\u0026rsquo;에 대한 오버헤드는 존재한다.\n타입스크립트 팀은 컴파일러 성능을 매우 중요하게 생각한다. (= \u0026lsquo;빌드타임\u0026rsquo;에 대해 중요하게 생각한다.) \u0026lsquo;빌드타임\u0026rsquo;에 대한 오버헤드가 너무 커질 경우, 타입 체크는 하지 않고 트랜스파일만 진행할 수도 있다. (transpile only) 요약 # 1. 타입은 런타임 동작 시에 어떠한 영향도 주지 않는다. (런타임 동작 시에 사용할 수도 없다.) 2. 타입 오류가 존재해도 트랜스파일(코드 생성)은 가능하다.\n책에서 말하고 있는 \u0026lsquo;타입\u0026rsquo; vs \u0026lsquo;값\u0026rsquo;에 대한 차이를 이해가 필요하다. 런타임 시에 타입이 제거된다. 타입 관련 로직들에 대한 주의가 필요하다. 의미 없는 코드 작성(예를 들어, 트랜스파일 후 제거되는 코드 작성)할 여지가 많이 있을 것 같다. 런타임 시에 타입은 아무런 영향도 끼칠 수 없다는 것을 기억해야 한다. "},{"id":34,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-04.-%EA%B5%AC%EC%A1%B0%EC%A0%81-%ED%83%80%EC%9D%B4%ED%95%91%EC%97%90-%EC%9D%B5%EC%88%99%ED%95%B4%EC%A7%80%EA%B8%B0/","title":"아이템 04. 구조적 타이핑에 익숙해지기","section":"이펙티브 타입스크립트","content":" 아이템 4. 구조적 타이핑에 익숙해지기 # 자바스크립트는 본질적으로 \u0026lsquo;덕 타이핑(duck typing)\u0026rsquo; 기반이다. # 덕타이핑이란? 어떤 값에 필요한 속성, 메서드가 존재한다면 그냥 사용하는 것을 의미한다.\n타입스크립트는 자바스크립트의 런타임 동작을 모델링한다. 덕타이핑을 모델링하기 위해 \u0026lsquo;구조적 타이핑\u0026rsquo; 기법을 사용한다. (올바른 표현인가\u0026hellip;?)\ninterface Vector2D { x: number; y: number; } interface NamedVector2D { name: string; x: number; y: number; } function calculateLength(v: Vector2D) { return Math.sqrt(v.x * v.x + v.y * v.y); } » tsc example.js » » cat example.js function calculateLength(v) { return Math.sqrt(v.x * v.x + v.y * v.y); } 자바스크립트의 \u0026lsquo;덕타이핑\u0026rsquo; 개념이 당여한다는 가정 하에, 타입스크립트의 \u0026lsquo;구조적 타이핑\u0026rsquo; 은 어떻게 보면 당연한 것일 수 있다. (위의 코드처럼 .js 로 트랜스파일 이후에 선언된 타입은 모두 제거되기 때문에)\n클래스에도 구조적 타이핑이 적용된다. # class C { foo: string; constructor(foo: string) { this.foo = foo; } } const c = new C(\u0026#39;hi\u0026#39;); // OK const d: C = { foo: \u0026#39;hi\u0026#39;; } // OK (구조적 타이핑에 의해) console.log(c); // C { foo: \u0026#39;hi\u0026#39; } console.log(c.constructor); // [Function: C] console.log(d); // { foo: \u0026#39;hi\u0026#39; } console.log(d.constructor); // [Function: Object] 요약 / 정리 # 1. 자바스크립트가 \u0026lsquo;덕 타이핑\u0026rsquo; 기반이고, 타입스크립트가 이를 모델링하기 위해 \u0026lsquo;구조적 타이핑\u0026rsquo;을 사용한다.\n2. 클래스도 구조적 타이핑 규칙을 따른다. 클래스의 인스턴스가 예상과 다를 수 있다.\n+ js 에서는 호환성(= 생산성, 다형성, \u0026hellip;) 을 중요하게 생각했던 것 같다. (+ 참고 : 덕 타이핑과 구조적 타이핑)\nC, Java 등의 정적타입언어에는 엄격한 타입 시스템이 적용되어 있다. 이는 생산성, 접근성 등을 어렵게 하는 요인 중 하나인데, 이 문제를 해결하고자 C++, Java 에서는 다형성을 도입했다. (= 상속, 인터페이스로 이 문제를 해결한 것)\n반면에 Javascript 에서는 (이러한 문제에 대해서) 애초에 동적타이핑을 통해 해결하고자 했다. 이 동적타이핑을 통해 자바스크립트에서도 (C, Java에서 표현하는, 다형성이라고 표현하는게 올바른지 모르겠지만) \u0026lsquo;다형성\u0026rsquo;의 개념이 녹아져있다. 때문에 C, Java에서 말하는 다형성의 이점들(역할, 구현의 분리 등)을 동일하게 사용한다고 볼 수 있을 것 같다.\n"},{"id":35,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-05.-any-%ED%83%80%EC%9E%85-%EC%A7%80%EC%96%91%ED%95%98%EA%B8%B0/","title":"아이템 05. Any 타입 지양하기","section":"이펙티브 타입스크립트","content":" 아이템 5. any 타입 지양하기 # 타입스크립트 타입 시스템은 \u0026lsquo;점진적(gradual)\u0026rsquo;, \u0026lsquo;선택적(optional)\u0026rsquo; 이다.\n점진적 : 코드에 타입을 조금씩 추가할 수 있다. 선택적 : 언제든지 타입 체킹을 해제할 수 있다. 이 기능의 핵심은 \u0026lsquo;any\u0026rsquo; 타입이다.\n하지만 (일부 특별한 경우를 제외하고는) any 를 사용하지 않는 것을 권장한다.\nany 타입에는 \u0026lsquo;타입 안정성\u0026rsquo;이 없다. # 예시 : any 사용 X\nlet age: number; age = \u0026#39;12\u0026#39;; // 에러 발생 (error TS2322: Type \u0026#39;string\u0026#39; is not assignable to type \u0026#39;number\u0026#39;.) » tsc example.ts example.ts:2:1 - error TS2322: Type \u0026#39;string\u0026#39; is not assignable to type \u0026#39;number\u0026#39;. 2 age = \u0026#39;12\u0026#39;; ~~~ Found 1 error in example1.ts:2 » cat example.js var age; age = \u0026#39;12\u0026#39;; 예시 : any 사용 O\nlet age: number; age = \u0026#39;12\u0026#39; as any; » tsc example.ts » cat example.ts var age; age = \u0026#39;12\u0026#39;; any는 함수 시그니처를 무시한다. # 즉, 트랜스파일의 결과물(output)은 동일하지만, 타입 체크의 도움을 받을 것인지, 받지 않을 것인지를 말하고 있는 것이다.\n예시 : any 사용 X\nfunction calculateAge(birthDate: Date): number { // ... return 1; } let birthDate = \u0026#39;2000-01-01\u0026#39;; calculateAge(birthDate); » tsc example.ts example.ts:7:14 - error TS2345: Argument of type \u0026#39;string\u0026#39; is not assignable to parameter of type \u0026#39;Date\u0026#39;. 7 calculateAge(birthDate); ~~~~~~~~~ Found 1 error in example.ts:7 » cat example.js function calculateAge(birthDate) { // ... return 1; } var birthDate = \u0026#39;2000-01-01\u0026#39;; calculateAge(birthDate); 예시 : any 사용 O\nfunction calculateAge(birthDate: Date): number { // ... return 1; } let birthDate: any = \u0026#39;2000-01-01\u0026#39;; calculateAge(birthDate); » tsc example.ts » cat example.js function calculateAge(birthDate) { // ... return 1; } var birthDate = \u0026#39;2000-01-01\u0026#39;; calculateAge(birthDate); any 타입에는 언어 서비스가 적용되지 않는다. # 여기서 말하는 언어 서비스란? 자동 완성, 변수명 변경(= 전체 변경해주는 기능, intellij 의 refactor) 등의 서비스를 의미한다.\n자동완성, 변수명 변경 등의 서비스를 제공받지 못한다.\n예시 생략\n타입스크립트의 모토는 \u0026lsquo;확장 가능한 자바스크립트\u0026rsquo;이다. \u0026lsquo;확장\u0026rsquo;의 중요한 부분 중 하나가 \u0026lsquo;언어 서비스\u0026rsquo;이다. (언어 서비스를 통해 개발자의 생산성이 향상되기 때문이다.)\nany 타입은 코드 리팩토링 때 버그를 감춘다. # 예시 : any 사용 X\n아래 코드는 ComponentProp 의 타입은 number 임에도 타입 체커가 별도의 에러를 발생시키지 않는다. 즉, 잠재적 버그를 감춘다.\nlet selectedId: number = 0; interface ComponentProps { onSelectItem: (item: number) =\u0026gt; void; } function handleSelectItem(item: any) { // ComponentProps 구현체 selectedId = item.id; } function renderSelector(props: ComponentProps) { /* ... */ } renderSelector({onSelectItem : handleSelectItem}) » tsc example.ts » cat example.js var selectedId = 0; function handleSelectItem(item) { selectedId = item.id; } function renderSelector(props) { /* ... */ } renderSelector({ onSelectItem: handleSelectItem }); 예시 : any 사용 O\nlet selectedId: number = 0; interface ComponentProps { onSelectItem: (item: any) =\u0026gt; void; } function handleSelectItem(item: any) { // ComponentProps 구현체 selectedId = item.id; } function renderSelector(props: ComponentProps) { /* ... */ } renderSelector({onSelectItem : handleSelectItem}) » tsc example.ts » cat example.js var selectedId = 0; function handleSelectItem(item) { selectedId = item.id; } function renderSelector(props) { /* ... */ } renderSelector({ onSelectItem: handleSelectItem }); any는 타입 설계를 감춘다. # 인터페이스, 클래스, 등 다양한 속성을 정의할 때 any 타입을 사용하면 코드의 설계를 감춘다.\n예를 들어 아래 Person 클래스 코드를 살펴보자.\nclass Person { personId: any; constructor(personId: any) { this.personId = personId; } } let p1 = new Person(\u0026#39;P1011\u0026#39;); let p2 = new Person(1); personId 의 타입이 any 라면,\nnumber 가 들어갈 지 string 이 들어갈 지 직접 코드를 보고 판단해야한다.\nany는 타입시스템의 신뢰도를 떨어뜨린다. # + 위의 예시들과 같이 타입 체커가 본 역할을 제대로 수행하지 않으면, 타입스크립트를 사용하는 이유가 없어지는 것과 같을 것이다.\n(이상적인 목표) 타입 체커가 실수를 잡아주고, 개발자는 타입스크립트(타입 시스템), 코드에 대한 신뢰도가 생성된다.\n하지만 any 타입을 사용할수록 타입 체커가 제대로 된 역할을 제대로 수행하지 못할 것이고, 신뢰도를 떨어뜨리게 할 것이다.\n요약 # 1. any 타입의 사용을 최대한 지양한다.\n2. any 타입을 사용하면 타입 체커와 타입스크립트 언어 서비스를 무력화시킨다. any 타입은 \u0026lsquo;문제점\u0026rsquo;을 감춘다. any 타입은 개발 경험을 나쁘게한다. any 타입은 신뢰도를 떨어뜨린다. "},{"id":36,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-06.-%ED%8E%B8%EC%A7%91%EA%B8%B0%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EC%97%AC-%ED%83%80%EC%9E%85-%EC%8B%9C%EC%8A%A4%ED%85%9C-%ED%83%90%EC%83%89%ED%95%98%EA%B8%B0/","title":"아이템 06. 편집기를 사용하여 타입 시스템 탐색하기","section":"이펙티브 타입스크립트","content":" 아이템 6. 편집기를 사용하여 타입 시스템 탐색하기 # 타입스크립트 설치 시, 다음 두 가지를 실행할 수 있다.\n타입스크립트 컴파일러 : tsc 타입스크립트 서버 : tsserver \u0026quot; 보통은 타입스크립트 컴파일러를 실행하는 것이 주된 목적이지만, 타입스크립트 서버 또한 \u0026lsquo;언어 서비스\u0026rsquo;를 제공한다는 점에서 중요합니다. \u0026ldquo;\n여기서 말하는 \u0026lsquo;언어 서비스\u0026rsquo;란? 자동 완성, 검색, 검사, 리팩터링 등을 의미한다. (예를 들면, IDE 에서 도와주는 기능들)\n이번 아이템에서는 IDE, 편집기에서 제공하는 언어 서비스에 대해 설명한다.\n상세한 내용은 생략한다.\n특별히 기록할만한 내용 없음.\n"},{"id":37,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-07.-%ED%83%80%EC%9E%85%EC%9D%B4-%EA%B0%92%EB%93%A4%EC%9D%98-%EC%A7%91%ED%95%A9%EC%9D%B4%EB%9D%BC%EA%B3%A0-%EC%83%9D%EA%B0%81%ED%95%98%EA%B8%B0-todo/","title":"아이템 07. 타입이 값들의 집합이라고 생각하기 (Todo)","section":"이펙티브 타입스크립트","content":" 아이템 7. 타입이 갑들의 집합이라고 생각하기 # 7장은 다시 확인/이해가 필요하다.\n\u0026lsquo;할당 가능한 값들의 집합(범위)\u0026rsquo; = \u0026lsquo;타입\u0026rsquo; 이라고 생각하면 된다. 예를 들어, 모든 숫자값의 집합(범위)는 number 타입이다. 1. 가장 작은 집합 = 아무 값도 포함하지 않는 공집합 = never\nconst x: neber = 12; // ~ \u0026#39;12\u0026#39; 형식은 \u0026#39;never\u0026#39; 형식에 할당할 수 없습니다. 2. 그 다음으로 작은 집합 = 한 가지 값만 포함하는 타입 = unit (literal)\ntype A = \u0026#39;A\u0026#39;; type B = \u0026#39;B\u0026#39;; type Twelve = \u0026#39;12\u0026#39;; 3. 두 개 이상으로 묶은 집합 = 값 집합들의 합집합 = union 타입\ntype AB = \u0026#39;A\u0026#39; | \u0026#39;B\u0026#39;; type AB12 = \u0026#39;A\u0026#39; | \u0026#39;B\u0026#39; | 12; \u0026amp; 연산자는 두 타입의 인터섹션(교집합)이다. # interface Person { name: string; } interface Lifespan { birth: Date; death?: Date; } type PersonSpan = Person \u0026amp; Lifespan 은 공집합(never) 라고 생각하기 쉬우나, 아래와 같이 Person, Lifespan 타입을 모두 갖는 것이 교집합에 속한다.\nconst ps: PersonSpan = { name: \u0026#39;Alan Turing\u0026#39;, birth: ne Date(\u0026#39;2000/01/01\u0026#39;), death: ne Date(\u0026#39;2100/01/01\u0026#39;), }; // 정상 name, birth, death 세 가지 속성보다 더 많은 값을 가지는 것도 PersonSpan 타입에 속한다. (by 구조적타이핑)\n| 연산자는 두 타입의 합집합이다. # type K = keyof (Person | Lifespan); // 타입: never Person, Lifespan 의 유니온 타입에 속하는 값은 없다. (?) Person, Lifespan 혹은 둘 다 갖는 타입이 없다는 것으로 이해했다. 이 부분이 헷갈린다. 다시 확인해볼 것\n그 외 내용 # keyof (A\u0026amp;B) = (keyof A) | (keyof B) keyof (A|B) = (keyof A) \u0026amp; (keyof B) 요약 # - \u0026lsquo;타입 = 값의 집합(범위)\u0026rsquo;\n타입 연산은 집합의 범위에 적용 - A | B → (객체 타입에서는)A 와 B의 속성을 모두 갖는 것 포함\n"},{"id":38,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-08.-%ED%83%80%EC%9E%85-%EA%B3%B5%EA%B0%84%EA%B3%BC-%EA%B0%92-%EA%B3%B5%EA%B0%84%EC%9D%98-%EC%8B%AC%EB%B2%8C-%EA%B5%AC%EB%B6%84%ED%95%98%EA%B8%B0-todo/","title":"아이템 08. 타입 공간과 값 공간의 심벌 구분하기 (Todo)","section":"이펙티브 타입스크립트","content":" 아이템 8. 타입 공간과 값 공간의 심벌 구분하기 # 타입스크립트의 심벌(symbol)은 타입 공간, 값 공간 중 한 곳에 존재한다.\n쉽게 말하면, 같은 네이밍을 가진 심벌은 타입이 될 수도, 값이 될 수도 있다는 의미이다.\n// \u0026#39;Cylinder\u0026#39; 라는 심볼은 \u0026#39;타입\u0026#39;이다. interface Cylinder { radius: number; height: number; } // \u0026#39;Cylinder\u0026#39; 라는 심볼은 \u0026#39;값\u0026#39;이다. const Cylinder = { radius: number, height: number} =\u0026gt; ({ radius, height }); 한 심벌이 \u0026lsquo;타입\u0026rsquo;인지, \u0026lsquo;값\u0026rsquo;인지 알기 위해서는 \u0026lsquo;문맥\u0026rsquo;을 살펴 알아냐애 한다.\n이 부분은 혼란을 야기하곤 한다.\n키워드 설명 type 타입 interface 타입 const 값 let 값 class 타입 / 값 enum 타입 / 값 연산자 중 \u0026lsquo;타입\u0026rsquo;에서 쓰일 때, \u0026lsquo;값\u0026rsquo;에서 쓰일 때 다른 기능을 하는 것들이 있다. # typeof 예시를 살펴본다.\ntype T1 = typoof p; // 타입 : Person type T2 = typeof email; // 타입 : (p: Person, subject: string, body: string) =\u0026gt; Response const v1 = typeof p; // 값 : \u0026#34;object\u0026#34; const v2 = typeof email;// 값 : \u0026#34;function\u0026#34; \u0026lsquo;타입\u0026rsquo; 관점 → 타입스크립트 \u0026lsquo;타입\u0026rsquo; 을 반환\n\u0026lsquo;값\u0026rsquo; 관점 → 자바스크립트 런타임의 typeof 연산자 (= 런타임 타입을 가리키는 문자열 반환, 타입스크립트 타입과는 다르다.)\n* 타입스크립트 타입은 무수히 많다. (사용자가 계속해서 정의 가능) * 자바스크립트 타입은 단 6개이다. (런타임타입 : string, number, boolean, undefined, object, function)\n작성중\u0026hellip;\n요약 # "},{"id":39,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-09.-%ED%83%80%EC%9E%85-%EB%8B%A8%EC%96%B8%EB%B3%B4%EB%8B%A4%EB%8A%94-%ED%83%80%EC%9E%85-%EC%84%A0%EC%96%B8%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0-todo/","title":"아이템 09. 타입 단언보다는 타입 선언을 사용하기 (Todo)","section":"이펙티브 타입스크립트","content":" 아이템 9. 타입 단언보다는 타입 선언을 사용하기 # 종류 설명 타입 선언 선언한 타입임을 명시한다. - alice: Person 타입 단언 (타입스크립트가 추론한 타입이 있더라도) 해당 타입으로 (강제로) 간주한다. - as Person 타입 단언보다 타입 선언을 사용하는 것이 좋다.\n"},{"id":40,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-10.-%EA%B0%9D%EC%B2%B4-%EB%9E%98%ED%8D%BC-%ED%83%80%EC%9E%85-%ED%94%BC%ED%95%98%EA%B8%B0-todo/","title":"아이템 10. 객체 래퍼 타입 피하기 (Todo)","section":"이펙티브 타입스크립트","content":" 아이템 10. 객체 래퍼 타입 피하기 # "},{"id":41,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-11.-%EC%9E%89%EC%97%AC-%EC%86%8D%EC%84%B1-%EC%B2%B4%ED%81%AC%EC%9D%98-%ED%95%9C%EA%B3%84-%EC%9D%B8%EC%A7%80%ED%95%98%EA%B8%B0/","title":"아이템 11. 잉여 속성 체크의 한계 인지하기","section":"이펙티브 타입스크립트","content":" 아이템 11. 잉여 속성 체크의 한계 인지하기 # \u0026quot; 잉여 속성 체크를 이용하면 기본적으로 타입 시스템의 구조적 본질을 해치지 않으면서도 객체 리터럴에 알 수 없는 속성을 허용하지 않음으로써, 이번 아이템에서 다룰 Room이나 Options 예제 같은 문제점을 방지할 수 있습니다. (\u0026lsquo;엄격한 객체 리터럴 체크\u0026rsquo;라고 불립니다.) \u0026ldquo;\n(구조적 타이핑 기반에서) 타입이 명시된 변수에 \u0026lsquo;객체 리터럴\u0026rsquo;을 할당할 때, 추가로 설정된/할당된 속성(잉여 속성)이 있는지 체크할 수 있다.\n객체 리터럴로 할당 시 적용된다. # \u0026lsquo;객체 리터럴\u0026rsquo;로 값을 할당하려고 하면, \u0026lsquo;잉여 속성 체크\u0026rsquo;에 의해 에러를 확인할 수 있다.\ninterface Room { numDoors: number; ceilingHeightFt: number; } const r: Room = { numDoors: 1, ceilingHeightFt: 10, elephant: \u0026#39;present\u0026#39;, }; » tsc example.ts example.ts:8:5 - error TS2322: Type \u0026#39;{ numDoors: number; ceilingHeightFt: number; elephant: string; }\u0026#39; is not assignable to type \u0026#39;Room\u0026#39;. Object literal may only specify known properties, and \u0026#39;elephant\u0026#39; does not exist in type \u0026#39;Room\u0026#39;. 8 elephant: \u0026#39;present\u0026#39;, ~~~~~~~~~~~~~~~~~~~ 단, 아래와 같이 \u0026lsquo;임시 변수\u0026rsquo;를 이용하는 경우에는 가능하다.\ninterface Room { numDoors: number; ceilingHeightFt: number; } const obj = { numDoors: 1, ceilingHeightFt: 10, elephant: \u0026#39;present\u0026#39;, }; const r: Room = obj; \u0026rdquo; obj 타입은 { numDoors: number; ceilingHeightFt: number; elephant: string } 으로 추론됩니다. obj 타입은 Room 타입의 부분 집합을 포함하므로, Room에 할당 가능하며 탕비 체커도 통과합니다. \u0026ldquo;\n+ \u0026lsquo;잉여 속성 체크\u0026rsquo;는 \u0026lsquo;할당 가능 검사\u0026rsquo;와는 별도의 과정이라는 것을 인지해야 한다.\n타입 단언문 사용 시에도 적용되지 않는다. # interface Options { title: string; darkMode?: boolean; } const o = { darkmode: true, title: \u0026#39;Ski Free\u0026#39; } as Options; // 정상 (잉여 속성 체크를 원치 않는다면) \u0026lsquo;인덱스 시그니처\u0026rsquo;를 사용해 추가 속성을 예상하도록 할 수 있다. # interface Options { darkMode?: boolean; [otherOptions: string]: unknown; } const o1: Options = { darkMode:true, plusoption: true }; // 정상 const o2: Options = { plusoption: true }; // 정상 \u0026rdquo; 이런 방법이 데이터를 모델링하는 데 적절한지 아닌지에 대해서는 아이템 15에서 다룹니다. \u0026ldquo;\n약한(weak) 타입에도 비슷한 체크가 동작한다. # 해당 내용은 다시 확인해볼 것\n요약 # \u0026lsquo;잉여 속성 체크\u0026rsquo;는 구조적 타이핑 시스템에서 허용되는 속성 이름의 오타와 같은 실수를 잡는 데 효과적이다.\n다만, 적용 범위가 매우 제한적이고 오직 객체 리터럴에만 적용된다는 특징이 있다. \u0026lsquo;잉여 속성 체크\u0026rsquo;와 \u0026lsquo;일반 타입 체크\u0026rsquo;를 구분하여 인지해야 한다.\n타입 체커가 수행하는 \u0026lsquo;할당 가능 체크\u0026rsquo;와 다르다는 얘기이다. \u0026lsquo;임시 변수\u0026rsquo;를 사용하면 \u0026lsquo;잉여 속성 체크\u0026rsquo;가 적용되지 않는다.\n"},{"id":42,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-14.-%ED%83%80%EC%9E%85-%EC%97%B0%EC%82%B0%EA%B3%BC-%EC%A0%9C%EB%84%88%EB%A6%AD-%EC%82%AC%EC%9A%A9%EC%9C%BC%EB%A1%9C-%EB%B0%98%EB%B3%B5-%EC%A4%84%EC%9D%B4%EA%B8%B0/","title":"아이템 14. 타입 연산과 제너릭 사용으로 반복 줄이기","section":"이펙티브 타입스크립트","content":" 아이템 14. 타입 연산과 제너릭 사용으로 반복 줄이기 # DRY(Don\u0026rsquo;t repeat yourself) 원칙에 따라 코드를 개선해볼 수 있다.\n함수, 상수, Loop 를 통해 개선했다.\n/** 원본 코드 (개선 전) */ console.log(\u0026#39;Cylinder 1 x 1 \u0026#39;, \u0026#39;Surface area: \u0026#39;, 6.283185 * 1 * 1 + 6.283185 * 1 * 1, \u0026#39;Volume: \u0026#39;, 3.14159 * 1 * 1 * 1 ) console.log(\u0026#39;Cylinder 1 x 2 \u0026#39;, \u0026#39;Surface area: \u0026#39;, 6.283185 * 1 * 1 + 6.283185 * 2 * 1, \u0026#39;Volume: \u0026#39;, 3.14159 * 1 * 2 * 1 ) console.log(\u0026#39;Cylinder 2 x 1 \u0026#39;, \u0026#39;Surface area: \u0026#39;, 6.283185 * 2 * 1 + 6.283185 * 2 * 1, \u0026#39;Volume: \u0026#39;, 3.14159 * 2 * 2 * 1 ) /** 수정 코드 (개선 후) */ const surfaceArea = (r, h) =\u0026gt; 2 * Math.PI * r * (r + h); const volume = (r, h) =\u0026gt; Math.PI * r * r * h; for (const [r, h] of [[1, 1], [1, 2], [2, 1]]) { console.log( \u0026#39;Cylinder ${r} x ${h} \u0026#39;, \u0026#39;Surface area: ${surfaceArea(r, h)}\u0026#39;, \u0026#39;Volume: ${volume(r, h)}\u0026#39; ); } 타입 중복은 어떻게 해결할 수 있을까? # 타입 중복은 코드 중복만큼이나 많은 문제를 발생시킨다.\ninterface Person { firstName: string; lastName: string; } interface PersonWithBirthDate { firstName: string; lastName: string; birth: Date; } 여기에 middleName 과 같은 속성이 추가되면 별도의 클래스가 한 개 더 생성될 것이다.\n타입에서도 DRY 원칙을 적용시킬 수 있다.\n/* 예시 : 시그니처 추출/분리 */ /* 개선 전 */ function get(url: stirng, opts: Options): Promise\u0026lt;Response\u0026gt; { /* ... */} function post(url: stirng, opts: Options): Promise\u0026lt;Response\u0026gt; { /* ... */} /* 개선 후 */ type HttpFunction = (url: string, opts: Options) =\u0026gt; Promise\u0026lt;Response\u0026gt;; const get: HttpFunction = (url, opts) =\u0026gt; { /* ... */} const post: HttpFunction = (url, opts) =\u0026gt; { /* ... */} /* 예시 : 상속 */ /* 개선 전 */ interface Person { firstName: string; lastName: string; } interface PersonWithBirthDate { firstName: string; lastName: string; birth: Date; } /* 개선 후 */ interface Person { firstName: string; lastName: string; } interface PersonWithBirthDate extends Person { birth: Date; } // 아래와 같은 방법도 가능하다. // type PersonwithBirthDate = Person \u0026amp; { birth: Date }; /* 개선 전 */ interface State { userId: string; pageTitle: string; recentFiles: string[]; pageContents: string; } interface TopNavState { userId: string; pageTitle: string; recentFiles: string[]; } /* 개선 후 */ interface State { userId: string; pageTitle: string; recentFiles: string[]; pageContents: string; }; type TopNavState { userId: State[\u0026#39;userId\u0026#39;]; pageTitle: State[\u0026#39;pageTitle\u0026#39;]; recentFiles: State[\u0026#39;recentFiles\u0026#39;]; // State 의 부분 집합으로 TopNavState 를 정의한다. // State 를 인덱싱하여 \u0026#39;속성의 타입\u0026#39;에서 중복을 제거할 수 있다. }; type TopNavState { [k in \u0026#39;userId\u0026#39; | \u0026#39;pageTitle\u0026#39; | \u0026#39;recentFiles\u0026#39;]: State[k] // \u0026#39;매핑된 타입\u0026#39;을 사용해서 조금 더 개선할 수 있다. }; \u0026lsquo;매핑된 타입\u0026rsquo;은 \u0026lsquo;배열의 필드\u0026rsquo;를 \u0026lsquo;루프(Loop)\u0026rsquo; 도는 것으로 이해하면 된다.\ntype Pick\u0026lt;T, K\u0026gt; = { [k in K]: T[k] }; type TopNavState = Pick\u0026lt;State, \u0026#39;userId\u0026#39; | \u0026#39;pageTitle\u0026#39; | \u0026#39;recentFiles\u0026#39;\u0026gt;; interface SaveAction { type: \u0026#39;save\u0026#39;; //... } interface LoadAction { type: \u0026#39;load\u0026#39;; //... } type Action = SaveAction | LoadAction; type ActionType = \u0026#39;save\u0026#39; | \u0026#39;load\u0026#39;; type ActionType = Action[\u0026#39;type\u0026#39;] // 타입은 \u0026#34;save\u0026#34; | \u0026#34;load\u0026#34; // [참고] type ActionRec = Pick\u0026lt;Action, \u0026#39;type\u0026#39;\u0026gt;; // {type: \u0026#34;save\u0026#34; | \u0026#34;load\u0026#34;} /* 개선 전 */ interface Options { width: number; height: number; color: string; label: string; } interface OptionsUpdate { width?: number; height?: number; color?: string; label?: string; } /* 개선 후 */ interface Options { width: number; height: number; color: string; label: string; } type OptionsUpdate = {[k in keyof Options] ?: Options[k]}; // type OptionsUpdate = {[k in \u0026#34;width\u0026#34; | \u0026#34;height\u0026#34; | \u0026#34;color\u0026#34; | \u0026#34;label\u0026#34;] ?: Options[k]}; // keyof Options =\u0026gt; \u0026#34;width\u0026#34; | \u0026#34;height\u0026#34; | \u0026#34;color\u0026#34; | \u0026#34;label\u0026#34; typeof : \u0026lsquo;값\u0026rsquo;으로부터 \u0026lsquo;타입\u0026rsquo;을 정의할 수도 있다.\nconst INIT_OPTIONS = { width: 640, height: 640, color: \u0026#39;#00FF00\u0026#39;, label: \u0026#39;VGA\u0026#39;, } type Options = typeof INIT_OPTIONS; /* 아래와 같다. */ /* interface Options { width: number; height: number; color: string; label: string; } */ 값으로부터 타입을 만들어 낼 때는 선언의 순서에 주의해야 한다.\n되도록 타입 정의를 먼저 하고 값이 그 타입에 할당 가능하다고 선언하는 것을 권장한다. 그래야 타입이 더 명확해지고, 예상이 가능해진다. 즉, 값으로부터 추출하는 것 보다 타입을 먼저 정의하는 것을 권장한다. (?)\nReturnType : 함수/메서드의 반환 값에 명명된 타입을 추출할 수 있다.\nfunction getUserInfo(userId: string) { // ... return { userId, name, age, height, weight, favoriteColor, } } type UserInfo = ReturnType\u0026lt;typeof getUserInfo\u0026gt;; // type UserInfo = { userId: string; name: string; age: number; ...} ReturnType 은 함수의 \u0026lsquo;값\u0026rsquo;인 getUserInfo 가 아니라 함수의 \u0026lsquo;타입\u0026rsquo;인 typeof getUserInfo 에 적용된 것에 주의하자.\n이러한 표준 기술을 사용할 때 대상이 \u0026lsquo;값\u0026rsquo;인지, \u0026lsquo;타입\u0026rsquo;인지 확실하게 인지해야 한다.\n요약 \u0026amp; 정리 # 현재 ~ 앞으로 다양한 주제를 이야기하게 될 것이지만 원래의 목표(유효한 프로그램은 통과시키고 무효한 프로그램은 오류를 발생시키는 것)를 잊으면 안된다. DRY 원칙을 \u0026lsquo;타입\u0026rsquo;에도 최대한 적용해야 한다. 타입에서 반복을 피할 수 있다. 타입스크립트가 제공하는 도구들을 익히자. (keyof, typeof, 인덱싱, 매핑된 타입 등) 표준 라이브러리 도구들을 익히자. (Pick, Partial, ReturnType) "},{"id":43,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-15.-%EB%8F%99%EC%A0%81-%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%97%90-%EC%9D%B8%EB%8D%B1%EC%8A%A4-%EC%8B%9C%EA%B7%B8%EB%8B%88%EC%B2%98-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/","title":"아이템 15. 동적 데이터에 인덱스 시그니처 사용하기","section":"이펙티브 타입스크립트","content":" 아이템 15. 동적 데이터에 인덱스 시그니처 사용하기 # // JS const rocket = { name: \u0026#39;Falcon 9\u0026#39;, variant: \u0026#39;v1.0\u0026#39;, thrust: \u0026#39;4,940 kN\u0026#39;, } // TS (인덱스 시그니처 사용 예시) // Rocket = {[property: string]: string}; const rocket: Rocket = { name: \u0026#39;Falcon 9\u0026#39;, variant: \u0026#39;v1.0\u0026#39;, thrust: \u0026#39;4,940 kN\u0026#39;, } 위 예시에서 {[property: string]: string} 부분이 인덱스 시그니처이다.\n**세 가지 기능을 한다.** 기능 설명 키의 이름 키의 위치만 표시하는 용도 (* 타입 체커에서는 사용하지 않는다.) 키의 타입 string, number, symbol 의 조합 (* 보통은 string 을 사용한다.) 값의 타입 어떤 것이든 가능 단, 아래와 같은 특징(단점, 커버할 수 없는 것들)이 있다.\n설명 잘못된 키를 포함, 모든 키를 허용 - name 대신 Name 으로 작성해도 OK 특정 키가 필요하지 않음 - {} 도 OK 키마다 다른 타입을 가질 수 없음 - thrust 를 number 로 사용하고 싶은데, 그럴 수 없음 (예시 : name: 을 입력할 때)키는 무엇이든 가능하기 때문에 자동 완성 기능 활용 X 인덱스 시그니처는 동적 데이터를 표현할 때 사용할 수 있다. # function parseCSV(input: string): {[columnName: string]: string}[] { const lines = input.split(\u0026#39;\\n\u0026#39;); const [header, ..., rows] = lines; const headerColumns = header.split(\u0026#39;,\u0026#39;); return rows.map(rowStr =\u0026gt; { const row: {[columnName: string]: string} = {}; rowStr.split(\u0026#39;,\u0026#39;).forEach((cell, i) =\u0026gt; { row[headerColumns[i]] = cell; }); return row; }); } // 혹은 (string 을 보장할 수 없다면 undefined 를 추가할 수 있다.) function safeParseCsv(input: string): {[columnName: string]: string | undefined}[] { return parseCsv(input); } 위와 같이 (업로드된 파일을 파싱하는 등의)일반적인 상황에서 \u0026lsquo;열\u0026rsquo;의 이름(header)이 무엇인지 미리 알 방법은 없다.\n이럴 때는 \u0026lsquo;인덱스 시그니처\u0026rsquo;를 사용할 수 있다.\n반면에 이미 \u0026lsquo;열\u0026rsquo;의 이름을 알고 있다면 인터페이스와 같은 것들을 사용하는 것이 훨씬 좋다.\nMap, Record, 매핑된 타입, interface 등을 사용할 수 있다. # Map\n연관배열의의 경우 객체에 인덱스 시그니처를 사용하는 대신 Map 타입을 사용할 수 있다.\nInterface\ninterface Vec3D { x: number; y: string; x: number; } Record\ntype Vec3D = Record\u0026lt;\u0026#39;x\u0026#39; | \u0026#39;y\u0026#39; | \u0026#39;z\u0026#39;, number\u0026gt;; // Type Vec3D = { // x: number; // y: number; // z: number; // } 매핑된 타입\ntype Vec3D = {[k in \u0026#39;x\u0026#39; | \u0026#39;y\u0026#39; | \u0026#39;z\u0026#39;]: number}; // Type Vec3D = { // x: number; // y: number; // z: number; // } type Vec3D = {[k in \u0026#39;x\u0026#39; | \u0026#39;y\u0026#39; | \u0026#39;z\u0026#39;]: k extends \u0026#39;y\u0026#39; ? string : number}; // Type Vec3D = { // x: number; // y: string; // z: number; // } 결론 : 인덱스 시그니처는 부정확하므로 더 나은 방법(interface, Record, 매핑된 타입, \u0026hellip;) 사용을 권장한다. # // 예시 : interface // 키마다 다른(다양한) 타입을 사용할 수 있다. interface Rocket { name: string; variant: string; thrust_kN: number; } const rocket: Rocket = { name: \u0026#39;Falcon heavy\u0026#39;, variant: \u0026#39;v1\u0026#39;, thrust_kN: 15200, } 요약 \u0026amp; 정리 # 런타임 때까지 객체의 속성을 알 수 없을 경우(예를 들어, 파일 업로드 후 파싱하는 경우)에만 \u0026lsquo;인덱스 시그니처\u0026rsquo;를 사용한다. 속성을 임의로 추가할 수 없으니까!! (by 잉여 속성 체크) 값이 있음을 보장할 수 없다면 undefined 를 사용할 수 있다. 가능하다면 인터페이스, Record, 매핑된 타입과 같은 (인덱스 시그니처보다)\u0026lsquo;정확한 타입\u0026rsquo;을 사용하는 것이 좋다. "},{"id":44,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-16.-number-%EC%9D%B8%EB%8D%B1%EC%8A%A4-%EC%8B%9C%EA%B7%B8%EB%8B%88%EC%B2%98%EB%B3%B4%EB%8B%A4%EB%8A%94-Array-%ED%8A%9C%ED%94%8C-ArrayLike%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/","title":"아이템 16. Number 인덱스 시그니처보다는 Array, 튜플, ArrayLike를 사용하기","section":"이펙티브 타입스크립트","content":" \u0026ldquo;자바스크립트는 이상하게 동작하기로 유명한 언어입니다.\u0026rdquo;\n아이템 16. number 인덱스 시그니처보다는 Array, 튜플, ArrayLike를 사용하기 # 자바스크립트에서 객체란 키/값 쌍의 모음입니다.\n키 : 보통 문자열 (ES2015 이후로는 \u0026lsquo;심벌\u0026rsquo;도 가능) \u0026lsquo;숫자\u0026rsquo; 불가 : \u0026lsquo;숫자\u0026rsquo;를 키로 사용할 경우 런타임에 \u0026lsquo;문자열\u0026rsquo;로 변환됩니다. 값 : 어떤 것이든 가능 파이썬이나 자바에서 볼 수 있는 \u0026lsquo;해시 가능(hashable)\u0026rsquo; 객체라는 표현이 자바스크립트에서는 없습니다. 만약 더 복잡한 객체(심볼)을 \u0026lsquo;키\u0026rsquo;로 사용하려고 하면, toString 메서드가 호출되어 객체가 문자열로 변환됩니다.\n배열 # 배열은 객체이다. →(그럼에도) 배열에 숫자 인덱스를 사용하는 것은 당연 시 되어왔다. →이것들도 런타임 시에 \u0026lsquo;문자열\u0026rsquo;로 변환된다.\n배열의 키를 출력하면 키가 문자열로 출력되는 것을 확인할 수 있다.\nx = [1, 2, 3] Object.keys(x) // [\u0026#39;0\u0026#39;, \u0026#39;1\u0026#39;, \u0026#39;2\u0026#39;] 타입스크립트에서는? # 타입스크립트에서는 이러한 혼란을 개선하기 위해 \u0026lsquo;숫자 키\u0026rsquo;를 허용한다.\n\u0026lsquo;문자열 키\u0026rsquo;와 다른 것으로 인식한다.\n다만, 런타임 시에는 역시 \u0026lsquo;문자열 키\u0026rsquo;로 변환되어 사용된다. (결국에 js 로 변환/사용되는 것이니까)\n타입스크립트에서 가능하다는 것은 \u0026lsquo;타입 체크 시점에 오류를 잡을 수 있는 것\u0026rsquo; 을 의미한다.\n이 부분은 오히려 혼란을 야기시킬 수도 있긴하다. 다만, 책에서는 일반적으로 string 대신 number 를 타입의 인덱스로 사용할 이유는 많지 않다고 한다.\n+ for-loop 관련하여\u0026hellip; # for-in\nconst keys = Object.kins(xs); for (const key in xs) { key; // string const x = xs[key]; // number // (책에서) for-in 에서는 string-\u0026gt;number 로의 변환에 대해서 예외적으로(?) 허용한다고 생각하면 된다고 한다. } 인덱스를 신경 쓰지 않는다면 : for-of\nfor (const x of xs) { x; } 인덱스의 타입이 중요하다면 : forEach\nxs.forEach((x, i) -\u0026gt; { i; x; }) loop 중간에 멈춰야 한다면 : for(;;)\nfor (let i = 0; i \u0026lt; xs.length; i++) { const x = xs[i]; if (x\u0026lt;0\u0026gt;) break; } 타입이 불확실하다면, (대부분의 브라우저, 자바스크립트 엔진에서) for-in 루프는 (for-of, for(;;))에 비해 몇 배나 느리다.\n숫자 인덱스 대신 Array, 튜플, ArrayLike # 이 부분은 실제 사용 후 다시 공감해볼 것\n요약 \u0026amp; 정리 # 키 : 문자열 타입스크립트에서 사용하는 \u0026lsquo;키가 number 인 것\u0026rsquo;은 순수 타입스크립트에서(타입 체크)만 동작하는 코드 숫자 인덱스 대신 Array, 튜플, ArrayLike "},{"id":45,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-19.-%EC%B6%94%EB%A1%A0-%EA%B0%80%EB%8A%A5%ED%95%9C-%ED%83%80%EC%9E%85%EC%9D%84-%EC%82%AC%EC%9A%A9%ED%95%B4-%EC%9E%A5%ED%99%A9%ED%95%9C-%EC%BD%94%EB%93%9C-%EB%B0%A9%EC%A7%80%ED%95%98%EA%B8%B0/","title":"아이템 19. 추론 가능한 타입을 사용해 장황한 코드 방지하기","section":"이펙티브 타입스크립트","content":" 아이템 19. 추론 가능한 타입을 사용해 장황한 코드 방지하기 # \u0026quot; 타입 구문을 생략하여, 방해되는 것들을 최소화하고 코드를 읽는 사람이 구현 로직에 집중할 수 있게 해주는 것이 좋습니다. \u0026ldquo;\n대부분의 경우 타입스크립트에서 타입 구문은 불필요하다.\n타입을 선언하는 것은 \u0026lsquo;비생상적\u0026rsquo;, \u0026lsquo;형편없는 스타일\u0026rsquo;로 여겨진다.\nlet x: number = 12; // vs // x: number = 12; (코드를 보면서) 타입을 확신하지 못한다면 편집기(IDE)를 통해 체크할 수 있다.\nㄴ 이 문장은 \u0026lsquo;타입이 명시적으로 있는 게 좋지 않은가?\u0026rsquo; 나의 질문에 대한 답변이 되었다.\n타입스크립트는 우리가 예상한 것보다 더 정확하게 추론하기도 한다. # const axis1: string = \u0026#39;x\u0026#39;; // 타입: string const axis2 = \u0026#39;y\u0026#39;; // 타입 : \u0026#34;y\u0026#34; axis2 변수를 string 으로 예상하기 쉽지만, \u0026ldquo;y\u0026quot;가 더 정확한 타입이다.\n타입이 추론되면 리팩터링도 용이해진다. # interface Product { id: number; name: string; price: number; } function logProduct(product: Product) { const id: number = product.id; const name: string = product.name; const price: number = product.price; console.log(id, name, price); } 이후에 Product.id 를 number 에서 string 으로 변경이 필요했을 때를 가정한다.\nㄴ 타입 추론으로 작성했다면 logProduct 와 같은 다른 곳에서 코드 변경(number → string) 없이 사용할 수 있다.\n다만, 이게 좋은 것일까?\n개발자가 인지하지 못하면서, 자동으로 해주는 것은 이후에 사이드 이펙트로 연결되지 않나?\n(프로젝트 내에서는 트랜스 파일, 테스트 코드 등이 다 잡아줄 것 같긴 해서) 예시를 찾기가 쉽지는 않다.\n다른 프로젝트와 연계되었을 때를 생각해볼 수 있을 것 같다.\n따라서, 인지를 잘 하고 쓰는게 좋을 것 같다.\n비구조화 할당문을 사용할 수도 있다. # 위의 예시를 비구조화 할당문을 사용하여 작성할 수도 있다.\n비구조화 할당문은 모든 지역 변수의 타입이 추론되도록 한다.\nfunction logProduct(product: Product) { const {id, name, price} = product; console.log(id, name, price); } 타입 선언이 꼭 필요한 경우도 있다. # 정보가 부족해서 타입스크립트가 스스로 타입을 판단하기 어려운 경우도 있다. 이럴 경우 타입을 선언해줘야 한다.\n\u0026rdquo; 어떤 언어들은 매개변수의 최종 사용처까지 참고하여 타입을 추론하지만, 타입스크립트는 최종 사용처까지 고려하지 않습니다. \u0026ldquo;\n이상적인 타입스크립트의 경우 아래와 같이 작성한다.\n코드 타입 구문 여부 함수/메서드 시그니처 O - 기본값이 설정되어 있는 경우, 생략 OK - (타입 정보가 있는) 라이브러리, 콜백 함수의 시그니처, 생략 OK 함수 내에서 생성된 지역 변수 X // 예시 : 라이브러리, 콜백 함수의 시그니처, 생략 OK app.get(\u0026#39;/health\u0026#39;, (request: express.Request, response: express.Response) =\u0026gt; { response.send(\u0026#39;OK\u0026#39;); }) app.get(\u0026#39;/health\u0026#39;, (request, response) =\u0026gt; { response.send(\u0026#39;OK\u0026#39;); }) 타입 생략이 가능함에도, 타입을 명시하는 경우도 있다. # 1. 객체 리터럴\n타입 체크 ↑ 잉여 속성 체크 const elmo: Product = { name: \u0026#39;~\u0026#39;, id: \u0026#39;~\u0026#39;, price: 28.00, }; 2. 함수 반환\n타입 체크 ↑ 함수 이해도(입,출력 타입) ↑ 명명된 타입 사용 (= 직관적 표현) function getQuote(ticker: string): Promise\u0026lt;number\u0026gt; { ... } no-inferrable-types # 이 옵션을 통해 작성된 모든 타입 구문이 정말로 필요한지 확인할 수 있다.\n요약 \u0026amp; 정리 # 타입 추론이 가능하다면, 불필요한 타입 선언을 하지 않는 것을 권장한다. 타입 명시 비교 : 함수/메서드 시그니처 O \u0026lt;-\u0026gt; 지역변수 X 타입 명시 고려 대상 : 객체 리터럴, 함수 반환 O "},{"id":46,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-20.-%EB%8B%A4%EB%A5%B8-%ED%83%80%EC%9E%85%EC%97%90%EB%8A%94-%EB%8B%A4%EB%A5%B8-%EB%B3%80%EC%88%98-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/","title":"아이템 20. 다른 타입에는 다른 변수 사용하기","section":"이펙티브 타입스크립트","content":" 아이템 20. 다른 타입에는 다른 변수 사용하기 # 결론 = 한 변수(명)를 무분별하게 재사용하지 말자.\n자바스크립트에서는 한 변수에 다른 타입을 재사용할 수 있다.\n타입스크립트에서는 한 변수에 다른 타입을 재사용할 수 없다. (= 타입 체커에서 걸린다.)\n// js : O // ts : X let id = \u0026#34;12-34-56\u0026#34;; id = 123456; \u0026quot; 변수의 \u0026lsquo;값\u0026rsquo;은 바뀔 수 있지만 \u0026lsquo;타입\u0026rsquo;은 보통 바뀌지 않는다. \u0026ldquo;\n타입을 바꿀 수 있는 한 가지 방법 : \u0026lsquo;(타입의)범위를 좁히는 것\u0026rsquo; # \u0026lsquo;타입을 더 작게 제한하는 것\u0026rsquo;을 의미한다.\n\u0026rdquo; 이 방법은 어디까지나 예외이지 규칙은 아니다. (= 권장하지 않는다?) \u0026ldquo;\nlet id: string|number = \u0026#34;12-34-56\u0026#34;; id = 123456; // 정상 이는 더 많은 문제점을 야기시킨다.\n코드 가독성을 떨어뜨린다. 이 변수를 사용할 때마다 타입을 확인해야한다. (string 타입인지, number 타입인지, \u0026hellip;) 별도의 변수를 사용하는 것을 권장한다. # const id = \u0026#34;12-34-56\u0026#34;; const serial = 123456; 아래와 같은 이점이 있다.\n가독성 향상 간결성 향상 타입 추론 향상 let 대신 const 사용 OK \u0026rdquo; 타입이 바뀌는 변수는 되도록 피해야 하며, 목적이 다른 곳에는 별도의 변수명을 사용해야 한다. \u0026ldquo;\n\u0026lsquo;재사용되는 변수\u0026rsquo; vs \u0026lsquo;가려지는 변수\u0026rsquo; # (위에서 설명한)\u0026lsquo;재사용되는 변수\u0026rsquo;와 \u0026lsquo;가려지는 변수\u0026rsquo;를 구분할 수 있어야 한다. (혼동해서는 안된다.)\n/** 예시 : 가려지는 변수 */ let id = \u0026#34;12-34-56\u0026#34;; // ... { const id = 123456; // 정상 //... } 여기서 두 id는 실제로는 서로 아무런 관계가 없다.\n요약 \u0026amp; 정리 # 변수의 \u0026lsquo;값\u0026rsquo;은 바뀔 수 있지만 \u0026lsquo;타입\u0026rsquo;은 보통 바뀌지 않는다. 타입이 다른 경우, 변수를 재사용하지 말자. "},{"id":47,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-21.-%ED%83%80%EC%9E%85-%EB%84%93%ED%9E%88%EA%B8%B0/","title":"아이템 21. 타입 넓히기","section":"이펙티브 타입스크립트","content":" 아이템 21. 타입 넓히기 # \u0026quot; 아이템 7에서 설명한 것처럼 런타임에 모든 변수는 유일한 값을 가집니다. \u0026ldquo;\n런타임(=자바스크립트) 시에는 모든 변수가 값을 가진다. 그러나 타입스크립트가 작성된 코드를 체크하는 정적 분석 시점에는, 변수는 \u0026lsquo;가능한 값들의 집합\u0026rsquo;인 타입을 가진다.\n넓히기 (widening) # 상수를 사용해서 변수를 초기화할 때, 타입을 명시하지 않으면 타입 체커는 타입을 추론/결정해야 한다. = \u0026lsquo;가능한 값들의 집합\u0026rsquo;(타입)을 추론해야 한다.\n타입스크립트에서는 이 과정을 \u0026lsquo;넓히기(widening)\u0026rsquo; 라고 부른다.\n\u0026lsquo;넓히기\u0026rsquo;가 진행될 때, 가능한 값의 범위를 최대한 좁히되 오류(잘못된 추론)는 발생하면 안된다. = \u0026lsquo;명확성\u0026rsquo;과 \u0026lsquo;유연성\u0026rsquo; 사이에 균형을 유지하려고 한다.\nlet x = \u0026#39;x\u0026#39;; 위 코드에서 x는 string 으로 추론된다.\n(let이기 때문에) x 에는 이후에\n'asdsadas' 라는 값이 들어갈 수도, 'dysdfds' 라는 값이 들어갈 수도 있다. 따라서, 타입스크립트는 \u0026lsquo;가능한 값의 범위(타입)\u0026lsquo;을 string 으로 추론했다.\n넓히기 제어 : const # 위의 예시를 아래와 같이 수정해보자.\nconst x = \u0026#39;x\u0026#39;; x 는 \u0026quot;x\u0026quot; 타입으로 추론된다.\n(const이기 때문에) x 에는 이후 값이 변경되지 않는다.\n따라서, 타입스크립트는 가능한 값의 범위를 최대한 구체적으로(좁게) 추론할 수 있다.\n\u0026rdquo; x는 재할당될 수 없으므로 타입스크립트는 의심의 여지 없이 더 좁은 타입(\u0026ldquo;x\u0026rdquo;)로 추론할 수 있다. \u0026ldquo;\n그러나 const 가 만능은 아니다. (with 객체, 배열) # 객체, 배열인 경우에는 여전히 문제가 남아있다.\n요소들을 어떤 타입으로 추론해야할 지 알 수 없기 때문이다.\n객체의 경우 타입스크립트의 넓히기 알고리즘은 각 요소를 let 으로 할당된 것처럼 다룬다. = 추상적인 타입으로 추론해야 한다. = 구체적인 타입(좁은 타입)으로 추론할 수 없다.\n타입 추론의 강도를 제어하는 방법 1 : 명시적 타입 구문 # 명시적으로 타입을 작성해준다.\nconst x: 1|3|5 = 1; 타입 추론의 강도를 제어하는 방법 2 : 추가적인 문맥 제공 # 함수의 매개변수로 값을 전달하거나하는 등의 문맥을 의미한다.\n타입 추론의 강도를 제어하는 방법 3 : const 단언문 # 변수 선언 시에 사용하는 let, const 와 혼동해서는 안된다.\n값 뒤에 타입 단언(as const)을 사용하면 타입스크립트는 \u0026lsquo;최대한 좁은 타입\u0026rsquo;으로 추론한다.\nconst v1 = { x: 1, y: 2, }; // 타입 : { x: number; y: number; } const v1 = { x: 1 as const, y: 2, }; // 타입 : { x: 1; y: number; } const v1 = { x: 1, y: 2, } as const; // 타입 : { readonly x: 1; readonly y: 2; } const a1 = [1, 2, 3]; // 타입 : number[] const a2 = [1, 2, 3] as const; // 타입 : readonly [1, 2, 3] * 넓히기로 인해 오류가 발생한다고 생각되면, 타입 추론의 강도를 제어하는 방법(명시적 타입 구문, 추가적인 문맥 제공, const 단언문)을 고려할 수 있다.\n요약 \u0026amp; 정리 # \u0026lsquo;넓히기\u0026rsquo; 개념을 이해하자. 동작(or 추론)에 영향을 주는 const, 타입 구문, 문맥, as const 를 이해하자. "},{"id":48,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-23.-%ED%95%9C%EA%BA%BC%EB%B2%88%EC%97%90-%EA%B0%9D%EC%B2%B4-%EC%83%9D%EC%84%B1%ED%95%98%EA%B8%B0/","title":"아이템 23. 한꺼번에 객체 생성하기","section":"이펙티브 타입스크립트","content":" 아이템 23. 한꺼번에 객체 생성하기 # 변수의 값은 변경될 수 있지만, 타입스크립트의 타입은 (일반적으로) 변경되지 않는다.\n즉, 객체를 생성할 때는 속성을 하나씩 추가하기보다는 여러 속성을 포함해서 \u0026lsquo;한꺼번에 생성해야 타입 추론에 유리\u0026rsquo;하다.\nconst pt = {}; pt.x = 3; pt.y = 4; » tsc example.ts example.ts:2:4 - error TS2339: Property \u0026#39;x\u0026#39; does not exist on type \u0026#39;{}\u0026#39;. 2 pt.x = 3; ~ example.ts:3:4 - error TS2339: Property \u0026#39;y\u0026#39; does not exist on type \u0026#39;{}\u0026#39;. 3 pt.y = 4; ~ (const pt = {}) pt 는 {} 값을 기준으로 타입 추론된다. 따라서 존재하지 않는 속성을 추가할 수 없다. (= 잉여 속성 체크(?))\n다만, 꼭 이렇게 속성을 따로따로 만들어야 한다면, 타입 단언문(as)을 사용할 수 있다.\ninterface Point { x:number; y:number; } const pt = {} as Point; pt.x = 3; pt.y = 4; \u0026quot; 물론 이 경우에도 선언할 때 객체를 한꺼번에 만드는 게 더 낫습니다. (아이템 9) \u0026ldquo;\n객체 전개 연산자 : ... # 요약 : 객체에 속성을 추가(= 타입스크립트가 새로운 타입을 추론할 수 있게)할 수 있다.\n\u0026lsquo;작은 객체\u0026rsquo;들을 조합해서 \u0026lsquo;큰 객체\u0026rsquo;를 만들어야 하는 경우에도 여러 단계를 거치는 것은 좋지 않다.\nconst pt = {x: 3, y: 4}; const id = {name: \u0026#39;Pythagoras\u0026#39;}; const namedPoint = {}; Object.assign(namedPoint, pt, id); console.log(namedPoint.name); // Error : \u0026#39;{}\u0026#39; 형식에 \u0026#39;name\u0026#39; 속성이 없습니다. (Property \u0026#39;name\u0026#39; does not exist on type \u0026#39;{}\u0026#39;) \u0026lsquo;객체 전개 연산자\u0026rsquo;를 사용하면 큰 객체를 한꺼번에 만들어 낼 수 있다.\nconst pt = {x: 3, y: 4}; const id = {name: \u0026#39;Pythagoras\u0026#39;}; const namedPoint = {...pt, ...id}; console.log(namedPoint.name); // 출력 : Pythagoras » cat example.js var __assign = (this \u0026amp;\u0026amp; this.__assign) || function () { __assign = Object.assign || function(t) { for (var s, i = 1, n = arguments.length; i \u0026lt; n; i++) { s = arguments[i]; for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p]; } return t; }; return __assign.apply(this, arguments); }; var pt = { x: 3, y: 4 }; var id = { name: \u0026#39;Pythagoras\u0026#39; }; var namedPoint = __assign(__assign({}, pt), id); console.log(namedPoint.name); \u0026lsquo;객체 전개 연산자\u0026rsquo;를 사용하면 (타입 걱정 없이)필드 단위로 객체를 생성할 수도 있다.\n이때 모든 업데이트마다 \u0026lsquo;새 변수\u0026rsquo;를 사용하여 각각 \u0026lsquo;새로운 타입\u0026rsquo;을 얻도록 하는게 중요하다.\ninterface Point { x:number; y:number; } const pt0 = {}; const pt1 = {...pt0, x:3}; const pt: Point = {...pt1, y:4}; // 정상 » cat example.js var __assign = (this \u0026amp;\u0026amp; this.__assign) || function () { __assign = Object.assign || function(t) { for (var s, i = 1, n = arguments.length; i \u0026lt; n; i++) { s = arguments[i]; for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p]; } return t; }; return __assign.apply(this, arguments); }; var pt0 = {}; var pt1 = __assign(__assign({}, pt0), { x: 3 }); var pt = __assign(__assign({}, pt1), { y: 4 }); // 정상 조건부로 속성을 추가할 수도 있다.\ndeclare let hasMiddle: boolean; const firstLast = {first: \u0026#39;Harry\u0026#39;, last: \u0026#39;Truman\u0026#39;}; const president = {...firstLast, ...(hasMiddle ? {middle: \u0026#39;S\u0026#39;} : {})}; /* const president: { middle?: string; first: string; last: string; } */ » cat example.js var __assign = (this \u0026amp;\u0026amp; this.__assign) || function () { __assign = Object.assign || function(t) { for (var s, i = 1, n = arguments.length; i \u0026lt; n; i++) { s = arguments[i]; for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p]; } return t; }; return __assign.apply(this, arguments); }; var firstLast = { first: \u0026#39;Harry\u0026#39;, last: \u0026#39;Truman\u0026#39; }; var president = __assign(__assign({}, firstLast), (hasMiddle ? { middle: \u0026#39;S\u0026#39; } : {})); declare let hasDates: boolean; const nameTitle = {name: \u0026#39;kk\u0026#39;, title: \u0026#39;ph\u0026#39;}; const pharaoh = { ...nameTitle, ...(hasDates ? {start: -2589, end: -2566} : {}) }; /* const pharaoh { start: number; end: number; name: string; title: string; } | { name: string; title: string; } */ 선택적 필드(?:) 가 아닌 이유 : 2개 이상의 속성일 경우에는 유니온으로 처리된다.\n\u0026rdquo; 이 경우는 start와 end가 항상 함께 정의됩니다. 이 점을 고려하면 유니온을 사용하는 게 가능한 값의 집합을 더 정확히 표현할 수 있습니다. (아이템 32) \u0026ldquo;\n(위 예시) 선택적 필드 방식으로 표현하려면 (다음과 같이)헬퍼 함수를 사용할 수 있다.\n이 부분은 아직 이해 X 선택적 필드 방식으로 표현할 수 있다 정도만 이해하고 넘어간다.\nfunction addOptional\u0026lt;T extends object, U extends object\u0026gt;( a: T, b: U | null ): T \u0026amp; Partial\u0026lt;U\u0026gt; { return {...a, ...b}; } const pharaoh = addOptional( nameTitle, hasDates ? {start: -2589, end: -2566} : null ) \u0026rdquo; 가끔 객체나 배열을 변환해서 새로운 객체나 배열을 생성하고 싶을 수 있습니다. 이런 경우 루프 대신 내장된 함수형 기법 또는 로대시(Lodash)같은 유틸리티 라이브러리를 사용하는 것이 \u0026lsquo;한꺼번에 객체 생성하기\u0026rsquo; 관점에서 보면 옳습니다. \u0026ldquo;\n요약 \u0026amp; 정리 # (되도록) 한꺼번에 객체를 생성한다. 타입 추론(with 잉여 속성 체크) 객체 전개 연산자(...)를 이해한다. 참고 # [개발상식] lodash 알고 쓰자. lodash.com "},{"id":49,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-24.-%EC%9D%BC%EA%B4%80%EC%84%B1-%EC%9E%88%EB%8A%94-%EB%B3%84%EC%B9%AD-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/","title":"아이템 24. 일관성 있는 별칭 사용하기","section":"이펙티브 타입스크립트","content":" 아이템 24. 일관성 있는 별칭 사용하기 # 별칭의 값을 변경하면 원래 속성값도 변경된다. 별칭 남발 시, 코드를 분석하기 어렵다. const borough = { name: \u0026#39;Brooklyn\u0026#39;, location: [40, -73] } const loc = borough.location // 별칭의 값을 변경하면 원래 속성값도 변경된다. loc[0] = 0; console.log(borough.location) // [0, -73] 타입 체크 시에도 신경써야한다. # function isPointinPolygon(polygon: Polygon, pt: Coordinate) { polygon.bbox; // 타입 : BoundingBox | undefined const box = polygon.bbox; // 타입 : BoundingBox | undefined if (polygon.bbox) { polygon.bbox // 타입 : BoundingBox box // 타입 : BoundingBox | undefined } } 위 예시에서 타입 체크(속성 체크, if)는\npolygon.bbox 의 타입을 체크했다.(정제했다.) box 의 타입을 체크하지는 않았다. (정제하지는 않았다.) (일관된 이름 사용을 위해) 비구조화를 이용할 수 있다. # 객체 비구조화를 통해 간결한 문법으로 일관된 이름(변수명)을 사용할 수 있다.\nfunction isPointinPolygon(polygon: Polygon, pt: Coordinate) { const {bbox} = polygon; // 타입 : BoundingBox | undefined if (bbox) { const {x, y} = bbox; ... } } 별칭은 타입 체커뿐만 아니라 런타임에도 혼란을 야기할 수 있다. # 아래 예시는 별칭과 원본 값이 다른 값을 참조하는 예시이다.\n별칭 대입 시 위 예시들을 봤을 때는 주소 참조인 줄 알았는데, 주소 참조도 아닌 것 같고 어떻게 동작하는 건지 알아봐야할 것 같다.\nconst {bbox} = polygon; if (!bbox) { calculatePolygonBbox(polygon); // 이 함수에서 polygon.bbox 가 채워진다고 가정한다. // 이제 polygon.bbox 와 bbox 는 다른 값을 참조한다. } (제어 흐름 분석) 객체 속성에 대해서는 주의해야한다. # 아래 예시는 (객체에 대해서) 함수 호출 후, 객체의 속성이 변경될 수 있는 예시이다.\nfunction fn(p: Polygon) { /* ... */} polygon.bbox // 타입 : BoundingBox | undefined if (polygon.bbox) { polygon.bbox // 타입 : BoundingBox fn(poylgon); // 이 함수에서 polygon.bbox 의 값이 제거될 수 있다고 가정해보자. 그럼 밑의 polygon.bbox 의 타입은 BoundingBox | undefined 가 되어야할 것이다. polygon.bbox // 타입 : BoundingBox } 위 예시에서 fn(polygon) 과 같이 객체의 속성이 변경된다고 한다면\n맨 밑의 polygon.bbox 의 타입은 BoundingBox | undefined 가 되어야할 것이다. = 즉, 타입 정제에 대해서 무효화가 되는 것이다. = 이렇게 되면 함수를 호출할 때마다 속성 체크를 반복해야할 것이다.\n하지만 타입스크립트는 함수가 타입 정제를 무효화하지 않는다고 가정한다.\n그러나 실제로는 무효화될 가능성이 있다는 것을 인지해야 한다.\n요약 \u0026amp; 정리 # 별칭은 타입스크립트가 타입을 좁히는 것을 방해한다. 별칭 사용 시 일관되게 사용해야 한다. 비구조화 문법을 사용할 수 있다. 함수 호출이 객체 속성 타입 정제에 대해 무효화할 수 있다는 것을 인지해야 한다. 속성보다 지역변수 사용하면 타입 정제를 믿을 수 있다. 이번 아이템에서 \u0026lsquo;변수\u0026rsquo;와 \u0026lsquo;별칭\u0026rsquo;은 다른 의미로 쓰이고 있는 것 같으니, 주의한다.\n"},{"id":50,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-25.-%EB%B9%84%EB%8F%99%EA%B8%B0-%EC%BD%94%EB%93%9C%EC%97%90%EB%8A%94-%EC%BD%9C%EB%B0%B1-%EB%8C%80%EC%8B%A0-async-%ED%95%A8%EC%88%98-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/","title":"아이템 25. 비동기 코드에는 콜백 대신 Async 함수 사용하기","section":"이펙티브 타입스크립트","content":" 아이템 25. 비동기 코드에는 콜백 대신 async 함수 사용하기 # ES2015, 프로미스(promis) 개념이 도입되었다.\n프로미스는 미래에 가능해질 어떤 것을 나타낸다. (future) ES2017, async/await 키워드가 도입되었다.\nawait : 각각의 프로미스가 처리(resolve)될 때까지 함수의 실행을 멈춘다. async : 함수 내에서 await 중인 프로미스가 거절(reject)되면 예외를 던진다. 이를 통해 일반적인 try/catch 구문을 사용할 수 있다. 아래 예시를 살펴보자. 콜백 지옥, 프로미스, async/await 를 사용하여 코드를 개선한 예시이다.\n/** 예시 : 콜백 */ fetchURL(url1, function(response1) { fetchURL(url2, function(response2) { fetchURL(url3, function(response3) { //... console.log(1); }) console.log(2); }) console.log(3); }) console.log(4); /** 예시 : 프로미스 */ const page1Promise = fetch(url1); page1Promise.then(response1 =\u0026gt; { return fetch(url2); }).then(response2 =\u0026gt; { return fetch(url3); }).then(response3 =\u0026gt; { // ... }).catch(error =\u0026gt; { // ... }) /** 예시 : async/await */ async function fetchPages() { const response1 = await fetch(url1); const response2 = await fetch(url2); const response3 = await fetch(url3); } \u0026quot; ES 또는 더 이전 버전을 대상으로 할 때, 타입스크립트 컴파일러는 async와 await가 동작하도록 정교한 변환을 수행한다. 다시 말해, 타입스크립트는 런타임에 관계없이 async/await를 사용할 수 있다.\u0026quot;\n콜백보다 프로미스, async/await 를 사용해야 하는 이유 # 코드를 작성하기 쉽다. 타입을 추론하기 쉽다. 아래 예시는 (프로미스)병렬 처리 예시이다.\nasync function fetchPages() { const [response1, response2, response3] = await Promise.all([ fetch(url1), fetch(url2), fetch(url3) ]); // ... } 이런 경우 \u0026lsquo;await\u0026rsquo;, \u0026lsquo;구조 분해 할당\u0026rsquo;과 궁합이 잘 어울린다. (\u0026lt;- ?)\n타입스크립트는 3가지 response 변수 각각의 타입을 Response 로 추론한다.\n콜백 스타일로 코드를 작성하려면 더 많은 코드와 타입 구문이 필요하다.\nfunction fetchPagesCB() { let numDone = 0; const responses: string[] = []; const done = () =\u0026gt; { const [response1, response2, response3] = responses; // 구조 분해 할당 // ... }; const urls = [url1, url2, url3]; urls.forEach((url, i) =\u0026gt; { fetchURL(url, r =\u0026gt; { responses[i] = url; numDone++; if(numDone === urls.length) done(); }) }) } 이 코드에 \u0026lsquo;오류 처리\u0026rsquo;를 포함하거나 Promise.all 같은 일반적인 코드로 확장하는 것은 쉽지 않다.\nPromise.race # 한편 입력된 프로미스들 중 첫 번째가 처리될 때 완료되는 Promise.race 도 타입 추론과 잘 맞는다.\nPromise.race를 사용하여 프로미스에 \u0026lsquo;타임아웃\u0026rsquo;을 추가하는 방법은 흔하게 사용되는 패턴이다.\nfunction timeout(millis: number): Promise\u0026lt;never\u0026gt; { return new Promise((resolve, reject) =\u0026gt; { setTimeout(() =\u0026gt; reject(\u0026#39;timeout\u0026#39;), millis); }) } async function fetchWithTimeout(url: string, ms: number) { return Promise.race([fetch(url), timeout(ms)]); // 타입 : Promise\u0026lt;Response\u0026gt; } fetchWithTiemout 의 반환 타입은 Promise\u0026lt;Response\u0026gt; 이다.\n\u0026quot; Promise.race 의 반환 타입은 입력 타입들의 유니온이고, 이번 경우는 Promise\u0026lt;Response | never\u0026gt;가 된다. 그러나 never(공집합)와의 유니온은 아무런 효과가 없으므로, 결과(타입)가 Promise\u0026lt;Response\u0026gt;로 간단해진다. \u0026ldquo;\n\u0026rdquo; 프로미스를 사용하면 타입스크립트의 모든 타입 추론이 제대로 동작한다. \u0026ldquo;\n(선택의 여지가 있다면) 프로미스를 직접 생성하기 보다는 async/await 를 사용해야한다. (권장한다.) # 일반적으로 더 간결하고 직관적인 코드가 된다. async 함수는 항상 프로미스를 반환하도록 강제한다. 콜백, 프로미스(직접 사용)를 사용하면 반(half)동기 코드를 작성할 수 있다. async 사용하면 비동기를 보장한다. async 함수에서 프로미스 반환 시 또 다른 프로미스로 래핑되지 않는다. Promise\u0026lt;Promise\u0026lt;T\u0026gt;\u0026gt; 가 아니라, Promise\u0026lt;T\u0026gt;가 된다. async function getNumber() { // 타입 : Promise\u0026lt;number\u0026gt; return 42; } 위 처럼 즉시 사용 가능한 값(42)에도 프로미스를 반환하는 것이 이상하게 보일 수 있지만, 실제로는 비동기 함수로 통일하도록 강제하는 데 도움이 된다.\n함수는 항상 동기 또는 비동기로 실행되어야 하며 절대 혼용해서는 안된다.\n책에서 이에 대한 예시가 있다. 동기, 비동기를 혼용해서 사용하면 코드의 동작(결과)가 달라질 수 있다. (p140 ~ p141)\n요악 \u0026amp; 정리 # 콜백 \u0026laquo;\u0026laquo; 프로미스 \u0026laquo;\u0026laquo; async/await 코드 작성, 타입 추론 면에서 유리하다. 어떤 함수가 프로미스를 반환한다면 async로 선언하는게 좋다. "},{"id":51,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-26.-%ED%83%80%EC%9E%85-%EC%B6%94%EB%A1%A0%EC%97%90-%EB%AC%B8%EB%A7%A5%EC%9D%B4-%EC%96%B4%EB%96%BB%EA%B2%8C-%EC%82%AC%EC%9A%A9%EB%90%98%EB%8A%94%EC%A7%80-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0/","title":"아이템 26. 타입 추론에 문맥이 어떻게 사용되는지 이해하기","section":"이펙티브 타입스크립트","content":" 아이템 26. 타입 추론에 문맥이 어떻게 사용되는지 이해하기 # 이번 아이템에서 말하는 문맥이란, 상수를 그대로 사용하지 않고 변수(?), 별칭(?)과 같은 것(=문맥)을 의미한다.\n문맥을 사용했을 때, 타입 추론이 다르다는 것을 이야기하는 내용이다.\n아래 예시는, 문맥을 활용했을 때 타입추론이 어떻게 변하는지 보여주는 예시이다.\ntype Language = \u0026#39;Javascript\u0026#39; | \u0026#39;TypeScript\u0026#39; | \u0026#39;Python\u0026#39; function setLanguage(language: Language) { /* ... */ } // 예시 1 : 상수 직접 사용 setLanguage(\u0026#39;Javascript\u0026#39;); // 예시 2 : 문맥 활용 let language = \u0026#39;Javascript\u0026#39;; setLanguage(language); // ~~~~~~~~ \u0026#39;string\u0026#39; 형식의 인수는 // \u0026#39;Language\u0026#39; 형식의 매개변수에 할당될 수 없습니다. 위 예시는 왜 오류가 나는지는 알 것이다.\n해결 방법 # (명시적) 타입 선언 상수 const 상수 단언 (as const) 해결 방법 : (명시적) 타입 선언 # let language: Language = \u0026#39;Javascript\u0026#39;; // 타입 : Language setLanguage(language); 해결 방법 : 상수 const # const language = \u0026#39;Javascript\u0026#39;; // 타입 : \u0026#39;Javascript\u0026#39; setLanguage(language); 해결 방법 : 상수 단언 as const # 상수(const)의 경우에는 \u0026lsquo;튜플\u0026rsquo;, \u0026lsquo;객체\u0026rsquo;, \u0026lsquo;콜백(함수)\u0026rsquo; 사용 시에는 문제가 해결되지 않는다.\n/* 문제 예시 : 튜플 */ function panTo(where: [number, number]) { /* ... */ } panTo([10, 20]); // OK const loc = [10, 20]; // 타입 : number[] panTo(loc); // ~~~ \u0026#39;number[]\u0026#39; 형식의 인수는 // \u0026#39;[number, number]\u0026#39; 형식의 매개변수에 할당될 수 없습니다. 위 예시에서 const loc = [10, 20] 은 number[] 로 타입이 추론되어 오류가 발생한다.\n/* 문제 예시 : 객체 */ type Language = \u0026#39;Javascript\u0026#39; | \u0026#39;TypeScript\u0026#39; | \u0026#39;Python\u0026#39;; interface GovernedLanguage { language: Language; organization: string; } function complain(language: GovernedLanguage) { /* ... */ } const ts = { language: \u0026#39;TypeScript\u0026#39;, // 타입 : string organization: \u0026#39;Mycrosoft\u0026#39;, // 타입 : string }; complain(ts); // ~~ \u0026#39;{ language: string; organization: string; }\u0026#39; 형식의 인수는 // \u0026#39;GovernedLanguage\u0026#39; 형식의 매개변수에 할당될 수 없습니다. // \u0026#39;language\u0026#39; 속성의 형식이 호환되지 않습니다. // \u0026#39;string\u0026#39; 형식은 \u0026#39;Language\u0026#39; 형식에 할당될 수 없습니다. 위 예시에서 language: 'TypeScript' 은 string 로 타입이 추론되어 오류가 발생한다.\n이때는 아래 방법으로 해결 가능하다.\n타입 선언 상수 단언 (as const, 상수 문맥) 다만, as const 의 경우 readonly 타입으로 적용되기 때문에 readonly 관련 오류가 또 발생할 수 있다. /* 예시 : 타입 선언 */ const loc: [number, number] = [10, 20]; panTo(loc); /* 예시 : 상수 단언 */ const loc = [10, 20] as const; panTo(loc); // ~~~ \u0026#39;readonly [10, 20]\u0026#39; 형식은 \u0026#39;readonly\u0026#39; 이며 // 변경 가능한 형식 \u0026#39;[number, number]\u0026#39;에 할당할 수 없습니다. 즉, 함수의 타입 시그니처를 수정할 수 없다면 타입 선언을 하면 된다.\n요약 \u0026amp; 정리 # (문맥에서 타입 추론 오류 시) 타입 선언, const, as const 를 사용할 수 있다. 변수를 뽑아서 사용할 때 오류가 발생한다면 타입 선언을 추가하자. 변수가 정말로 상수(readonly)라면 상수 단언(as const)을 사용해야 한다. 단, readonly 타입에 주의하자. "},{"id":52,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-27.-%ED%95%A8%EC%88%98%ED%98%95-%EA%B8%B0%EB%B2%95%EA%B3%BC-%EB%9D%BC%EC%9D%B4%EB%B8%8C%EB%9F%AC%EB%A6%AC%EB%A1%9C-%ED%83%80%EC%9E%85-%ED%9D%90%EB%A6%84-%EC%9C%A0%EC%A7%80%ED%95%98%EA%B8%B0/","title":"아이템 27. 함수형 기법과 라이브러리로 타입 흐름 유지하기","section":"이펙티브 타입스크립트","content":" 아이템 27. 함수형 기법과 라이브러리로 타입 흐름 유지하기 # 라이브러리는 타입스크립트와 조합하여 사용하면 더욱 빛을 발휘한다.\n이유는 타입 정보가 그대로 유지되면서 타입 흐름(flow)가 계속 전달되기 때문이다.\n즉, 타입이 추론되고 추론된 타입이 계속 사용되고, 사용되고, 사용된다.\n자바스크립트의 경우 라이브러리를 쓰는 것은 \u0026lsquo;고려 사항\u0026rsquo;이다. # 서드파티 라이브러리 종속성을 추가할 때 신중해야 한다.\n서드파티 라이브러리를 통해 시간, 비용이 많이 든다면 사용하지 않는게 나을 것이다.\n타입스크립트의 경우 라이브러리를 쓰는 것은 \u0026lsquo;필수\u0026rsquo;이다. (매우 권장) # 타입이 \u0026lsquo;정확하게\u0026rsquo; 추론된다.\n= 타입 추론을 더 확실하고 정확하게 사용할 수 있다.\n= 타입 정보를 참고하며 작업 가능하다.\n= 시간, 비용이 대부분의 경우 단축된다.\n아래는 로대시 라이브러리 사용 예시이다.\n타입이 정확하고 자유롭게 추론되는 것을 확인할 수 있다.\nconst namesA = allPlayers.map(player =\u0026gt; player.name) // 타입 : string[] const namesB = _.map(allPlayers, player =\u0026gt; player.name) // 타입 : string[] const namseC = _.map(allPlayers, \u0026#39;name\u0026#39;) // 타입 : string[] 요약 \u0026amp; 정리 # 직접 구현하기보다는 내장된 함수, 서드파티 라이브러리를 사용하자. (매우 권장) 타입 흐름(타입 추론) 개선 가독성 개선 "},{"id":53,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-28.-%EC%9C%A0%ED%9A%A8%ED%95%9C-%EC%83%81%ED%83%9C%EB%A7%8C-%ED%91%9C%ED%98%84%ED%95%98%EB%8A%94-%ED%83%80%EC%9E%85%EC%9D%84-%EC%A7%80%ED%96%A5%ED%95%98%EA%B8%B0/","title":"아이템 28. 유효한 상태만 표현하는 타입을 지향하기","section":"이펙티브 타입스크립트","content":" 타입 시스템의 큰 장점 중 하나는 데이터 타입을 명확히 알 수 있어 코드를 이해하기 쉽다는 것이다. 4장(타입 설계)에서는 타입 자체의 설계에 대해 다룬다. 대부분 다른 언어에서도 적용될 수 있는 아이디어다.\n아이템 28. 유효한 상태만 표현하는 타입을 지향하기 # 효과적으로 타입을 설계하려면, 유효한 상태만 표현할 수 있는 타입을 만들어 내는 것이 중요합니다.\ninterface State { pageText: string; isLoading: boolean; error?: string; } 위 타입이 페이지를 렌더링하는 상태를 나타낸다고 가정할 때, 이 타입은 애매하다. (모호하다.)\n즉 잘못된 타입(설계)이다. 어떻게 사용하느냐에 따라 다를 수도 있을 것 같다.\n예를 들어 다음과 같은 코드가 있다.\nfunction renderPage(state: State) { if(state.error) { // 에러 ... } else if(state.isLoading) { // 로딩 중... } else { // 정상 ... } } 위 코드에서 만약 \u0026rsquo;error 값이 있고\u0026rsquo;, isLoading 이 true 라면?\nerror 분기를 타겠지만 이건 의도한건가?\n이런 관점에서 이 타입은 명확하지 않다.\n아래와 같이 개선해볼 수 있다.\ninterface RequestPending { state: \u0026#39;pending\u0026#39;; } interface RequestError { state: \u0026#39;error\u0026#39;; error: string; } interface RequestSuccess { state: \u0026#39;ok\u0026#39;; pageText: string; } type RequestState = RequestPending | RequestError | RequestSuccess interface State { currentPage: string; requests: {[page: string]: RequestState}; } function renderPage(state: State) { const {currentPage} = state; const requestState = state.requests[currentPage]; switch(requestState.state) { case \u0026#39;pending\u0026#39;: // pending ... case \u0026#39;error\u0026#39;: // error ... case \u0026#39;ok\u0026#39;: // ok ... } } 요청에 대한 각각의 상태를 명시적으로 모델링하는 태그된 유니온(또는 구별된 유니온) 을 사용했다.\n이 상태는 무효한 상태를 허용하지 않는다. 각각의 상태에서 발생할 수 있는 요청의 모든 상태를 표현한다.\n이후 책에서 설명하는 에어프랑스 447 항공편 에어버스 이야기가 재밌다.\n유효한 상태를 표현하는 값만 허용한다면 코드를 작성하기 쉬워지고 타입 체크가 용이해진다. # 타입을 설계할 때는 어떤 값들을 포함하고, 어떤 값들을 제외할지 신중하게 생각해야 한다.\n유효한 상태를 표현하는 것에 집중하자.\n요약 \u0026amp; 정리 # 유효한 상태와 무효한 상태를 둘 다 표현하는 타입은 혼란을 초래하기 쉽다. (+ 오류를 유발하기 쉽다.) 유효한 상태만 표현하는 타입을 지향해야 한다. 코드가 길어지거나 표현하기 어려울 수 있다. 하지만 결국에는 시간을 절약하고 고통을 줄일 수 있다. "},{"id":54,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-29.-%EC%82%AC%EC%9A%A9%ED%95%A0-%EB%95%8C%EB%8A%94-%EB%84%88%EA%B7%B8%EB%9F%BD%EA%B2%8C-%EC%83%9D%EC%84%B1%ED%95%A0-%EB%95%8C%EB%8A%94-%EC%97%84%EA%B2%A9%ED%95%98%EA%B2%8C/","title":"아이템 29. 사용할 때는 너그럽게, 생성할 때는 엄격하게","section":"이펙티브 타입스크립트","content":" 아이템 29. 사용할 때는 너그럽게, 생성할 때는 엄격하게 # \u0026quot; 아이템 29의 제목은 TCP 관련해서 존 포스텔이 쓴 견고성 원칙(포스텔의 법칙)에서 따왔습니다. \u0026ldquo;\n\u0026rdquo; TCP 구현체는 견고성의 일반적 원칙을 따라야 한다. 당신의 작업은 엄격하게 하고, 다른 사람의 작업은 너그럽게 받아들여야 한다. \u0026ldquo;\n함수의 시그니처에도 비슷한 규칙을 적용해야 한다. # 함수의 매개변수는 타입의 범위가 넓어도 되지만, 결과를 반환할 때는 일반적으로 타입의 범위가 더 구체적이어야 한다.\n어떤 함수의 반환타입의 범위가 넓으면 사용하기 불편하다.\n사용하기 편리한 API일수록 반환 타입이 엄격하다.\n예시 생략\n어쩔 수 없이 다양한 타입을 허용해야 하는 경우가 생길 수 있다.\n다만 이때도 나쁜 설계일 수 있다는 것을 인지해야 한다.\n요약 \u0026amp; 정리 # 기본 형태(반환 타입)와 느슨한 형태(매개변수 타입)를 도입하는 것이 좋다. 매개변수 타입은 반환 타입에 비해 범위가 넓은 경향이 있다. 선택적 속성과 유니온 타입은 반환 타입보다 매개변수 타입에 더 일반적이다. "},{"id":55,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-30.-%EB%AC%B8%EC%84%9C%EC%97%90-%ED%83%80%EC%9E%85-%EC%A0%95%EB%B3%B4%EB%A5%BC-%EC%93%B0%EC%A7%80-%EC%95%8A%EA%B8%B0/","title":"아이템 30. 문서에 타입 정보를 쓰지 않기","section":"이펙티브 타입스크립트","content":" 아이템 30. 문서에 타입 정보를 쓰지 않기 # 주석을 통해 타입에 대해 설명하곤 한다.\n/** * 0개 또는 1개의 매개변수를 받습니다. * 매개변수가 없을 때는 표준 전경색을 반환합니다. */ function getForegroundColor(page?: string) { return page === \u0026#39;login\u0026#39; ? {r: 127, g: 127, b: 127} : {r: 0, g: 0, b: 0}; } 코드와 주석의 정보가 맞지 않는다.\n둘 중 어느것이 맞는지 판단해야하는 상황이 생긴다.\n코드를 수정하면서 함께 수정하지 않는 경우가 많다.\n함수의 입력, 출력을 코드(타입)로 표현하는 것이 주석보다 더 나은 방법이다. # 타입을 사용하여 코드를 분명하게 작성하는 것이 더 좋은 \u0026lsquo;정보 제공\u0026rsquo; 방법이다.\nfunction getForegroundColor(page?: string): Color { // ... } 추가적인 예시 \u0026amp; 권장사항은 다음과 같다. # 변경하면 안되는, 변경되지 않는 값이라면 readonly 를 쓸 수도 있다.\n변수명에 타입 정보를 넣지 않도록 한다.\nageNumber 대신 age: number 와 같이 작성할 수 있다. 변수명에 헷갈리고 타입으로 표현하기 힘든 것들(\u0026lsquo;단위 정보\u0026rsquo; 같은)을 포함하는 것은 고려해볼만 하다.\ntimeMs, timeNs 요약 \u0026amp; 정리 # 주석, 변수명에 타입 정보를 적는 것은 피해야 한다. 타입이 명확하지 않는 경우, 변수명에 \u0026lsquo;단위 정보\u0026rsquo;를 포함하는 것은 고려해볼만 하다. timeMs, timeNs "},{"id":56,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-31.-%ED%83%80%EC%9E%85-%EC%A3%BC%EB%B3%80%EC%97%90-null-%EA%B0%92-%EB%B0%B0%EC%B9%98%ED%95%98%EA%B8%B0/","title":"아이템 31. 타입 주변에 Null 값 배치하기","section":"이펙티브 타입스크립트","content":" 아이템 31. 타입 주변에 null 값 배치하기 # 값이 전부 null, null이 아닌 경우로 분명히 구분한다면 값이 섞여 있을 때보다 다루기 쉽다.\nif 혹은 !(단언) 을 통해 쉽게 타입을 좁힐 수 있다. 추가로 undefined 를 포함하는 객체는 다루기 어렵고 절대 권장하지 않는다.\n타입에 null 을 추가하는 방식으로 이러한 경우를 모델링할 수 있다.\nfunction extent(nums: number[]) { let result: [number, number] | null = null; for (const num of nums) { if(!result) { result = [num, num]; } else { result = [Math.min(num, results[0]), Math.min(num, results[1])] } } return result; } // 반환 타입(return result)이 [number, number] | null 이 되어서 사용하기가 더 수월해진다. // (= undefined 를 명시적으로 없애는 것이 중요하다고 말하는 것 같다.) null, null이 아닌 값을 섞어서 사용하면 안좋다. # class UserPosts { user: UserInfo | null; posts: Post[] | null; constructor() { this.user = null; this.posts = null; } async init(userId: string) { return Promise.all([ async () =\u0026gt; this.user = await fetchUser(userId), async () =\u0026gt; this.posts = await fetchPostsForUser(userId), ]); } getUserName() { // ...? } } 두 번의 네트워크 요청(fetchUser, fetchPostsForUser) 동안 user, posts 속성은 null 값이다.\n특정 시점에는 아래와 같은 경우의 수를 가질 수 있다. (두 변수에 대해서만 계산해도 4가지이다.)\nuser : null , posts : null user : not null , posts : not null user : null , posts : not null user : not null , posts : null 속성 값의 불확실성(null, not null)이 클래스의, 메서드의 모든 부분에 나쁜 영향을 미친다. = null 체크가 난무하고, 버그를 양산한다.\n아래와 같이 개선해볼 수 있다.\nclass UserPosts { user: UserInfo; posts: Post[]; constructor(user: UserInfo, posts: Post[]) { this.user = user; this.posts = posts; } static async init(userId: string): Promise\u0026lt;UserPosts\u0026gt; { const [user, posts] = await Promise.all([ fetchUser(userId), fetchPostsForUser(userId) ]); return new UserPosts(user, posts); } getUserName() { return this.user.name; } } UserPosts 클래스는 이제 null 인 경우의 수를 고려하지 않아도 된다. = 이제 클래스, 메서드를 작성하기 쉬워졌다.\n요약 \u0026amp; 정리 # 한 값의 null 여부가 다른 값의 null 여부에 암시적으로 관련되도록 설계하며 안된다. 즉, null 값들이 관계가 있어서 위의 예시처럼 n^2 와 같은 경우의 수가 나오지 않도록 한다. API 작성 시 \u0026lsquo;반환 타입\u0026rsquo;을 (전체가) null 이거나, (전체가) null 이 아니게 만들어야 한다. 클래스를 만들 때는 필요한 모든 값이 준비되었을 때 생성하여 null 이 존재하지 않도록 한다. strictNullChecks 를 설정하자. 아래 내용은 기억하자.\n\u0026quot; 클래스를 만들 때는 필요한 모든 값이 준비되었을 때 생성하여 null 이 존재하지 않도록 한다. \u0026ldquo;\n"},{"id":57,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/%EC%95%84%EC%9D%B4%ED%85%9C-33.-string-%ED%83%80%EC%9E%85%EB%B3%B4%EB%8B%A4-%EB%8D%94-%EA%B5%AC%EC%B2%B4%EC%A0%81%EC%9D%B8-%ED%83%80%EC%9E%85-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/","title":"아이템 33. String 타입보다 더 구체적인 타입 사용하기","section":"이펙티브 타입스크립트","content":" 아이템 33. string 타입보다 더 구체적인 타입 사용하기 # string 타입의 범위는 매우 넓다.(\u0026ldquo;a\u0026rdquo;, \u0026ldquo;b\u0026rdquo;, \u0026ldquo;casdsad\u0026rdquo;, \u0026hellip;)\n다음은 string 타입이 남발된 타입의 예시이다.\ninterface Album { artist: string; title: string; releaseDate: string; // 예를 들어, yyyy-mm-dd recordingType: string; // 예를 들어, \u0026#34;live\u0026#34; 또는 \u0026#34;studio\u0026#34; } string 은 다음과 같은 단점이 있다.\n예를 들어,\nrecordingType 에 \u0026ldquo;Live\u0026rdquo; 값이 들어가도, 타입 체커는 완벽하게 체크할 수 없다. releaseDate 에 \u0026ldquo;asdsad\u0026rdquo; 값이 들어가도, 타입체커는 완벽하게 체크할 수 없다. 혹은 매개변수의 순서가 바뀌어도 (releaseDate 위치에 recordingType 값을 넣는다던가\u0026hellip;) 다음과 같이 개선해볼 수 있다. # type RecordingType = \u0026#39;studio\u0026#39; | \u0026#39;live\u0026#39;; interface Album { artist: string; title: string; releaseDate: Date; recordingType: RecordingType; } 다음과 같은 이점이 있다.\n(타입을 명시적으로 정의함으로써) 다른 곳으로 값이 전달되어도, 타입 정보가 유지된다. 즉, 타입 정보를 계속 갖고간다. 타입을 명시적으로 정의하고, 해당 타입의 의미를 설명하는 주석을 붙여 넣을 수 있다. IDE 상에서 주석 및 타입 정보를 쉽게 확인 가능하다. keyof 연산자로 더욱 세밀하게 타입 체크가 가능하다. 아래는 추가적인 개선 예시이다.\n// 개선 X function pluck\u0026lt;T\u0026gt;(records: T[], key: string): any[] { return records.map(r =\u0026gt; r[key]); // ~~~~~~~~ \u0026#39;{}\u0026#39; 형식에 인덱스 시그니처가 없으므로 요소에 암시적으로 \u0026#39;any\u0026#39; 형식이 있습니다. } // 개선 function pluck\u0026lt;T\u0026gt;(records: T[], key: keyOf T) { return records.map(r =\u0026gt; r[key]); } // 개선의 개선 function pluck\u0026lt;T, K extends keyof T\u0026gt;(records: T[], key: K): T[K][] { return records.map(r =\u0026gt; r[key]); } 위(개선의 개선)와 같은 경우, 매개변수 타입이 정밀해진 덕분에 (IDE 단에서)자동완성 기능도 제공될 수 있다.\nstring 은 any와 비슷한 문제를 가지고 있다. # 무효한 값을 허용하고, 타입 간의 관계도 감춰버린다.\n타입 체커를 방해하고, 실제 버그를 찾지 못하게 한다.\nstring의 부분 집합을 정의하는 것은, js에 타입 안정성을 크게 높인다.\n요약 \u0026amp; 정리 # string 을 남발하여 선언된 코드를 피하자. 변수의 범위를 보다 정확하게 표현하자. string 타입보다는 리터럴 타입의 유니온을 사용할 수 있다. 객체의 속성 이름을 함수 매개변수로 받을 때는, string 보다 keyof T 를 사용하자. "},{"id":58,"href":"/docs/BOOKS/%EC%9E%90%EB%B0%94-ORM-%ED%91%9C%EC%A4%80-JPA-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/03%EC%9E%A5_%EC%98%81%EC%86%8D%EC%84%B1%EA%B4%80%EB%A6%AC/","title":"03장_영속성관리","section":"자바 ORM 표준 JPA 프로그래밍","content":" EntityManagerFactory, EntityManager # (보통) EntityManagerFactory를 생성할 때, 커넥션 풀을 만든다.\nEntityManager는 EntityManagerFactory 에서 생성한다.\nEntityManager는 데이터베이스 연결이 꼭 필요한 시점(like transaction)까지 커넥션(connection, conn)을 얻지 않는다.\n영속성 컨텍스트란? # \u0026lsquo;엔티티를 영구히 저장하는 환경\u0026rsquo; 이다. (EntityManager 로) entity 를 저장, 조회하면 EntityManager 는 영속성 컨텍스트에 entity 를 보관/관리한다. EntityManager 를 생성하면 \u0026lsquo;영속성 컨텍스트\u0026rsquo; 라는 것이 (한 개) 같이 생성된다. EntityManager 를 통해 영속성 컨텍스트에 접근,관리할 수 있다.\n즉, 애플리케이션과 DB 사이에서 객체를 보관하는 가상의 데이터베이스와 같은 역할을 한다. 영속성 컨텍스트 덕분에 1차 캐시, 동일성 보장, 쓰기 지연, 변경 감지, 지연 로딩 등의 기능을 사용할 수 있게 된다.\nem.persist(member); 위의 코드가 의미하는 것은 다음과 같다.\n\u0026quot; EntityManager 를 사용해서 member 엔티티를 영속성 컨텍스트에 저장한다. (간단하게는, member 엔티티를 저장한다.)\u0026quot;\nEntity 의 생명주기 # Entity 에는 4가지의 상태(생명주기)가 있다.\n비영속 상태(new/transient) : 영속성 컨텍스트와 전혀 관계가 없는 상태 영속 상태(managed) : 영속성 컨텍스트에 저장된 상태 준영속 상태(detached) : 영속성 컨텍스트에 저장되었다가 분리된 상태 삭제 상태(removed) : 삭제된 상태 준영속(detached) ↑ | | | 비영속(new) ------\u0026gt; 영속(managed) \u0026lt;------\u0026gt; DB | ↑ | | | | ↓ | 삭제(removed) ---------- 비영속 상태\n객체(엔티티)를 생성했을 때이다. (영속성 컨텍스트, DB 등과 전혀 관련이 없는) 순수한 Java 객체이다.\n영속 상태\nEntityManager 를 통해 객체(엔티티)를 영속성 컨텍스트에 저장했을 때이다. \u0026lsquo;영속성 컨텍스트에 저장한다\u0026rsquo;는 것은 \u0026lsquo;EntityManager(영속성 컨텍스트)가 관리하는 엔티티\u0026rsquo;라는 것을 의미한다.\n준영속 상태\n영속성 컨텍스트가 관리하던 객체(엔티티)가 더 이상 관리하지 않으면 준영속 상태가 된다. 영속성 컨텍스트를 닫거나(em.close()), 초기화하거나(em.clear()), 해당 엔티티를 명시적으로 분리하거나(em.detach()) 하면 준영속 상태가 된다.\n(준영속 상태에 관하여 조금 더 깊게 알아볼 필요가 있다.)\n삭제 상태\n객체(엔티티)를 영속성 컨텍스트(DB)에서 삭제한다.\n영속성 컨텍스트의 특징 # 1. 식별자 값이 반드시 있어야 한다.\n영속성 컨텍스트는 (관리하는)엔티티를 식별자 값(@Id)으로 구분한다. (식별자 값이 없으면 예외 발생한다.)\n2. flush : (영속성 컨텍스트에서 관리되고 있는) 엔티티의 내용이 실제 데이터베이스에 저장되는 시점이다.\n* 영속성 컨텍스트가 엔티티를 관리하여 얻는 장점은 무엇이 있을까?\n1차 캐시 동일성 보장 쓰기 지연 (트랜잭션 지원) Dirty checking (변경 감지) 지연 로딩 인메모리 상에서 객체를 관리하여 얻는 장점(DB와의 접촉 자제)들인 것 같다. 객체로써 관리할 수 있다는 장점도 자연스럽게 이어지는 것 같다.\n1차 캐시\n영속성 컨텍스트는(?, EntityManager는 이라고 하면 안되는건가(?)) 내부에 캐시(cache)를 가지고 있다. 이를 1차 캐시라고 한다. 1차 캐시는 영속상태의 엔티티가 저장되는 곳이다. (영속성 컨텍스트 내부에 Map 객체 가 있다. Key는 @Id 의 값이고, Value는 엔티티 인스턴스이다.)\n엔티티를 저장(save)하면 1차 캐시에 저장되는 것이고, 엔티티를 조회(find)하면 먼저 1차 캐시에서 찾고, (1차 캐시에 없으면) DB에서 찾는 것이다.\n만약 조회하고자 하는 엔티티가 1차 캐시에 없다면, DB에서 조회해올 것이다. DB에서 조회한 후에 1차 캐시에 저장(영속 상태로 관리)하고 이 객체(엔티티)를 반환한다.\n(위의 문장에서)엄밀히 구분하면 \u0026lsquo;영속성 컨텍스트는\u0026rsquo;이 아니라 \u0026lsquo;EntityManager는\u0026rsquo; 이 더 적절한 것은 아닌가? (영속성 컨텍스트 == EntityManager 와 같이 동일선상에서 보는 건가?)\n+ EntityManager 는 영속성 컨텍스트를 사용하기 위한 인터페이스라고 볼 수 있을 것 같다. ( https://docs.oracle.com/javaee/7/api/javax/persistence/EntityManager.html) 편의상(?) 영속성 컨텍스트 == EntityManager 라는 동일선상에서 보는 것 같다.(?)\n+ 1차 캐시를 통해 트랜잭션 격리 수준을 데이터베이스가 아닌 애플리케이션 차원에서 제공한다는 장점이 있다. ( = 이해할 것!)\n동일성 보장\n1차 캐시에 있는 같은 엔티티를 반환 == 같은 객체 == 동일성 보장\nMember member1 = em.find(Member.class, \u0026#34;member1\u0026#34;); Member member2 = em.find(Member.class, \u0026#34;member1\u0026#34;); System.out.println(a == b); // 참(true) * 동일성 : 실제로 인스턴스(참조 값)가 같다. 즉, == 의 값이 참이다.\n* 동등성 : 인스턴스가 갖고 있는 값이 같다. equals() 메서드의 값이 참이다. (equals() 가 구현되었다는 가정하에)\n쓰기 지연\n트랜잭션을 커밋(commit)하기 전까지 데이터베이스에 쿼리를 날리지 않는다. 즉, 데이터베이스에 엔티티(값)을 저장하지 않는다. 커밋하기 전까지는 내부의 쿼리 저장소에 쿼리문을 쌓아둔다. 트랜잭션을 커밋하면, 쌓아둔 쿼리를 DB에 보낸다. 이 과정(개념)을 트랜잭션을 지원하는 쓰기 지연이라고 한다.\n(영속성 컨텍스트, EntityManager에서) 트랜잭션을 커밋(commit) == 영속성 컨텍스트를 flush == 영속성 컨텍스트의 내용을 DB에 동기화하는 작업(즉, 삽입, 수정, 삭제의 내용을 반영) == 내부에 쌓아둔 쿼리를 DB에 보낸다.\n이후 실제 DB의 트랜잭션을 커밋(commit)한다.\n쓰기 지연이 가능한 이유는, \u0026ldquo;트랜잭션\u0026rdquo; 덕분이다. DB에 쿼리를 날리는 것은 결국에 (해당하는)트랜잭션이 끝나기 전에만 쿼리를 날리면 된다. 그렇기에 DB에 쿼리를 보내는 것은 일찍 보내든, 늦게 보내든 트랜잭션이 끝나기 전에만 보내지면 된다.\nDirty Checking(변경 감지)\n공감되는 문구가 있다. 기존 개발 방식(Update 쿼리를 작성하는 것)의 문제점은 비슷비슷한 수정 쿼리가 많아진다는 것, 많아짐에 따라 (분석을 위해) 계속해서 확인해야하는 것, (+ Query에 의존하게 된다는 것)\n(JPA)는 엔티티를 영속성 컨텍스트에 보관(관리를 시작)할 때, 최초의 상태를 복사하여 저장해둔다. 이것을 스냅샷이라고 한다. 이후 플러시 시점에 해당 엔티티와 스냅샷의 값을 비교해서 변경된 엔티티(혹은 부분/값)을 찾는다.\n* 당연하게도, 변경 감지는 영속성 컨텍스트가 관리하는 엔티티에만 적용이 된다. 비영속, 준영속 상태의 엔티티는 적용되지 않는다.\n흐름은 다음과 같다.\nflush() 엔티티와 스냅샷 비교하여 변경된 엔티티를 찾는다. 변경된 엔티티가 있다면, update 쿼리를 생성하여 쓰기 지연 sql 저장소에 보관한다. sql 저장소에서 DB로 쿼리를 보낸다. DB 트랜잭션을 커밋한다. 변경 감지로 인해 생성된 Update 쿼리는 모든 필드에 대한 update 쿼리를 생성하여 보낸다.\n예시는 다음과 같다.\n// (name 만 변경했을 때) 우리가 예상한 쿼리는 아래와 같을 것이다. update member set name = ? where id = ? 실제 발생하는 쿼리는 모든 필드에 대한 쿼리가 발생한다.\nupdate member set name = ?, age = ?, grade = ?, ... where id = ? 이렇게 모든 필드에 대한 쿼리가 발생하면 (데이터 전송량이 증가되니)단점이 아닌가? 라는 생각이 들 수 있다. 하지만 아래와 같은 장점이 더욱 많다고 한다.\n수정 쿼리가 항상 같다. (동일한 form 이다.) 따라서 애플리케이션 로딩 시점에 수정 쿼리를 미리 생성해두고 재사용할 수 있다. 데이터베이스 관점에서 동일한 쿼리(form)라면 이전에 한 번 파싱된 쿼리를 빠르게 재사용할 수 있다고 한다. + 필드가 너무 많거나, 수정하고자 하는 데이터가 너무 크다면(즉, 데이터 전송량이 너무 클 것 같다면) 동적으로 Update 쿼리를 생성하는 전략을 사용할 수도 있다. + 상황에 따라 다르지만, 컬럼(필드)이 대략 30개 이상이면 @DynamicUpdate 를 사용하는게 더 빠르다고 한다. (정확한 것은 직접 테스트해보는 것이다.) + 추천하는 것은 일단 정적 update 쿼리를 사용하고, 튜닝이 필요하다고 느낄 때 테스트 -\u0026gt; 사용 하는 것이다.\n@Entity @org.hibernate.annotations.DynamicUpdate \u0026lt;-- 이것! @Table(name = \u0026#34;Member\u0026#34;) public class Member { ... } 엔티티 삭제\n엔티티를 삭제하려면 먼저 대상 엔티티를 조회해야 한다. 삭제 역시 \u0026lsquo;쓰기 지연 SQL 저장소\u0026rsquo; 에서 query가 관리되고, 커밋(flush)시점에 쿼리를 DB에 전달한다.\n다만, 엔티티를 삭제하면(em.remove(entity)) 그 즉시 영속성 컨텍스트에서 제거(관리되지 않음)된다.\n이렇게 삭제된 엔티티는 재사용하지 말고 GC에 의해 자연스럽게 제거될 수 있도록 두는 것이 좋다.\n플러시(Flush) # * 플러시라는 이름으로 인해 영속성 컨텍스트에 보관된 엔티티를 지운다고 생각하면 안된다고 한다.\n* 영속성 컨텍스트의 변경 내용을 DB에 동기화하는 것이 \u0026lsquo;플러시\u0026rsquo;이다. * 데이터베이스와의 동기화는 최대한 늦춘다. (가능한 이유 = 트랜잭션이라는 작업 단위가 있기 때문이다.)\n플러시는(flush)는 영속성 컨텍스트의 내용(변경 내용)을 데이터베이스에 반영하는 것이다.\n구체적으로는 다음의 과정이 수행된다.\n변경 감지 동작 -\u0026gt; 영속성 컨텍스트에 있는 모든 엔티티들에 대하여 스냅샷 비교 -\u0026gt; 변경(수정)된 엔티티를 찾는다. 수정된 엔티티에 대해서는 update 쿼리를 만들어 \u0026lsquo;쓰기 지연 sql 저장소\u0026rsquo;에 쿼리를 등록한다. 쓰기 지연 SQL 저장소의 쿼리를 DB에 전송한다. (삽입, 수정, 삭제 쿼리) 영속성 컨텍스트를 플러시하는 방법은 3가지이다.\nem.flush() 직접 호출 트랜잭션 커밋 시 flush 자동 호출 jpql(criteria 등) 쿼리 실행 시 flush 자동 호출 (* 이 부분은 기억해두자! ) jpql 쿼리 실행 시 flush 가 자동으로 호출되는 이유\nem.persist(member1); em.persist(member2); em.persist(member3); query = em.createQuery(\u0026#34;select m from Member m\u0026#34;, Member.class); List\u0026lt;Member\u0026gt; members = query.getResultList(); (1차 캐시에서 가져오는 것이 아니기 때문에) 만약 jpql 실행 전에 flush가 되지 않는다면, jpql(sql)을 실행 시 member1, 2, 3이 조회되지 않을 것이다.\n(jpql 과 같이) 이렇게 sql 을 직접 수행하는 것에는 다 동일한 개념일 것이다.\n플러시 모드 옵션\nEntityManager 에 플러시 모드를 직접 지정할 수 있다.\nFlushModeType.AUTO : 커밋이나 쿼리를 실행할 때 플러시 (default) FlushModeType.COMMIT : 커밋할 때만 플러시 (간혹 성능 최적화를 위해 사용될 수 있다고 한다.) 준영속 # 영속성 컨텍스트에서 관리하던 엔티티가 분리된 것을 준영속 상태라고 한다. 준영속 상태의 엔티티는 영속성 컨텍스트가 제공하는 기능(1차 캐시, 쓰기 지연 SQL 저장소, dirty checking 등)을 사용할 수 없다.\n준영속 상태가 되는 순간 1차 캐시, 쓰기 지연 SQL 저장소에서 해당 엔티티와 관련된 모든 정보가 제거된다.\n준영속 상태로 만드는 방법은 3가지이다.\nem.detach(entity) : 특정 엔티티를 준영속 상태로 전환한다. 해당 엔티티와 관련된 1차 캐시, 쓰기 지연 SQL 저장소의 정보가 제거된다. em.clear() : 영속성 컨텍스트를 완전히 초기화한다. 즉, 1차 캐시, 쓰기 지연 SQL 저장소 등의 모든 정보가 초기화된다. em.close() : 영속성 컨텍스트를 종료한다. * 주로 영속성 컨텍스트가 종료되면서 영속 상태 -\u0026gt; 준영속 상태의 엔티티가 된다고 한다. 개발자가 직접 준영속 상태로 만드는 일은 드물다고 한다.\n준영속 상태의 특징\n비영속 상태와 거의 동일하다.\n영속성 컨텍스트가 관리하지 않으므로 1차 캐시, 쓰기 지연, 변경 감지, 지연 로딩 등의 어떠한 기능도 제공(동작)되지 않는다. 식별자 값을 가지고 있다.\n비영속 상태는 식별자 값이 있을 수도, 없을 수도 있다. 하지만 준영속 상태는 이미 한번은 영속 상태에 있었기에, 반드시 식별자 값을 가지고 있다. (식별자가 있다. = DB에 row가 있다. = 다시 영속 상태로 돌아올 때, 이전에 어떤 엔티티였는지 구분이 가능하다.) 지연 로딩이 불가능하다.\n지연 로딩은 실제 객체 대신 프록시 객체를 로딩해두고, 해당 객체가 실제로 사용될 때 영속성 컨텍스트를 통해 데이터를 불러오는 방법이다.\n준영속 상태에서는 영속성 컨텍스트가 더 이상 관리하지 않으므로 지연 로딩 시 문제가 발생된다. 병합(merge())\n비영속/준영속 상태의 엔티티를 다시 영속 상태로 변경하려면 \u0026lsquo;병합(merge())\u0026rsquo; 을 사용한다.\n병합(merge()) 은 비영속/준영속 상태의 엔티티를 받아서, 그 정보로 새오운 영속 상태의 엔티티를 반환한다.\n비영속 상태에서 병합할 때, 1차 캐시나 DB에 찾고자 하는 엔티티가 없다면 새로운 엔티티를 생성하는 개념이다.\n준영속 상태에서 병합할 때는, (무조건) DB에 찾고하는 엔티티가 있다. 그 엔티티를 1차 캐시로 조회해오고, 병합하는 개념이다.\n"},{"id":59,"href":"/docs/BOOKS/%EC%9E%90%EB%B0%94-ORM-%ED%91%9C%EC%A4%80-JPA-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/04%EC%9E%A5_%EC%97%94%ED%8B%B0%ED%8B%B0%EB%A7%A4%ED%95%91/","title":"04장_엔티티매핑","section":"자바 ORM 표준 JPA 프로그래밍","content":" 4장. 엔티티 매핑 # JPA 에서 지원하는 매핑 어노테이션은 크게 4가지로 분류할 수 있다.\n설명 어노테이션 객체 / 테이블 매핑 @Entity, @Table Primary 키 매핑 @Id 필드 / 컬럼 매핑 @Column 연관관계 매핑 @ManyToOne, @JoinColumn @Entity # 테이블과 매핑할 클래스에 @Entity 어노테이션을 사용한다.\n@Entity가 붙은 클래스는 JPA 가 관리하는 것이며, 엔티티라 부른다.\n주의사항\n기본 생성자(Default Constructor, @NoArgsConstructor)는 필수 final, enum, interface, inner 클래스에는 사용할 수 없다. 매핑할 필드(컬럼)에 final 값을 사용할 수 없다. @Table # 엔티티와 매핑할 테이블을 지정한다. (생략 시 엔티티 이름을 사용한다.)\n@Id # @Id 적용 가능한 자바 타입은 다음과 같다.\nprimitive type wrapper class type String java.util.Date java.sql.Date java.math.BigDecimal java.math.BigInteger * 개발자가 기본키를 직접 할당할 때에는 em.persist()로 엔티티를 저장하기 전에 (아래와 같이)애플리케이션에서 단에서 기본키를 직접 할당해야한다.\nBoard board = new Board(); board.setId(1); em.persist(board); @Column # 객체의 필드를 테이블의 컬럼에 매핑한다.\n* @Column 속성 중 name, nullable 이 주로 사용된다. (나머지는 자주 사용되지는 않는다고 한다.)\n속성 기능 기본값 name 필드, 컬럼 매핑 시 사용되는 이름 true insertable\n(거의사용되지않음) false 일 경우, 이 필드는 저장하지 않는다.\n읽기 전용일 때 사용하곤 한다. true updatable\n(거의사용되지않음) false 일 경우, 이 필드는 수정하지 않는다.\n읽기 전용일 때 사용하곤 한다. true table\n(거의사용되지않음) 하나의 엔티티를 두 개 이상의 테이블에 매핑할 때 사용한다. 지정한 필드를 다른 테이블에 매핑할 수 있다. 현재 클래스가 매핑된 테이블 nullable(DDL) null 제약, false 일 경우 not null 제약 true unique(DDL) 한 컬럼에 유니크 제약 조건 걸 수 있다. columnDefinition(DDL) 데이터베이스 컬럼 정보를 직접 줄 수 있다. length(DDL) 문자 길이 제약조건 (String 타입에만 적용 가능) 255 precision, scale(DDL) BigDecimal(BigInteger)타입에서 사용할 수 있다. precision은 소수점을 포함한 전체 자릿수를, scale은 소수의 자릿수다.\ndouble, float 타입에는 적용되지 않는다. 아주 큰 숫자, 정밀한 소수를 다룰 때 사용한다. precision=19\nscale=2 @Enumerated # enum 타입 매핑할 때 사용한다.\nORDINAL STRING @Temporal # 날짜 타입(java.util.Date, java.util.Calendar) 매핑 시 사용한다.\nTemporalType.DATE : 날짜, DB의 date 타입과 매핑된다. (e.g. 2013-10-11) TemporalType.TIME : 시간, DB의 time 타입과 매핑된다. (e.g. 12:30:30) TemporalType.TIMESTAMP: 날짜와 시간, DB의 timestamp 타입과 매핑된다. (e.g. 2013-10-11 12:30:30) 예시는 다음과 같다.\n@Temporal(TemporalType.DATE) private Date date; @Temporal(TemporalType.TIME) private Date time; @Temporal(TemporalType.TIMESTAMP) private Date timestamp; @Lob # BLOB, CLOB 타입과 매핑한다.\nBLOB : byte[], java.sql.BLOB CLOB : String, char[], java.sql.CLOB @Transient # 매핑하지 않는다는 의미이다. DB에 저장하지 않고 조회하지 않는다. 객체에 임시로 어떤 값을 보관하고 싶을 때 사용한다.\n@Access # JPA가 엔티티 데이터에 접근하는 방식을 지정한다.\nAccessType.FIELD : 필드 접근, 필드에 직접 접근한다. 필드 접근 권한이 private 여도 접근할 수 있다. AccessType.PROPERTY : 접근자(Getter)를 사용한다. "},{"id":60,"href":"/docs/BOOKS/%EC%9E%90%EB%B0%94-ORM-%ED%91%9C%EC%A4%80-JPA-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/13%EC%9E%A5_%EC%9B%B9-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98%EA%B3%BC-%EC%98%81%EC%86%8D%EC%84%B1-%EA%B4%80%EB%A6%AC/","title":"13장_웹 애플리케이션과 영속성 관리","section":"자바 ORM 표준 JPA 프로그래밍","content":" \u0026quot; 컨테이너 환경(스프링)에서 동작하는 JPA 내부 동작 방식을 이해해보자 \u0026ldquo;\n트랜잭션 범위의 영속성 컨텍스트 # 컨테이너의 도움 없이 순수 자바 환경에서 JPA 를 사용한다면, 아래와 같은 작업을 직접 처리해야 한다.\nEntityManager 관리 트랜잭션(Transaction) 관리 컨테이너(스프링)는 위와 같은 작업을 대신해준다. 따라서, 컨테이너가 제공하는 방법/전략(영속성 컨텍스트, 트랜잭션과의 관계)을 이해할 필요가 있다.\n스프링 컨테이너 기본 전략 : 트랜잭션 범위 = 영속성 컨텍스트 범위 # OSIV : false\n트랜잭션 범위와 영속성 컨텍스트의 생존 범위가 같다.\n트랜잭션 시작될 때, 영속성 컨텍스트 생성 같은 트랜잭션 = 같은 영속성 컨텍스트 트랜잭션 종료될 때, 영속성 컨텍스트 종료 준영속 상태가 되기 때문에 지연 로딩, 변경 감지와 같은 기능을 사용할 수 없다. JPA 표준에는 이 문제가 발생했을 때에 대해서 구체적으로 정의되지 않았다고 한다. 즉, 구현체마다 발생하는 예외가 다를 것이다. (하이버네이트 기준으로는, org.hibernate.LazyInitializationException 예외가 발생한다.) @Transactional 을 사용하면, 해당 메서드 실행 직전/직후에 스프링의 트랜잭션 AOP 가 동작한다.\n@Controller class MyController { @Autowired MyService myService; public void my() { My my = myService.getMy(); // \u0026#34;준영속 상태\u0026#34; } } (다양한 위치에서 엔티티 매니저를 주입받아 사용해도) 트랜잭션이 같다면 영속성 컨텍스트는 같다.\n반대로 트랜잭션이 다르다면, 영속성 컨텍스트는 다르다. Thread-Safe 를 보장한다. Thread 별로 서로 다른 트랜잭션/영속성 컨텍스트를 사용한다고 한다. @Service class MyService { @Autowired MyRepository1 myRepository1; @Autowired MyRepository2 myRepository2; @Transactional public void my() { // MyRepository1, MyRepository2 의 영속성 컨텍스트는 같다. myRepository1.findMy(); // MyRepository1 의 EntityManager myRepository2.findMy(); // MyRepository2 의 EntityManager } } 개발자가 직접 멀티 스레드 환경이나 영속성 컨텍스트/트랜잭션 등에 대해 관리했다고 한다면, 엄청 복잡했을 것이다.\n준영속 상태에서는 지연로딩을 활용할 수 없다.\n따라서, 아래와 같은 방법을 사용할 수 있다.\n페치 전략 변경 : LAZY -\u0026gt; EAGER 강제초기화 : LAZY 엔티티에 대해 강제로 초기화한다. (* 영속성 컨텍스트 종료 전에) JPA 표준 : 프록시 강제초기화 메서드를 제공하지 않는다. 단, 초기화 여부 확인 메서드는 제공한다. (PersistenceUnitUtil.isLoaded()) 하이버네이트 : 프록시 강제초기화 메서드를 제공한다. FETCH JOIN : fetch join 하여 초기화를 해둔다. FACADE 계층 추가 : Controller / Service 사이에 하나의 Layer 를 더 둔다. 여기서 @Transactional 시작한다. (전제 : Service 는 비즈니스 로직만 처리하고, 프리젠테이션 계층을 위한 초기화 작업 등은 새로운 Layer 에서 한다.) Front(View)에 맞는 데이터를 내려주기 위해 무분별하게 (service, repository) method 를 생성하는 것은 프리젠테이션 계층이 백엔드의 계층에 관여하는 것을 의미한다. (적당한 선에서 데이터를 공통으로 내려줄 수 있도록 하는 것이 좋을 수도 있다.) 이 부분을 인지하자.\nOSIV # 위의 \u0026lsquo;준영속 상태\u0026rsquo;와 관련된 문제를 해결하기 위해 나온 개념이다.\n영속성 컨텍스트를 View 단까지 열어둔다는 것이다.\nJPA 용어는 OEIV 라고 한다. 다만, 관례상 OSIV 로 부른다고 한다.\nJPA : OEIV (Open EntityManager In View) Hibernate : OSIV (Open Session In View) 아래와 같은 방식이 있는데, 이에 대한 자세한 글은 따로 작성한다.\n요청 당 트랜잭션 요청 시 : 트랜잭션, 영속성 컨텍스트 생성 응답 시 : 트랜잭션, 영속성 컨텍스트 종료 (스프링에서 제공하는) 비즈니스 계층 트랜잭션 요청 시 : 영속성 컨텍스트 생성 @Transactional 시 : 트랜잭션 생성 ~ 종료 응답 시 : 영속성 컨텍스트 종료 스프링 프레임워크가 제공하는 OSIV 라이브러리는 다음과 같다.\n아래의 원하는 필터/인터셉터를 등록하면 된다.\nVendor 적용 시점 Class JPA 서블릿 필터 org.springframework.orm.jpa.support.OpenEntityManagerInViewFilter JPA 스프링 인터셉터 org.springframeowkr.orm.jpa.support.OpenEntityManagerInViewInterceptor Hibernate 서블릿 필터 org.springframework.hibernate4.support.OpenSessionInViewFilter Hibernate 스프링 인터셉터 org.springframework.hibernate4.support.OpenSessionInViewInterceptor 트랜잭션 없이 읽기\n스프링의 비즈니스 계층 트랜잭션(OSIV)와 관련하여 같이 이해해야할 내용이다.\n영속성 컨텍스트를 통한 모든 변경은 트랜잭션 안에서 이뤄져야 한다.\n트랜잭션 없이 엔티티 변경 후 영속성 컨텍스트를 플러시하면, javax.persistence.TransactionRequiredException 예외가 발생한다. 조회 기능은 트랜잭션 없이 가능하다.\n지연로딩 가능 "},{"id":61,"href":"/docs/BOOKS/%EC%9E%90%EB%B0%94-ORM-%ED%91%9C%EC%A4%80-JPA-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/16%EC%9E%A5_%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98%EA%B3%BC-%EB%9D%BD-2%EC%B0%A8%EC%BA%90%EC%8B%9C/","title":"16장_트랜잭션과 락, 2차캐시","section":"자바 ORM 표준 JPA 프로그래밍","content":" 트랜잭션과 락 # 2차 캐시 # 1차 캐시와 2차 캐시\n영속성 컨텍스트 내부에 Entity 를 보관하는 저장소, 1차캐시가 있다.\n1차캐시를 통해 얻을 수 있는 이점은 많이 있지만 일반적으로 1차캐시의 유효 범위는 짧기 때문에 큰 이점을 보기는 힘들다.\n* 1차캐시는 트랜잭션 시작 ~ 끝에서 유효하다. OSIV 를 사용해도 클라이언트의 요청이 들어온 시점 ~ 끝날 때까지만 유효하다.\n하이버네이트를 포함하여 대부분의 JPA 구현체는 애플리케이션 범위의 캐시를 지원한다. 이것을 \u0026lsquo;공유 캐시\u0026rsquo;, \u0026lsquo;2차 캐시\u0026rsquo;라고 한다.\n* 2차 캐시를 활용하면 애플리케이션의 조회 성능을 향상할 수 있다.\n애플리케이션 범위의 캐시는 애플리케이션이 종료될 때까지 유지되는 캐시를 의미한다. 분산 캐시나 클러스터링 환경의 캐시는 애플리케이션보다 더 오래 유지될 수 있다.\n2차 캐시를 적절히 활용하면 데이터베이스 접근 횟수를 획기적으로 줄일 수 있다.\n2차 캐시의 구조(원리)는 1차 캐시와 동일하다. 다만 2차 캐시에서는 엔티티를 내어줄 때, 복사본을 내어준다.\n복사본을 내어주는 이유는 \u0026lsquo;동시성\u0026rsquo;을 위함이다. 만약 객체 그대로를 내어준다면 동시에 여러 곳에서 같은 객체를 수정하는 문제가 발생할 수 있다. 이를 해결하려면 객체에 락을 걸어줘야하는데, 이는 동시성을 떨어뜨릴 수 있다. 따라서, 2차 캐시는 원본 대신에 복사본을 반환한다.\n2차캐시의 특징은 다음과 같다.\n영속성 유닛 범위의 캐시다. DB로부터 조회한 객체를 그대로 반환하지 않고, 복사본을 만들어서 반환한다. DB의 PK 를 기준으로 캐시하지만, 영속성 컨텍스트가 다르면 객체 동일성(a==b)을 보장하지 않는다. JPA 2차 캐시 기능\nJPA 2.0 부터 캐시에 대한 표준이 정의되었다고 한다. 다만 여러 구현체가 공통으로 사용하는 부분에 대해서만 표준화되었기에, (세밀한 기능은) 구현체에 의존해야 한다.\n2차 캐시를 사용하려면 아래와 같은 어노테이션을 사용한다.\njavax.persistence.Cacheable\n@Cacheable @Entity public class Memeber { @Id @GeneratedValue private Long id; ... } 다음으로 xml 에 shared-cache-mode 를 설정한다. 이는 애플리케이션 전체에 캐시를 어떻게 적용할지 설정하는 것이다.\n* 보통 ENABLE_SELECTIVE 를 사용한다고 한다.\nALL : 모든 엔티티를 캐시한다. NONE : 캐시를 사용하지 않는다. ENABLE_SELECTIVE : Cacheable(true) 로 설정된 엔티티에만 캐시를 적용한다. DISABLE_SELECTIVE : 모든 엔티티를 캐시하는데, Cacheable(false)로 명시된 엔티티는 캐시하지 않는다. UNSPECIFIED : JPA 구현체가 정의한 설정을 따른다. 캐시 조회, 저장 방식 설정\n캐시를 무시하고 데이터베이스를 직접 조회하거나 캐시를 갱신하려면 \u0026lsquo;캐시 조회 모드\u0026rsquo;와 \u0026lsquo;캐시 보관 모드\u0026rsquo;를 사용한다.\n캐시 조회 모드\npublic enum CacheRetrieveMode { USE, BYPASS } USE : (기본값) 캐시에서 조회한다. BYPASS : 캐시를 무시하고 데이터베이스에 접근한다. 캐시 보관 모드\npublic enum CacheStoreMode { USE, BYPASS, REFRESH } USE : (기본값) 조회한 데이터를 캐시에 저장한다. 조회한 데이터가 이미 캐시에 있으면 데이터를 최신 상태로 갱신하지 않는다. 트랜잭션을 커밋하면 등록 수정한 엔티티도 캐시에 저장한다. BYPASS : 캐시에 저장하지 않는다. REFERSH : USE 전략 + 데이터베이스에서 조회한 엔티티를 최신 상태로 다시 캐시한다. 캐시 모드는 아래 예제 처럼 엔티티 매니저(EntityManager) 단위로 설정하거나 EntityManager.find(), EntityManager.refresh() 에 설정할 수 있다. Query.setHint() 에도 사용할 수 있다.\nem.setProperty(\u0026#34;javax.persistence.cache.retrieveMode\u0026#34;, CacheRetrieveMode.BYPASS); em.setProperty(\u0026#34;javax.persistence.cache.storeMode\u0026#34;, CacheStoreMode.BYPASS); Map\u0026lt;Stirng, Object\u0026gt; param = new HashMap\u0026lt;String, Object\u0026gt;(); param.put(\u0026#34;javax.persistence.cache.retrieveMode\u0026#34;, CacheRetrieveMode.BYPASS); param.put(\u0026#34;javax.persistence.cache.storeMode\u0026#34;, CacheStoreMode.BYPASS); em.find(TestEntity.class, id, param); em.createQuery(\u0026#34;select e from TestEntity e where e.id = :id\u0026#34;, TestEntity.class) .setParameter(\u0026#34;id\u0026#34;, id) .setHint(\u0026#34;javax.persistence.cache.retrieveMode\u0026#34;, CacheRetrieveMode.BYPASS) .setHint(\u0026#34;javax.persistence.cache.storeMode\u0026#34;, CacheStoreMode.BYPASS) .getSingleResult(); JPA 캐시 관리 API\nJPA 는 캐시를 관리하기 위한 javax.persistence.Cache 인터페이스를 제공한다. (앞서 말한 JPA 가 표준화한 부분이다.)\n앞서 언급했듯이 세부적인 기능은 구현체에 의존해야하기에, 구현체의 설명서를 읽어봐야한다.\npublic interface Cache { // 캐시에 해당 엔티티가 있는지 확인한다. public boolean contains(Calss cls, Object primaryKey); // 캐시에서 제거한다. public void evict(Class cls, Object primaryKey); // 해당 엔티티(클래스) 전체를 캐시에서 제거한다. public void evict(Class cls); // 모든 캐시 데이터를 제거한다. public void evictAll(); // JPA Cache 구현체를 조회한다. public \u0026lt;T\u0026gt; T unwrap(Class\u0026lt;T\u0026gt; cls); } 하이버네이트와 EMCACHE 적용\n하이버네이트가 지원하는 캐시는 크게 3가지가 있다.\n엔티티 캐시 : 엔티티 단위로 캐시한다. 식별자로 엔티티를 조회하거나 컬렉션이 아닌 연관된 엔티티를 로딩할 때 사용한다. 컬렉션 캐시 : 엔티티와 연관된 컬렉션을 캐시한다. 컬렉션이 엔티티를 담고 있으면 식별자 값만 캐시한다. (하이버네이트 기능) 쿼리 캐시 : 쿼리와 파라미터 정보를 키로 사용해서 캐시한다. 결과가 엔티티면 식별자 값만 캐시한다. (하이버네이트 기능) * JPA 표준에는 엔티티 캐시만 정의되어 있다.\n하이버네이트의 EMCACHE 를 적용하기 위해서는 아래와 같은 추가적인 설정이 필요하다.\ngradle hibernate-emcache 라이브러리 추가 emcache.xml 추가 : emcache 관련 설정 persistence.xml 내용 추가 : 하이버네이트에 캐시 사용 정보 설정 (configuration 통해서도 가능할 것이다.) 아래는 엔티티에 2차 캐시를 적용했을 때의 예시이다.\n@Cacheable // 2차 캐시를 적용하기 위해 JPA 표준 어노테이션을 사용한다. @Cache(usage = CacheConcurrencyStrategy.READ_WRTIE) // 하이버네이트 전용 어노테이션이다. 캐시와 관련되어 세밀한 기능을 설정하기 위해 사용된다. @Entity public class Member { ... } 하이버네이트 전용 어노테이션 @Cache 의 사용법은 다음과 같다.\nusage : CacheConcurrencyStrategy 를 사용해서 \u0026lsquo;캐시 동시성 전략\u0026rsquo;을 설정한다. region : 캐시 region 을 설정한다. include : 연관 객체를 캐시에 포함할지 설정한다. all, non-lazy 옵션을 선택할 수 있다. 기본값은 all 이다. * 중요한 옵션은 usage 옵션이다.\norg.hibernate.annotations.CacheConcurrencyStrategy 에 대해 살펴보면 아래와 같다.\nNONE : 캐시를 설정하지 않는다. READ_ONLY : 읽기 전용으로 설정한다. 등록, 삭제는 가능하지만 수정은 불가능하다. 읽기 전용인 불변 객체는 수정되지 않음이 보장되기에 하이버네이트는 2차 캐시에서 복사본이 아닌 원본 객체를 반환한다. NONSTRICT_READ_WRITE : (엄격하지 않은) 읽고 쓰기 전략이다. 동시에 같은 엔티티를 수정하면 데이터의 일관성이 깨질 수 있다. EMCACHE 는 데이터를 수정하면 캐시 데이터를 무효화한다. READ_WRITE : 읽고 쓰기가 가능하다. READ COMMITTED 정도의 격리 수준을 보장한다. EMCACHE 는 데이터를 수정하면 캐시 데이터도 같이 수정한다. TRANSACTIONAL : 컨테이너 관리 환경에서 사용할 수 있다. 설정에 따라 REPEATABLE READ 정도의 격리 수준을 보장받을 수 있다. 하이버네이트가 제공하는 캐시의 종류는 아래와 같다.\n* ConcurrentHashMap 은 개발 시에만 사용하길 권장한다.\nConcurrentHashMap EMCache Infinispan 캐시 영역\n엔티티 캐시 영역은 기본값으로 \u0026lsquo;[패키지 명 + 클래스 명]\u0026rsquo; 을 사용한다.\n컬렉션 캐시 영역은 [엔티티 캐시 영역 + 컬렉션의 필드명] 으로 사용한다.\n* 필요 시 캐시 영역을 직접 지정할 수 있다.\n캐시 영역을 구분함으로써, 캐시 영역 별로 세부 설정이 가능하다. 예를 들어 TestEntity 엔티티에 대한 캐시 설정을 따로 해줄 수 있다.\n쿼리 캐시\n쿼리와 파라미터 정보를 키로 사용해서 쿼리 결과를 캐시하는 방법이다.\n쿼리 캐시를 사용하기 위해서는 hibernate.cache.use_query_cache 옵션을 꼭 true 로 설정해주어야 한다.\n또, 쿼리 캐시를 적용하려는 쿼리마다 org.hibernate.cacheable 을 true 로 설정하는 힌트를 주어야 한다.\nem.createQuery(\u0026#34;select i from Item i\u0026#34;, Item.class) .setHint(\u0026#34;org.hiberante.cacheable\u0026#34;, true) .getResultList(); @Entity @NamedQuery( hints = @QueryHint(name = \u0026#34;org.hibernate.cacheable\u0026#34;, value = \u0026#34;true\u0026#34;), name = \u0026#34;Member.findByUsername\u0026#34;, query = \u0026#34;select m.address from Member m where m.name = :username\u0026#34; ) public class Member { ... } 쿼리 캐시 영역\norg.hibernate.cache.internal.StandardQueryCache : 쿼리 캐시를 저장하는 영역이다. 쿼리, 쿼리 결과 집합, 쿼리를 실행한 시점의 타임스탬프를 보관한다. org.hibernate.cache.spi.UpdateTimestampsCache : 쿼리 캐시가 유효한지 확인하기 위해 쿼리 대상 테이블의 가장 최근 변경 시간을 저장하는 영역이다. 테이블 명과 테이블의 최근 변경된 타임스탬프를 보관한다. 쿼리 캐시는 캐시한 데이터 집합을 최신 데이터로 유지하기 위해, 쿼리 캐시를 실행하는 시간과 쿼리 캐시가 사용하는 테이블들이 가장 최근에 변경된 시간을 비교한다.\n쿼리 캐시를 적용하고 난 후에 쿼리 캐시가 사용하는 테이블에 조금이라도 변경이 있으면 데이터베이스에서 데이터를 읽어와서 쿼리 결과를 다시 캐시한다.\n예시\nStandardQueryCache 에서 쿼리의 타임스태프를 조회한다. UpdateTimestampsCache 에서 해당 테이블의 타임스탬프를 조회한다. 만약 StandardQueryCache 의 타임스탬프가 더 오래되었다면, 캐시가 유효하지 않은 것으로 보고 데이터베이스에서 데이터를 조회하고 다시 캐시한다. 쿼리 캐시를 잘 활용하면 극적인 성능 향상이 있다. 하지만 빈번하게 변경이 있는 테이블에 사용하면 오히려 성능이 저하된다.\n따라서 수정이 거의 일어나지 않는 테이블에 사용해야 효과를 볼 수 있다.\n* UpdateTimestapmsCache 캐시 영역은 만료되지 않도록 설정해주어야 한다. 해당 영역이 만료되면 모든 쿼리 캐시가 무효화된다. EMCACHE 의 eternal=\u0026quot;true\u0026quot; 옵션을 사용하면 캐시에서 삭제되지 않는다.\n쿼리 캐시와 컬렉션 캐시의 주의점\n엔티티 캐시를 사용해서 엔티티를 캐시하면 엔티티 정보 모두를 캐시한다.\n하지만 쿼리 캐시와 컬렉션 캐시는 결과 집합의 식별자 값만 캐시한다. 따라서 쿼리 캐시와 컬렉션 캐시를 조회하면 그 안에는 식별자 값만 들어있다. 이 식별자 값을 하나씩 엔티티 캐시에서 조회하여 실제 엔티티를 찾는 것이다.\n문제는 쿼리 캐시나 컬렉션 캐시만 사용하고 대상 엔티티에 엔티티 캐시를 적용하지 않으면 성능상 심각한 문제가 발생할 수 있다.\n예시는 다음과 같다.\nselect m from Member m 쿼리를 실행하였는데, 쿼리 캐시가 적용되어 있고 결과 집합은 100건이라고 하자. 결과 집합에는 식별자만 있으므로 한 건씩 엔티티 캐시 영역에서 조회한다. Member 엔티티는 엔티티 캐시를 사용하지 않으므로 한 건씩 DB에서 조회한다. 결국 100건의 SQL 이 실행된다. 쿼리 캐시나 컬렉션 캐시만 사용하고 엔티티 캐시를 사용하면 최악의 상황이 발생할 수 있다. 따라서 쿼리 캐시나 컬렉션 캐시를 사용하면 (대상) 엔티티에는 꼭 엔티티 캐시를 적용해야 한다.\n"},{"id":62,"href":"/docs/BOOKS/%EC%BD%94%ED%8B%80%EB%A6%B0-%EC%9D%B8-%EC%95%A1%EC%85%98/2%EC%9E%A5.-%EC%BD%94%ED%8B%80%EB%A6%B0-%EA%B8%B0%EC%B4%88/","title":"2장. 코틀린 기초","section":"코틀린 인 액션","content":" 기본적인 내용은 생략한다.\n키워드 #프로퍼티 #변수 #함수 #클래스 #스마트캐스트 #예외처리\n식 : 값을 만들어 내는 것 문장(문) : 값을 만들어내지 않는 것\n2.1 기본 요소 : 함수와 변수 # 아래 내용을 통해 알 수 있는 것은 다음과 같다.\n함수, 변수를 최상위 수준에 정의 가능 (꼭 클래스 내에 정의하는 것이 아니라) println : 코틀린 표준 라이브러리 → 표준 자바 라이브러리 함수를 간결하게 사용할 수 있도록 래핑 \u0026hellip; fun main(args: Array\u0026lt;String\u0026gt;) { println(\u0026#34;Hello, world!\u0026#34;) } 함수 # 종류 설명 블록이 본문인 함수 본문이 중괄호({})로 둘러싸인 함수 식이 본문인 함수 등호(=)와 식(expression)으로 이뤄진 함수 * 코틀린에서는 식이 본문인 함수가 자주 사용된다. /** 예시 : 블록이 본문인 함수 */ fun max(a: Int, b: Int): Int { return if (a \u0026gt; b) a else b } // \u0026#39;블록이 본문인 함수\u0026#39;의 경우, \u0026#39;반환 타입\u0026#39;을 꼭 명시해줘야한다. /** 예시 : 식이 본문인 함수 */ fun max(a: Int, b: Int): Int = if (a \u0026gt; b) a else b // \u0026#39;식이 본문인 함수\u0026#39;의 경우, \u0026#39;반환 타입\u0026#39;에 대해서 컴파일러가 타입 추론한다. // 따라서, 반환 타입을 생략할 수 있다. (반환 타입만 생략 가능하다.) /** 예시 : 식이 본문인 함수 */ fun max(a: Int, b: Int) = if (a \u0026gt; b) a else b // \u0026#39;식이 본문인 함수\u0026#39;의 경우, \u0026#39;반환 타입\u0026#39;에 대해서 컴파일러가 타입 추론한다. // 따라서, 반환 타입을 생략할 수 있다. (반환 타입만 생략 가능하다.) \u0026lsquo;식이 본문인 함수\u0026rsquo;의 경우, \u0026lsquo;반환 타입\u0026rsquo;에 대해서 컴파일러가 타입 추론한다. 따라서, 반환 타입을 생략할 수 있다. (반환 타입만 생략 가능하다.)\n변수 # 종류 설명 val(value) immutable 정확히 1번만 초기화되어야 한다.\n* 자바의 final 변수 var(variable) mutable * 자바의 일반 변수 기본적으로 모든 변수를 val 로 사용하고, 필요 시에만 var 을 사용하는 것을 권장한다.\n단, val의 경우 초기화를 한번만 하면 되기에 아래 코드도 가능하다.\nval message: String if(~~~) { message = \u0026#34;success\u0026#34; } else { message = \u0026#34;error\u0026#34; } 초기화 식이 있다면,\n타입 추론할 수 있다. (타입을 지정하지 않으면, 컴파일러가 초기화 식을 이용)\nval answer = 42 초기화 식이 없다면,\n타입 추론할 수 없다. (추론할 수 있는 요소가 없는 것이니까)\nval answer: Int answer = 42 문자열 템플릿 # println(\u0026#34;Hello, $name!\u0026#34;) 단, 아래처럼 중괄호로 감싸는 습관을 들이는 것을 권장한다.\nprintln(\u0026#34;Hello, ${name}!\u0026#34;) println(\u0026#34;Hello, ${if (args.size \u0026gt; 0) args[0] else \u0026#34;someone\u0026#34;}!\u0026#34;) \u0026hellip;\n클래스와 프로퍼티 # 언어 프로퍼티 개념 Java 필드(Field)와 접근자(accessor method)를 묶어 → 프로퍼티(property) Kotlin 기본으로 \u0026lsquo;프로퍼티\u0026rsquo;라는 개념 사용 val, var (?) \u0026ldquo;대부분의 프로퍼티에는 그 프로퍼티의 값을 저장하기 위한 필드가 있다. 이를 프로퍼티를 뒷받침하는 필드(backing field)라고 부른다.\u0026rdquo;\n커스텀 접근자 # class Rectangle(val height: Int, val width: Int) { val isSquare: Boolean get() { return height == width } } \u0026hellip;\n디렉터리 / 패키지 # 디렉터리, 패키지 개념은 자바와 비슷하다.\n패키지 안에 모든 선언(클래스, 함수, 프로퍼티 + 최상위 함수, 프로퍼티 포함)가 선언된다.\n추가적으로 소개할 특징은 다음과 같다.\n여러 클래스를 한 파일에 넣을 수 있다. 파일의 이름도 자유롭게 정할 수 있다. (자바 처럼, 클래스 명과 동일해야 하는 규칙 없음) 디스크 상의 어느 디렉터리에 소스코드 파일을 위치시켜도 상관 없다. \u0026ldquo;다만, 대부분의 경우 자바와 같이 패키지별로 디렉터리를 구성하는 편이 낫다. 특히 자바와 코틀린을 함께 사용하는 프로젝트, 자바 클래스를 코틀린 클래스로 마이그레이션할 때는 더더욱 그렇다\u0026rdquo;\nenum / when # enum\n소프트 키워드 enum clss : enum 클래스로 사용한다. (즉 class 앞에 사용될 때만 특별한 의미를 갖는 것) enum : 키워드가 아니다. 변수명으로도 사용 가능하다. when\n자바의 if - elseif 는 when (+is)으로 대체할 수 있다.\nfun getMnemonic(color: Color) = when (color) { // 이 위치에는 식(expression)이라면 모두 들어올 수 있다. RED, GREEN -\u0026gt; \u0026#34;Richard\u0026#34; YELLOW -\u0026gt; \u0026#34;Jackson\u0026#34; ... } // 이러한 \u0026#39;객체\u0026#39;의 경우, \u0026#39;동등성\u0026#39; 비교를 한다. fun max(c1: Color, c2: Color) = when (setOf(c1, c2)) { setOf(RED, YELLOW) -\u0026gt; ORANGE ... } // 위 예시는 객체를 생성하고 버리기 때문에, 실무에서는 주의해야한다. fun mixOptimized(c1: Color, c2: Color) = when { (c1 === RED \u0026amp;\u0026amp; c2 === YELLOW) || (c1 === YELLOW \u0026amp;\u0026amp; c2 === RED) -\u0026gt; ORANGE ... } fun eval(e: Expr): Int = when(e) { is Num -\u0026gt; e.value is Sum -\u0026gt; eval(e.right) + eval(e.left) else -\u0026gt; ... } /** 블록의 경우, 마지막 문장이 return 되는 값이다. */ fun eval(e: Expr): Int = when(e) { is Num -\u0026gt; { println(\u0026#34;hi\u0026#34;) e.value } is Sum -\u0026gt; { println(\u0026#34;hi\u0026#34;) eval(e.right) + eval(e.left) } else -\u0026gt; ... } break 를 넣지 않아도 된다. 콤마(,) 사용 가능하다. 객체 경우 → 동등성 비교를 한다. 객체의 경우 객체를 생성하고 버린다는 것에 유의한다. 인자 없이 사용 가능하다. 인자 없이 사용하려면, 각 분기의 조건이 boolean 결과식이어야 한다. 블록의 마지막 식이 블록의 결과라는 규칙은 블록이 값을 만들어내야 하는 경우 항상 성립한다. 즉 when 에서만 성립하는게 아니라 코틀린 내의 모든 곳에 적용되는 규칙이다.\n스마트 캐스트 # 스마트 캐스트 : 타입 검사 + 타입 캐스트\nfun eval(e: Expr): Int { if (e is Num) { ... } } Loop (while / for) # for \u0026lt;야이템\u0026gt; in \u0026lt;컬렉션\u0026gt;\nval oneToTen = 1..10\nval tenToOne = 10 downTo 1\nval tenToOneBy2Step = 10 downTo 1 step 2\n/** Map 예제 */ fun((letter, binray) in binaryReps) { // \u0026#39;구조 분해 문법\u0026#39; 사용 ... } [추가 예시 - \u0026lsquo;범위 검사\u0026rsquo;] c in 'a'..'z' c !in '0'..'9'\n예외 처리 # 1. 체크 예외 / 언체크 예외를 구분하지 않는다.\n자바에서 체크 예외의 경우 명시적으로 throws 를 작성한다. 하지만 개발자들이 무의미하게 처리(다시 던지거나, 무시하거나)하는 경우가 흔하기 때문에, 코틀린에서는 이렇게 설계했다고 한다.\n2. try 는 식이다.\ntry 의 경우 본문을 반드시 중괄호({})로 감싸야 한다.\nval number = try { ~~~ } catch () { ... } "},{"id":63,"href":"/docs/BOOKS/%EC%BD%94%ED%8B%80%EB%A6%B0-%EC%9D%B8-%EC%95%A1%EC%85%98/3%EC%9E%A5.-%ED%95%A8%EC%88%98-%EC%A0%95%EC%9D%98%EC%99%80-%ED%98%B8%EC%B6%9C/","title":"3장. 함수 정의와 호출","section":"코틀린 인 액션","content":" 기본적인 내용은 생략한다.\n키워드 # (자바와 다른) 함수 정의 / 함수 호출 확장 함수 (+ 프로퍼티) 3.1 코틀린에서 컬렉션 만들기 # 핵심 : 자바 컬렉션을 사용한다.\n다양한 방법으로 컬렉션을 만들 수 있다.\nval hashSet = hashSetOf(1, 7, 53) val arrayList = arrayListOf(1, 7, 53) val hashMap = hashMapOf(1 to \u0026#34;one\u0026#34;, 7 to \u0026#34;seven\u0026#34;, 53 to \u0026#34;fifty-three\u0026#34;) println(hashSet) // [1, 53, 7] | java.util.HashSet println(arrayList) // [1, 7, 53] | java.util.ArrayList println(hashMap) // {1=one, 53=fifty-three, 7=seven} | java.util.HashMap 코틀린만의 특별한 컬렉션이 있는 것이 아니다. 자바 컬렉션을 그대로 사용한다. 표준 자바 컬렉션 활용 → 자바와 호환/상호작용↑ 코틀린에셔는 자바 컬렉션에서보다 더 많은 기능을 사용할 수 있다. (있는 것 처럼 보여준다.) 있는 것 처럼 보여준다. (= 확장함수를 이용하는 거니까 \u0026lsquo;있는 것 처럼 보인다\u0026rsquo;라고 말할 수 있지 않을까) to # to 는 특별한 키워드가 아닌, 일반 함수(= 중위 함수 = infix)이다.\npublic infix fun \u0026lt;A, B\u0026gt; A.to(that: B): Pair\u0026lt;A, B\u0026gt; = Pair(this, that) 3.2 함수를 호출하기 쉽게 만들기 # 코틀린에서는 함수를 클래스 안에 선언할 필요가 전혀 없다.\n이름 붙인 인자 # 함수에 전달하는 (일부, 혹은 전부)인자의 이름을 명시할 수 있다.\n단, 인자 이름 명시 후 그 뒤에 오는 모든 인자는 이름을 꼭 명시해야 한다.\njoinToString( collection, separator = \u0026#34; \u0026#34;, prefix = \u0026#34; \u0026#34;, postfix = \u0026#34; \u0026#34; ) \u0026quot; \u0026lsquo;이름 붙인 인자\u0026rsquo;는 \u0026lsquo;default 파라미터 값\u0026rsquo;과 함께 쓸모가 많다. \u0026ldquo;\n디폴트 파라미터 값 # 자바 (너무 많아지는)오버로딩 문제를 해결 가능\nfun \u0026lt;T\u0026gt; joinToString( collection: Collection\u0026lt;T\u0026gt;, separator: String = \u0026#34;, \u0026#34;, prefix: String = \u0026#34;\u0026#34;, postfix: String = \u0026#34;\u0026#34; ) /** 사용 예시 */ joinToString(list) joinToString(list, \u0026#34;; \u0026#34;) ... @JvmOverloads # 자바에서는 디폴트 파라미터 기능이 없다.\n자바 → 코틀린 클래스 호출 시 모든 인자를 명시해줘야한다.\n이때, @JvmOverloads 함수를 추가해주면 (컴파일 시)맨 마지막 파라미터부터 하나씩 생략한 오버로딩 메서드들을 추가해준다.\n정적 유틸리티 클래스 없애기 : 최상위 함수, 프로퍼티 # 코틀린에서는 함수를 클래스 안에 선언할 필요가 전혀 없다.\n자바에서는 특별한 클래스에 속하지 않는, 유틸리티성 함수를 만들기 위해 유틸리티 클래스/함수를 생성했었다.\n코틀린에서는 이런 \u0026lsquo;무의미한 클래스(= 무분별한 정적 유틸리티 클래스)\u0026lsquo;가 필요 없다.\n함수를 소스 파일의 최상위 수준(클래스 밖)에 위치시키면 된다.\n근데 소스를 보다보면 이게 가독성에 좋은지는 모르겠다. (아직 익숙하지 않아서일수도 있다.)\n코틀린 컴파일러가 생성하는 \u0026lsquo;클래스명\u0026rsquo;은 최상위 함수가 들어있던 \u0026lsquo;코틀린 소스 파일의 이름\u0026rsquo;과 대응한다.\n[컴파일 전]\n// 파일명 : join.kt // kotlin package strings fun joinToString(...): String { ... } [컴파일 후]\n// java package strings; public class JoinKt { public static String joinToString(...) { ... } } [사용 예시]\nimport strings.JoinKt; JoinKt.joinToString(...); @JvmNames # 기본적으로는 파일에 대응하여 생성되는 클래스명을 바꿀 수 있다.\n@JvmNames 를 파일의 맨 앞(패키지 선언 전)에 위치시킨다.\n@file:JvmNames(\u0026#34;StringFunctions\u0026#34;) package strings fun joinToString(...): String { ... } package strings; public class StringFunctions { public static String joinToString(...) { ... } } 최상위 프로퍼티 # (함수와 마찬가지로) 프로퍼티도 최상위 수준에 놓을 수 있다. = \u0026lsquo;정적 필드\u0026rsquo;에 대응/저장된다. = \u0026lsquo;상수\u0026rsquo;를 선언할 때 사용할 수 있다.\n\u0026rdquo; 어떤 데이터를 클래스 밖에 위치시켜야 하는 경우는 흔하지는 않지만, 그래도 가끔 유용할 때가 있다. \u0026ldquo;\nvar opCount = 0 fun performOperation() { opCount++ } val UNIX_LINE_SEPARATOR = \u0026#34;\\n\u0026#34; 다만, 다른 프로퍼티와 동일하게 (var, val 에 따라) 접근자 메서드(getter, setter)가 생긴다.\n\u0026lsquo;상수\u0026rsquo;를 이용할 때 접근자 메서드가 생기는 것은 부자연스럽다.\n= 즉, public static final 변수를 만들어야 한다. = 이를 위해 const 키워드를 사용한다.\nconst val UNIX_LINE_SEPARATOR = \u0026#34;\\n\u0026#34; // public static final String UNIX_LINE_SEPARATOR = \u0026#34;\\n\u0026#34;; 3.3 메서드를 다른 클래스에 추가 : 확장 함수, 확장 프로퍼티 # \u0026rdquo; 기존 코드와 코틀린 코드를 자연스럽게 통합하는 것은 코틀린의 핵심 목표 중 하나이다. \u0026ldquo;\n자바 → 코틀린, 코틀린 → 자바로 전환/통합할 때 전혀 문제가 없어야한다.\n전혀 문제가 없으면서도 추가적인 편리한 기능을 제공하고 싶다.\n확장 함수 가 위 이슈를 해결한다.\n확장 함수 # 어떤 클래스의 멤버 메서드인 것처럼 호출할 수 있지만, 클래스 밖에 선언된 함수이다.\n멤버 함수와 확장 함수가 시그니처가 같다면, 멤버 함수가 우선적으로 호출된다.\n용어 설명 수신 객체 타입 확장이 정의될 클래스 타입 (확장 함수를 통해)확장할 대상 클래스 타입 수신 객체 그 클래스에 속한 인스턴스 객체 확장 함수가 호출되는 대상 객체 // 수신 객체 타입(String) 수신 객체(this) (+ this 는 생략 가능) fun String.lastChar(): Char = this.get(this.length - 1) println(\u0026#34;kotlin\u0026#34;.lastChar()) // 수신 객체 타입 : String // 수신 객체 : \u0026#34;kotlin\u0026#34; 확장 함수가 캡슐화를 깨지는 않는다.\n확장 함수는 확장 함수 내부에서 인스턴스의 메서드, 프로퍼티를 바로 사용할 수 있다.\n단, 확장 함수가 캡슐화를 깨지는 않는다.\n(멤버 메서드와 달리) 확장 함수 안에서는 클래스 내부에서만 사용할 수 있는 private, protected 멤버를 사용할 수 없다.\n자바 변환 시 : \u0026lsquo;수신 객체를 첫 번째 인자로 받는 정적 메서드\u0026rsquo;\n// java char c = StringUtilKt.lastChar(\u0026#34;kotin\u0026#34;); \u0026rdquo; 확장 함수는 단지 정적 메서드 호출에 대한 \u0026lsquo;문법적 편의\u0026rsquo;일 뿐이다. \u0026ldquo;\n오버라이딩 X\n정적 메서드와 같은 특징을 가지므로, 확장 함수를 하위 클래스에서 오버라이딩할 수 없다.\n// View : super class // Button : sub class fun View.showOff() = println(\u0026#34;view\u0026#34;) fun Button.showOff() = println(\u0026#34;button\u0026#34;) val view:View = Button() view.showOff() // \u0026#34;view\u0026#34; 확장 함수는 정적으로 결정된다.\n확장 함수를 호출할 때 수신 객체의 정적 타입에 의해 어떤 확장함수가 실행될 지 결정된다.\n동적 타입 = 런타임 타입 = 실 객체 타입에 의해 결정되지 않는다. 확장 프로퍼티 # 다시 읽어볼 것 (p123)\n다른 클래스에 대해서, 프로퍼티 형식의 구문으로 사용할 수 있는 API를 추가할 수 있다.\n프로퍼티라는 이름으로 불리긴 하지만 상태를 저장할 방법이 없기 때문에(기존 클래스/객체에 필드를 추가할 방법은 없다.), 실제로 확장 프로퍼티는 아무 상태도 가질 수 없다.\n다만 문법 사용 시 더 짧은 코드(가독성↑)를 작성할 수 있게 도와줄 수 있다.\nval String.lastChar: Char get() = this.get(length - 1) var StringBuilder.lastChar: Char get() = get(length - 1) set(value: Char) { this.setCharAt(length - 1, value) } 확장 함수의 경우와 마찬가지로 확장 프로퍼티도 일반적은 프로퍼티와 같은데, 단지 \u0026lsquo;수신 객체 클래스\u0026rsquo;가 추가되었을 뿐이다.\n뒷받침하는 필드가 없어서 기본 게터 구현을 제공할 수 없으므로 최소한 게터는 꼭 정의해야 한다.\n마찬가지로 초기화 코드에서 계산한 값을 담을 장소가 전혀 없으므로, 초기화 코드도 쓸 수 없다.\n3.4 컬렉션 처리 : 가변 길이 인자, 중위 함수 호출, 라이브러리 지원 # 키워드 요약(설명) vararg 가변 인자를 처리한다. infix 중위 함수 구조 분해 선언 (destructuring declaration) 복합적인 값을 분해해서 여러 변수에 담을 수 있다. vararg # 코틀린 : vararg 자바 : ... 이미 배열에 들어있는 원소를 \u0026lsquo;가변 길이 인자\u0026rsquo;로 넘길 때에는 주의가 필요하다.\n자바에서는 그냥 넘기면 되지만, 코틀린에서는 스프레드 연산자(spread)를 사용해야 한다. (실재로는 * 를 붙이기만 하면 된다고한다.)\n스프레드 = 배열을 명시적으로 풀어서 배열의 각 원소가 인자로 전달되게 하는 것\nfun main(args: Array\u0026lt;String\u0026gt;) { val list = listOf(\u0026#34;args:\u0026#34;, *args) // 스프레드 연산자가 배열의 내용을 펼쳐준다. println(list) } 스프레드 연산자를 통해 \u0026lsquo;배열의 원소\u0026rsquo; + \u0026lsquo;다른 여러 값\u0026rsquo;들을 함께 넘길 수 있다.\ninfix # // 수신 객체 + 중위 함수 + 유일한 메서드 인자 (1개) 1 to \u0026#34;oen\u0026#34; 수신 객체, 메서드 이름, 유일한 인자 사이에는 \u0026lsquo;공백\u0026rsquo;이 들어가야 한다.\n구조 분해 선언 # val (number, name) = 1 to \u0026#34;one\u0026#34; // Pair\u0026lt;A, B\u0026gt; for ((index, element) in collection.withIndex()) { println(\u0026#34;$index : $element\u0026#34;) } 3.5 문자열과 정규식 다루기 # 코틀린 문자열 = 자바 문자열 (같다.)\n코틀린에서는 확장 함수를 통해 좀 더 명확하고 실수를 줄일 수 있는 함수를 제공한다.\n예를 들어 split 의 정규표현식 / 문자열 인자 등\n\u0026#34;12.345-6.A\u0026#34;.split(\u0026#34;\\\\.|-\u0026#34;.toRegex()) \u0026#34;12.345-6.A\u0026#34;.split(\u0026#34;.\u0026#34;, \u0026#34;-\u0026#34;) 3중 따옴표 # \u0026quot;\u0026rdquo;\u0026quot; 안에서는\n역슬래시()를 포함하여 어떤 문자도 이스케이프할 필요가 없다. 줄바꿈이 그대로 표현된다. 3.6 코드 다듬기 : 로컬 함수와 확장 # 로컬 함수\n함수 내부에 중첩된 함수를 만들 수 있다. (자신이 속한) 바깥 함수의 모든 파라미터와 변수를 사용할 수 있다. 일반적으로 1단계만 중첩시킬 것을 권장한다. (중첩의 중첩의 \u0026hellip; =\u0026gt; 더 어렵다.) 간혹 리팩토링의 의미로 메서드를 잘게잘게 쪼개는 경우가 있다. 잘되면 좋지만, 종종 코드를 이해하기 더 힘들게 한다. (예를 들며느 클래스에 파편화된 메서드가 많아지는 느낌)\n이때 대체제로 유용하게 사용할 수 있을 것 같다.\n책에서도 다음과 같이 말하고 있다.\n\u0026quot; 작은 메서드가 많아지고 각 메서드 사이의 관계를 파악하기 힘들어서 코드를 이해하기 더 어려워질 수도 있다. \u0026ldquo;\nfun saveUser(user: User) { fun validate(user: User, value: String, filedName: String) { ... } validate(user, user.name, \u0026#34;Name\u0026#34;) validate(user, user.address, \u0026#34;Address\u0026#34;) ... } fun saveUser(user: User) { fun validate(value: String, filedName: String) { ... } validate(user.name, \u0026#34;Name\u0026#34;) validate(user.address, \u0026#34;Address\u0026#34;) ... } 이것을 더 확장해서 User 클래스의 확장함수로 만들 수도 있다.\nfun User.validate(~) { ... } 3.7 요약 # 확장함수 편리한, 다양한 API 제공 \u0026lsquo;이름 붙인 인자\u0026rsquo; + \u0026lsquo;인자 디폴트 값\u0026rsquo; 가능 함수, 프로퍼티 → 최상위 수준 작성 가능 중위 호출 구조 분해 선언 3중 따옴표 (\u0026quot;\u0026quot;\u0026quot;) 로컬 함수 "},{"id":64,"href":"/docs/BOOKS/%EC%BD%94%ED%8B%80%EB%A6%B0-%EC%9D%B8-%EC%95%A1%EC%85%98/4%EC%9E%A5.-%ED%81%B4%EB%9E%98%EC%8A%A4-%EA%B0%9D%EC%B2%B4-%EC%9D%B8%ED%84%B0%ED%8E%98%EC%9D%B4%EC%8A%A4/","title":"4장. 클래스, 객체, 인터페이스","section":"코틀린 인 액션","content":" 기본적인 내용은 생략한다.\n키워드 # 인터페이스 프로퍼티 선언 가능 클래스 final final public sealed 중첩 클래스 중첩 클래스 vs 내부 클래스 초기화 블록 data 클래스 위임(delegation) object 싱글턴 객체 동반 객체 객체 식 + 참고 : 스마트 캐스트는 val(불변)일 때에만 사용 가능하다.\n4.1 클래스 계층 정의 # 기본 가시성 다르다.\njava : default kotlin : public sealed 클래스는 상속을 제한한다. (중첩(?), 내부(?) 클래스만 허용한다.)\n4.1.1 코틀린 인터페이스 # 추상 메서드 구현이 있는 메서드 (default 메서드) 상태(필드) 자바와 다른 점이다. 상속, 구현에서 오버라이딩 할 때 override 키워드 무조건 사용해야 한다.\ndefault 메서드의 경우, default 키워드 사용하지 않는다.\n그냥 구현체 작성하면 된다.\n자바 8 이전, 6, 7과 대응할 때는 정적 메서드가 들어있는 클래스를 함께 제공한다고 한다.\nsuper() 작성법은 다음과 같다.\nclass Button: Clickable, Focusable { override fun click() = println(\u0026#34;I was clicked\u0026#34;) override fun showOff() { super\u0026lt;Clickable\u0026gt;.showOff() // 자바 : Clickable.super.showOff() super\u0026lt;Focusable\u0026gt;.showOff() // 자바 : Focusable.super.showOff() } } 접근 제어자 (가시성 변경자)\ndefault : public\n변경자 클래스 멤버 최상위 선언 public (기본 가시성) 모든 곳에서 볼 수 있다. 모든 곳에서 볼 수 있다. internal 같은 모듈 안에서만 볼 수 있다. 같은 모듈 안에서만 볼 수 있다. protected 같은 클래스 + 하위 클래스에서만 볼 수 있다. * 최상위 선언에 적용 불가 * (자바 처럼)같은 패키지에서 볼 수 없음에 유의 private 같은 클래스 안에서만 볼 수 있다. 같은 파일 안에서만 볼 수 있다. \u0026quot; 코틀린의 public, protected, private 변경자는 컴파일된 자바 바이트코드 안에서도 그대로 유지된다. 유일한 예외는 private 클래스다. 자바에서는 클래스를 private 으로 만들 수 없으므로, 내부적으로 코틀린은 private 을 default 클래스로 컴파일한다.\ninternal 변경자는 public 으로 컴파일된다. 즉, 코틀린에서는 접근할 수 없는 대상을 자바에서 접근할 수 있게 되는 경우가 생긴다. 하지만 코틀린 컴파일러가 internal 멤버의 이름을 나쁘게 바꾼다(mangle)는 사실을 기억해야 한다. 정리하면 기술적으로는 mangle 된 멤버를 문제없이 사용할 수 있지만, 사용하기 불편하고 코드가 지저분해질 것이다.\n또, 이렇게 하는 두 가지 이유가 있다고 한다. 하위 클래스에서 우연히 이름이 같아 오버라이딩할 수 있는 경우를 방지한다. 실수로 internal 클래스를 모듈 외부에서 사용하는 일을 방지한다. \u0026quot; 4.1.4 내부 클래스와 중첩된 클래스: 기본적으로 중첩 클래스 # 자바\n중첩 클래스 작성 시, 기본적으로 inner class(내부 클래스) 이다. 코틀린\n중첩 클래스 작성 시, 기본적으로 nested class(중첩 클래스) 이다. (자바와의 차이) 코틀린의 중첩 클래스(nested class)는 명시적으로 요청하지 않는 한 바깥쪽 클래스 인스턴스에 대한 접근 권한이 없다는 점이다.\npublic class Button implements View { @Override public State getCurrentState() { return new ButtonState(); } @Override public void restoreState(State state) { ... } public class ButtonState implements State { ... } } 위 코드는 문제가 있다.\nButtonState 직렬화 시 java.io.NotSeriallizableException: Button 오류가 발생한다.\nJava에서 다른 클래스 안에 정의한 클래스는 자동으로 내부 클래스(inner class)가 된다는 것을 기억하면 명확히 알 수 있다.\nButtonState 클래스는 바깥쪽 Button 클래스에 대한 참조를 묵시적으로 포함한다. 그 참조로 인해 ButtonState를 직렬화할 수 없다.\n이 문제를 해결하려면 ButtonState 를 static 으로 선언해야 한다.\n자바에서 중첩 클래스를 static 으로 선언하면 그 클래스를 둘러싼 바깥쪽 클래스에 대한 묵시적인 참조가 사라진다.\n코틀린에서 중첩된 클래스가 동작하는 방식은 정반대이다.\n클래스 B 안에 A 자바 코틀린 중첩 클래스(바깥쪽 클래스에 대한 참조를 저장하지 않음) static class A class A 내부 클래스(바깥쪽 클래스에 대한 참조를 저장) class A inner class A 바깥쪽 클래스의 인스턴스를 가리키는 참조 표기 방법도 다르다.\nthis@Outer\n4.1.5 봉인된 클래스 : 클래스 계층 정의 시 계층 확장 제한 # sealed\n하위 클래스 정의를 제한한다. 하위 클래스 정의 시 반드시 상위 클래스 안에 중첩시켜야 한다.\n자동으로 open 클래스가 된다.\n클래스 계층을 만들되 그 계층에 속한 클래스 수를 제한하고 싶은 경우, 중첩 클래스를 쓰면 편하다.\n특히? 예를들어 책에서 소개한 when 식과 함께 쓸 때 궁합이 좋다.\nwhen 에서 else 구문 안써도 되고, 하위 클래스 추가되었을 경우 (when 식에 생기는)컴파일 오류 통해 바로 알 수 있다. (확인해보자.)\n4.2 뻔하지 않은 생성자와 프로퍼티를 갖는 클래스 선언 # 코틀린에서는 아래 기능이 있다.\n주 생성자 부 생성자 초기화 블록 4.2.1 클래스 초기화 : 주 생성자, 초기화 블록 # // 위 코드, 아래 코드가 동일하다. // class User(val nickname: String) class User constructor(_nickname: String) { val nickname: String init { nickname = _nickname } } 초기화 블록 안에서만 주 생성자의 파라미터에 참조할 수 있다.\n모든 생성자 파라미터에 기본 값을 지정하면 컴파일러가 자동으로 파라미터가 없는 기본 생성자를 만들어준다.\n기본 생성자 사용 시 파라미터 기본 값으로 생성 가능하다.\nDI 프레임워크와 쉽게 통합되게 한다.\n상위 클래스 초기화는 다음과 같이 한다.\nclass TwitterUser(nickname: String): User(nickname) { ... } 이 규칙으로 인해 상위 클래스쪽에는 항상 () 괄호를 쓴다.\n인터페이스쪽에는 괄호 안쓴다. (인터페이스는 생성자 없으니까)\n4.2.2 부 생성자 : 상위 클래스를 다른 방식으로 초기화 # "},{"id":65,"href":"/docs/BOOKS/%EC%BD%94%ED%8B%80%EB%A6%B0-%EC%9D%B8-%EC%95%A1%EC%85%98/5%EC%9E%A5.-%EB%9E%8C%EB%8B%A4%EB%A1%9C-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/","title":"5장. 람다로 프로그래밍","section":"코틀린 인 액션","content":" 기본적인 내용은 생략한다.\n키워드 # 람다, 멤버 참조 sequence (지연 컬렉션 연산) 함수형 인터페이스 (SAM 인터페이) 수신 객체 지정 람다 + 참고 : 스마트 캐스트는 val(불변)일 때에만 사용 가능하다.\n5장. 람다로 프로그래밍 # 람다(= 람다 식)은 기본적으로 다른 함수에 넘길 수 있는 작은 코드 조각을 뜻한다.\n5.1 람다 식과 멤버 참조 # 5.1.1 람다 소개 : 코드 블록을 함수 인자로 넘기기 # button.setOnClickListener { /* 클릭 시 수행할 동작 */ } 5.1.2 람다와 컬렉션 # 자바에서는 필요한 컬렉션 기능을 직접 작성하곤 했다. 코틀린에서는 (람다가 있기 때문에)이런 습관을 버려야 한다.\n// 람다를 활용한다. people.maxBy { it.age } // 나이로 비교하여, 가장 큰 원소를 찾는다. // 멤버 참조를 활용한다. people.maxBy(Person::age) // 나이로 비교하여, 가장 큰 원소를 찾는다. 코틀린 람다 식은 항상 \u0026lsquo;중괄호\u0026rsquo;로 둘러싸여 있다.\n인자 목록 주변에 괄호가 없기도 하다. (-\u0026gt; 로 인자 목록과 본문을 구분할 수 있기 때문이다.)\n{ (a, b) -\u0026gt; ...} 가 아니고, { a, b -\u0026gt; ... } 로 작성한다. 코틀린에서 함수 호출 시 맨 뒤에 있는 인자가 람다 식이면, 그 람다를 괄호 밖으로 빼낼 수 있다.\n따라서, 괄호 뒤에 람다 식을 둘 수 있다.\n// 개선 전 people.maxBy({ p: Person -\u0026gt; p.age }) // 개선 후 people.maxBy() { p: Person -\u0026gt; p.age } (위와 같이) 람다가 함수의 유일한 인자이고, 괄호 뒤에 람다를 썼다면 호출 시 빈 괄호를 없앨 수 있다.\npeople.maxBy { p: Person -\u0026gt; p.age } 람다의 파라미터명을 디폴트 파라미터명 it로 사용할 수 있다.\npeople.maxBy { it.age } 5.1.4 현재 영역에 있는 변수에 접근 # 람다의 파라미터뿐만 아니라, 람다 정의 앞에 선언된 로컬 변수까지 람다에서 모두 사용할 수 있다.\nfun printMessagesWithPrefix(messages: Collection\u0026lt;String\u0026gt;, prefix: String) { messages.foreach { println(\u0026#34;$prefix $it\u0026#34;) // prefix 변수를 사용할 수 있다. } } (자바와 다른 점은) 람다 안에서 파이널 변수가 아닌 변수에도 접근할 수 있다.\n람다 안에서 바깥의 변수를 변경할 수도 있다. fun printProblemCounts(responses: Collection\u0026lt;String\u0026gt;) { var clientErros = 0 var serverErros = 0 responses.forEach { if(it.startWith(\u0026#34;4\u0026#34;)) { clientErros++ } else { serverErros++; } } } 위와 같이 람다 내부에서 사용하는 외부 변수를 \u0026lsquo;람다가 포획(capture)한 변수\u0026rsquo;라고 부른다.\n내부적으로 아래와 같이 동작한다.\n파이널 변수를 포획한 경우 : 람다 코드를 변수 값과 함께 저장한다. 일반 변수를 포획한 경우 : 변수를 특별한 래퍼(Ref)로 감싸서 나중에 변경하거나 읽을 수 있게 한다. (래퍼를 참조하는 것) 컴파일된 코드를 한번 살펴보자.\n// (1) class Ref\u0026lt;T\u0026gt;(var value: T) val counter = Ref(0) val inc = { counter.value++ } // (2) var counter = 0 val inc = { counter++ } (2) 코드의 내부 원리가 (1)이다.\n\u0026quot; 한 가지 꼭 알아둬야 할 함정이 있다. 람다를 이벤트 핸들러나 다른 비동기적으로 실행되는 코드로 활용하는 경우 함수 호출이 끝난 다음에 로컬 변수가 변경될 수도 있다. \u0026ldquo;\n5.1.5 멤버 참조 # 람다와 같이 코드를 인자로 넘길 수 있다. 다만 함수로 생성이 되어 있는 코드를 넘기려면 어떻게 해야할까?\n멤버 참조를 통해 해결할 수 있다.\nval getAge = Person::age // val getAge = { person:Person -\u0026gt; person.age } 와 같다. :: 를 사용하는 식을 멤버 참조 라고 부른다.\n멤버 참조는 프로퍼티나 메서드를 \u0026lsquo;단 하나\u0026rsquo;만 호출하는 함수 값으로 만들어준다. 멤버 참조 뒤에는 () 를 붙여서는 안된다. 최상위에 선언된 함수/프로퍼티도 참조할 수 있다.\nfun salute() = println(\u0026#34;salute\u0026#34;) run(::salute) // 최상위 함수를 호출한다. 생성자 참조(constructor reference)를 사용하면 클래스 생성 작업을 연기하거나 저장해둘 수 있다.\n:: 뒤에 클래스 이름을 넣으면 생성자 참조를 만들 수 있다.\nval createPerson = ::Person createPerson(\u0026#34;alice\u0026#34;, 29) 확장함수도 멤버 함수와 똑같은 방식으로 참조할 수 있다.\nfun Person.isAudit() = age \u0026gt;= 21 val predicate = Person::isAudit 바운드 멤버 참조\n코틀린 1.0에서는 클래스의 메서드, 프로퍼티에 대한 참조를 얻은 다음에 그 참조를 호출할 때 항상 인스턴스 객체를 제공해야 했다.\n코틀린 1.1부터는 바운드 멤버 참조(bound member reference)를 지원한다. 바운드 멤버 참조를 사용하면 멤버 참조를 생성할 때 클래스 인스턴스를 함께 저장한 다음 나중에 그 인스턴스에 대해 멤버를 호출한다.\nval p = Person(\u0026#34;Dmitry\u0026#34;, 34) val personAgeFunction = Person::age println(personAgeFunction(p)) // 인스턴스를 넘긴다. val dmitryAgeFunction = p::age // 인스턴스를 함께 저장한다. println(dmitryAgeFunction()) // 인스턴스를 넘기지 않는다. 5.2 컬렉션 함수형 API # 5.2.1 필수적인 함수 : filter, map # 생략\n5.2.2 all, any, count, find : 컬렉션에 술어 적용 # all : 모든 술어를 만족하는지 확인한다.\nval canBeInClub27 = { p: Person -\u0026gt; p.age \u0026lt;= 27 } people.all(list) any : 하나라도 만족하는지 확인한다.\nval canBeInClub27 = { p: Person -\u0026gt; p.age \u0026lt;= 27 } people.any(list) count : 술어를 만족하는 원소의 개수를 센다.\nval canBeInClub27 = { p: Person -\u0026gt; p.age \u0026lt;= 27 } people.count(list) find : 술어를 만족하는 원소를 찾는다.\n가장 먼저 발견된 원소 \u0026lsquo;하나\u0026rsquo;를 반환한다. 발견되는 원소가 없다면 null 을 반환한다. val canBeInClub27 = { p: Person -\u0026gt; p.age \u0026lt;= 27 } people.find(list) 5.2.3 groupBy: 리스트를 여러 그룹으로 이뤄진 맵으로 변경 # 컬렉션의 모든 원소를 어떤 특성에 따라 여러 그룹으로 나눌 때 사용할 수 있다.\nval people = listOf(...) println(people.groupBy { it.age }) // { // 29 = [Person(...), Person(...)], // 31 = [Person(...), Person(...)] // } 5.2.4 flatMap, flatten : 중첩된 컬렉션 안의 원소 처리 # flatMap : 주어진 람다를 컬렉션의 모든 객체에 적용하고(또는 매핑하고), 람다를 적용한 결과로 얻어지는 여러 리스트를 한 리스트로 모은다.\n즉, map → flat 한다? val strings = listOf(\u0026#34;abc\u0026#34;, \u0026#34;def\u0026#34;) strings.flatMap { it.toList() } // [a, b, c, d, e, f] // 1. string -\u0026gt; list mapping // 2. flat val books = lostOf(Book(...), Book(...), Book(...), ...) books.flatMap { it.authors }.toSet() // [길동, 철수, ...] flatten : (flatMap과 같이 매핑할 게 없고) 펼치기(flat)만 필요하다면 flatten 을 사용한다.\n5.3 지연 계산(lazy) 컬렉션 연산 # 위에서 살펴본 map, filter 등의 연산은 즉시(eager) 연산한다. = 체이닝 연산을 할 때 계산의 중간 결과를 새로운 컬렉션에 담는다는 의미이다.\n시퀀스(sequence) 를 사용하면 중간의 임시 컬렉션을 사용하지 않고도 컬렉션 연산을 체이닝(연쇄)할 수 있다.\n시퀀스의 원소는 필요할 때 비로소 계산된다. asSequence 확장 함수를 호출하면 어떤 컬렉션이든 시퀀스로 바꿀 수 있다. 아래 예시를 살펴보자.\n참고로, map, filter 는 연산 후 리스트를 반환한다.\npeople.map(Person::name).filter { it.startsWith(\u0026#34;A\u0026#34;) } 위 코드는 리스트를 2개 만든다.\n원소가 많을 수록, 체이닝이 많을 수록 문제가 심해진다.\n이를 더 효율적으로 개선하기 위해서 시퀀스를 사용해볼 수 있다.\npeople.asSequence() .map(Person::name) .filter { it.startsWith(\u0026#34;A\u0026#34;) } .toList() 위 코드는 중간 결과를 저장하는 컬렉션이 생기지 않기 때문에, 성능이 눈에 띄게 좋아진다.\n코틀린 지연 계산 시퀀스는 Sequence 인터페이스에서 시작한다.\n이 인터페이스는 단지 한 번에 하나씩 열거될 수 있는 원소의 시퀀스를 표현한다. Sequence 안에는 iterator 라는 단 하나의 메서드가 있다. 이 메서드를 통해 시퀀스로부터 원소 값을 얻을 수 있다. 왜 시퀀스를 다시 리스트로 변경해야할까? 꼭 변경하지 않아도 된다. 이터레이터를 통해 접근해도 된다면 시퀀스를 그대로 써도 된다. 하지만 대부분의 경우 인덱스를 통해 접근하거나 다른 기능들을 사용하기 편리한 리스트를 다루기 때문에 대부분의 예시에서 변경하는 것이다.\n\u0026rdquo; 큰 컬렉션에 대해서 연산을 체이닝할 때는 시퀀스를 사용하는 것을 규칙으로 삼아라 \u0026ldquo;\n5.3.1 시퀀스 연산 실행: 중간 연산과 최종 연산 # Java Stream 쪽 내용과 비슷해서 생략한다.\n5.3.2 시퀀스 만들기 # asSequence() generateSequence() 생략\n5.4 자바 함수형 인터페이스 활용 # 코틀린은 \u0026lsquo;함수형 인터페이스\u0026rsquo;를 인자로 취하는 자바 메서드를 호출할 때 람다를 넘길 수 있게 해준다.\n\u0026rdquo; 자바와 달리 코틀린에서는 제대로 된 함수 타입이 존재한다. 따라서 코틀린에서 함수를 인자로 받을 필요가 있는 함수는 함수형 인터페이스가 아니라 함수 타입을 인자 타입으로 사용해야 한다. 다만, 컴파일러가 이 함수 타입을 함수형 인터페이스로 변환해주지는 않는다. (이에 대한 내용은 8.1 절에서 자세하게 다룬다.) \u0026ldquo;\n5.4.1 자바 메서드에 람다를 인자로 전달 # 함수형 인터페이스를 인자로 원하는 자바 메서드에 코틀린 람다(혹은 익명객체)를 전달할 수 있다.\nvoid postponeComputation(int delay, Runnable computation); postponeComputation(1000) { println(42) } postponeComputation(1000, object: Runnable { override fun run() { println(42) } }) 람다와 익명객체 사이에는 차이가 있다.\n익명 객체 : 메서드를 호출할 때마다 새로운 객체가 생성된다. 람다 : (내부적으로 생성한 익명 객체를) 재사용한다. 다만, 주변 영역의 변수를 포획한다면 매 호출마다 같은 인스턴스를 사용할 수 없기 때문에 새로 객체를 생성한다. 위 코드에서 postponeComputation(1000) { println(42) } 코드는 다음과 동일하다.\nval runnable = Runnable { println(42) } postponeComputation(1000, runnable) 람다의 자세한 구현\n코틀린 1.0에서 인라인(inline) 되지 않은 모든 람다 식은 무명 클래스로 컴파일된다. (?)\n생략\n코틀린 inline 으로 표시된 코틀린 함수에게 람다를 넘기면 아무런 무명 클래스도 만들어지지 않는다. 대부분의 코틀린 확장 함수는 inline 표시가 붙어 있다. inline 함수에 대해 찾아볼 것\n5.4.2 SAM 생성자: 람다를 함수형 인터페이스로 명시적으로 변경 # \u0026lsquo;SAM 생성자\u0026rsquo;에 대해 찾아볼 것\n5.5 수신 객체 지정 람다 : with 와 apply # 생략\n5.6 요약 # 생략\n"},{"id":66,"href":"/docs/DB/01.-Mysql-%EC%84%9C%EB%B2%84-Mysql%EC%97%94%EC%A7%84-+-%EC%8A%A4%ED%86%A0%EB%A6%AC%EC%A7%80-%EC%97%94%EC%A7%84/","title":"01. Mysql 서버 (Mysql엔진 + 스토리지 엔진)","section":"DB","content":" Mysql 서버는 아래와 같이 구분할 수 있습니다.\nMysql 엔진 스토리지 엔진 Mysql 엔진(Mysql Engine) # 클라이언트의 요청을 받거나, 쿼리를 파싱하거나 캐싱하는 등의 전반적인 기능을 담당합니다.\ndisk와의 직접적인 접근을 제외한 전반적인 역할을 수행합니다.\n커넥션 핸들러 : 커넥션 및 쿼리 요청을 처리합니다. SQL 인터페이스 : DML, DDL, Procedure, View 등 SQL 인터페이스를 제공합니다. SQL 파서 : SQL 쿼리 파싱(토큰화)합니다. 이 과정에서 SQL 문법 오류를 탐지할 수 있습니다. SQL 옵티마이저 : 쿼리를 최적화합니다. 캐시 \u0026amp; 버퍼 : 성능 향상을 위한 보조 저장소 기능을 담당합니다. 스토리지 엔진(Storage Engine) # 실제 데이터를 Disk에 저장하거나 Disk로부터 읽어오는 부분을 담당합니다.\n스토리지 엔진은 테이블 별로 다르게 설정할 수 있어, 하나의 데이터베이스에서 여러 개를 동시에 사용할 수 있습니다.\nInnoDB\n(무결성 보장, 트랜잭션 지원, 오류 복구 기능 제공되기에)비교적 중요한 데이터를 다룰 때, 쓰기 작업이 빈번할 때 권장됩니다.\n(MyISAM에 비해)비교적 많은 기능을 제공하여 무겁습니다. 상대적으로 작업속도가 느릴 수 있습니다. 시스템 자원을 많이 사용합니다. Default로 설정되는 스토리지 엔진입니다. 트랜잭션(커밋, 롤백)을 지원합니다. Row-Level Locking 을 제공합니다. 데이터 복구 기능을 제공합니다. 외래키를 지원합니다. 인덱스(Index)를 지원합니다. 스토리지 용량 사이즈는 64TB 입니다. MyISAM\n쓰기 작업은 느리고, 읽기(검색)작업은 빠르기 때문에 정적인 데이터를 저장하고 검색하는 데에 적합할 수 있습니다.\n(InnoDB에 비해)기본적인 기능만 제공하여 가볍습니다. 트랜잭션을 지원하지 않습니다. Table Level Locking 을 제공합니다. 쓰기 작업이 느립니다. 검색(SELECT) 작업이 빠릅니다. 외래키를 지원하지 않습니다. 인덱스(Index)를 지원합니다. 스토리지 용량 사이즈는 256TB 입니다. Archive\n데이터가 메모리 상에서 압축되고, 압축된 상태로 디스크에 저장합니다.\n\u0026lsquo;로그 수집\u0026rsquo;에 적합합니다. 원시 데이터 관리하는데 효율적일 수 있습니다. Row Level Locking 한번 삽입(Insert)된 데이터는 수정(UPDATE), 삭제(DELETE)할 수 없습니다. 트랜잭션을 지원하지 않습니다. 인덱스(Index)를 지원하지 않습니다. 외래키를 지원하지 않습니다. 스토리지 용량 사이즈는 unlimit 입니다. Memory, Federated, \u0026hellip;\n핸들러 API(Handler API) # Mysql 엔진이 데이터를 읽기/쓰기 작업을 할 때, 스토리지 엔진에 읽기/쓰기를 요청합니다. 이 요청을 핸들러 요청이라고 하고 여기서 사용되는 API를 핸들러 API라고 합니다.\n즉, 핸들러 API 를 통해 스토리지 엔진에 작업을 요청할 수 있습니다.\nshow global status like \u0026#39;Handler%\u0026#39;; +--------------------------+-----------+ |Variable_name |Value | +--------------------------+-----------+ |Handler_commit |145753485 | |Handler_delete |420139 | |Handler_discover |0 | |Handler_external_lock |378322641 | |Handler_mrr_init |0 | |Handler_prepare |21529250 | |Handler_read_first |49551083 | |Handler_read_key |422580944 | |Handler_read_last |9891 | |Handler_read_next |351618495 | |Handler_read_prev |33289560 | |Handler_read_rnd |42499941 | |Handler_read_rnd_next |20689540902| |Handler_rollback |2647 | |Handler_savepoint |1 | |Handler_savepoint_rollback|0 | |Handler_update |711264 | |Handler_write |10041446135| +--------------------------+-----------+ Variable_name : 핸들러 API 이름 Value : 해당 API 를 통해 작업된 레코드의 수 참고 # [MySQL] 주요 스토리지 엔진(Storage Engine) 간단 비교 [MySQL] Engine 별 기능 알아보기 "},{"id":67,"href":"/docs/DB/02.-Mysql-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EA%B5%AC%EC%A1%B0/","title":"02. Mysql 메모리 구조","section":"DB","content":" 메모리 구조는 아래와 같이 구분됩니다.\nGlobal Memory Area(글로벌 메모리 영역) Local Memory Area(Session Memory Area) Global Memory Area # Mysql 데몬이 뜨는 순간 OS로부터 할당받는 메모리 영역입니다.\n모든 쓰레드에서 공유되는 영역입니다.\nBuffer Pool (InnoDB) Key Cache (MyISAM) Query Cache (쿼리 캐시) Binlog Buffer (바이너리 로그 버퍼) Log Buffer (로그 버퍼) Table Cache (테이블 캐시) 대게 1개의 공간으로 할당되지만, 필요에 따라 2개의 공간이 할당될 수 있습니다.\nLocal Memory Area # Client Thread(Foreground Thread(?)) 별로 공간을 할당받는 메모리 영역입니다.\nClient Thread 가 사용자의 요청을 처리하기 위해 사용합니다.\nConnection 버퍼 Read 버퍼 Result 버퍼 Join 버퍼 Sort 버퍼 Random Read 버퍼 \u0026lsquo;커넥션(세션)이 유지되는 동안 계속해서 할당되어 있는 공간(e.g. Connection 버퍼)\u0026lsquo;과 \u0026lsquo;처리 순간에만 할당되는 공간(e.g. Sort버퍼, Join 버퍼)\u0026rsquo; 이 있습니다.\n참고 # [Real MySQL 정리], 3장 MySQL 아키텍처\n"},{"id":68,"href":"/docs/DB/03.-Mysql-%EC%93%B0%EB%A0%88%EB%93%9C/","title":"03. Mysql 쓰레드","section":"DB","content":" Mysql 서버는 쓰레드 기반으로 동작합니다.\nForeground Thread Background Thread Foreground Thread (Client Thread, 사용자 쓰레도) # Client의 커넥션/요청을 처리하기 위해 존재하는 쓰레드입니다. 즉, 최소한 클라이언트가 접속된 만큼 쓰레드가 존재합니다.\nClient가 커넥션을 종료하면, Thread Pool로 되돌아갑니다.\nForeground Thread는 데이터를 Mysql의 캐시나 버퍼로부터 데이터를 읽어옵니다. 캐시/버퍼에 데이터가 없으면 디스크로부터 데이터를 읽어옵니다.\n스토리지엔진(InnoDb, MyISAM)에 따라 Foreground Thread가 디스크의 쓰기 역할이 다릅니다.\nInnoDB 디스크 쓰기 작업은 Background Thread 가 처리합니다. MyISAM 디스크로 쓰기 작업은 Foreground Thread 가 처리합니다. (이유는 읽기 작업을 주로 할 것이기 때문이라고 합니다.) Background Thread # 스토리지엔진에 따라 Background Thread의 역할이 다릅니다.\nCase1. MyISAM\nDisk 읽기/쓰기 작업이 Foreground Thread 에서 처리되기 때문에 Background Thread 가 크게 할 일이 없습니다.\nCase2. InnoDB\nDisk 쓰기 작업은 Background Thread 가 책임집니다. Disk 쓰기 작업을 위한 (역할이 나뉘어진)여러 쓰레드가 존재합니다. 또, Multi-Thread 방식으로 동작합니다.\nMain thread : 아래의 쓰레드를 관리하는 메인 쓰레드입니다. Log thread : log 를 disk 에 기록합니다. Write thread : Buffer의 데이터를 disk에 기록합니다. Insert Buffer Merge Thread : Inert 버퍼에 있는 내용을 병합합니다. "},{"id":69,"href":"/docs/DB/04.-Replication/","title":"04. Replication","section":"DB","content":" Replication 에 대해 이해해보기\nReplication # 회사에서 대용량의, 중요한 테이블에 대한 스키마 변경 작업을 하게 되었다. 작업을 진행하기 전 Replication 에 대한 개념이 부족하여 replication 에 대해 공부해보고 정리해보고자 한다.\nReplication 은 말그대로 \u0026lsquo;복제\u0026rsquo;이다. DB에 데이터를 insert, update, delete 하면 그 내용을 그대로 (여분의, 추가의)DB에 저장해놓는 것이다.\n이렇게 복제된 DB는 백업용으로 사용할 수도 있고, select query를 처리해줄 수도 있다. 예를 들어, select query를 slave DB에 위임하면 메인 DB의 부하를 감소시킬 수 있을 것이다. 보통의 경우 (성능을 고려하여)master DB에 insert, update, delete 동작을 실행하고, slace DB에 select 쿼리를 질의한다고 한다.\n알아야 할 것 # binary log (binlog)\nslave DB가 master DB의 내용을 복제할 때 어떻게 복제할까? binlog 파일을 보고 복제한다고 한다. binlog는 mysql에서 실행된 모든 내용이 기록되는 파일이라고 한다. mysql은 이 binlog 와 binlog의 position(pos) 값을 가지고 있는데, 이 값들을 토대로 slave DB가 복제할 수 있는 것이다.\n아래와 같이 명령어를 통해 binlog(현재 파일명)와 binlog의 position 값을 알 수 있다. 이 값을 slave 도 동일하게 바라보고 있는 것이다.\nmysql\u0026gt; show master status; +---------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +---------------+----------+--------------+------------------+-------------------+ | binlog.000004 | 156 | | | | +---------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) binlog의 내용을 간단히 살펴보면 다음과 같다.\n먼저 mysql 의 binlog 파일이 있는 경로로 이동한다. (환경마다 다르기에, 인터넷에서 경로를 찾아 확인하면 된다.)\n\u0026gt; cd /opt/homebrew/var/mysql \u0026gt; ls ... binlog.000003 binlog.000004 ... 그럼 아래와 같이 binlog 의 내용을 볼 수 있다. cat 과 같은 명령어를 사용해서는 읽을 수 없고 mysqlbinlog 명령어를 통해 읽을 수 있다.\n\u0026gt; mysqlbinlog binlog.000004 # The proper term is pseudo_replica_mode, but we use this compatibility alias # to make the statement usable on server versions 8.0.24 and older. /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/; /*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/; DELIMITER /*!*/; # at 4 ... ROLLBACK/*!*/; ... # [empty] SET @@SESSION.GTID_NEXT= \u0026#39;AUTOMATIC\u0026#39; /* added by mysqlbinlog */ /*!*/; DELIMITER ; # End of log file /*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/; /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 그리고 이때의 binlog, position 값은 다음과 같다.\nmysql\u0026gt; show master status; +---------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +---------------+----------+--------------+------------------+-------------------+ | binlog.000004 | 156 | | | | +---------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 그리고 테스트로 생성한 DB에 insert 쿼리를 날려보면 다음과 같이 값이 추가되어 있음을 확인할 수 있다.\n\u0026gt; mysqlbinlog binlog.000004 # The proper term is pseudo_replica_mode, but we use this compatibility alias # to make the statement usable on server versions 8.0.24 and older. /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/; /*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/; DELIMITER /*!*/; # at 4 ... ROLLBACK/*!*/; ... # [empty] SET @@SESSION.GTID_NEXT= \u0026#39;AUTOMATIC\u0026#39; /* added by mysqlbinlog */ /*!*/; DELIMITER ; # End of log file /*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/; /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; ###################### 여기부터는 추가된 내용이다. # at 156 ... SET TIMESTAMP=1636549521/*!*/; SET @@session.pseudo_thread_id=11/*!*/; SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/; ... SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/; /*!\\C utf8mb4 *//*!*/; SET @@session.character_set_client=255,@@session.collation_connection=255,@@session.collation_server=255/*!*/; SET @@session.lc_time_names=0/*!*/; SET @@session.collation_database=DEFAULT/*!*/; ... # End of log file /*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/; /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; 이때의 binlog, position 값은 다음과 같고 position 의 값이 올라간 것을 알 수 있다.\nmysql\u0026gt; show master status; +---------------+----------+--------------+------------------+-------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +---------------+----------+--------------+------------------+-------------------+ | binlog.000004 | 488 | | | | +---------------+----------+--------------+------------------+-------------------+ 1 row in set (0.00 sec) 참고 # MySQL Master-Slave 복제소개 및 사용방법 "},{"id":70,"href":"/docs/DB/05.-%EC%9D%B8%EB%8D%B1%EC%8A%A4Index/","title":"05. 인덱스(Index)","section":"DB","content":" 인덱스(Index) # 테이블의 검색 성능(속도)를 향상시켜주기 위해 사용되는 기술(혹은 자료 구조)입니다.\n데이터들을 정렬된 상태로 관리하여, 검색 시 이점이 있습니다.\nOrder by 효율성 : 이미 정렬되어 있기에 인덱스에서 관리된 형태 그대로 가져올 수 있다. Min, Max 효율성 : 첫 번째 값, 마지막 값을 가져와 사용할 수 있다. Where 효율성 : 테이블의 데이터들은 내부적으로는 정렬되지 않은 상태로 저장되기 때문에 인덱스 없는 검색 시 Full-Scan이 필요하다. 인덱스 사용 시에는 정렬된 형태로 값을 저장하기 때문에 빠르게 데이터를 검색할 수 있다. 페이지 : InnoDB에서는 디스크에 데이터를 저장하는 가장 기본 단위를 \u0026lsquo;페이지\u0026lsquo;라고 한다. 인덱스도 \u0026lsquo;페이지\u0026rsquo; 단위로 관리된다. 페이지는 16KB로 크기가 고정되어 있다. 인덱스의 키의 크기가 크면, 페이지를 많이 생성하게 되어(많은 페이지를 읽게 되어) 성능 이슈가 발생한다. 인덱스는 카디널리티(Cardinality)가 높은 것을 선택한다. 복합 인덱스의 경우 # 복합인덱스 구성 시, 카디널리티가 높은 순에서 낮은 순으로 구성한다.\ne.g. idx(주민번호, 성별) vs (성별, 주민번호) 카디널리티가 높은 순으로 하면, btree 탐색 과정이 효율적일 것 같다. 직접 테스트를 통해 비교하는 것은 필요하다. 복합인덱스 구성 시, 조건 절에 가장 맨 앞의 컬럼은 포함되어야 한다.\n중간이나 뒤에 컬럼은 빠져도 된다. (물론, 정확한 확인 필요하다.) 복합인덱스 구성 시, 범위 조건(between, like, \u0026gt;, \u0026lt;) 이후 컬럼은 인덱스로 사용되지 않는다.\n=, in은 이후 컬럼도 인덱스로 사용된다. (in 은 = 를 여러번 실행 시킨 것) 단, in 의 인자값으로 서브쿼리가 들어가면 이것은 인덱스로 활용되지 않는다. 체크조건으로 실행된다. (서브 쿼리의 외부가 먼저 실행, 이후 체크조건으로 in 절 실행) 인덱스(Index) 자료구조 # 해시 테이블 # 해시테이블은 등호(=)연산에만 특화되어있다. 부등호 연산에는 적합하지 않다. RedBlack-Tree # 밸런스를 유지하는 트리이다. 하나의 노드에 하나의 값만을 갖는다. (DB 인덱스 자료구조로 적절하지 않다.)\n값을 탐색할 때, 1.하나의 노드에 배열의 형태로 여러 값이 있는 것(b-tree)과 2.노드 마다 주소를 찾아가야하는 것(redblack-tree)의 차이이다. 배열 # 배열로 관리한다면 탐색 시에는 이점이 있다. (선형 탐색) 값 추가, 수정, 삭제 등의 경우 배열의 순서를 다시 유지해주어야 하는 비용이 크다. (DB 인덱스 자료구조로 적절하지 않다.) B-Tree # 트리의 균형을 맞춘다. 중간 노드를 포함한 모든 노드에서 Key, Data를 담을 수 있다. 2개보다 더 많은 자식 노드를 가질 수 있다.(Binary Tree 를 확장한 구조이다.)\n하나의 노드에 N개의 자료를 가지고 있다면, N차 B-Tree라고 부른다. 각 노드 = Disk Block 과 같다. Full-Scan 시 모든 노드를 방문한다. B+Tree # 리프 노드에만 Key, Data를 담는다. Key가 중복될 수 있다. (리프 노드에만 Data가 있기 때문에) 리프노드끼리는 (양방향, Double)연결리스트로 연결되어 있다. 부등호 검색과 같은 것이나 순차적으로 순회할 필요가 있을 때 이점이 있다. 중간 노드에는 Key 만을 갖는다. 따라서, 더 많은 값들을 수용할 수 있다. (= 더 적은 수의 노드를 사용한다 = 더 적은 용량을 차지한다 = B-Tree에 비해 상대적으로 더 적은 Disk Block을 읽어도 된다.) Full-Scan 시 리프 노드 레벨에서 선형 시간으로 탐색할 수 있다. 참고 # 데이터베이스 인덱스는 왜 \u0026lsquo;B-Tree\u0026rsquo;를 선택하였는가 [Database] 인덱스(index)란? [DB] 데이터베이스 인덱스(Index) 란 무엇인가? [DB] 10. B-Tree (B-트리) "},{"id":71,"href":"/docs/DB/06.-%EC%BF%BC%EB%A6%AC-%EC%8B%A4%ED%96%89-%EC%88%9C%EC%84%9C-%EB%B0%8F-%EC%A3%BC%EC%9D%98%EC%82%AC%ED%95%AD/","title":"06. 쿼리 실행 순서 및 주의사항","section":"DB","content":" SELECT 쿼리 실행 순서 # 드라이빙 테이블 (where 적용 / 조인 실행) 드리븐 테이블1 드리븐 테이블2 -\u0026gt; GROUP BY -\u0026gt; DISTINCT -\u0026gt; HAVING -\u0026gt; ORDER BY -\u0026gt; LIMIT // 주로 group by 없이 order by만 적용된 쿼리에서 사용될 수 있는 순서이다. 드라이빙 테이블 -\u0026gt; ORDER BY -\u0026gt; 드리븐 테이블1, 드리븐 테이블2 (were 적용 / 조인 실행) -\u0026gt; LIMIT 적용 인덱스 컬럼의 값을 변환/조작하지 않는다. # 인덱스를 사용하지 않는 경우\n-- user_id 가 index라고 가정한다. explain select * from poster where user_id * 1 = 12; +--+-----------+------+----------+----+-------------+----+-------+----+----+--------+-----------+ |id|select_type|table |partitions|type|possible_keys|key |key_len|ref |rows|filtered|Extra | +--+-----------+------+----------+----+-------------+----+-------+----+----+--------+-----------+ |1 |SIMPLE |poster|NULL |ALL |NULL |NULL|NULL |NULL|17 |100 |Using where| +--+-----------+------+----------+----+-------------+----+-------+----+----+--------+-----------+ 인덱스를 사용하는 경우\n-- user_id 가 index라고 가정한다. explain select * from poster where user_id = 12; +--+-----------+------+----------+----+-------------+-------+-------+-----+----+--------+-----+ |id|select_type|table |partitions|type|possible_keys|key |key_len|ref |rows|filtered|Extra| +--+-----------+------+----------+----+-------------+-------+-------+-----+----+--------+-----+ |1 |SIMPLE |poster|NULL |ref |user_id |user_id|9 |const|2 |100 |NULL | +--+-----------+------+----------+----+-------------+-------+-------+-----+----+--------+-----+ OR 연산자는 주의한다. # or 연산자는 row 수가 더 늘어나기에 테이플 풀스캔이 발생할 수 있다. 주의하여 사용한다.\nGROUP BY # (복합 인덱스의 경우) where 절과 달리 group by 절에서는 컬럼의 순서가 같아야한다. 뒤쪽 컬럼의 경우, 없어도 인덱스를 탈 수 있다. group by 절에, 인덱스에 없는 컬럼이 하나라도 있다면 인덱스를 탈 수 없다. -- 인덱스가 (COL1, COL2, COL3, COL4)라고 가정했을 때, 아래의 경우 인덱스를 탈 수 있다. ... GROUP BY COL1 ... GROUP BY COL1, COL2 ... GROUP BY COL1, COL2, COL3 ... GROUP BY COL1, COL2, COL3, COL4 (앞쪽 컬럼이) where 절에 동등 비교 조건으로 컬럼이 들어가면, group by 에서 빠져도 될 수도 있다. explain select started_date from poster group by user_id, started_date; +--+-----------+------+----------+-----+--------------------+--------------------+-------+----+----+--------+------------------------+ |id|select_type|table |partitions|type |possible_keys |key |key_len|ref |rows|filtered|Extra | +--+-----------+------+----------+-----+--------------------+--------------------+-------+----+----+--------+------------------------+ |1 |SIMPLE |poster|NULL |range|user_id_started_date|user_id_started_date|13 |NULL|5 |100 |Using index for group-by| +--+-----------+------+----------+-----+--------------------+--------------------+-------+----+----+--------+------------------------+ -- 인덱스 (user_id, started_date) 가정한다. -- where 절에 앞쪽 컬럼, group by 에 뒤쪽 컬럼인 경우 explain select started_date from poster where user_id = 12 group by started_date; +--+-----------+------+----------+----+-----------------------------------------+--------------------+-------+-----+----+--------+------------------------+ |id|select_type|table |partitions|type|possible_keys |key |key_len|ref |rows|filtered|Extra | +--+-----------+------+----------+----+-----------------------------------------+--------------------+-------+-----+----+--------+------------------------+ |1 |SIMPLE |poster|NULL |ref |user_id,user_id_started_date,started_date|user_id_started_date|9 |const|2 |100 |Using where; Using index| +--+-----------+------+----------+----+-----------------------------------------+--------------------+-------+-----+----+--------+------------------------+ -- 인덱스 (started_date, user_id) 사용한 경우 +--+-----------+------+----------+-----+--------------------------------------------------------------+--------------------+-------+----+----+--------+-------------------------------------+ |id|select_type|table |partitions|type |possible_keys |key |key_len|ref |rows|filtered|Extra | +--+-----------+------+----------+-----+--------------------------------------------------------------+--------------------+-------+----+----+--------+-------------------------------------+ |1 |SIMPLE |poster|NULL |range|user_id,user_id_started_date,started_date,started_date_user_id|started_date_user_id|13 |NULL|5 |100 |Using where; Using index for group-by| +--+-----------+------+----------+-----+--------------------------------------------------------------+--------------------+-------+----+----+--------+-------------------------------------+ -- 인덱스 (user_id, started_date) 가정한다. -- where 절에 뒤쪽 컬럼, group by 에 앞쪽 컬럼인 경우 explain select user_id from poster where started_date = \u0026#39;2020-12-24\u0026#39; group by user_id; +--+-----------+------+----------+-----+-----------------------------------------+--------------------+-------+----+----+--------+-------------------------------------+ |id|select_type|table |partitions|type |possible_keys |key |key_len|ref |rows|filtered|Extra | +--+-----------+------+----------+-----+-----------------------------------------+--------------------+-------+----+----+--------+-------------------------------------+ |1 |SIMPLE |poster|NULL |range|user_id,user_id_started_date,started_date|user_id_started_date|13 |NULL|3 |100 |Using where; Using index for group-by| +--+-----------+------+----------+-----+-----------------------------------------+--------------------+-------+----+----+--------+-------------------------------------+ ORDER BY # group by와 유사하다. 다만 asc, desc 를 통일시켜야 한다.\nexplain select poster_id from poster where user_id = 12 order by started_date; +--+-----------+------+----------+----+----------------------------+--------------------+-------+-----+----+--------+------------------------+ |id|select_type|table |partitions|type|possible_keys |key |key_len|ref |rows|filtered|Extra | +--+-----------+------+----------+----+----------------------------+--------------------+-------+-----+----+--------+------------------------+ |1 |SIMPLE |poster|NULL |ref |user_id,user_id_started_date|user_id_started_date|9 |const|18 |100 |Using where; Using index| +--+-----------+------+----------+----+----------------------------+--------------------+-------+-----+----+--------+------------------------+ explain select poster_id from poster order by user_id, started_date; +--+-----------+------+----------+-----+-------------+--------------------+-------+----+----+--------+-----------+ |id|select_type|table |partitions|type |possible_keys|key |key_len|ref |rows|filtered|Extra | +--+-----------+------+----------+-----+-------------+--------------------+-------+----+----+--------+-----------+ |1 |SIMPLE |poster|NULL |index|NULL |user_id_started_date|13 |NULL|18 |100 |Using index| +--+-----------+------+----------+-----+-------------+--------------------+-------+----+----+--------+-----------+ explain select poster_id from poster where started_date = \u0026#39;2020-12-24\u0026#39; order by user_id; +--+-----------+------+----------+----+-------------+------------+-------+-----+----+--------+-------------------------------------+ |id|select_type|table |partitions|type|possible_keys|key |key_len|ref |rows|filtered|Extra | +--+-----------+------+----------+----+-------------+------------+-------+-----+----+--------+-------------------------------------+ |1 |SIMPLE |poster|NULL |ref |started_date |started_date|4 |const|12 |100 |Using index condition; Using filesort| +--+-----------+------+----------+----+-------------+------------+-------+-----+----+--------+-------------------------------------+ -- 비교를 위해, (start_date, user_id) 인덱스인 경우는 아래와 같다. +--+-----------+------+----------+----+---------------------------------+--------------------+-------+-----+----+--------+------------------------+ |id|select_type|table |partitions|type|possible_keys |key |key_len|ref |rows|filtered|Extra | +--+-----------+------+----------+----+---------------------------------+--------------------+-------+-----+----+--------+------------------------+ |1 |SIMPLE |poster|NULL |ref |started_date,started_date_user_id|started_date_user_id|4 |const|12 |100 |Using where; Using index| +--+-----------+------+----------+----+---------------------------------+--------------------+-------+-----+----+--------+------------------------+ WHERE 조건 + ORDER BY (or GROUP BY) # 1. where절 + order by절이 동시에 같은 인덱스 사용\nwhere 조건에 들어가는 컬럼, order by 절에 들어가는 컬럼이 모두 하나의 인덱스에 포함되어 있을 때이다.\n물론 order by가 있기 때문에 order by의 순서도 지켜져야할 것이다.\n2. where절만 인덱스 사용\nwere 절만 인덱스를 통해 데이터를 조회하고, order by 절은 인덱스를 사용하지 않는다. 즉, order by 쪽은 filesort 를 통해 정렬한다.\nwhere 절 이후 레코드 수가 없을 경우 효율적일 것이다.\n3. order by절만 인덱스 사용\norder by 절은 인덱스를 사용한다.\n즉, 인덱스 통해 이미 정렬되어 있는 데이터를 순서대로 읽으면서 where 절의 조건에 일치하는지 확인하는 것이다. 일차히지 않으면 버리는 형태이다.\n\u0026quot; 위 그림은 WHERE 과 ORDER BY 절이 결합된 두 가지 패턴의 쿼리를 표현한 것이다. 그림 오른쪽과 같이 ORDER BY 절에 해당 칼럼이 사용되고 있다면 WHERE 절에 동등 비교 이외의 연산자로 비교돼도 WHERE 조건과 ORDER BY 조건이 모두 인덱스를 이용할 수 있다. 위 그림의 왼쪽 패턴 쿼리 예제는 다음과 같다. \u0026quot;\n출처 : https://weicomes.tistory.com/191?category=669169\nORDER BY + GROUP BY # 하나의 인덱스를 사용하려면, 두 절(order by, group by)모두 인덱스 컬럼과 동일하게, 순서대로 작성되어야 한다.\n둘 중 하나라도 인덱스를 이용하지 못하면 둘 다 인덱스를 타지 못한다.\nWHERE + ORDER BY + GROUP BY (:star::star:) # 출처 : https://weicomes.tistory.com/191?category=669169\n참고 # [mysql]인덱스 정리 및 팁 28. MySQL 실행 계획 : 실행 계획 분석(6) "},{"id":72,"href":"/docs/DB/07.-Lock-%EB%82%99%EA%B4%80%EC%A0%81-%EB%9D%BD-%EB%B9%84%EA%B4%80%EC%A0%81-%EB%9D%BD/","title":"07. Lock (낙관적 락, 비관적 락)","section":"DB","content":" 정리하면 아래와 같을 수 있을 것 같음\n낙관적 락 : CAS\n비관적 락 : Lock\nOptimistic Lock (낙관적 락) # 트랜잭션 충돌이 발생하지 않는다고 가정하는 것\nDB 제공하는 Lock 을 사용하지 않고, Application Level(e.g. JPA)에서 버전 관리 직접함\n\u0026gt; 버전 관리 : version, timestamp, hashcode 등\nCAS 개념으로 볼 수 있을 것 같다.\nLock 을 사용하지 않기 때문에, 트랜잭션 충돌이 많지 않은 상황에 사용하면 성능 향상\nLock vs CAS 의 비교로도 볼 수 있을 듯\n... @Entity public class Member { @Id @GeneratedValue(strategy = GenerationType.AUTO) private Long id; ... @Version private Long version; } Pessimistic Lock (비관적 락) # 트랜잭션 충돌이 발생한다고 가정하는 것\n트랜잭션이 충돌이 발생한다고 가정하고, 우선적으로 Lock 을 거는 것\n트랜잭션 충돌이 발생하는 것을 가정하기에, Lock(공유 잠금, 배타 잠금)을 건다.\npublic interface MemberRepository extends JpaRepository\u0026lt;Member, Long\u0026gt; { @Lock(LockModeType.PESSIMISTIC_WRITE) @Query(\u0026#34;~\u0026#34;) Member findByName(String name); } 참고 : 공유 잠금, 배타 잠금 예시 # -- 공유 잠금 SELECT * FROM mytable WHERE id = 1 LOCK IN SHARE MODE; -- 배타 잠금 SELECT * FROM mytable WHERE id = 1 FOR UPDATE; "},{"id":73,"href":"/docs/DB/08.-Charset-Collation/","title":"08. Charset \u0026 Collation","section":"DB","content":" Mysql 기준\nMysql에서 제공하는 Charset 종류 # 아래의 명령어로 확인할 수 있다.\nshow character set ; 대표적으로 아래와 같다.\nutf8 utf8mb4 ascii euckr 특징 (중요!!) # Mysql utf8은 3byte까지 지원한다. 4byte 문자를 사용하기 위해서는 utf8mb4를 사용한다. utf16, utf32도 4byte를 지원한다. Mysql에서 제공하는 Collation 종류 # 아래의 명령어로 확인할 수 있다.\nshow collation ; 대표적으로 아래와 같다.\nutf8_bin, utf8mb4_bin (utf8, utf8mb4) binary 값(hex)으로 비교한다. utf8_general_ci, utf8mb4_general_ci (utf8, utf8mb4) a, b, \u0026hellip; 순서 (즉 휴머니스틱하게 정렬) utf8_unicode_ci, utf8mb4_unicode_ci (utf8, utf8mb4) utf8_general_ci 보다 조금 더 휴머니스틱하게 정렬한다고 한다. (우리나라에서 잘 사용되지 않는)특수 문자들의 순서가 다르다고 한다. "},{"id":74,"href":"/docs/DB/09.-GTID/","title":"09. GTID","section":"DB","content":" GTID 에 대해 이해해보기\nGTID(Global Transaction IDentifier) (작성중) # 형태 : 고유한 식별자(ID):TRANSACTION ID\nMaster,Slave 복제 기준이 되었던 binlog, pos 대신 GTID 를 사용할 수 있다. Master 의 binglog file, pos 를 따라가지 않아도 된다. GTID 정보만으로 Master, Slave 간의 일관성을 쉽게 확인할 수 있다. GTID 트랜잭션은 mysql.gtid_executed 로 관리되기에, 중복 수행되지 않는다. 트랜잭션이 commit 되면 GTID 를 할당 받고 binlog 에 기록한다. 할당된 GTID 는 gtid_executed system variable, mysql.gtid_executed 에 저장된다. (Mysql 5.7 기준)GTID 에서는 CTAS, CREATE TEMPORARY TABLE 실행 불가와 같은 몇 가지 제약사항이 있다. ( 참고)\n"},{"id":75,"href":"/docs/DB/10.-InnoDB-auto_increment-%EC%B4%88%EA%B8%B0%ED%99%94-%EB%B0%A9%EC%8B%9D/","title":"10. InnoDB Auto_increment 초기화 방식","section":"DB","content":" InnoDB 엔진, auto_increment 초기화 방식 # (InnoDB 엔진을 사용할 때) Mysql 5.7과 이전버전에서, 서버 재시작 시 auto_increment 의 값은 아래와 같이 초기화된다.\n이유는 auto_increment 값을 메모리 상에서 관리하기 때문.\n\u0026quot; In MySQL 5.7 and earlier, the auto-increment counter is stored in main memory, not on disk. To initialize an auto-increment counter after a server restart, InnoDB would execute the equivalent of the following statement on the first insert into a table containing an AUTO_INCREMENT column. \u0026quot;\nSELECT MAX(ai_col) FROM table_name FOR UPDATE; 즉, 아래와 같은 시나리오가 발생할 수 있다. # 데이터에 1, 2, 3, 4, 5 라는 값을 넣는다. 이때 다음 auto_increment 값은 6 이다. 데이터 5를 지운다. 서버를 재시작한다. 데이터 6을 넣는다. 이때 다음 auto_increment 값 5가 된다. mysql\u0026gt; select * from test; +----+-------+ | id | name | +----+-------+ | 1 | name1 | | 2 | name2 | | 3 | name3 | | 4 | name4 | | 5 | name5 | +----+-------+ 5 rows in set (0.01 sec) mysql\u0026gt; delete from test where id = \u0026#39;5\u0026#39;; Query OK, 1 row affected (0.01 sec) mysql\u0026gt; select * from test; +----+-------+ | id | name | +----+-------+ | 1 | name1 | | 2 | name2 | | 3 | name3 | | 4 | name4 | +----+-------+ 4 rows in set (0.00 sec) mysql\u0026gt; insert into test(name) values(\u0026#39;name6\u0026#39;); Query OK, 1 row affected (0.00 sec) mysql\u0026gt; select * from test; +----+-------+ | id | name | +----+-------+ | 1 | name1 | | 2 | name2 | | 3 | name3 | | 4 | name4 | | 5 | name6 | +----+-------+ 5 rows in set (0.00 sec) 테이블 설계에 따라 아래와 같이 문제가 발생할 수 있다. # 테이블 A, B가 있다. 테이블 A의 PK는 auto_increment 로 설정되어있다. 테이블 B에서 unique 값으로 A의 PK 값을 갖는다. 테이블 A가 삽입/삭제될 때 테이블 B도 삽입/삭제된다. 위와 같은 구조에서 테이블 A의 PK 값이 변경되어 원래 예정된 값(6)보다 작아졌다면(5) 테이블 B에 unique 제약에 걸려 오류가 발생할 수 있다.\nMysql 8.0 부터는 동작방식이 변경되어 위와 같은 현상은 발생하지 않는다. # Mysql 8.0 부터는 redo log, data dictionary 라는 곳에 값이 저장되어 영속적으로 관리된다고 한다.\n\u0026quot; In MySQL 8.0, this behavior is changed. The current maximum auto-increment counter value is written to the redo log each time it changes and saved to the data dictionary on each checkpoint. These changes make the current maximum auto-increment counter value persistent across server restarts. \u0026quot;\n참고 # 15.6.1.6 AUTO_INCREMENT Handling in InnoDB : InnoDB AUTO_INCREMENT Counter Initialization "},{"id":76,"href":"/docs/DEV/AWS-Community-Day-2022/Amazon-CloudFront%EC%99%80-AWS-Lambda@Edge%EB%A1%9C-SPA%EC%97%90%EC%84%9C-%EB%8F%99%EC%A0%81-SEO-%EA%B5%AC%ED%98%84%ED%95%98%EA%B8%B0/","title":"Amazon CloudFront와 AWS Lambda@Edge로 SPA에서 동적 SEO 구현하기","section":"AWS Community Day 2022","content":" OpenGraph # SPA 는 왜 링크마다 OpenGraph 적용이 안될까? # OpenGraph 스크랩 봇의 행동 강령 : JS는 버린다. (JS 를 읽는데에 시간이 많이 쓰이기 때문에)\n이건 별도로 찾아보자. SPA 는 기본 뼈대가 아주 단순한 구조이다.\n대처 방법은? # SSR, Static 웹으로 제공할 수 있다.\n다만 위 방법도 단점은 있다. 동적으로 제공하기 힘들다.\n코드 레벨이 아닌 인프라로 해결할 수 있을까? # 인프라로 해결할 수 있다. 웹 앱 앞에 프록시를 두고 메타 태그를 추가할 수 있다.\nLambda@Edge 를 통해 구현할 수 있다.\nLambda@Edge # CF 기능 중 하나로 사용자와 가장 가까운 위치의 람다를 실행하게 하는 서비스이다.\nCF 캐싱 규칙 (캐싱 정규화) # 어떤 캐싱 기준(URL, Request Object, \u0026hellip;)을 설정할 것인지?에 대한 내용이다. AWS 에서 기본적으로 제공하는 기준을 사용할 수도 있고 커스텀하게 설정하여 사용할 수도 있다.\nBot / User 여부 Bot 이라면, 해당 (단건)페이지 response 를 내려준다. 사용자면 origin 서버에 그냥 넘겨준다. SEO 도 가능할까? # 결론: 애매하다.\n검색엔진의 알고리즘에 따라 다를 수 있다.\n대부분 시맨틱 태그, Body 내부의 아티클이 필요하다. 이런 설정도 가능할 수는 있겠지만 CF의 설정이 너무 복잡해질 것이다. (배보다 배꼽이 더 커질 것이다.)\n"},{"id":77,"href":"/docs/DEV/AWS-Community-Day-2022/AWS-Lambda-Container%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-%EC%84%9C%EB%B2%84%EB%A6%AC%EC%8A%A4-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98-%EB%B0%B0%ED%8F%AC-%EB%B0%8F-%EC%84%B1%EB%8A%A5-%ED%96%A5%EC%83%81/","title":"AWS Lambda Container를 활용한 서버리스 아키텍처 배포 및 성능 향상","section":"AWS Community Day 2022","content":" Introduction # Fargate Kinesis (Data Firehost, Stream) S3 SQS Lambda Step Functions 구조화된 Lambda workflow 를 구성하고 있다. Why Lambda Container? # Data 처리 \u0026amp; Lambda 사용에 있어서 용량 제한으로 인해 다양한 라이브러리 사용에 제한이 있었다. 라이브러리 용량이 조금만 커도 사용에 제한이 있었다.\n기존 labmda 기반 아키텍처를 유지하면서 conatiner 기반으로 변경할 수 있어야 했다.\nLambda Container with Serverless Framework # 도커 이미지 필요하다. AWS 에서 제공하는 이미지를 사용하는게 제일 속 편하다. (이 경우가 아니면 추가 설정이 들어갈 수 있다고 한다.)\nserverless framework의 provider 설정을 통해 ecr 에 배포할 수 있다.\n장점\n용량 문제 해소 하나의 이미지를 통해 다용도(API server, Lambda 등 다양한 곳에서 같은 이미지)로 사용 가능했다. AWS Lambda 에서 지원하지 않는 런타임 사용 가능했다. 기존 Lambda 환경과 달리 완전히 캡슐화된 Lambda 함수를 제공할 수 있었다. 단점\n용량 한계 극복한 점 외에 실행 시간, 실행 횟수 제한 동일했다. 여전히 람다 이므로, 동일한 제약사항이 있었다. 이미지 생성 시간이 필요해지면서 배포 시간 증가했다. serverless framework 로 배포 시 일부 plugin 들과 충돌 문제가 있었다. Lambda Cold Start 시간 증가했다. 추천 환경\n컨테이너 방식으로 개발된 환경에서 Lambda로도 지원해야할 때 용량이 큰 라이브러리 사용 및 용량 제한 없이 배포하고 있을 때 lambda 컨테이너의 최대 장점인 것 같다. Lambda에서의 코드가 실행되는 전체 환경에 대한 제어가 필요할 때 * 기존 lambda 환경에서 불편함이 없다면, lambda container로 변경해야할 이유는 없을 것 같다.\nServerless 에서의 성능 향상을 위해 사용한 3가지 방법 # 개선 1. 동기 -\u0026gt; 비동기 # 왼쪽 동기 방식은 안전하고 확실하지만 요청이 많은 경우 힘들다.\n개선 2. S3 Multi-Part Upload / CLoud Storage Parted Downalod # 큰 용량의 비디오 데이터를 처리하던 도중에 발견하여 사용하게 되었다.\n개선 3. Step function Parallel # 결론 # "},{"id":78,"href":"/docs/DEV/AWS-Community-Day-2022/AWS-Nitro-Enclave%EB%A5%BC-%EC%9D%B4%EC%9A%A9%ED%95%98%EC%97%AC-%EC%95%88%EC%A0%84%ED%95%98%EA%B2%8C-%EA%B3%A0%EA%B0%9D-%EC%A0%95%EB%B3%B4-%EB%8B%A4%EB%A3%A8%EA%B8%B0/","title":"AWS Nitro Enclave를 이용하여 안전하게 고객 정보 다루기","section":"AWS Community Day 2022","content":""},{"id":79,"href":"/docs/DEV/AWS-Community-Day-2022/AWS%EC%97%90%EC%84%9C-%EC%BB%A8%ED%85%8C%EC%9D%B4%EB%84%88-%EC%9A%B4%EC%98%81%ED%95%98%EA%B8%B0.-%EA%B7%B8%EB%A6%AC%EA%B3%A0-ROSA/","title":"AWS에서 컨테이너 운영하기. 그리고 ROSA","section":"AWS Community Day 2022","content":" PaaS # AWS Lightsail AWS Elastic Beanstalk serverless # 대표적으로 아래와 같은 서비스를 제공합니다.\nAWS Lambda What is cold-start (issue)? AWS App Runner AWS Fargate orchestration # 대표적으로 아래와 같은 서비스를 제공합니다.\nAWS ECS AWS EKS AWS ECS # EKS에 비해 단순함 을 강조한 서비스\nAWS EKS # ECS 에 비해 조금 복잡하지만 유연성(확장성) 을 강조한 서비스\n입문자 입장에서는 ECS를 사용하다가 EKS를 사용하는 것을 권장한다.\nROSA # RedHat + OpenShift + AWS\nOpenShift는 k8s + 다양한 기능을 사용할 수 있는 서비스이다.\nSecurity # 클라우드 운영 시 신경써야 하는 부분이 많이 있다. 그 중 첫 번째 허들은 보안이다.\n4\n"},{"id":80,"href":"/docs/DEV/AWS-Community-Day-2022/CDK-for-Terraform%EC%9C%BC%EB%A1%9C-%EB%82%98%EB%A7%8C%EC%9D%98-AWS-Resource-%EC%A0%95%EC%9D%98%ED%95%98%EA%B8%B0/","title":"CDK for Terraform으로 나만의 AWS Resource 정의하기","section":"AWS Community Day 2022","content":" IaC의 장점 # Infrastructure 버전을 관리할 수 있다. Infrastructure 선언적으로 관리할 수 있다. Infrastructure 여러 벌(set) 배포할 수 있다. 각 리소스의 필수 요소들을 파악하기 쉽다. 리소스가 대체될 것이라는 warning 문구를 표시해주기도 하고, replace 할 것인지 확인 여부를 묻는 기능도 있다. (approval 하면 실제 배포되는 것) 예상치 못한 과금을 예방할 수 있다. 비즈니스 로직 작성에 집중할 수 있다. CDK for TF # AWS CDK 개발진이 Hashi Corp와 함께 개발한 IaC Kit Generally Available at 2022.08.09 ts, python, java, c#, go 로 infrastructure 정의, 배포, 운영 가능하다. CDKTF와 AWS CDK는 호환성을 보장하려고 한다. 왜 CDK for TF 를 사용해야할까? # 콘솔(AWS Management Console) 관리의 경우,\n쉽다. 작업 기록이 남지 않는다. 규모가 커질수록 운영이 어렵다. AWS CLI \u0026amp; SDK, AWS CloudFormation 의 경우,\n작업 기록을 남길 수 있다. 어렵다. 작업량이 많다. 개발자 친화적이지 않다. AWS CDK 의 경우,\n쉽다. 작업량이 적다. 개발자 친화적이다. CDK for TF 의 경우,\nAWS CDK + TF 장점(TF 의 경우, docker, k8s 등 AWS 외의 리소스도 관리할 수 있다.) TF ecosystem 활용 가능하다. CDKTF Building Blocks # Resource = AWS 리소스\nCDKTF와 AWS CDK를 관통하는 개념 : Construct # CDK 프로젝트를 설명할 수 있는 용어 모든 구성요소는 Construct의 하위 클래스 App, Stack, Resource 모두 Construct이다. 추상화 정도에 따라서 Construct Type 이 존재 L1: single resource 수준의 configuration e.g.) EC2 하나 생성 L2: 하나 이상의 resource와 추가적인 기능이 포함된 configuration e.g.) S3 Bucket 생성 후 업로드 메서드 구현 L3: 배포, 호스팅에 필요한 모든 resource 를 포함한 configuration Demo # "},{"id":81,"href":"/docs/DEV/AWS-Community-Day-2022/%EA%B4%91%EA%B3%A0-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%88%98%EC%A7%91%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%9D%B8%ED%94%84%EB%9D%BC-%EA%B5%AC%EC%B6%95/","title":"광고 데이터 수집을 위한 인프라 구축","section":"AWS Community Day 2022","content":" https://jybaek.tistory.com/\nAgenda # 광고 도메인 설명 # 굉장히 많은 (수십 개의) 매체에서 데이터를 수집하고 있다.\n광고주마다 성과측정의 기준이 되는 기여기간이 다르다. 각 매체가 관리하는 광고 지면들로부터 뒤늦게 데이터가 집계되는 경우도 있다. (예를 들어, 시간이 지나면서 클릭수가 막 변경된다.) 수집 : (다양한 매체의) 대용량 광고 데이터 수집 # ECS 서비스를 사용하고 있다.\n왼쪽부터 1번 순서로 진행된다. RDS 에서 스케줄러가 데이터 읽고, 키 정보? 조회 하여 Cache에 보낸다. Cache 에 보내지면 Collector 가 일겅와? \u0008수집을 시갖한다.\n다만, 대량의 요청을 할 때 429 에러(및 차단)가 발생할 수 있다.\n따라서 쓰로틀링을 조절하여 수집할 수 있도록 변경했다.\n수집 : ElastiCache for Redis(stream)으로 stateless 수집 # 아래와 같은 상황(=컬렉팅 하는 과정에서 deploy 를 하면)에서 어떤 일이 발생할까?\n서비스가 내려간다. 수집되던것은 중단된다. (물론, gracefully shutdown 을 설정할 수도 있다.)\n배포는 아무때나 할 수 있어야 한다. 어떻게 할 수 있을까?\n// 다시\n데이터 적재 \u0026amp; Redshift 튜닝 # 아까 말한 것 처럼 시간이 지남에 따라 지표 값이 변경되기도 했다. 일반적인 DB를 사용하기는 어려웠고 Redshift 를 사용했다.\ndelete \u0026amp; copy\n(redshift 와 사용할 때, 같은 컬럼 기반이라)parquet 가 보통 성능이 좋다. json 을 선택했다. (수집 시 키 컬럼이 변경되는 경우가 허다하기에 컬럼이 계속해서 변해서)\n튜닝 : 분산 키 설정 # 분산 키 설정은 필수다. 꼭 설정해야한다.\nsuperuser 큐 1개 보통 이건 포함안시켜서 말한다. default 큐 1개 커스텀 큐 n개 // 다시\nAirflow 환경 선택 # EKS 운영한다. pod를 죽였다 살렸다 해야해서 꽤나 부담스러울 수 있다. EC2 운영한다. 성능은 좋지만, 가용성은 역시 떨어진다. CloudWatch 를 사용한다. Terraform 으로 ECS 인프라 구축 # 모듈 구조를 어떻게 잡을 지가 결정해야하는 요소이다.\n인스턴스 t 타입의 버스트 기능은 유용할 수 있다.\n다시 볼 것\n"},{"id":82,"href":"/docs/DEV/AWS-Community-Day-2022/%EC%98%A4%ED%94%88-%EC%86%8C%EC%8A%A4-Karpenter%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-Amazon-EKS-%ED%99%95%EC%9E%A5-%EC%9A%B4%EC%98%81-%EC%A0%84%EB%9E%B5/","title":"오픈 소스 Karpenter를 활용한 Amazon EKS 확장 운영 전략","section":"AWS Community Day 2022","content":"Karpenter\n오토스케일링 솔루션에 대한 고민 # 무신사는 ASG를 적극적으로 활용하고 있다.\n(평소의)트래픽에 대한 예측이 (나름) 가능하다. 많이 들어오는 비슷하다. 트래픽 증가 폭이 완만하다. 평소에는 ASG 활용해서 CPU 사용률을 기반으로 점진적으로 스케일링 한다. 서비스 마다 CPU, 메모리 사용률이 제각각이기에 다양한 인스턴스 타입을 사용 중이다. 다만, 이벤트 기간에는 다르다.\n사전에 미리 스케일 아웃 해둔다. 사전에 인지 못해도, 가능한 빨리 스케일 아웃될 수 있어야 한다. :zap: 따라서, 스케일 인/아웃 모두 빠르면서 서비스에 적합한 인스턴스를 비용-효율적으로 운영해야 한다.\nCluster Autoscaler 및 단점 # 기존에는 Cluster Autoscaler 를 사용해왔다. 당시에는 k8s로 이전하는 것에 중점을 뒀다.\nㄴ 수동으로 노드를 삭제한 경우?\nKarpenter (카펜터, K8S Native AutoScaler) # 아직 레퍼런스가 많지는 않다.\n어떻게 작동하는지? # pod에 대한 모니터링이 pulling 방식이 아닌 pub/sub 방식으로 동작한다.\n따라서, 이벤트(메시지)가 발생하자마자 스케줄링이 동작한다. (Cluster Autoscaler의 pulling 방식은 주기적으로 동작하니까, 실시간적으로 동작 하지 않는 특징이 있다.)\n시작 템플릿이 필요 없다.\nASG의 경우 시작 템플릿(launch template?)이 필요한데, 애는 필요하지 않다.\nResource Id, Tag 기반으로 리소스를 시작할 수 있다.\nAMI 를 지정하지 않으면, 가장 최신의 EKS 최적화 AMI로 증설된다.\n인스턴스 타입은 가드레일 방식으로 선언 가능하다.\nPod 에 적합한 인스턴스 중 가장 저렴한 인스턴스로 증설된다.\nPV를 위해 단일 서브넷에 노드 그룹을 만들 필요가 없다.\n가중치 기반으로 배포될 인스턴스 타입을 설계할 수 있다.\n\u0026hellip;\n사용 안하는 노드는 자동으로 정리한다.\n\u0026hellip;\n일정 기간이 지나면 자동으로 노드를 만료시킨다.\n노드가 제때 drain 되지 않으면, 비효율적으로 운영될 수 있다.\n노드를 줄여도 다른 노드에 충분한 여유가 있다면 자동으로 정리해준다.\n노드 최적화를 해준다.(비용을 줄일 수 있도록 노드를 자동으로 합쳐준다.)\n카펜터에 문제(= 노드 띄우는 시간)도 있다.\n위 문제는 다음과 같이 해결했다.\n"},{"id":83,"href":"/docs/DEV/ifkakaodev-2022/Batch-Performance-%EA%B7%B9%ED%95%9C%EC%9C%BC%EB%A1%9C-%EB%81%8C%EC%96%B4%EC%98%AC%EB%A6%AC%EA%B8%B0/","title":"Batch Performance 극한으로 끌어올리기","section":"If Kakao 2022","content":" 배치 코드의 경우 (비교적)운영 중 모니터링, 성능에 관심을 기울이지 않게 되는 것 같다.\nREAD # 성능 개선의 첫 걸음, Reader 개선\n대부분의 배치에서 writer 보다 reader 가 차지하는 비중이 크다.\n예를 들어, 위 그림과 같이 10억 건 중 100만 건을 추출해야 할 때 select 쿼리의 수정만으로도 큰 효과를 볼 수 있을 것이다.\nChunk Processing # 대용량에서는 chunk processing 이 필수이다. (절대적으로 사용될 것이다.)\n문제점 : Pagination\nPagination 을 주로 사용할텐데 성능 관점에서 좋지 않다.\noffset이 커질 수록 비용이 커진다.\n개선 방법 1 : ZeroOffsetItemReader\nZeroOffsetItemReader 를 (먄들어)사용한다.\noffset 은 항상 0으로 유지하고, where 절을 변경한다.\n개선 방법 2 : Cursor\nJpa 말고 Jdbc 커서를 추천한다.\n다만 쿼리를 문자열로 작성해야 한다는 문제점이 있다.\nexposed 를 사용하고 있다.\nItemReader 성능 비교 # 핵심 : JpaPagingItemReader 만 개수에 비례하여 시간이 증가되지 않는다.\n성능 뿐만 아니라 안정성도 검증되었다고 볼 수 있다.\n정리 # Aggregation # sum, group by 등의 쿼리를 사용하는 경우가 빈번할 것이다.\n이 쿼리들은 비용이 클 수 있다. (꼭 실행 계획을 확인해보자.)\n쿼리 자체가 비효율적이라면 앞서 개선한 ItemReader 도 무용지물이 될 것이다.\nGroup By 포기 # 이 팀에서는 group by를 포기했다.\n쿼리는 단순하게 작성하고 애플리케이션 단에서 aggregation 한다.\n문제점 : 애플리케이션 단에서 집계하기 위해 데이터를 가져와야하는데 OOM 유발 가능성이 커진다.\n새로운 Architecture (for 애플리케이션 집계) # group by 를 포기하고 애플리케이션 레이어에서의 집계를 위해 아키텍쳐를 설계했다.\n문제점 : Network I/O\n개선 : Redis Pipeline\nWrite # write 성능 개선을 위해 두 가지 핵심 포인트가 있다.\n핵심 포인트 설명 Batch Insert - 일괄 쿼리 요청 명시적 쿼리 - 필요한 컬럼만 Update - 영속성 컨텍스트 사용 X 결론\n(아쉽지만) JPA(영속성 관리, Dirty Checking 등)를 버려야한다.\nBatch 에서 JPA Write 에 대한 고찰 # Batch 환경에서 JPA 가 잘 맞는지\n1. 불필요한 Dirty Checking \u0026amp; 영속성 관리\n실제로 reader 에서도 영속성 관리되지 않게 사용하고 있다. DTO로 반환받는다.\n(불필요한 check 로직으로 인해) 큰 성능 저하를 유발시킬 수 있다.\n2. Update 할 때 불필요한 컬럼도 업데이트 (쿼리에 포함)\n쿼리 statement 가 커진다. jpa dynamic update 는 오히려 성능이 저하된다.\n소폭의 성능 저하를 유발시킬 수 있다.\n3. Jpa Batch Insert 지원이 어렵다.\nIdentity 의 경우, batch insert 를 지원하지 않는다. (물론 다른 채번 방법을 사용하면 되긴 한다.)\nBatch Insert 는 필수다.\n매우 큰 성능 저하를 유발시킬 수 있다.\nJdbcBatchInsert, Exposed 사용한다.\nBatch 구동 환경 (기존 스케줄 도구의 아쉬운 점) # Jenkins, crontab, \u0026hellip;\n자원 관리의 어려움 # 배치 실행 시에만 자원이 사용되고 나머지 시간에는 자원이 사용되지 않는다.\n또, 특정 시간에는 배치 실행이 밀집되어 자원 경쟁이 발생할 수 있다.\n모니터링의 어려움 # Spring Cloud Data Flow 도입 # 자세한 내용은 직접 찾아보자\n간단하게 소개한 기능은 다음과 같다.\n기능 설명 오케스트레이션 - k8s와 완벽하게 연동되어 batch 실행을 오케스트레이션할 수 있다.\n- 다수 Batch 가 상호 간섭 없이 동작할 수 있다. (by 컨테이너) - k8s에서 resource 사용과 반납을 조율한다. 모니터링 - Spring Batch 와 완벽하게 호환된다. - 유용한 정보를 시각적으로 모니터링할 수 있다. (Spring Cloud Date Flow 자체 Dashboard 를 제공) - 그라파나 연동 가능하다. 발표 내용 정리 # "},{"id":84,"href":"/docs/DEV/ifkakaodev-2022/JVM-warm-up/","title":"JVM Warm Up","section":"If Kakao 2022","content":" 카카오 계정 서버의 API 배포 과정 # Rolling update\nApplication Ready - Warm Up 사이에 n초 delay를 줄 수 있다.\nCompilation Level # JIT # 위 과정에서 C1, C2는 별도 쓰레드로 동작한다.\nC2 컴파일러의 큐가 가득차면, C1의 Level2 로 컴파일한다. 이후 여유가 생기면 Level3, 4 컴파일 처리가 진행된다.\nLevel2 컴파일이 많이 발생한다면, C2 컴파일러 큐가 가득찼다는 것을 알 수 있겠다. 이때는 C2 컴파일러 쓰레드 수를 조정할 필요가 있겠다.\nCode Cache # 초기 캐시 사이즈와 최대 사이즈 조정이 가능하다.\n코드 캐시가 가득차면 성능 상 이점을 볼 수 없다. 아래와 같은 메시지가 발생하면 사이즈를 늘려주어야 한다.\n카카오 계정 서버에서는 위 메시지는 발생하지 않았다. 기본 값을 그대로 사용했다. (기본 값은 몇인지 확인해보자.)\nCompilation Level Threshold # 다음의 지표들을 확인해볼 수 있다.\nInvocationThreshold : 메서드 호출 수 BackEdgeThreshold : 메서드 내 반복문 수 CompileThreshold : InvocationThreshold + BackEdgeThreshold (?) JIT Log # 아래 옵션을 활성화하여 컴파일 로그를 확인할 수 있다.\n결론 # 카카오 계정 서버에서는 다음과 같이 지표를 확인했다.\nwarm up 시간도 고려해야 하기 때문에 결론적으로 250번 진행하는 것을 선택했다. (지연 문제가 발생하지 않는 선에서, 짧은 시간 선택)\n"},{"id":85,"href":"/docs/DEV/ifkakaodev-2022/%EC%B9%B4%EC%B9%B4%EC%98%A4%ED%86%A1-%EB%A9%94%EC%8B%9C%EC%A7%95-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%9E%AC%EA%B1%B4%EC%B6%95-%EC%9D%B4%EC%95%BC%EA%B8%B0/","title":"카카오톡 메시징 시스템 재건축 이야기","section":"If Kakao 2022","content":" 카카오톡 메시징시스템 # 기준 값 평균 트래픽(TPS) 500K 최고 트래픽(TPS) 6.5M 평균 연결 세션 수 40M C++ 사용 이유 : 대량 트래픽 다루기 위해\nC++ 백엔드 서버 애플리케이션 # epoll 기반의 비동기 입출력 지원 쓰레드 별로 미리 할당한 메모리 버퍼 사용 system call 호출(지연)을 줄이기 위해 미리 메모리 버퍼를 할당 받아 놓음 대당 500K 이상의 세션 관리 앞으로의 10년도 커버 가능할까? # 현재까지의 구조는 최적화에 목적을 둔, 하지만 유지보수하기는 힘든 구조였다. (성능은 뛰어나지만, 관리가 힘들다.)\n직접 개발한 프로토콜, 라이브러리 라이브러리 내재화(스태틱화) 코드 최적화 -\u0026gt; 가독성 저하 적은 단위 테스트, 너무 복잡한 통합 테스트 노후화된 배포 시스템 : shell script + python 인적 리소스 불균형 (c++ 인력 vs java 인력) \u0026hellip; 부분 별로 개선은 진행하고 있지만, 어쨌든 C++ + Java 기반의 구조, 극한의 커스텀 구조를 아예 개편하기로 결정했다.\n다른 파트들의 기술 스택은 어떨까? # 진행 과정 # 1단계 # 각 모듈을 대체하는 모듈을 새로 만들었다.\nPAPI 서버 # 앞단을 새로 만들고, 기존 서버를 거둬내는 형태로 작업했다.\n세션 서버 # 카카오톡 클라이언트의 세션 정보를 저장하는 서버다.\n애플리케이션 서버 내 인메모리 형태로 관리했었다.\n외부 스토리지(Redis)를 사용했다.\n현재 config, session, papi 서버에 대해서는 대체했다.\n2단계 # Relay \u0026amp; Session Manager 서버 # 고성능 애플리케이션\ng1gc, zgc 간에 \u0026lsquo;프로토콜 처리\u0026rsquo; 성능 측면에서도 차이를 보였다.\n현재 최적화 작업 진행 중이다.\n정리 # 릴레이 서버의 경우 코드 라인 수가 4만 라인 -\u0026gt; 2만 라인으로 줄었다.\n앞으로의 계획 # "},{"id":86,"href":"/docs/DEV/int%EB%8A%94-%EB%AA%87-%EB%B0%94%EC%9D%B4%ED%8A%B8-%EC%9D%B8%EA%B0%80%EC%9A%94/","title":"Int는 몇 바이트 인가요","section":"DEV","content":" https://devocean.sk.com/blog/techBoardDetail.do?ID=164788\n결론 # 1. 언어마다 다를 수 있다.\n2. 시스템(플랫폼)마다 다를 수 있다.\nC/C++ : 4 or 8 Byte # 시스템(플랫폼)에 의존적이다.\nLLP64, LP64 등 데이터 모델에 따라 다르다.\nJava : 4 Byte 고정 # 플랫폼에 독립적인 가상머신(JVM)에서 동작하기에 플랫폼의 영향을 받지 않는다.\n4Byte 로 고정되어 있다.\nPython : 8 Byte ~ # Python 의 경우 int 의 크기가 정해져 있지 않다.\nsys.maxsize 의 경우, 시스템에 의존적인 형태라고 볼 수 있을 것 같다.\n정해진 범위를 초과하더라도 (자동으로)데이터 범위(?)를 증가시켜준다.\n참고 # "},{"id":87,"href":"/docs/DEV/NGINX-%EA%B8%B0%EC%88%A0-%EB%B6%80%EC%B1%84%EA%B0%80-%EB%90%98%EC%A7%80-%EC%95%8A%EC%9C%BC%EB%A0%A4%EB%A9%B4/","title":"NGINX, 기술 부채가 되지 않으려면","section":"DEV","content":" 로드밸런서 # GSLB, LSLB, CSLB\n요약 # Nginx 설정도 저장소에서 관리하자. 배포까지 자동화할 수 있다. 주석은 꼼꼼히 작성하자. 주기적으로 확인하여 필요하지 않은 설정은 제거하자. (계속해서 관리하자.) mirror # nginx 설정은 업데이트를 한다. 기존 설정이 변경되다보니 항상 걱정하게 된다.\nmirror 는 들어온 요청을 그대로 복제해서 또 다른 upstream 서버 / block 으로 보내주는 역할을 한다.\n이를 통해 기존 로직을 손대지 않고 설정 테스트가 가능하다.\n"},{"id":88,"href":"/docs/DEV/Reactive-Programming/","title":"Reactive Programming","section":"DEV","content":" Reactive Programming # 참고\nhttps://gngsn.tistory.com/223 https://en.wikipedia.org/wiki/Reactive_programming Keywords\nData Stream Functional Programming Asynchronous Declarative Programming Paradigm Reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change.\n\u0026quot; Reactive Programming은 데이터 스트림을 비동기 처리하는 선언형 프로그래밍입니다. 선언형 프로그래밍이란 기존의 명령형 프로그래밍 방식과 대비되는 새로운 프로그래밍 패러다임으로, 라인 단위의 프로그래밍 과정과 달리 특정 목적과 같이 무엇을 하는 지를 명시하여 개발하는 과정입니다. 리액티브 프로그래밍은 아래 3가지(Data Stream, Functional Programming, Asynchronous) 측면으로 기존 프로그래밍 방식의 문제점들을 해결합니다. \u0026ldquo;\n출처: https://gngsn.tistory.com/223\nChange propagation algorithms # Pull # The consumer queries the observed source for values and reacts whenever a relevant value is available.\nThe practice of regularly checking for events or value changes is commonly referred to as polling.\nPush # The consumer receives a value from the source whenever the value becomes available.\nThese values are self-contained, e.g. they contain all the necessary information, and no further information needs to be queried by the consumer.\n:star: 이 부분(\u0026lsquo;필요한 정보는 모두 Push 한다\u0026rsquo;는 특징)이 Push-Pull 알고리즘과의 차이점이다.\nPush-Pull # The consumer receives a change notification. (Push part)\nHowever, the notification dose not contain all the necessary information.\nSo the consumer needs to query the source for more information (after it receives the notification). (Pull part)\nThis \u0026lsquo;Push-Pull\u0026rsquo; method is commonly used when there is a large volume of data tha the consumers might be potentially interedted in. (So in order to reduce throughput and latency, only light-weight notifications are sent.)\nThis approach also has the drawback that the source might be overwhelmed by many requests(query) for additional information after a notification is sent.\n"},{"id":89,"href":"/docs/DEV/The-NIST-Model-for-Role-Based-Access-Control-Towards-A-Unified-Standard/","title":"The NIST Model for Role-Based Access Control: Towards a Unified Standard","section":"DEV","content":" 1. INTRODUCTION # The lack of standards for RBAC has led to roles being implemented in different ways, impeding the advance of RBAC technology.\nThe goal of this paper is to provide a standard in this arena.\nThe basic role concept is simple: establish permissions based on the functional roles in the enterprise, and then appropriately assign users to a role or set of roles\nRoles colud represent the tasks, responsibilities, and qualifications associated with an enterprise.\nRBAC is a rich and open-ended concept which ranges from very simple at one extreme to fairly complex and sophisticated at the other. It has been recognized that a single definitive model for RBAC is therefore unrealistic.\nThe NIST RBAC model is consequently organized in a four step sequence of increasing functional capabilities given below.\nFlat RBAC Hierarchical RBAC Constrained RBAC Symmetric RBAC 2. MODEL OVERVIEW # These levels are cummulative in that each includes the requirements of the previous ones in the sequence. Each level adds exatly one new requirement.\n2.1 Flat RBAC # Flat RBAC embodies the essential aspects of RBAC.\nThe basic concept of RBAC is that users are assigned to roles, permissions are assignes to roles and users aquire permissions by being members of roles.\nThe NIST RBAC model requires that user-role assignment and permission-role assignment can be many-to-many.\nFlat RBAC requires that users can simultaneously exercise permissions of multiple roles.\nThe features required of flat RBAC are obligatory for any form of RBAC and are almost obvious.\nThe main issue in defining flat RBAC is to determine which features to exclude.\nThe NIST flat RBAC model has deliberately kept a very minimal set of features.\nIn particular, these features accommodate traditional but robust group-based access control.\n2.2 Hierarchical RBAC # Hierarchical RBAC adds a requirement for supporting role hierarchies.\nA hierarchy is mathematically a partial order defining a seniority relation between roles, whereby senior roles acquire the permissions of their juniors.\nThe NIST model recognizes two sub-levels in this respect.\n1. General Hierarchical RBAC\nIn this case there is support for an arbitrary partial order to serve as the role hierarchy. 2. Restricted Hierarchical RBAC\nSome systems may impose restrictions on the role hierarchy. Most commonly, hierarchies are limited to simple structures such as trees or inverted trees. 2.3 Constrained RBAC # Constrained RBAC adds a requirement for enforcing separation of duties(SOD).\nMany different SOD requirements have been identified in the literature.\nstatic SOD (based on user-role assignment) dynamic SOD (based on role activation) 2.4 Symmetric RBAC # Symmetric RBAC adds a requirement for permission-role review similar to user-role review introduced in level 1. Thus the roles to which a particular permissions is assigned can be determined as well as permissions assigned to a speciffic role.\n3. FLAT RBAC # \u0026quot; The requirement that users acquire permissions through roles is the essence of RBAC. \u0026ldquo;\nIn Figure 1, A permission is an approval of a particular mode of access to one or more objects in the system.\nPermissions are always positive and confer the ability to the holder of the permission to perform some action(s) in the system. :star:\nFlat RBAC requires that UA(user-role assignment), PA(permission-role assignment) are many-to-many relations. This is an essential aspect of RBAC. :star:\nThe concept of a session is not explicitly a part of flat RBAC.\nIn some cases all roles of a user are activated in every session of the user. In other cases the user is given a choice to activate and deactivate roles in a given session at the user\u0026rsquo;s discretion. :star:\n후자는 AWS 계정 선택 행위가 예시가 될 수 있겠다.\nThe NIST model dose not require support for sessions with discretionary role activation. It does require the ability to activate multiple roles simultaneously and in a single session.\nFlat RBAC requires support for user-role review whereby it can be effciently determined which roles a given user belongs to and which users a given role is assigned to. :star:\nThe flat RBAC model leaves open many important issues that must be addressed in an implementation.\nThere are no scalability requirements on the numbers of roles, users, permissions, etc.., that should supported. The nature of permissions and support for discretionary role activation is not fully specified. Revocation can occur when a user is removed from a role or a permission is removed from a role. How quickly the revocation actually takes place, particulary with respect to activity which is already under way, is left unspecified. The important issue of role administration is not specified. Role administration is concerned with who gets to assign users to roles and permissions to roles. 위 요소들을 다루지 않은 이유는 (1)모든 상황(벤더, 시장)에 적절한 기준이 아닐 수 있고, (2)충분한 협의가 이뤄지지 않았기 때문이다.\n4. HIERARCHICAL RBAC # \u0026hellip;\n5. CONSTRAINED RBAC # \u0026hellip;\n6. SYMMETRIC RBAC # \u0026hellip;\n7. OTHER RBAC ATTRIBUTES # \u0026hellip;\n7.3 Negative permissions # The NIST model is based on positive permissions that confer the ability to do something on holders of the permission.\nBut the NIST model does not rule out the use of so-called negative permissions which deny access. Thus vendors are free to add this feature.\nNevertheless vendors and users are cautioned that use of negative permissions can be very confusing.\n7.4 Nature of permissions :star::star: # The nature of permissions is not specified in the NIST RBAC model.\nPermissions can be fine-grained(e.g., at the level of individual objects) or coarse-grained(e.g., at the level of entire sub-systems).\nThey can be defined in terms of primitive operations such as read and write, or abstract operations such as credit and debit.\nPermissions can also be customize.\nThe exact nature of permissions is determined by the nature of the product.\nOS, DBMS, workflow systems, network management systems will all support different kinds of permissions.\nStandardization of permissions is beyond the scope of a general-purpose access control model.\n7.6 Role engineering :star: # The NIST RBAC model does not provide guidelines for designing roles and assigning permissions and users to roles.\nThis activity is called role engineering. Effective use of RBAC in large-scale is strongly dependent on effective role engineering.\nHowever, this issue is outside the scope of the NIST RBAC model.\n"},{"id":90,"href":"/docs/DEV/Top-10-Architecture-Characteristics/","title":"Top 10 Architecture Characteristics","section":"DEV","content":" Top 10 Architecture Characteristics # 참고 : https://medium.com/@abd0hrz/top-10-architecture-characteristics-non-functional-requirements-with-cheatsheet-f639458d357d\n1. Scalability # Scalability is a achievable with horizontal/vertical scaling of the machine.\nTraffic Pattern # Understand the traffic pattern of the system. :star:\nPattern Diurnal Pattern Traffic increases in the morning and decreases in the evening for a particular region. Global / Regional Regional Heavy usage of the application. Thundering Herd These could occur during peak time or in densely populated areas. 우리 시스템의 트래픽 패턴을 이해하자. :star:\n일반적인 패턴(낮에 트래픽이 증가하고 저녁에 감소하는 패턴) 지역 패턴(지역 별로 트래픽이 집중되고, 집중되지 않는 패턴) Thundering Herd (피크 타임, 지역에 의해 요청이 급격하게 증가하는 패턴) Elasticity # Ability to quickly spawn a few machines (for handling) and shrink when the demand is reducing.\nLatency # Ability to serve the request as quickly as possible.\n2. Availability # The proportion of time that a system is functional and working.\nIt is measured as a percentage of uptime.\n3. Extensibility # The ability to extend a system.\nThe cost about effort required to implement the extension.\nModular / Reusability # 생략\nPluggability # Ability to easily plug in/out.\n(개인적으로) 최근에 이 Pluggability 측면에 대해서 고민했다.\n4. Consistency # 생략\n5. Resiliency # The ability to handle and recover from accidental and malicious failures.\nRecoverability # DR(Disaster Recovery) : DR consists of best practices designed to prevent or minimise data loss and business disruption resulting from catastrophic events. Design Patterns # BulkHead : Isloate elements of an application into pools so that if one fails, the others will contine to function. (장애를 고립시키자.) Circuit Breaker Leader Election : Elect leader instance that can coordinates, manages other instances. 6. Usability # Accessibility : Make the software available to people with the broadest range of characteristics and capabilities. Learnability : How easy users can learn how to use the software? API Contract : API Contracts can help to understand easily 7. Observability # The ability to collect data bout program execution, internal states of modules, and communication between components.\nTo improve this, use various logging and tracing techniques, tools.\nLogging : event logs, transaction logs, message logs, server logs, \u0026hellip; Alerts \u0026amp; Monitoring L1 / L2 / L3 : Setup on-call support process for L1 / L2. L1 / L2 / L3 프로세스는 흥미롭다. :star:\n찾아봐보자.\n8. Security # auditability, legality, authentication, authorization, \u0026hellip;\n9. Durability # Replication Fault Tolerance Archivability 10. Agility # It has become today’s buzzword when describing a contemporary software method.\nMaintainability Deployability Configurability Conclusion # 모든 아키텍처의 특징이 필요한 건 아니다. (반대로 모두 필요할 수도 있다.)\n이는 개발자(아키텍터)가 현재 프로젝트에 맞게, 기능 요구 사항에 맞게 적절하게 선택하고 설계할 수 있어야 한다.\n다음과 같은 질문들을 던져봐도 좋을 것이다.\n어느 정도 처리량이 필요한지? 보안적 요구 사항은 없는지? 코드 유지보수(기능 추가, 변경, 삭제)는 쉬운지? \u0026hellip; "},{"id":91,"href":"/docs/DEV/Woowa-course-%EC%BD%94%EB%93%9C%EB%A6%AC%EB%B7%B0/","title":"Woowa-Course 코드리뷰","section":"DEV","content":"1. getter 대신에 객체에 물어보는 형태로 작성해보자.\n* 적절한 예시인지 모르겠다. 아무튼 getter 보다 최대한 객체의 method 를 활용해보는 것? 이 포인트 인 것 같다.\nMan man = new Man(); ... // A if(man.getAge() \u0026gt; 10) { ... } // B if(man.isOverTenAge()) { ... } 2. 될 수 있으면 숫자, 문자열 값에 대한 상수(변수) 처리를 하자.\n혹은 Enum 클래스를 사용하도록 하자.\n3. 한 테스트 함수(코드)에서 여러 개를 테스트하지 말자.\nn 개를 테스트하고자 한다면, n 개의 테스트 함수를 만들자.\n4. 리뷰 사항 중 SCP 에 대한 코멘트가 종종 있었다. 한 클래스가 너무 많은 역할을 하는 것은 아닌지 확인하자.\n5. 리뷰 사항 중 전략 패턴에 대한 코멘트가 있었다. 전략 패턴에 대해 공부해보고, 적용해보자.\n6. Interface 가 정말 필요한 지에 대해 생각해보자.\n예를 들어, BoardService 라는 service 클래스가 있을 때 이것을 BoardService(I), BoardServiceImpl 의 형태로 작성한 코드가 있다. 여러 구현체가 공통적으로 묶이지 않는 상황에서 정말 필요한 것인지? 에 대해 생각해봐야한다.\n그리고 ~~~Impl 이라는 명칭도 좋지 않은 것 같다라는 피드백이 있었다.\n7. Composition 에 대해 주의깊게 생각해보자.\n예를 들어, Man 클래스에 xPosition, yPosition 이 있다면 Position class 로 빼는 것은 어떤지? 에 대해 생각해볼 수 있다.\n8. 일급 컬렉션에 대해 생각해보자.\n9. Optional 을 활용하자.\n단, 아래와 같은 피드백도 있었다.\n\u0026quot; Optional의 경우 필드에 사용을 지양해야 합니다. 정확히는 사용하면 안됩니다. 그 이유로 Optional은 변수의 null 유무를 파악하기 위해 나왔습니다. 더 정확히는 메서드의 반환값의 null 유무를 체크하기 위해 설계했기 때문에 메서드의 반환에만 사용하도록 지향해야 합니다. Optional에 대해서는 더 공부해보시면 좋을 것 같습니다:) 예를 들어, 자바 8 인 액션 책을 살펴보시면 좋습니다. \u0026ldquo;\n10. NPE 에 대해 주의하자.\n가령 아래와 같은 코드가 있다.\n... if(book.equals(\u0026#34;comic\u0026#34;)) { ... } 위 코드를 아래와 같이 개선할 수 있다.\n// (\u0026#34;comic\u0026#34; 을 변수 처리하는 것은 생략) ... if(\u0026#34;comic\u0026#34;.equals(book)) { ... } "},{"id":92,"href":"/docs/DEV/%EB%B8%94%EB%9E%99%EC%9E%AD-%EC%BD%94%EB%93%9C%EB%A6%AC%EB%B7%B0-%EA%B8%80%EC%9D%84-%EC%9D%BD%EA%B3%A0/","title":"블랙잭 코드리뷰 글을 읽고","section":"DEV","content":" Okky fender, jojoldu 님의 글을 읽고 느껴지는 부분, 공감되는 부분에 대해서 정리해보기\n초보 개발자에게 권장하는 객체지향 모델링 공부 방법\n객체지향 좀 더 이해하기 - 블랙잭 게임 구현(1)\n아래 코드에서 개선할 수 있는 부분은 무엇이 있을지 생각해본다. # public Card draw(){ int size = cards.size(); int select = (int)(Math.random()*size); Card selectedCard = cards.get(select); cards.remove(select); return selectedCard; } 위의 코드는 (카드덱)객체에서\n가지고 있는 카드 리스트 중 랜덤한 카드 한장을 뽑고 그 카드는 리스트에서 제거하는 코드이다. 이 코드를 한번 더 개선할 수 있다고 한다면, 무엇을 개선하면 좋을까?\n객체를 모델링할 때, 다음과 같은 것들을 고려해본다. # 구체적인 구현 사항은 이후에 생각한다. 일단은 인터페이스 레벨에서 모델링을 해본다.\n1번의 모델링이 어느정도 익숙해지면, 그 다음은 (다음단계)일반화/추상화에 대해 고민해본다.\n모델링을 연습할 때에는 어떠한 프레임워크를 사용하지 않고 순수 언어(java) 로 작성해본다.\n가능하다면 API 는 에러를 발생하지 않도록 작성한다. # API 는 유효하지 않은 상태가 발생하지 않는 방향으로 설계/작성한다.\n나의 경우에 유효하지 않은 요청이나 특정 조건에 맞지 않으면, 무의식적으로/가벼운 마음으로 Exception 을 던졌던 부분들이 있었다.\n\u0026ldquo;API 는 유효하지 않는 상태가 발생하지 않는 방향으로 설계하는 것\u0026rdquo; 은 이런 상황에서도 좋은 피드백이 되는 것 같다. (이렇게 이해하였다.)\n객체, 객체의 행위의 역할/책임에 대해서 더욱 신중히 생각한다. # \u0026quot; 예를들어 \u0026lsquo;Player.showCards()\u0026rsquo; 같은 메서드는 과연 가지고 있는 카드를 콘솔에 뿌리는 것이 플레이어의 역할인가 자문해볼 여지가 있습니다. 만일 이 프로젝트가 카드 게임 제작을 위한 일반적인 API로 사용될 수 있다면 그런 부분은 나중에 웹기반 게임을 구현한다던지 할 때 문제가 될 것입니다. \u0026ldquo;\n\u0026rdquo; \u0026lsquo;Dealer.receiveCard()\u0026lsquo;을 보면 내부적인 규칙에 따라 카드를 받는 것을 거부하더라도 호출자 입장에서는 알 수 있는 방법이 없습니다. 콘솔 메시지를 보이는 건 사용자를 위한 것이지 호출하는 프로그램을 위한 것이 아니기 때문에 이러한 부분은 좀 더 개선이 필요하다고 생각합니다. \u0026ldquo;\n영어는 정확한 문법에 맞게 작성한다. # 메서드명을 작석할 때, 호출하는 쪽에서 내부 사항에 대해 예측할 수 있도록 (혹은 꼭 뜯어보지 않아도 알 수 있도록) 작성한다. # 직관적/가독성이 좋은 네이밍은 중요하다.\n메서드가 하나의 역할/행위만 하는 것이 보장될 때, 이는 더욱 잘 지켜질 것이다.\n"},{"id":93,"href":"/docs/DEV/%EC%98%88%EC%99%B8-%EC%B2%98%EB%A6%AC-%EC%A0%84%EB%9E%B5/","title":"예외 처리 전략","section":"DEV","content":" 예외 처리 전략 # 예외 복구 다른 작업의 흐름을 유도한다.\n예외 처리 회피 처리하지 않고 호출한 쪽으로 예외를 던진다.\n예외 전환 명확한 의미의 예외로 전환하여 예외를 던진다.\nReference\nhttps://www.nextree.co.kr/p3239/ "},{"id":94,"href":"/docs/DEV/%EC%9A%B0%EC%95%84%ED%95%9C-%ED%85%8C%ED%81%AC-%EC%84%B8%EB%AF%B8%EB%82%98-%EC%96%B4%EB%94%94-%EA%B0%80%EC%84%9C-%EC%BD%94%ED%94%84%EB%A7%81-%EB%A7%A4%EC%9A%B0-%EC%95%8C%EC%9D%80-%EC%B2%B4%ED%95%98%EA%B8%B0/","title":"우아한 테크 세미나 : 어디 가서 코프링 매우 알은 체하기","section":"DEV","content":" DSL (Domain Specific Language) : 도메인에 특화된 언어, 즉 범용적인 언어가 아닌 (해당 도메인에 대해서만) 사용되는 언어.\n이번 세미나의 내용은 간략하게 아래의 내용을 포함하고 있다.\nKotlin DSL 에 대해 살펴보고 Kotlin 사용 시 주의사항 (with SpringBoot) 개요 # 코틀린은 JVM, 안드로이드, Javascript, 네이티브 등에서 동작할 수 있는 (혹은 이것들을 대상으로 하는) 컴파일 언어이다. OO(Object-Oriented), FP(Functional-Programmin) 두 스타일 모두 활용할 수 있다. 간결하고, 실용적이다. (+ 최근에 \u0026lsquo;코루틴\u0026rsquo; 이라는 것이 주목받고 있다고 한다.) 아이템 1 : (코틀린의) 표준 라이브러리를 사용한다. # 자바 라이브러리(+ 외부 라이브러리)보다 코틀린 표준 라이브러리를 사용한다.\n이후에 JVM, Javascript, Android 등의 코드를 하나의 코드로 만든다고 가정했을 때에도, 코틀린에서 제공하는 라이브러리를 쓴다면 충돌할 일은 없을 것이다. \u0026lsquo;표준\u0026rsquo; 사용은 언제나 권장된다. 되도록 Java 라이브러리 사용을 자제해보자. 아이템 2 : \u0026lsquo;Java\u0026rsquo;로 역컴파일하는 습관을 들여보자. # 처음 코틀린이 어색할 때에는 의도치 못한 실수를 방지하기 위해서라도 Java 로 역컴파일하여 생성된 코드를 확인해보자.\n코드가 어떻게 생겼는지 확인하고, 이해해보자.\n아이템 3 : \u0026lsquo;Lombok\u0026rsquo; 대신 Data 클래스를 사용할 수 있다. # Data 클래스는 equals(), hashcode(), toString(), copy() 등의 기능을 자동으로 생성해준다.\n덕분에 코드가 훨씬 간결해진다. (클래스 코드가 간결해지기 때문에) 하나의 (kt)파일에 (관련이 있는)여러 클래스를 작성하는 것도 좋은 방법이라고 한다. * 참고 : kt1.5 부터 Java 16 이상부터 지원하는 record 키워드도 지원한다. 즉, Kotlin 에서는 Java 와 최대한 같이 사용될 수 있도록 많은 지원을 하고 있다.\n필드 주입이 필요하다면, \u0026lsquo;지연 초기화\u0026rsquo;를 사용하자. # 생성자 주입이 권장되고 있지만, 때로는 필드 주입이 필요할 수도 있다. 이렇게 필드 주입이 필요하다면 lateinit(지연 초기화) 를 사용할 수 있다.\nlateinit + var 키워드를 통해 지연 초기화를 사용할 수 있다.\n이 덕분에 (원래대로라면) nullable field 를 만들어야 하는 것을 nullable 하지 않게 만들 수도 있다. (좀 더 찾아보자.)\n\u0026lsquo;변경 가능성\u0026rsquo; 을 제한하자. # val 를 기본으로 사용하고, 필요 시에만 var 를 사용하자.\n기타 # All-open 컴파일러 플러그인 # Spring 의 경우, 프록시 메커니즘에 의해 \u0026lsquo;상속\u0026rsquo;을 허용해야 하는 부분들이 많이 있다.\n코틀린에서는 final 이 기본이다. 따라서, 이를 위해 open 키워드를 통해 상속을 허용해주어야 하는데, 수많은 클래스에 이 키워드를 다시 작성해주어야 하는 비효율성이 있다.\n이것을 해결하기 위해 제공하는 플러그인, \u0026lsquo;all-open 컴파일러 플러그인\u0026rsquo; 이라고 한다.\n@Transactional, @Configuration, @Async 등의 지정된 어노테이션 사용 시 내부적으로 open 키워드를 (클래스, 필드 모두에)삽입해준다고 한다.\n스프링 이니셜라이저를 통해 프로젝트 생성 시 기본적으로 포함되어 있다고 한다.\n어노테이션 # 코틀린의 경우 프로퍼티가 아래의 역할을 한다.\n생성자 매개변수 getter setter 필드 이 중 어떤 곳에 어노테이션을 적용시키고 싶은가?\n내부적으로 알아서 필요한 곳에 적용이 된다고 한다. 하지만 이것들을 정확하게 확인하지 못해 놓치는 부분도 많다고 한다.\n이런 경우를 위해 아래와 같이 어노테이션을 적용할 곳을 지정할 수 있다.\ndata class My( @param:JsonProperty(\u0026#34;my_id\u0026#34;) @get:JsonProperty(\u0026#34;my_id) val id: String, @param:JsonProperty(\u0026#34;my_name\u0026#34;) @get:JsonProperty(\u0026#34;my_name\u0026#34;) val name: String, val amount: Long, ... ) { constructor(...) : this( ... ) } 코틀린 모듈 # 많은 라이브러리, 프레임워크에서 코틀린을 위해 많은 지원을 하고 있다고 한다.\n예를 들어, \u0026lsquo;잭슨 라이브러리\u0026rsquo;는 기본생성자를 만들기 귀찮은 코틀린을 위해 기본생성자가 없더라도 직렬화/역직렬화가 가능하도록 기능을 제공한다고 한다.\n코틀린 환경에서 objectMapper 설정에 주의하자.\nObjectMapper().registerKotlinModule() 과 같이 꼭 코틀린 모듈을 등록해주어야 한다고 한다.\nBacking Property(뒷받침하는 프로퍼티) # (클래스에) 동일한 기능/필드이지만, - 하나는 공개된 API - 다른 하나는 내부적으로만 사용하는 API (예 : 구현 세부사항 등)\n이렇게 두 개의 프로퍼티가 있는 경우, private 프로퍼티 이름의 접두사로 밑줄을 사용한다.\nprivate val _students: MutableSet\u0026lt;Student\u0026gt; = students.toMutableSet() val students: Set\u0026lt;Student\u0026gt; get() = _students (위의 예시 처럼) 클래스 내부에서는 mutable 한 필드를 사용하고, 외부에 반환 시에는 immutable 상태로 반환할 수도 있다.\n* JVM 에서는 기본 getter 및 setter 가 있는 private 프로퍼티에 대해 함수 호출 오버헤드를 방지하도록 최적화 되어 있다고 한다. (이 부분은 좀 더 찾아볼 것.)\nKotlinDetector 클래스 확인해볼 것 # 코틀린(+ 자바) 컴파일 순서 # 작성 중\u0026hellip;\n"},{"id":95,"href":"/docs/DEV/%EC%9A%B0%EC%95%84%ED%95%9C-%ED%85%8C%ED%81%AC-%EC%84%B8%EB%AF%B8%EB%82%98-%EC%9A%B0%EC%95%84%ED%95%9C-Redis-2019/","title":"우아한 테크 세미나 : 우아한 Redis 2019","section":"DEV","content":" 우아한 테크 세미나 : 우아한 Redis (2019) # 이번 세미나에서 다루지 않는 것들\nRedis Persistence(RDB, AOF) Redis Pub/Sub Redis Stream 확률적 자료구조 Hyperlog Redis Module Redis 소개 # In-Memory 데이터 저장소 Open Source (BSD 3 License) 지원하는 자료구조 String Set Sorted-Set Hash List Hyperloglog Bitmap Geospatial index Stream Only 1 Commiter Cache 란? # 결과를 미리 저장해두었다가 빠르게 제공하는 것\nex : (dp) factorial Disk Memory L3 cache L2 cache L1 cache core Cache 아키텍처 #1 : Look-Aside Cache # Client - Server - DB ㄴ Cache 캐시를 먼저 조회한다. 캐시에 데이터가 있다면 캐시에서 응답한다. DB를 조회한다. 응답한다. DB 조회/응답하면서 캐시에 내용을 저장한다. Cache 아키텍처 #2 : Write-Back Cache # Client - Server - DB ㄴ Cache 서버는 \u0026lsquo;캐시\u0026rsquo;에만 데이터 저장(+조회)한다. 캐시에는 데이터가 저장된다. 메모리 용량이 한계가 있으니 특정 시간(주기) 동안 저장한다고 볼 수 있다. (DB에 저장하고 삭제한다.) (특정 시간마다)캐시의 데이터를 DB에 저장한다. DB에 저장한 내용은 캐시(메모리)에서 삭제한다. 특징\n데이터가 유실될 수 있다. 메모리 -\u0026gt; DB로 데이터를 저장하기 전에 문제가 생긴다면 Log를 DB에 저장하는 경우 Write-Back 을 활용하기도 한다. 왜 Collection 이 중요할까? # Redis 는 Memcached 와 많이 비교된다.\nMemcached 에는 Collection 을 제공하지 않는다.\n개발의 편의성 개발의 난이도 Redis 에서는 Collection 기능을 처리/제공하기 때문에 개발을 편리하고, 쉽게 해준다.\n데이터 자료구조를 잘 선택해야 한다.\n예시 1 : 랭킹 서버를 구현한다면? # 방법 1 : DB 에 score 저장, order by 조회\n데이터가 많아지면, latency가 증가될 수 있다. (결국 disk를 사용하니까)\n방법 2 : Redis sorted-set 활용\n예시 2 : 친구 리스트 관리 기능을 구현한다면? # 연결 리스트로 데이터를 관리하여 구현할 것이다.\n[예시]\n(A, B, C 라는 사람이 있을 때)\nA List 에 B, C 를 저장\n방법 1 : DB로 구현한다.\n동시성 문제에 직면할 수 있다.\n(동시에 B, C 를 저장할 때 둘 중 하나의 데이터만 저장될 수 있다.)\n방법 2 : Redis로 구현한다.\n(싱글 스레드 기반)Redis 의 자료구조는 Atomic 하다.\nRace Condition 을 피할 수 있다.\nRedis 활용 예시 # 1. Remote Data Store (공유 캐시 저장소)\n2. 인증 토큰 (string, hash, \u0026hellip;)\n3. Ranking 보드 (sorted set)\n4. 사용자 API Limit\n5. Job Queue(list)\nRedis Collections # string list 중간에 데이터를 삽입해야하면 리스트를 사용하는 것을 다시 고려해봐야 한다. set 중복된 데이터를 저장하지 않아야 할 때 sorted-set set + 순서를 보장한다. hash string # set \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; mset \u0026lt;key1\u0026gt; \u0026lt;value1\u0026gt; \u0026lt;key2\u0026gt; \u0026lt;value2\u0026gt; ... get \u0026lt;key\u0026gt; mget \u0026lt;key1\u0026gt; \u0026lt;key2\u0026gt; \u0026lt;key3\u0026gt; ... 고민 포인트\nKey 를 어떤 것으로 설정할 것인지? Key 에 따라 데이터의 분산(?)이 달라질 수 있다. list # lpush \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; rpush \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; lpop \u0026lt;key\u0026gt; rpop \u0026lt;key\u0026gt; blpop \u0026lt;key\u0026gt; brpop \u0026lt;key\u0026gt; (데이터를 push 하기 전까지 대기) 고민 포인트\n활용 : 리스트에 넣어놓고 앞에서 부터 하나씩 가져갈 때 (Job Queue) 등등\nset # sadd \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; : value 가 이미 key에 있으면 추가되지 않는다. smembers \u0026lt;key\u0026gt; : 모든 value 를 돌려준다. sismember \u0026lt;key\u0026gt; \u0026lt;value\u0026gt; : value 가 존재하면 1, 없으면 0 활용 : 특정 유저를 Follow 하는 목록을 저장 (즉, 유니크한 관리가 필요할 때)\nsorted-set # 가장 많이 활용되는 것 중 하나\nzadd \u0026lt;key\u0026gt; \u0026lt;score\u0026gt; \u0026lt;value\u0026gt; : value 가 이미 key에 있으면 score 가 overwrite 된다. zrange \u0026lt;key\u0026gt; \u0026lt;startIndex\u0026gt; \u0026lt;endIndex\u0026gt; zrevrange \u0026lt;key\u0026gt; \u0026lt;startIndex\u0026gt; \u0026lt;endIndex\u0026gt; zrange testkey 0 -1 : 모든 범위를 다 가져옴 특징\nscore : double 타입(실수형)이다.(정수형 X) 실수형이기 때문에 표현할 수 없는 정수 값들이 있다. 따라서, score 를 사용할 때 주의해야한다. 실제로 자바스크립트에서 (js 아닌)서버쪽으로 데이터를 보낼 때, 숫자 값들을 string 으로 보내곤한다. 활용 : 사용자 랭킹 보드\nhash # key 밑에 sub key 가 존재한다.\nhmset \u0026lt;key\u0026gt; \u0026lt;subkey1\u0026gt; \u0026lt;value1\u0026gt; \u0026lt;subkey2\u0026gt; \u0026lt;value2\u0026gt; ... hgetall \u0026lt;key\u0026gt; hget \u0026lt;key\u0026gt; \u0026lt;subkey\u0026gt; hmget \u0026lt;key\u0026gt; \u0026lt;subkey1\u0026gt; \u0026lt;subkey2\u0026gt; ... Collection 주의 사항 # 하나의 컬렉션에 너무 많은 아이템(x만개, xx만개, \u0026hellip;)을 담으면 좋지 않다. 1만개 이하의 몇 천개 수준으로 유지하는게 좋다. Expire는 Collection 의 원소(item 개별)별로 걸리지 않고, 전체 Collection(key 별로?)에 대해서만 걸린다. 10000개의 아이템을 가진 Collection에 Expire 가 걸려있다면, expire 시간 후에 10000개의 아이템 모두 삭제 Redis 운영 # 1. 메모리 관리를 잘하자.\n2. O(N) 관련 명령어는 주의하자.\n3. Replication\n4. 권장 설정 Tip\n메모리 관리를 잘하자. # 메모리 관리가 매우 중요하다.\n물리 메모리 이상을 사용하면 문제가 발생한다.\nSwap이 있다면 Swap 사용으로 해당 메모리 Page 접근 시마다 늦어진다. 성능이 확 떨어질 것이다. (= Disk를 사용하는 것) 더 이상 In-Memory 의 이점이 없다. Swap이 없다면, OOM 등으로 죽을 수 있다. Maxmemory 를 설정하더라도 이보다 더 사용할 가능성이 있다. maxmemory는 memory 에 제한을 거는 건데, 이것보다 더 사용할 수 있다. memory allocator(ex : jemalloc, \u0026hellip;) 의 구현에 따라 디테일이 달라질 수 있다. 이 부분은 좀 더 찾아보자. 많은 곳에서 현재 Swap을 쓰고 있다는 사실 조차 모를 때가 많다.\nRedis 장비에 대한 메모리 모니터링이 꼭 필요하다. 메모리 파편화가 발생할 수 있다. 다양한 사이즈를 갖는 데이터 보다는 유사한 사이즈의 데이터를 저장하는 것이 유리하다. 큰 메모리를 사용하는 instance 하나보다, 작은 메모리로 여러 instance를 사용하는 것이 안전하다.\n24GB instance \u0026lt; 8GB instance (x3) Redis 필연적으로 fork 를 하게된다.\nread 가 많은 것은 크게 상관 없다. write 가 많은 것은 최대 메모리를 2배까지 사용할 수 있다. 메모리가 부족할 때는? # 1. Scale-Up\n메모리가 빡빡하면 migration 중에 문제가 발생할 수도 있다. 2. 있는 데이터 줄이기\n데이터를 일정 수준에서만 사용하도록 특정데이터를 줄인다. 다만 이미 swap을 사용중이라면, 프로세스를 재시작해야한다. 3. 기본적으로 Collection 들은 다음과 같은 자료구조를 사용한다.\nHash -\u0026gt; HashTable 을 하나 더 사용한다. Sorted-Set -\u0026gt; Skiplist, HashTable 을 사용한다. Set -\u0026gt; HashTable 을 사용한다. 해당 자료구조들은 (우리가 생각하는 것 보다)메모리를 많이 사용한다. 4. Ziplist 를 이용한다.\n속도는 약간 느려질 수 있는데, 메모리는 적게 사용할 수 있다. hash, sorted-set, set 을 사용하는데, 내부적으로 ziplist 를 사용하도록 변경하는 느낌 Ziplist 구조 # 찾아볼 것\n선형으로 데이터를 저장한다.\nIn-Memory 특성 상, 적은 개수라면 선형 탐색(O(n))을 하더라도 빠르다. (그래서 Ziplist 를 써도 되는 거다.)\nzlbytes|zltail|zllen|entry|entry|...|entry|zlend List, hash, sorted-set 등을 ziplist 로 대체해서 처리하는 설정이 존재한다.\nhash-max-ziplist-entries hash-max-ziplist-value list-max-ziplist-size list-max-ziplist-value zset-max-ziplist-entries zset-max-ziplist-value \u0026hellip; ㄴ 데이터 몇개 까지는 ziplist를 사용하겠다는 설정 등을 할 수 있다.\nㄴ 이걸 넘어가면 원래 자료구조로 바뀌는 느낌\n쓰는 것과 안쓰는 것이 메모리 사용량 20~30% 정도 차이가 난다고 한다.\nO(n) 명령어를 주의한다. # Redis = Single Thread\n동시에 한 개의 명령어를 처리할 수 있다. 단순한 get/set 의 경우, 초당 10만 TPS 이상 처리 가능하다. 하나의 명령어가 1초가 걸렸다면 초당 TPS 가 1로 떨어질 수 있다. CPU 속도에 영향을 받을 수 있다. processInputBuffre 에 packet 이 들어온다. (packet 은 분리되어 들어올 수 있기 때문에 우선 packet 을 받는다.)\npackaet 을 받아서, processCommand (하나의 명령어) 가 완성이 되면 실행한다.\n처리 시간이 긴 명령어(O(n))를 사용하면 안된다.\nkeys (all) scan (cursor) 으로 대체할 수 있다. flushall, flushdb 이거는 꼭 필요한 경우가 있긴 하니까, 그때만 주의해서 쓰자 delete collections 원소가 n만개 있는 것을 지운다면\u0026hellip; get all collections 원소가 n만개 있는 것을 조회한다면\u0026hellip; (특히 매번 조회한다면\u0026hellip;) Collection 을 일부만 가져온다. (sorted-set 의 경우 가능) Collection 을 작게 관리한다.(작은 collection 으로 관리한다.) 한 키당 몇천개 안쪽으로 저장하는게 좋다. (예전) Spring Security Oauth RedisTokenStore\n이전 : List (O(n)) 자료구조 사용\n현재 : Set (O(1)) 자료구조 사용\nRedis Replication # Async Replication Replication Lag 이 발생할 수 있다. Lag 이 커지면, master-slave 커넥션 끊어버리고 다시 연결한다. (이때 부하가..) replicaof (\u0026gt; = 5.0.0) / slaveof 명령으로 설정 가능 Replicaof hostname port DBMS 의 statement replication 이 유사 즉, 쿼리가 보내지는 것 이때 now 같은 명령어가 들어있으면 (primary, secondary에서)다르게 저장될 수 있다. 경우에 따라 다른 값이 저장될 수 있다는 것을 인지하자. (Lua script 같은 거?) \u0026lt;-\u0026gt; row replication X Replication 동작 과정 # Priamry -\u0026gt; Secondary replicaof (or slaveof) 명령 전달 Secondary 는 Primary 에 sync 명령어 전달 Primary 는 현재 메모리 상태를 저장하기 위해 Fork 이 부분이 좀 문젠데, 현재 어쩔 수 없음 Fork 한 프로세스는 현재 메모리 정보를 Disk 에 dump 해당 정보를 secondary 에 전달 fork 이후의 데이터를 secondary 에 계속 전달 찾아볼 것\nReplication 주의사항 # Replication 과정에서 fork 발생 -\u0026gt; 메모리 부족 발생할 수 있음 redis-cli --rdb 명령 : 현재 상태의 메모리 스냅샷을 가져온다. fork 와 같은 문제 aws, 혹은 클라우드의 redis 는 좀 다르게 구현되어서 위 부분(vanila redis)들이 좀 더 안정적이다. fork 없이 replication 하기도 한다. 다만 속도가 좀 더 느릴 수 있다. 많은 대수의 redis 서버가 replica를 두고 있다면, 네트워크 이슈(대역폭)가 발생할 수 있다. 같은 네트워크 안에서 30GB를 사용하는 Redis Master 100대 정도가 replication 을 동시제 재시작 하면\u0026hellip; (네트워크에 의해 끊어지고 다시 연결하고 끊어지고 다시 연결되고 등등\u0026hellip;) 다양한 문제가 발생할 수 있다. Redis 권장 설정 Tip # MaxClient 설정 : 50000 MaxClient 만큼만 네트워크로 접속 가능하다. (값을 높여주는 것이 중요하다. 낮으면 연결 안되니까) RDB/AOF 설정 : OFF 성능상 유리 안정성 유리 보통 실무에서는 rdb/aof 설정 다 끈다. 혹시 필요하면 secondary 만 설정한다. primary 는 무조건 끈다. 특정 커맨드 disable keys (aws)elasticcache 는 이미 하고 있다. 적절한 ziplist 설정 전체 장애의 90%~99% 이상이 keys, save(rdb/aof) 사용(설정)에 의해 발생한다.\nsave 설정이란?\nn 분마다 n 개 write 되었으면, rdb 에 저장해라! 라는 설정\nRedis 데이터 분산 # 데이터의 특성에 따라, 선택할 수 있는 방법이 달라진다.\nCache 일 때는 우아한 Redis Persistent 해야한다면, 우아하지 않은 Redis 1. Application\nConsistent Hashing twemproxy를 사용하는 방법으로 쉽게 사용 가능 Sharding 2. Redis Cluster\nConsistent Hasing # 단순 Mod 연산으로 인한 \u0026lsquo;데이터 분배\u0026rsquo;는 서버 추가/감소 시 리밸런싱이 너무 많이 일어날 수 있다.\n(ex: 50% 이상의 데이터가 리밸런싱)\n키(A)에 해싱 함수를 연산한다. \u0026mdash; A\u0026rsquo; 이때 서버마다 기준 값이 있다. 키(A)는 A\u0026rsquo; 값보다 크되, 가장 가까운 서버를 찾아간다. 서버가 감소되었을 때 : 리밸런싱되는 데이터는, \u0026lsquo;그 서버에 해당되는 데이터\u0026rsquo; 만 리밸런싱 된다. 리밸런싱의 비율이 mod 연산보다 적다.\nSharding # 데이터를 어떻게 나눌 것인가? = 데이터를 어떻게 찾을 것인가? 하나의 데이터를 모든 서버에서 찾는다면\n모든 서버에 부하를 일으키고 낮은 레이턴시 Range Sharding\n특정 Range 를 정의하고, 해당 Range 에 속하면 그곳에 저장/조회\nServer 1 : 1~1000 Server 2 : 1001~2000 =\u0026gt; Key(1500)은 Server 2 에 저장/조회한다.\nHot Key (Famous key) 에 의한 문제가 발생할 수 있다. 특정 서버만 너무 놀거나 꽉 찰 수 있다. Modular Sharding\n서버를 x2 수만큼 늘리면, 데이터가 리밸런싱되는 위치 계산이 쉽다.\n예를 들어,\nMod1, 2 서버가 있다가 Mod3, 4 서버가 증설되었다면\nMod0의 일부 데이터 -\u0026gt; Mod2 Mod1의 일부 데이터 -\u0026gt; Mod3 Indexed\n해당 key가 어디에 저장되어야 하는지 별도의 (인덱스) 서버가 따로 존재\n서비스 디스커버리, 혹은 seq 테이블 처럼 Redis Cluster # Hash 기반으로 slot 16384 로 구분한다.\nHash 알고리즘 : CRC16 slot = CRC16(key) % 16384 클러스터의 수는 16384를 넘어갈 수 없다는 것을 의미하기도 한다. key 가 key{hashkey} 패턴이면, 실제 crc16에 hashkey가 사용된다. (?) 위와 같은 패턴이면, 원하는 서버 쪽으로 보낼 수 있다고 한다. 좀 더 찾아볼 것 특정 Redis 서버는 이 slot range 를 가지고 있고, 데이터 migration 은 이 slot 단위의 데이터를 다른 서버로 전달하게 된다. (migrateCommand 이용) 좀 더 찾아볼 것\n장점\n자체적인 primary, secondary Failover slot 단위의 데이터 관리 단점\n메모리 사용량이 더 많음 slot 관리 Migration 자체는 관리자가 시점을 결정해야 함 slot 을 어디로 옮기겠다 등등 (?) library 구현이 필요함 일반적인 라이브러리는 MOVED 처리를 해준다.\n직접 개발 시에는 이 부분을 직접 구현해야한다. Redis Failover # Coordinator 기반 Failover 클라이언트의 추가적인 구현이 필요하다. VIP/DNS 기반 Failover 클라이언트의 추가적인 구현이 필요 없다. VIP 기반 : 외부로 서비스를 제공해야 하는 서비스 업자에 유리 (ex : 클라우드 업체) Domain 기반 : DNS Cache TTL 을 관리해야 한다. 사용하는 언어별 DNS 캐싱 정책을 잘 알아야 한다. 툴(클라이언트)에 따라서 한번 가져온 DNS 정보를 다시 호출하지 않는 경우도 존재한다. ex : java 30초, \u0026hellip; 위와 같은 특징이 있긴 하지만, DNS 가 살짝 더 편하긴한다. 서비스 특징마다 선택할 수 있도록 해야 한다. Redis Cluster 사용 Coordinator 기반 Failover # Coordinator 기반으로 설정/관리하면 동일한 방식으로 관리 가능 (IaC 느낌을 말하는 듯) 아래 그림과 같이, 기능을 이용하도록 개발 필요 VIP(Virtual IP) 기반 Failover # 레디스 서버에 실제 IP 말고 VIP를 추가로 부여한다. 클라이언트는 VIP 를 통해서만 Redis에 접속한다. 주의할 점\nFailover 시, 기존 서버의 연결을 모두 끊어줘야 한다. 클라이언트의 재접속을 유도한다. DNS 기반 Failover # VIP 와 동일한 개념이다.\nDomain 을 이용하는 차이다.\n주의할 점\nFailover 시, 기존 서버의 연결을 모두 끊어줘야 한다. 클라이언트의 재접속을 유도한다. Monitoring # Redis 에서 확인해야할 것 # RSS 꼭 모니터링 해야한다. 물리 메모리를 얼마나 쓰고 있는지에 대한 정보 Used Memory (Redis 가 판단하는) 사용하고 있는 메모리 정보 RSS와 차이가 있다. Connection 수 초당 처리 요청 수 System 자체에서 확인해야할 것 # CPU DISK Network rx/tx 너무 많은 데이터를 처리하면, 네트워크 단(패킷)에서 Drop 되는 경우가 생겨서 문제(?)가 발생할 수도 있다고 한다. CPU가 100%를 칠 경우 # 처리량이 매우 많다면?\nScale Up 실제 CPU 성능에 영향을 받는다. 단순 get/set 은 초당 10만 이상처리 가능 O(n) 계열의 특정 명령이 많은 경우\nmonitor 명령어를 통해 명령 패턴을 파악할 수 있다. monitor 명령어를 잘못 쓰면, 오히려 부하 발생시킬 수 있다. 짧게 쓰는 것이 좋다. 결론 # 1. Redis 는 매우 좋은 도구이다.\n다만, 메모리를 빡빡하게 쓰기 시작하면서부터, 관리하기가 어려워진다.\n32GB 장비라면, 24GB 이상 사용하면 장비 증설을 고려하는 것이 좋다. 넉넉하게 사용하는 것이 좋다. write 가 heavy할 때는 migration 도 매우 주의해야 한다. write 가 heavy 할 때는, 사실 뭘 쓰든 문제가 발생할 수 있다. 2. client-output-buffer-limit 설정이 필요하다.\n메모리가 커질수록, 크게 잡아야된다.\n이 값보다 크면 연결을 끊는다.\n좀 더 찾아볼 것\n3. Redis as Cache 로 사용한다면, 문제가 발생하더라도 영향력이 적다\nCache는 어처피 Cache 이다.\nRedis가 문제가 있을 때 DB등의 부하가 어느정도 증가하는지 확인이 필요하다. DB가 못버틸정도면, 문제이지만 DB가 버틸정도면, 캐시는 다시 만들면 된다. Consistent Hashing 도 실제 부하를 아주 균등하게 나눠주지는 않는다. Adaptive Consistent Hasing 을 이용해 볼 수도 있다. 4. Redis as Persistent Store 로 사용한다면, 문제 발생 시 영향력이 크다.\n무조건 primary/secondary 구성이 필요하다. 메모리를 절대 빡빡하게 사용하면 안된다. 정기적인 migration 필요 (migration 작업이 생각보다 너무 많다.) 가능하면 자동화 도구를 만들어서 이용한다. RDB/AOF가 필요하다면, Secondary에서만 구동한다. RDB 보다는 AOF (?) 찾아볼 것 영속성 도구로써는 사실 권장하지는 않는 듯 하다. 문제가 발생할 여지가 많다. "},{"id":96,"href":"/docs/DEV/%EC%9A%B0%EC%95%84%ED%95%9C-%ED%85%8C%ED%81%AC-%EC%84%B8%EB%AF%B8%EB%82%98-%EC%9A%B0%EC%95%84%ED%95%9C%EA%B0%9D%EC%B2%B4%EC%A7%80%ED%96%A5-2019/","title":"우아한 테크 세미나 : 우아한객체지향 2019","section":"DEV","content":" 2019년 \u0026ldquo;우아한Tech - 우아한객체지향 by 조영호님\u0026rdquo; 유투브 세미나를 듣고 내용 정리하기\n제목 : \u0026lsquo;우아한 객체지향 의존성을 이용해 설계 진화시키키\u0026rsquo;\n설계에서 가장 중요한 것은 \u0026lsquo;의존성\u0026rsquo;이다. \u0026lsquo;의존성\u0026rsquo;을 어떻게 설정,관리하느냐에 따라 설계가 많이 달라진다.\n의존성(Dependency)\n설계는 코드를 어떻게 배치할 것인가? 어떤 코드를 어디에 넣을 것인가? 어떤 코드를 어디 클래스에, 어디 패키지에 넣을건지 등에 대한 고민을 하는 것이다.\n변경에 초점을 맞춰야한다. 같이 변경되는 코드를 같이 넣어줘야하고, 같이 변경되지 않는 것은 따로 넣는다. (= 결국에는 의존성과 관련이 있다.)\n// a 가 b 에 의존한다고 한다. a ---\u0026gt; b // b가 변경될 때 a도 변경이 될 수 있다. (변경 될 가능성이 있다.) // 즉 \u0026#39;의존성\u0026#39;이 있다. // 즉 \u0026#39;의존성\u0026#39;은 \u0026#39;변경\u0026#39;과 관련되어 있는 것이다. 의존성 = 변경에 의해서 영향을 받을 수 있는 가능성\n클래스 사이에, 패키지 사이에 의존성이 있다.\n클래스 의존성의 종류\n연관관계(Association)\nA-\u0026gt;B 로 영구적으로 갈 수 있음\n// A -\u0026gt; B class A { private B b; } 의존관계(Dependency)\nA-\u0026gt;B 일시적으로 연관\nparameter, return type, method 안에서 해당 type 을 사용한다.\nclass A { public B method(B b) { return new B(); } } 상속관계(Inheritance)\n상속관계는 B 가 변경되면 A 도 변경됨\nclass A extends B { } 실체화관계(Realization) (인터페이스 구현 관계)\n실체화관계에서는 B의 시그니처가 변경될 때에만 A가 변경된다.\nclass A implements B { } 패키지 의존성이란?\npcakage b 안의 클래스B가 변경될 때 package a 안의 A클래스가 변경된다. (package a -\u0026gt; package b)\nusing, import 등의 문법이 있다? = 패키지 의존성이 있다.\n좋은 의존성을 관리하기 위한 몇가지 팁이 있다.\n양방향 의존성을 피하라\n양방향 의존성 -\u0026gt; A가 바뀔 때, B가 바뀌고, B가 바뀌면 A가 바뀐다 -\u0026gt; 하나의 클래스를 억지로 찢어놓은것과 같다.\n양방향일 때에는 항상 sync 도 맞춰줘야하고 등등 너무 복잡하다. 하나를 수정할 때 둘 다 수정해줘야하기때문에 (단방향으로 바꿔주어야 한다.)\n다중성이 적은 방향을 선택해라\n일대다 보다는 다대일을 선택해라.\nclass A { private Collection\u0026lt;B\u0026gt; bList; } class B { } class A { } class B { class A a; } 위의 방식 보단 아래의 방식을 택한다.\n의존성이 필요없다면 제거하라\nclass A { private B b; } class B { } class A{ } class B{ } 위의 방식보단 아래의 방식을 택한다.\n패키지 사이의 의존성 사이클(양방향 의존성)을 제거하라\nA -\u0026gt; B -\u0026gt; C -\u0026gt; A 등의 관계(사이클)이 있다면 제거하라. (양방향 포함)\n설계의 원칙은 무조건 \u0026lsquo;변경\u0026rsquo; 이다.\n만약 A 가 변경되면, 누가 변경되는지 봐야한다.\n예제를 살펴보자. # 먼저 배달의민족앱 주문 flow 를 살펴보자. (아래 flow 에서 특정한 부분에 대해 설명하고자 한다.)\n가게 선택 -\u0026gt; 메뉴 선택 -\u0026gt; 장바구니 담기 -\u0026gt; 주문\n/* 가게 엔티티 설계 */ 가게 1 --- * 메뉴 메뉴 1 --- * 옵션그룹 1 --- * 옵션 /* 주문 엔티티 설계 */ 주문 1 --- * 주문항목 1 --- * 주문옵션그룹 1 --- * 주문옵션 간단하게 정리하면, \u0026lsquo;가게\u0026rsquo;를 중심으로 \u0026lsquo;메뉴\u0026rsquo;와 \u0026lsquo;주문\u0026rsquo;이 런타임시에 연관되어 동작한다.\n문제1 : 메뉴 불일치\n고객이 장바구니에 \u0026lsquo;1인 메뉴 세트\u0026rsquo;를 담았다. 이 장바구니 데이터는 고객 디바이스 로컬에 저장된다.\n메뉴 클래스 옵션, 옵션그룹 클래스 이 시점에 가게에서 \u0026lsquo;1인 메뉴 세트\u0026rsquo;의 명칭과 가격을 변경했다고 가정하자. -\u0026gt; \u0026lsquo;0.5인 메뉴 세트\u0026rsquo;, 15000원 -\u0026gt; 7500원\n주문 클래스 주문항목, 주문옵션, 주문옵션그룹 클래스 즉, 주문 시에 고객이 주문한 메뉴와 가게 메뉴를 검증한다. (Validation)\n메뉴명 - 주문항목 이름 검증(비교) 옵션그룹명 - 주문옵션그룹명 이름 검증(비교) 옵션명 - 주문옵션명 이름 검증(비교) 옵션가격 - 주문옵션가격 이름 검증(비교) 가게의 최소주문금액 체크 가게의 영업여부 체크 \u0026hellip; -------- 메뉴 - 옵션그룹 - 옵션 | 가게 | ----- 주문 - 주문항목 - 주문옵션그룹 - 주문옵션 협력 설계하기\n이제 위 Validation 협력,로직 등에 대해 살펴본다.\n// 이후 이미지 대체 // 이후 이미지 대체\n클래스 사이의 \u0026lsquo;관계/협력/의존성\u0026rsquo;에는 방향성이 필요하다.\n관계의 방향 = 협력의 방향 = 의존성의 방향 A 가 B 에 의존해/요청해. (어떤 객체 A 가 어떤 객체 B 에게 메세지를 보내야해.) DB와는 조금 다르다. DB는 foreign key 가 잡히면 양방향으로 움직일 수 있다. 하지만 객체는 다르다. 객체는 정확한 방향성을 선택할 수 있다. 앞서 소개했던 연관관계, 의존관계 중에 생각해보자. (이건 상속이나 실체화관계가 아닌 것은 확실하니까)\n협력을 위해 영구적으로 탐색이 필요한 구조라면 -\u0026gt; 연관관계\norder, shop 이 한번만/일시적으로만 관계를 맺으면 -\u0026gt; 연관관계 객체 참조 (composition) 협력을 위해 일시적으로 탐색이 필요한 구조라면 -\u0026gt; 의존관계\nparameter, return type, local variable 메서드 파라미터, 메서드 내부에서 new() 등등 관계를 맺을 때에는 \u0026lsquo;이유\u0026rsquo;가 있어야한다.\nA -\u0026gt; B 로 향할 때에는 \u0026lsquo;이유\u0026rsquo;가 필요함 예를 들어, 아래와 같다.\nOrder -\u0026gt; OrderLineItem 으로 연관관계를 맺어야 하는 이유?\nOrder 가 뭔지 알면, OrderLienItemr 을 찾을 수 있어야 한다. 이 두 클래스(객체)는 영구적으로 관계가 맺어져 있어야 한다. class Order { private List\u0026lt;OrderLienItem\u0026gt; orderLineItems; // 연관관계를 통해 협력한다. 여기서는 객체참조를 통해 연관관계를 구현한 것이다. public void place() { validate(); ordered(); } public void validate() { ... for(OrderLineItem orderLineItem : orderLineItems) { // 연관관계를 통해 협력한다. orderLineItem.validate(); } } } * \u0026lsquo;연관관계\u0026rsquo; 는 \u0026lsquo;개념\u0026rsquo;, \u0026lsquo;객체참조\u0026rsquo; 는 \u0026lsquo;구현방법\u0026rsquo; 이다. 이 둘을 같다고 오해하지말자.\n* 연관관계를 구현할 수 있는 방법은 객체참조 말고도 다른 방법이 있다.\n메서드가 필요한 이유는, 메세지를 전달하기 위해서이다.\n메서드를 만들었기 때문에 메세지를 받는게 아니다. 메세지를 받기 위해 메서드를 만드는 것이다.\n// Order 라는 객체가 place 라는 메세지를 받는다. public class Order { public void place() { // 주문 메세지를 위해 메서드를 만들었다. validate(); ordered(); } ... } 주문은 \u0026lsquo;가게\u0026rsquo; 와 \u0026lsquo;주문항목\u0026rsquo; 에 메세지를 보내야한다. (위의 flow 대로)\n@Entity public class Order{ @Id private Long id; @ManyToOne @JoinColumn(name=\u0026#34;SHOP_ID\u0026#34;) private Shop shop; // 가게와 협력해야한다. 메세지를 보내야한다. @OneToMany(cascade = CascadeType.ALL) @JoinColumn(name=\u0026#34;ORDER_ID\u0026#34;) private List\u0026lt;OrderLineItem\u0026gt; orderLineItems = new ArrayList\u0026lt;\u0026gt;(); // 주문항목과 협력해야한다. 메세지를 보내야한다. public void place() { validate(); ordered(); } public void validate() { if(orderLineItems.isEmpty()) { throw new IllegalStateException(\u0026#34;주문 항목이 비어 있습니다.\u0026#34;); } if(!shop.isOpen()) { // 가게에 메세지를 보낸다. throw new IllegalArgumentException(\u0026#34;가게가 영업중이 아닙니다.\u0026#34;); } if(!shop.isValidOrderAmount(calculateTotalPrice())) { // 주문항목에 메세지를 보낸다. throw new IllegalStateException(String.format(\u0026#34;최소 주문 금액 %s 이상을 주문해주세요\u0026#34;, shop.getMinOrderAmount())); } for(OrderLineItem orderLineItem : orderLineItems) { orderLineItem.validate(); // 주문항목에 메세지를 보낸다. } } public void ordered() { this.orderStatus = OrderStatus.ORDERED; } } 위 코드의 베이스는 아래와 같다.\n주문은 가게,주문항목과 (영구적으로) 협력해야 한다. 강한 연관관계를 갖는다. (라는 것을 의도한 것이다.) @Entity public class OrderLineItem { ... public void validate() { menu.validateOrder(name, this.orderOptionGroups); // 메뉴에 메세지를 보낸다. } } public class Menu { public void validateOrder(String menuName, List\u0026lt;OrderOptionGroup\u0026gt; groups) { if(!this.name.equal(menuName)) { // 메뉴와 주문옵션그룹의 이름을 비교한다. throw new IllegalArgumentException(\u0026#34;기본상품이 변경되었습니다.\u0026#34;); } if(!isSatisfiedBy(groups)) { throw new IllegalArgumentException(\u0026#34;메뉴가 변경되었습니다.\u0026#34;); } } private boolean isSatisfiedBy(List\u0026lt;OrderOptionGroup\u0026gt; groups) { return cartOptionGroups.stream().anyMatch(this::isSatisfiedBy); } private boolean isSatisfiedBy(OrderOptionGroup group) { return optionGroupSpecs.stream().anyMatch(spec -\u0026gt; spec.isSatisfiedBy(group)); // 메뉴에서 옵션그룹으로 메세지를 보낸다. } } public class OptionGroupSpecification { ... public boolean isSatisfiedBy(OrderOptionGroup group) { return !isSatisfied(group.getName(), satisfied(group.getOptions())); } private boolean isSatisfied(String groupName, List\u0026lt;OrderOption\u0026gt; satisfied) { if(!name.equals(groupName) || satisfied.isEmpty() || (exclusive \u0026amp;\u0026amp; satisfied.size() \u0026gt; 1)) { return false; } return true; } private List\u0026lt;Options\u0026gt; satisfied(List\u0026lt;OrderOption\u0026gt; options) { return optionSpecs.stream().flatMap(spec -\u0026gt; option.stream().filter(spec::isSatisfiedBy)).collect(toList()); } } * 나머지 코드는 github 에서 살펴보자.\n즉, 위와 같이 한 클래스가 다른 클래스에 메세지를 보낸다.\n(위의 코드는 레이어 아키텍처에서 Domain 사이에서의 관계를 나타낸 것이다. 비즈니스 로직을 구현한 부분!)\nService, Infrastructure(Repository) 등의 대한 부분도 작성해야할 것이다. 간단히 보면 아래와 같다.\n// Service 예시 @Service public class OrderService { @Transactional public void placeOrder(Cart cart) { Order order = orderMapper.mapFrom(cart); order.place(); // 이 안에서 order 검증하고, 상태값 변경함...!! (문제가 있다면 예외가 발생한다. ) orderRepository.save(order); } } @Repository public class OrderRepositoryImpl implements OrderRepository { } 설계 개선하기 # 대부분 class 하나를 보여주고 어떻게 개선하는지 물어본다. 이때에는 이름이나 메서드의 사이즈나, 책임/원칙 등에 대해서만 피드백할 수 있다.\n큰 그림에서 보곤해야한다. 코드를 짜고, class 간의 dependency 를 그려봐야한다. (손으로 직접 그려보자.)\n객체를 어디에 두고 메서드를 어디에 작성하고 하는 것들이 처음엔 정말 어렵다. 그러면 일단 코드를 작성해보고 의존성을 그려보자. 그리고 다시 봐보자.\n오늘은 (위에서 작성했던 코드들에 대한) 아래의 2가지 문제에 대해 살펴본다.\n객체 참조로 인한 결합도 상승 패키지 의존성 사이클 패키지 의존성 사이클의 문제\n// package order \u0026lt;-\u0026gt; shop class Order { private void validate() { if(!shop.isOpen()) { // package order -\u0026gt; package shop 의존 ... } ... } } class OptionGroupSpecification { public boolean isSatisfiedBy(OrderOptionGroup group) { // package shop -\u0026gt; package order 의존 ... } } class OptionSpecification { public boolean isSatisfiedBy(OrderOption option) { // package shop -\u0026gt; package order 의존 ... } } 개선 방법1. 중간 객체를 이용한 의존성 사이클 끊기(ManyToMany 를 쪼개듯 중간에 하나의 도메인을 만든다)\n// OptionGroupSpecification -\u0026gt; OptionGroup \u0026lt;- OrderOptionGroup // OptionSpecification -\u0026gt; Option \u0026lt;- OrderOption class OptionGroupSpecification { public boolean isSatisfiedBy(OptionGroup group) { // OptionGroupSpecification -\u0026gt; OptionGroup ... } } class OrderOptionGroup { public OptionGroup convertToOptionGroup() { // OrderOptionGroup -\u0026gt; OrderOption return new OptionGroup(name, ...); } } class OrderOption { public Option convertToOption() { return new Option(name, ...); } } 이렇게 바꿨을 때의 장점은 무엇일까?\nOptioGroup, Option 의 재사용성이 증가될 수 있다. 저 클래스는 다른 곳에서도 사용할 수 있게 되었다. (Cart 에서 사용한다거나 등등)\n다만, 위의 방법은 확실히 어색하게 보는 사람이 많이 있다. 이 방법은 하나의 방법으로 보자. 따라서 기존대로 유지하되 이것도 하나의 방법으로 둘 것같다고 말씀해주셨다.\n* 여기서 참고!!\nDIP 는 클래스들이 구체적인것이 아닌 추상화된 것에 의존하라는 것인데, 이걸로 패키지 싸이클을 끊을 수 있다. 근데 사람들이 오해하는게 여기서 말하는 추상화는 인터페이스나 super 클래스가 아니다. 그냥 자주 안변하는 클래스라고 보면된다. 객체 참조의 문제\n객체들이 다 연결되어 있기 때문에, 하나의 객체에서 연결되어 있는 모든 객체를 다 탐색할 수 있다.\n이것은 ORM 을 사용할 때 헬게이트로 다가온다..! (LazyLoading 등등. .. JPA 사용할 때의 연관관계 문제 등등)\n객체가 다 연결되어 있다보니, 하나를 볼 때 어디까지 봐야하는지 알기 힘들다. 하나의 객체가 변경될 때, 같이 변경되어야 하는 객체들은 어디까지?(어디까지 변경시킬 건지?, 범위) -\u0026gt; Transaction 의 경계가 모호해진다. (Locking) 객체 참조는 너무 쉽게 다른 객체를 참조할 수 있다보니 다른 객체에 대한 수정이나 작업을 계속해서, 쉽게 변경하게 되곤 한다.\npublic class OrderService { @Transactional public void payOrder(Long orderId) { Order order = orderRepository.findById(orderId) ... order.payed(); Delivery delivery = Delivery.started(order); deliveryRepository.save(delivery); } ... @Transactional public void deliverOrder(Long orderId) { Order order = orderRepository.findById(orderId); order.delivered(); Delivery delivery = deliveryRepository.findById(orderId); delivery.complete(); } } public class Order { public enum OrderStatus { ORDERED, PAYED, DELIVERED } @Enumerated(EnumType.STRING) @Column(name=\u0026#34;STATUS\u0026#34;) private OrderStatus orderStatus; public void payed() { this.orderStatus = PAYED; } public void delivered() { this.orderStatus = DELIVERED; // 여기에 가게에 수수료를 부과한다라는 부분도 추가해보자. this.shop.billCommissionFee(calculateTotalPrice()); } } public class Delivery { enum DeliveryStatus { DELIVERING, DELIVERED } ... @OneToOne @JoinColumn(name=\u0026#34;ORDER_ID\u0026#34;) private Order order; @Enumerated(EnumType.STRING) @Column(name=\u0026#34;STATUS\u0026#34;) private DeliveryStatus deliveryStatus; public static Delivery started(Order order) { return new Delivery(order, DELIVERING); } public void complete() { this.deliveryStatus = DELIVERED; this.order.completed(); } } public class Shop { private Ratio commissionRate; private Money commision = Money.ZERO; public void billCommissionFee(Money price) { commission = commission.plus(commissionRate.of(price)); } } 문제점 : 이들은 변경의 빈도/순간이 다르다.\n위의 OrderService.deliverOrder() 는 shop, order, delivery 에 대해서 transaction(lock) 을 건다. 그런데.. 각각의 아래 요청을 처리할 수 있다.\nShop \u0026lt;- admin 에서 가게 상태 변경\nOrder \u0026lt;- 주문 상태 변경\nDelivery \u0026lt;- 배달 상태 변경\n서비스가 커지면 커질수록 lock 늪에 빠질 수 있다.\n객체 참조로 인해 -\u0026gt; 트랜잭션 경합이 발생할 가능성이 높아진다. -\u0026gt; 성능 저하로 이뤄진다. (잘못된다면 장애까지 발생할 수 있다.)\n객체참조 = 한 트랜잭션 안에서 동작하는 객체가 많아진다.\n객체 참조는 결합도가 굉장히 굉장히 높은 의존성이다. 꼭 필요한 경우를 제외하곤 다 끊어야한다. (\u0026lsquo;어떤 객체들을 묶고 어떤 객체들을 분리할 것인가?\u0026rsquo; 부분에서 다시 봐보자.)\n그러면 어떻게 해결할 수 있을까??\n\u0026lsquo;Repository 를 통한 탐색(약한 결합도)\u0026rsquo; 방법을 사용한다.\npublic class Order { @Column(name=\u0026#34;SHOP_ID\u0026#34;) private Long shopId; } Shop shop = shopRepository.findById(order.getShopId()); @Entity @Table(name=\u0026#34;SHOPS\u0026#34;) public class Shop { @Id private Long id; } 특히 이 부분은 내가 아예 잘못된 방향으로 생각했다..! 나는 객체 탐색을 쉽게 하기 위해 오히려 객체 참조를 걸곤 했다.\n즉.. Repository 로 연관관계를 넘기는 것이다.\n-\u0026gt; 비즈니스 로직은 단방향으로 깔끔하게 작성할 수 있곤하는데, 조회로직이 들어가면서부터 양방향 등등의 복잡한 관계가 설정되곤한다.\n어떤 객체들을 묶고 어떤 객체들을 분리할 것인가?\n(* 모든 객체참조가 불필요하지는 않다.) 즉 알고쓰자는 것이다.\n함께 생성되고 함께 삭제되는, 함께 변경되는 애들은 묶자.\n(객체참조는 트랜잭션이 같이 묶이는 것이라고 했다. 그러니까 도메인 관점에서 같이 변경될 것들은 객체참조로 묶어도된다는 것이다.) (트랜잭션단위, 조회단위(lazy,eager) 등등)\n도메인 제약사항을 공유하는 객체들은 묶자.\n가능하면 분리하자.\n(도메인)의미적으로 강하게 묶여야하는 애들은 묶자. 근데 이걸 repository 방식으로 풀수 있다고 생각한다면 풀자.\n장바구니, 장바구니항목은 무조건 (객체참조로) 결합되어야 한다? -\u0026gt; 아닐 수 있다. 보통 장바구니, 장바구니항목이 변경되는 시점이나 도메인 제약사항에 따라 다르다.\n-\u0026gt; 단순하게 이름으로만, 쉽게 생각해서는 안된다!\n즉, 규칙은 없다. 도메인에 따라 다를 것이다.\n// 이후에 이미지 참조 (객체 묶기)\n위의 그림에서 같은 경계안에 있다면 연관관계로 묶었다고 한다. (묶는 것이 맞다고한다.)\nlazy/eager loading 같이 CRUD 되어야하고 등등 그림에서 같은 경계에 있따면 id(repository)로 묶는다.\npublic class Order { private List\u0026lt;OrderLineItem\u0026gt; orderLineItems; @Column(name=\u0026#34;SHOP_ID\u0026#34;) private Long shopId; } 객체참조를 사용하는것은 굉장히 편하고, 이론적으로 설명하기에 너무 쉽다.\n다만 실무에서는 객체간에 어디서 끊고, 어디까지 관리할건지 등이 중요하기에 이런것들이 중요하다.\n위에처럼 경계를 나누면\n어디까지 db에서 한번에 가져올건지, 트랜잭션을 어디까지 잡을건지 확 알 수 있다. 그룹별로 (영속성) 저장소도 변경할 수 있다. public class Order { private Shop shop; // 이제 더이상 안쓰이니까 컴파일 에러 발생할 것이다. private Long shopId; } 이렇게 끊고나면 일단 컴파일 에러가 날텐데 아래 부터는 어떻게 해결했는지 설명한다. (객체참조로 된 기존 소스와 다르니까)\n이렇게 해결했다 1 : \u0026ldquo;객체를 직접 참조하는 로직을 다른 객체(OrderValidator)로 옮기자.\u0026rdquo;\n// 컴파일 에러가 났던 부분(order-shop)을 이쪽으로 다 뺸다. @Component public class OrderValidator { public void validate(Order order) { validate(order, getShop(order), getMenus(order)); } private void validate(Order order, Shop shop, Map\u0026lt;Long, Menu\u0026gt; Menus) { if(!shop.isOpen()) ... ... } } @Service public class OrderService { private OrderValidator orderValidator; @Transactional public void placeOrder(Cart cart) { Order order = orderMapper.mapFrom(cart); order.place(orderValidator); // 이것도 보면, 나같으면 service 에서 orderValidator.validate(order) 이런식으로 했을 것 같은데, order 쪽에 넘겼다. orderRepository.save(order); } } public class Order { public void place(OrderValidator orderValidator) { orderValidator.validate(this); ordered(); } } 위의 로직을 좋다고 생각한 이유.\n사실 여러 객체를 타고타고 들어가는 것은 이해하기 힘들 수 있다. 한곳에 모은 것이 좋다고 생각한다. (한눈에 볼 수 있다.) 응집도가 높아진다. 응집도 = 관련된 책임의 집합, 다르게 말하면 응집도는 \u0026lsquo;변경\u0026rsquo;과 관련이 있다. (모든 설계는 변경과 관련이 있다.) 같이 변경되는 게 한곳에 있다? == 응집도가 높다. 다르게 변경되는 것이 한곳에 있다? == 응집도가 낮다. (기존 order 는 주문처리, validation 둘다 있음) (* 때로는 절차지향이 객체지향보다 좋을 수 있다.)\n객체 안에 validation 로직을 넣어야한다는 강박관념을 벗어나자.\n간단한 validation 이라면 ok, 여러 객체가 사용되야한다면 위에처럼 따로 뺴는 것도 방법(절차지향) (tradeoff, 잘 선택할 것)\n이렇게 해결했다 2 : 1번 방법처럼 \u0026ldquo;절차지향\u0026rdquo;, 도메인 이벤트(domain event) 발행\n1. 절차지향\n// 문제 코드 public class Order { public void delivered() { this.orderStatus = OrderStatus.DELIVERED; this.shop.billCommissionFee(calculateTotalPrice()); // 이코드가 작성된 이유 // 1. orderStatus 먼저 변경되고 shop 의 수수료 값이 변경 되어야한다.(도메인 규칙) // 2. order -\u0026gt; shop 갖고 있으니 편하게 작성하자. } } // OrderDeliverdService 만든다. public class OrderDeliveredService { public void deliverOrder(Long orderId) { // 1번 처럼 기존 로직을 여기로 다 넣는다. // 현재 내가 작성하고 있는 코드와 유사함. Order order = orderRepository.findById(orderId); Shop shop = shopRepository.findById(order.getShopId()); Delivery delivery = deliveryRepository.findByOrderId(orderId); order.delivered(); shop.billCommissionFee(order.calculateTotalPrice()); delivery.complete(); } } 위의 코드는 주문 완료후 변경되는 로직으 2개의 클래스에 있음. (OrderService, Order)\n아래 코드는 OrderDeliveredService 한 곳에 있음\n(* 이렇게 수정하면 패키지 사이클돔)\n이럴 때에는 인터페이스 써서 의존성 역전하면됨.\n// 이후에 이미지 참조 (의존성 싸이클!!)\n// 이후에 이미지 참조 (의존셩 역전)\n* 위와같이 서비스에서 해결하면, 로직을 한눈에 볼 수 있다라는 장점 : 객체간의 결합도 낮되 로직간의 결합도 명확히 확인\n2. 도메인 이벤트\n* 로직간의 순서를 명확히 알되 느슨하게한다?\nOrder -\u0026gt; OrderDeliveredEvent -\u0026gt; Delivery,Shop\n// 이후에 이미지 참조 (Domain Event 를 이용한 의존성 제거)\n// 직접 구현해도 되고, // Spring 에서 제공하는 AbstractAggregateRoot 써도됨 public class Order extends AbstractAggregateRoot\u0026lt;Order\u0026gt; { public void delivered() { this.orderStatus = OrderStatus.DELIVERED; registerEvent(new OrderDeliveredEvent(this)); // DB commit 시에 발행해줌 (바로 발행하는 게아님) } } public class OrderDeliveredEvent { private Order order; public Long getOrderId() {...} public Long getShopId() {...} public Money getTotalPrice() {...} } // Shop 이벤트 핸들러 @Component public class BillShopWithOrderDeliveredEvnetHandler { // 동기,비동기 가능 // 다른 트랜잭션, 같은 트랜잭션 다 가능 @Asnyc @EventListener @Transactional public void handle(OrderDeliveredEvent event) { Shop shop = shopRepository.findById(event.getShopId()); shop.billCommissionFee(event.getTotalPrice()); } } // Delivery 이벤트 핸들러 @Component public class CompleteDeliveryWithOrderDeliveredEventHandler { @Asnyc @EventListner @Transactional public void handle(OrderDeliveredEvent event) { Delivery delivery = deliveryRepository.findById(event.getOrderId()); delivery.complete(); } } * 이것도 그려보면 사이클 돈다.\n여기서는 패키지를 분리해서 해결해보자.\nBillShopWithOrderDeliveredEvnetHandler 를 특정 패키지/클래스로 뺀다.\n// Shop -\u0026gt; Shop, Billing public class Shop { private Ratio commissionRate; private Money commission = Money.ZERO; public void billCommissionFee(Money price) { commission = commission.plus(commissionRate.of(price)); } } // 아래와 같이 분리 public class Shop { private Ratio commissionRate; public Money calculateCommissionFee(Money price) { return commissionRate.of(price); } } public class Billing { private Long shopId; private Money commission = Money.ZERO; public void billCommissionFee(Money commission) { commission = commission.plus(commission); } } @Component public class BillShopWithOrderDeliveredEvnetHandler { @Asnyc ... public void handle(OrderDeliveredEvent event) { Shop shop = ...; Billing billing = ...; billing.billCommissionFee(...); } } // 이후에 이미지 참고(Billing 을 새로 만든 패키지에 포함)\n패키지가 싸이클이 돌아서 해결해보면, 도메인(클래스)을 분리해야되는 경우가 많은 것을 확인할 수 있다.\nShop 안에 정산로직이 있었던 것이 이상했던 것을 자연스럽게 알게 된다. (정산)Billing 이라는 클래스를 따로 뺀다는 의사결정을 자연스럽게 하게 된다. * 세미나에서는 패키지 사이클이 돌면 기계처럼 분리했는데, 실제로 해보면 도메인이 분리되어야 하는 것을 보게 되는 경우가 많다.\n패키지 사이클 해결법\n추상화 + 의존성 역전 중간객체(클래스) 두는것 패키지/클래스 새로 생성한다. tradeoff\n의존성과 시스템 분리 # 의존성을 관리하다보면, 시스템을 쉽게 분리할 수 있게 된다.\n내가 지금 작성하고 있는 방식은 layered architecture 에 도메인들을 넣어 사용하고 있는 것이다. 의존성 관리 없이 이렇게 사용하는 것은 그나마 나을 수 있다고한다 (같은 레이어 안에서만 의존성 관리해주면 되니까.) (고민할 게 없다. 걍 쓰곤한다.)\n근데 의존성 관리하면 (도메인단위로 패키지 분리할 수 있다.) 도메인이 먼저, 그다음 layered architecture 가 나오게 만들 수 있다. (의존성을 컨트롤 할 수 있다.)\n// 이후에 이미지 참조(Domain Evnet 사용 전의 의존성) // 이후에 이미지 참조(도메인 단위 모듈)\n이렇게 하면, 추후에 시스템 분리도 가능하다. (물론 작업이 필요하겠지만 패키지 관리를 안하는 것보단 훨씬 수월할 것이다.)\n* 도메인 이벤트, 시스템 이벤트\nmono 로 가더라도, 꼭 패키지(의존성)관리는 해주자..!\n시스템 관리 = 의존성 관리\n의존성을 따라 시스템을 진화시켜라\n"},{"id":97,"href":"/docs/DEV/%EC%9A%B0%EC%95%84%ED%95%9C-%ED%85%8C%ED%81%AC-%EC%84%B8%EB%AF%B8%EB%82%98-%EC%9A%B0%EC%95%84%ED%95%9C%EC%8A%A4%ED%94%84%EB%A7%81%EB%B0%B0%EC%B9%98-2019/","title":"우아한 테크 세미나 : 우아한스프링배치 2019","section":"DEV","content":" @ConditionalOnProperty 사용 여부 # 개요 : Job(Bean) 수가 많아짐에 따라, 초기 로딩 속도가 느려질 수 있음\n현재 실행할 Job 만 Bean 으로 띄우기 위해 @ConditionalOnProperty 사용\n= 필요한 Bean 만 등록 -\u0026gt; 초기 로딩 속도 빨라짐 = 단, @ConditionalOnProperty 사용 시 테스트 코드 실행 시 속도가 느려짐\n@ConditionalOnProperty 사용 시 마다 (테스트)컨텍스트를 다시 띄움 결론\n목적 사용 여부 실제 동작에 우선순위가 있을 때\n빠르게 Job 을 띄우고 실행할 때 @ConditionalOnProperty 사용 O 테스트 코드에 우선순위가 있을 때\n(테스트 코드를 퉁해)코드의 정확성, 빠른 확인이 필요할 때 @ConditionalOnProperty 사용 X @ConditionalOnProperty 사용하지 않을 경우, 모든 것을 Bean 으로 등록하는 것임. (테스트 코드 작성 시) ApplicationContext 에서 Bean 찾아와서 코드 작성하는 방식\nStep N개 vs 파이프라인 # 하나의 Job 에서 여러 Step 을 정의하여 사용함\n순차적으로 실행이 필요할 때 몇몇 작업이 연관이 있을 때 문제점\n유연성이 떨어짐 Step1, 2, 3 이 있을 때, Step 2 혹은 3 만 실행하고 싶을 경우 Step2 는 실행하고 싶지 않을 경우 등등 따라서, 파이프라인으로 구성하는 것도 좋은 방법 (권장)\n파이프라인으로 구성 시 위의 경우 유연하게 대처 가능\n우형에서는 보통 Job1 - Step1 개로 구성하고 파이프라인 방식으로 한다고 함\n* 단, 파이프라인 활용 =\u0026gt; 배포 툴에 조금 종속적인 것 같음\n이 외 # JpaItemWriter : merge / persist Jenkins 배포 툴 무중단 배포 (readlink) * 무중단 배포 관련해서 더 알아볼 것\n"},{"id":98,"href":"/docs/DEV/%EC%9A%B0%EC%95%84%ED%95%9C-%ED%85%8C%ED%81%AC-%EC%BD%94%EC%8A%A4-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98-%EB%82%B4%EC%97%90-%EC%99%B8%EB%B6%80-%EB%A6%AC%EC%86%8C%EC%8A%A4-%EC%9A%94%EC%B2%AD%EC%9D%B4-%EB%8B%B4%EA%B8%B0%EA%B2%8C-%EB%90%98%EB%A9%B4-%EC%96%B4%EB%96%A4-%EB%AC%B8%EC%A0%9C%EA%B0%80-%EB%B0%9C%EC%83%9D%ED%95%A0%EA%B9%8C/","title":"우아한 테크 코스 : 트랜잭션 내에 외부 리소스 요청이 담기게 되면 어떤 문제가 발생할까?","section":"DEV","content":" 출처 : 트랜잭션 내에 외부 리소스 요청이 담기게 되면 어떤 문제가 발생할까?\n간단 요약 # DB 트랜잭션 시, 꼭 필요한 부분(범위)에만 트랜잭션이 걸릴 수 있도록 한다.\n불필요한 부분(예를 들어, DB 트랜잭션과 관련 없는 외부 API 호출 등)은 분리한다.\n예시 # OutGoingService : 외부API호출서비스.class DBTxService : 꼭필요한DB트랜잭션서비스.class\nclass DBTxService { @Transactional void save() { ... } } class OutGoingService { private final DBTxService dbTxService; void save() { // 외부 API 호출 로직 dbTxService.save(); // DB 트랜잭션 // 외부 API 호출 로직 } } "},{"id":99,"href":"/docs/DEV/%EC%B9%B4%EC%B9%B4%EC%98%A4%ED%86%A1-Java-App-Server-Refactoring-%ED%9B%84%EA%B8%B0/","title":"카카오톡 Java App Server Refactoring 후기","section":"DEV","content":" 객체를 수정하기 위해서, (메서드에서) 객체를 파라미터로 받아 메서드 내부에서 해당 객체를 수정하지 말자. # 어떤 클래스를 파라미터로 받으면 결합도가 높아진다.\n다음은 (Car 객체를 필드로 갖는) CarContext 객체의 Car 필드를 새로운 값으로 설정하는 예시이다.\n\u0026quot; 아래와 같이, 함수 내부에서 만드는 새로운 값 또는 상태를 함수의 안에서 외부 객체의 상태 변경에 직접 적용하는 것은 좋지 않습니다. 가능하면 리턴으로 받아서 처리하는 방식이 좋습니다. \u0026quot;\n// Bad Result createCar(CarContext carContext, Something A, Something B) { ... carContext.setCar(new Car()); ... return new Result(someValue); } // Good Pair\u0026lt;Result, Car\u0026gt; createCar(Something A, Something B) { ... return new Pair\u0026lt;\u0026gt;(new Result(someValue), new Car()); } 위 코드는 (새롭게 설정할)Car 객체를 받아서, 메서드 외부에서 설정한다.\n정리하면, 객체(클래스)에 어떤 새로운 값을 설정할 때 메서드의 인자로 넘겨, 메서드 내부에서 처리하지 말자. 설정할 새로운 값을 받아와서 처리하자. :star::star:\n(가능하면) 메서드에서 클래스(객체)를 받지 말고, 필요한 것만 명시적으로 받자. # 메서드에 어떤 객체를 넘겼을 때, 메서드를 사용하는 사용처에서는 메서드 내에서 해당 객체에 어떤 행위(값을 수정한다거나, 어떤 값에 접근한다거나 등등)를 하는지 알 수가 없다.\n즉, 객체에 어떤 행위를 하는지 알 수 없어 불안하다.\n물론 메서드명을 직관적으로 지어, 추측할 수 있을 것이긴 하다.\n이를 보완하기 위해서는 메서드에서 필요한 값만 받아 사용하는 것이 좋다.\n// Bad void doSomethingForPassengers(CarContext carContext, Something A, Something B) { List\u0026lt;People\u0026gt; passengers = carContext.getPassengers(); SomeValue someValue = carContext.getSomeValue(); … } // Good void doSomethingForPassengers(List\u0026lt;People\u0026gt; passengers, SomeValue someValue, Something A, Something B) { ... } 정리하면 다음과 같은 이점이 있다.\n메서드 사용처에서 객체를 넘겼을 때의 불안감을 제거할 수 있다. 객체를 넘겼을 때 보다 더 직관적(명시적)이다. (메서드의 의도가 명확해진다.) 코드 간 결합도가 줄어든다. 이때 파라미터의 수가 계속 증가해서 불편할 수 있다. 이런 경우 일단은 변경하고(외부 종속을 끊고) 함수를 더 작은 책임 단위로 리팩터링 하는 것을 검토해볼 수 있다. :thumbsup:\n꿀팁이다. :thumbsup:\n루프 최적화를 위해서 캐싱하고 싶다면 Context에 넣지 말고, 루프 밖으로 뺄 수 있는지부터 보자 # 요약 : (캐시를 위해)전역 변수와 같은 형태로 사용하지 말자\n여기까지 위 내용의 핵심을 정리해보면 \u0026ldquo;메서드에 객체를 넘기지 말자\u0026rdquo; 인 것 같다.\n고차 함수로 의존성 줄이기 # 서비스(클래스) 간 의존성을 고차 함수를 통해 제거할 수 있다. :star::star:\n다만, 이번 글은 서비스 간에 순환 의존성이 있을 때 이것을 제거하기 위한 방법으로 소개됐다.\n// Before @Service public class ServiceA { @Resource ServiceB serviceB; public void methodA(Integer paramFirst) { Output.printf(\u0026#34;\u0026#39;pass %d to ServiceB and get %s\u0026#39; by ServiceA\\n\u0026#34;, paramFirst, serviceB.methodB(paramFirst)); } public Integer getValue() { return 10; } } // After @Service public class ServiceA { public void methodA(Integer paramFirst, Function\u0026lt;Integer, Integer\u0026gt; methodB) { Output.printf(\u0026#34;\u0026#39;pass %d to ServiceB and get %s\u0026#39; by ServiceA\\n\u0026#34;, paramFirst, methodB.apply(paramFirst)); } public Integer getValue() { return 10; } } \u0026quot; ServiceA::methodA()의 시그니처를 수정하고, serviceB.methodB() 메서드 호출을 함수형 인터페이스 apply() 호출로 변경합니다. \u0026ldquo;\n위의 예시 서비스(ServiceA)를 사용하는 사용처에서는 다음과 같이 변경될 것이다.\n// Before @Component public class Handler { private final ServiceA serviceA; public Handler(final ServiceA serviceA) { this.serviceA = serviceA; } public void execute(long count) { for (long cnt = 0; cnt \u0026lt; count; cnt++) { serviceA.methodA(2); } } } // After @Component public class Handler { private final ServiceA serviceA; private final ServiceB serviceB; public Handler(final ServiceA serviceA, final ServiceB serviceB) { this.serviceA = serviceA; this.serviceB = serviceB; } public void execute(long count) { for (long cnt = 0; cnt \u0026lt; count; cnt++) { serviceA.methodA(2, serviceB::methodB); } } } 추가로 위와 같이 리팩터링하면 단위 테스트를 작성할 때도 의존성이 제거될 것이다. (조금 더 작성이 쉬워질 것이다.)\nService A 에서의 의존성은 제거됐지만, 해당 의존성들은 Handler에 추가됐다.\n이 글의 목적이 \u0026lsquo;순환 의존성을 제거하기 위한 방법\u0026rsquo;인 부분을 기억하자.\n위 리팩터링에서 주의할 점이 있다.\n메서드를 넘기면서 성능 차이가 발생할 수 있다.\n자세한 내용은 https://tech.kakao.com/2023/01/19/kakaotalk-java-app-server-refactoring/ 글을 참고한다.\n코드 복잡도 줄이기 (Cyclomatic Complexity, NPath Complexity) # 위의 내용 (메서드에 객체를 넘기지 않는 것, 고차 함수로 의존성을 줄이는 것)을 적용하면, 이미 코드 내 의존성들이 많이 정리된 상태가 된다.\n(코드가 정리된)이후 본격적으로 코드의 복잡도를 줄여봤다는 내용이다.\n코드 복잡도를 수치로 계산하는 다양한 방법들이 있지만, 그 중 Cyclomatic Complexity(이하 CC), NPath Complexity(이하 NPath)를 기준으로 정리했다.\n\u0026rdquo; CC는 함수에 제어문(분기, 루프 등)이 없다면 1점, 있다면 제어문마다 1점을 부여합니다. 또한, 조건식 안의 논리식도 1점으로 계산하여 각각의 점수를 모두 더합니다. NPath는 코드를 실행할 수 있는 비순환 경로의 수를 의미합니다. \u0026ldquo;\n\u0026rdquo; 코드의 복잡도를 줄이는 건 반드시 특별할 필요가 없습니다. 기본은 동일합니다. 하나의 함수에 많은 코드가 있다는 건, 코드 내부에서 필요 이상의 책임을 가지고 있다는 것입니다. 함수가 현재 가지고 있는 많은 책임을 더 작은 단위의 책임으로 나눈 뒤, 각 함수가 각 1개의 책임만 담당하도록 한다면, 복잡도 역시 각 함수가 나누어 가지게 됩니다. 그러면 이후에 추가되는 개별 함수들의 복잡도 또한 낮아지게 됩니다. \u0026ldquo; :star::star:\n함수 추출하기 # public Data buildData(boolean isConditionA, boolean isConditionB, boolean isConditionC, String extraCondition) { int someValue; if (isConditionA) { someValue = 10; } else { if (extraCondition.equals(\u0026#34;ForceB\u0026#34;) || isConditionB) { someValue = 20; } else { if (isConditionC) { someValue = 30; } else { someValue = 40; } } } Data data = new Data(); data.setA(someValue + 1); if (someValue == 30) { data.setB(someValue + 2); } else { data.setB(someValue + 4); } data.setC(someValue + 3); return data; } 위 메서드(buildData)는 2가지 책임을 갖고 있다.\nsomeValue 를 구하는 것 Data 객체를 생성하는 것 이것을 각각의 메서드로 추출할 수 있다.\nsomeValue 를 구하는 것 : getSomeValue() Data 객체를 생성하는 것 : makeData() 잘 해가고 있는 것 같다.\n다만 간혹 추출된 메서드가 많아 해당 클래스를 읽을 때 혼잡할 것 같다는 생각이 들 때가 있다. 이때는 클래스의 책임이 큰 것일 수 있겠다.\n중첩 조건문을 보호 구문으로 바꾸기 # // Bad private int getSomeValue(boolean isConditionA, boolean isConditionB, boolean isConditionC, String extraCondition) { if (isConditionA) { return 10; } else { if (extraCondition.equals(\u0026#34;ForceB\u0026#34;) || isConditionB) { return 20; } else { if (isConditionC) { return 30; } else { return 40; } } } } // Better private int getSomeValue(boolean isConditionA, boolean isConditionB, boolean isConditionC, String extraCondition) { if (isConditionA) { return 10; } if (extraCondition.equals(\u0026#34;ForceB\u0026#34;) || isConditionB) { return 20; } if (isConditionC) { return 30; } return 40; } \u0026rdquo; 코드가 한결 보기 편해졌습니다. 혹 Complexity reducer Plugin을 활성화해 두고 리팩토링 작업을 따라왔다면 중첩된 if 문들을 정리하면서 getSomeValue() 함수의 NPath가 4에서 8로 2배가 증가한 것을 확인할 수 있었을 것입니다. 코드의 로직은 동일하고 가독성도 좋아졌는데 오히려 코드 복잡도를 나타내는 수치가 증가했습니다. 그 이유는 첫 번째 if 문의 조건이 만족하면 바로 return 하여 함수를 나오기 때문에, 두 번째 if 문을 타지 않는다는 것을 계산에 포함하지 않고 나온 수치라서 그렇습니다. 계산 수치를 개선하기 위해 다시금 아래와 같이 수정해 보겠습니다. \u0026ldquo;\n// Best private int getSomeValue(boolean isConditionA, boolean isConditionB, boolean isConditionC, String extraCondition) { if (isConditionA) { return 10; } else if (extraCondition.equals(\u0026#34;ForceB\u0026#34;) || isConditionB) { return 20; } else if (isConditionC) { return 30; } return 40; } if-else 구문으로 변경을 통해 if 문의 조건이 만족될 경우 다음 if가 타지 않음을 명시할 수 있다. (복잡도 수치도 개선된다.)\n"},{"id":100,"href":"/docs/DEV/%EC%BA%90%EC%8B%B1-%EC%A0%84%EB%9E%B5/","title":"캐싱 전략","section":"DEV","content":" 6-Caching Strategies to Remember while designing Cache System\nKey Metrics # 캐시 히트율 (cache hit ratio) 응답 시간 (latency) 처리량 (throughput) 캐시 사이즈 (cache size) 캐시 미스율 (cache miss ratio) Read Intensive Application Caching # Cache-aside Cache-through Refresh-ahead Cache-aside # 캐시가 미스됐을 때, 3번의 trip 이 발생해 급격한 딜레이가 생길 수 있다. 데이터베이스에 업데이트하고 캐시에는 업데이트를 누락하여 캐시의 데이터가 낡은 상태로 유지될 수 있다. \u0026quot; Data might become stale if someone updates the database without writing to the cache. (Hence, Cache-aside is usually used alongside other strategies). \u0026ldquo;\nRead-through # Cache-aside 와 비슷하지만, 애플리케이션이 캐시에만 질의하고, (캐시 미스 상태인 경우) 캐시가 DB에 질의하는 차이가 있다.\nRead-through 는 (애플리케이션 -\u0026gt; 캐시 -\u0026gt; DB)흐름/로직이 단순해진다. Better read scalability. Cache-aside 에서 키가 만료된 경우, 동시 요청이 발생해 DB에 여러번 질의할 수 있다. 그러나 Read-through의 경우, (동시 요청이 발생해도)DB에는 오직 1번의 쿼리만 질의되는 것이 보장된다. (아마도 흐름은\u0026hellip;)\n캐시에 동시 여러개의 요청이 왔을 때 그 중 하나의 처리에서 업데이트(DB로부터 데이터 질의 \u0026amp; 업데이트) 이때 나머지 요청은 블락(큐잉) 상태 Refersh-ahead # \u0026rdquo; So what refresh ahead caching does is it essentially refreshes the cache at a configured interval just before the next possible cache access although it might take some time due to network latency to refresh the data \u0026amp; meanwhile few thousand read operation already might have happened in a very highly read heavy system in just a duration of few milliseconds. \u0026ldquo;\nWrite Intensive Application Caching # Write-through Write-back (Write-behind) Write-around Write-through # \u0026quot; The Write-Through strategy treats cache as its primary data store, that is , the data is updated first in cache and then in database. \u0026quot;\nRead-through 와 비슷하다. Write-through 는 캐시가 primary data store 로 취급되는 것과 마찬가지다.\nRead-through 전략과 같이 사용될 때, 효율적인? 적절한 구조가 되겠다. 캐시의 데이터는 항상 최신 상태로 유지될 것이고, DB와 캐시의 데이터가 (거의)일치하겠다. Write-back # write-through 와 유사하지만, DB 동기화를 비동기로 처리하는 점이 다르다.\n캐시에 먼저 쓰기 때문에(= 최신화된 데이터가 유지되기 때문에)읽기 작업, (비동기로 DB에 쓰기 때문에) 쓰기 작업 모두에 적합하다.\n쓰기 성능이 향상된다. (많은 양의 write 가 발생해도 대응할 수 있다.) 네트워크 비용을 줄일 수 있다. 비동기로 처리할 때 배치성으로 처리하면 네트워크 콜 수(비용)를 줄일 수 있다. 캐시에 먼저 쓰기 때문에 자주 요청되지 않은 데이터도 캐시에 기록된다. (즉, 불필요한 데이터도 함께 쌓인다.) 이런 데이터는 TTL 설정으로 최소화시킬 수 있다. 위 특징 중 읽기 요청에 대응할 수 있다는 점과, 3번은 Write-through 에도 동일할 것이다. (캐시에 먼저 쓰는 행위가 같기 때문에)\nWrite-around # 읽기 작업이 빈번하지 않을 때 (=데이터가 한 번 쓰이고 안읽히거나 조금 읽힐 때) 사용될 수 있다. (로그성 데이터 등)\nCache Invalidation Methods # Cache invalidation : the process of removing stale or outdated data from a cache\n몇 가지 전략은 다음과 같다.\nTime-based invalidation (TTL) Event-based invalidation This is a more targeted approach to invalidation that ensures that data is invalidated only when necessary. Version-based invalidation 데이터에 버저닝을 하고, 업데이트 시 마다 버전을 올린다. 가장 최신 버전의 데이터만 사용된다. 데이터가 빈번하게 변경될 때 사용될 수 있지만 :thinking:, 버전을 관리해야하니 추가 오버헤드가 발생한다. LRU invalidation Manual invalidation "},{"id":101,"href":"/docs/ETC/01.-AB-%ED%85%8C%EC%8A%A4%ED%8A%B8/","title":"01. AB 테스트","section":"ETC","content":" A/B 테스트 # 전체 대상자를 대조군과 실험군(A, B)로 나누어 변수(UI, 알고리즘 등)를 실험하는 것 = 더 가치 있는 변수를 식별 → 최고의 시안을 선정하는 것\n예를 들어, 웹사이트의 디자인, 마케팅, 광고에서 \u0026lsquo;가장 좋은 효과를 낼 수 있는 전략\u0026rsquo;을 선택하기 위해 실험하는 것이다.\n용어 설명 대조군 (control group) 현재 사용 중이거나 주로 사용되어온 변경되지 않은 버전 실험군(Experimental Group) 처리군 (Treatment Group) 챌린저 (Challenger) 새롭게 실험할(시도할) 버전 챔피언 (champion) (AB 테스트 실행 후 얻은) 목표에 근접한 버전 방식 방법 특징 적합한 사용 노출 분산 방식 A, B 의 노출을 \u0026lsquo;일정 비율\u0026rsquo;로 노출한다. - 가장 통계적 유의성이 높다. - UI/UX 실험일 경우, 사용자에게 혼란을 줄 수 있다. (일정 비율로 노출이 계속 변경되니까) - Heavy User 에 의한 영향이 덜하다. 알고리즘 테스트에 적합하다. 요약 : - 통계적 유의미 ↑ - 사용자 친화적 ↓ 사용자 분산 방식 사용자(그룹)를 분리 → 그룹별로 A, B 버전을 (고정적으로) 노출한다. - UI/UX 테스트에 적합하다. - Heavy User에 의해 결과값이 왜곡될 수 있다. 요약 : - 통계적 유의미 ↓ (비교적) - 사용자 친화적 ↑ UI/UX 테스트에 적합하다. 시간 분산 방식 초~분 단위 정도로 시간대를 세밀하게 분할하여 A, B를 노출한다. - 노출/사용자 분산 방식을 사용할 수 없는 경우 대안적으로 활용할 수 있다. - 많이 활용되는 방식은 아니다. 노출/사용자 분산 방식을 사용할 수 없는 경우 대안적으로 활용할 수 있다. 검증 # 가장 많이 활용되는 방식\n분석 AA Test P-Value 분석 자세한 내용은 이후 추가적으로 찾아볼 것\n예시 # 각각 다른 버전을 배포하고, 각각 다른 고객(그룹)에게 보여준다. A 버전은 \u0026lsquo;a\u0026rsquo; 그룹(고객군)에게 보여준다. B 버전은 \u0026lsquo;b\u0026rsquo; 그룹(고객군)에게 보여준다. \u0026lsquo;미리 설정한 목표\u0026rsquo;에 근접한 버전을 선택/결정한다. 주의 \u0026amp; 특징 # A/B 테스트는 1회 시행으로 끝나는 것이 아니라, 지속해서 반복하는 것이 중요 예를 들어, 팀이 원하는 목표, 결과를 얻을 때까지 A/B 테스트를 수행 단순한 접근은 지양 AB테스트를 통해 얻은 결과가 모든 상황에 적용되는 것은 아니다. 특정 고객(\u0026lsquo;a\u0026rsquo;) 에게 A 변수가 효과적이라는 결과를 얻었어도, 다른 고객(\u0026lsquo;b\u0026rsquo;) 에게는 적용되지 않을 수 있다. AB 테스트에서는 시간이 중심적은 역할을 한다. 둘 이상의 변형을 동시에 실행해야 한다. (?) 트래픽 할당은 \u0026lsquo;랜덤\u0026rsquo;으로 유지하는 것이 중요하다. 트래픽 양은 두 변형 페이지에 유사하게 보내 무결성을 유지하고, 유의미한 결과를 얻을 수 있도록 한다. 가장 일반적인 방법은 50:50, 60:40 비율로 유지하는 것이다. 참고 # AB 테스트: 무엇이며 어떻게 작동할까요? AB Test 기본부터 심화까지 - 1편 "},{"id":102,"href":"/docs/ETC/02.-Blocking-NonBlocking-Sync-Async/","title":"02. Blocking, NonBlocking, Sync, Async","section":"ETC","content":" Blocking-NonBlocking-Synchronous-Asynchronous 글을 참고합니다.\n관심사의 차이 # 키워드 관심사 Blocking / Non-Blocking 함수가 바로 응답하는지, 안하는지 Blocking : 함수 호출 후 함수가 완료될 때까지 기다린다. Non-Blocking : 함수 호출 후 함수가 완료되는 것을 기다리지 않는다.\n= 즉, 함수를 호출한 곳에 제어권을 곧바로 넘겨준다. = 즉, 함수를 호출한 곳은 다른 일을 할 수 있다. Sync / Async 함수의 \u0026lsquo;완료\u0026rsquo;를 누가 신경쓰는지 Sync : 함수의 완료(응답)을 호출한 쪽에서 신경쓴다. Async : 함수의 완료(응답)을 호출당한 쪽에서 신경쓴다. (callback 함수) 상황별 예시 # 아래와 같은 컴포넌트가 있다고 가정한다.\nA : 함수 호출자 B : 함수 피호출자 Blocking Sync # 함수 호출 후, 응답(처리)를 기다린다. (Blocking) 함수 호출 후, 응답을 반환받는다. (Sync) A ---\u0026gt; B | | B에서 처리가 완료될 때까지 기다린다. | B에서 처리가 완료되면 결과를 반환받는다. | A \u0026lt;--- B 아래와 같은 예시가 있다고 한다. file.read() file.write() \u0026hellip; Blocking Async # 함수 호출 후, 응답(처리)를 기다린다. (Blocking) 함수 호출 후, 응답은 신경쓰지 않는다. - 피호출자에서 callback 함수를 통해 처리한다. A ---\u0026gt; B | | B에서 처리가 완료될 때까지 기다린다. | B에서 처리가 완료되면 callback 함수를 통해 처리한다. | A \u0026lt;--- B (callback) 이 경우는 이점이 없다.\nBlocking 된 상태이기 때문에, 굳이 callback 함수를 통해 결과를 처리받지 않아도 된다. (직접 결과를 받으면 된다.)\n참고한 글에서는 Non-Blocking + Async 의 방식을 시도했지만 Blocking 처리되는 부분이 있을 때 발생할 수 있는 조합이라고 설명한다. (즉, 의도하지 않은 사용으로 인해 발생할 수 있는 조합)\n\u0026quot; NonBlocking-Async 방식을 쓰는데 그 과정 중에 하나라도 Blocking으로 동작하는 놈이 포함되어 있다면 의도하지 않게 Blocking-Async로 동작할 수 있다. \u0026ldquo;\n아래와 같은 예시가 있다고 한다. Node.js + Mysql Non-Blocking Sync # 함수 호출 후, 응답(처리)를 기다리지 않는다. (Non-Blocking) - 함수 호출자는 다른 일을 할 수 있다. 함수 호출 후, 응답을 반환받는다. (Sync) // B에서 처리가 완료될 때까지 기다리지 않는다. // B에서 처리가 완료되었는지 확인한다. (주기적으로 polling 하는 느낌과 비슷하다.) A ---\u0026gt; B A --- 다른 작업 A ---\u0026gt; B 결과 확인 A --- 다른 작업 A ---\u0026gt; B 결과 확인 A --- 다른 작업 A ---\u0026gt; B 결과 확인 A \u0026lt;--- B 아래와 같은 예시가 있다고 한다. Future.isDone() (while(!Future.isDone()){...}) \u0026hellip; Non-Blocking Asnyc # 함수 호출 후, 응답(처리)를 기다리지 않는다. (Non-Blocking) - 함수 호출자는 다른 일을 할 수 있다. 함수 호출 후, 응답을 반환받는다. (Sync) // B에서 처리가 완료될 때까지 기다리지 않는다. // B에서 처리가 완료되면 callback 함수를 통해 처리한다. A ---\u0026gt; B A --- 다른 작업 A --- 다른 작업 A --- 다른 작업 A \u0026lt;--- B (callback) 아래와 같은 예시가 있다고 한다. asyncFileChannel.read() asyncFileChannel.write() \u0026hellip; "},{"id":103,"href":"/docs/ETC/03.-DB-Trigger/","title":"03. DB Trigger","section":"ETC","content":" 트리거에 대해 찾아본 내용 정리해보기\n트리거란? # (데이터베이스에서) 데이터의 입력, 수정, 삭제 등의 이벤트가 발생할 때 자동으로 수행되는 (사용자 정의)프로시저이다.\n(즉, 이벤트에 반응하여 실행되는 프로그램)\n트리거는 TABLE 에 종속되는 개념이 아니라, DATABASE 에 종속되는 개념이다.\n(즉, DATABASE에 저장된다.)\n트리거는 VIEW 가 아닌 실제 TABLE 에 관해서만 작성(정의)할 수 있다.\n보통 제약조건으로 명시할 수 없는 무결성 제약조건을 지키기 위해(무결성 보장), 혹은 관련 테이블의 데이터를 일치(수정)시켜야 할 때(DB 관리 자동화) 등의 목적으로 사용된다고 한다.\n유의 사항 # Trigger 는 트랜잭션 제어문(COMMIT, ROLLBACK, SAVEPOINT) 을 사용할 수 없다. Trigger 는 걸려있는 대상(트리거링, 테이블이나 ROW를 의미)의 \u0026lsquo;하나의 실행 부분\u0026rsquo;으로써 트리거링과 같은 트랜잭션 안에 있다. 2번에 의해 Trigger 가 걸려있는 대상이 commit, rollback 될 때 Trigger 도 commit, rollback 된다. Trigger 의 종류 # 1. 문장 트리거\n트리거가 설정된 테이블에 트리거 이벤트가 발생하면, (많은 행에 대해 변경 작업이 발생하더라도) 오직 한번만 트리거를 발생시키는 것이다.\n2. Row 트리거 (행 트리거)\n조건을 만족하는 여러 개의 Row에 대해 트리거를 반복적으로(여러 번) 수행하는 방법이다. Row의 변경 내역은 OLD, NEW(변수) 를 통해 가져올 수 있다.\nTrigger 표현식 # CREATE [OR REPLACE] TRIGGER \u0026#39;트리거명\u0026#39; BEFORE|AFTER -- 트리거가 적용되는 시점, 테이블이 변경되기 전에, 혹은 변경된 후에 (INSERT|UPDATE|DELETE) ON \u0026#39;테이블명\u0026#39; -- 테이블의 어떤 동작에 대해 적용할건지 [REFERENCING NEW|OLD TABLE AS 테이블명] -- NEW : 새로 추가되거나 변경된 후의 값에 Trigger 적용(INSERT: 삽입할 값, UPDATE: 수정할 값), OLD : 변경 전의 값에 Trigger 적용(UPDATE: 수정 전의 값, DELETE: 삭제할 값) [FOR EACH ROW] [WHEN 조건식] -- Trigger 가 실행되면서 적용될 where 조건 트리거 BODY문 -- Trigger 의 본문 코드 입력, BEIGN ... END 형태이며 적어도 하나의 SQL문이 있어야 한다. 그렇지 않으면 오류를 발생한다고 한다. 변수를 사용할 때는 SET 예약어를 사용한다.? DECLARE 는? -- [예시] -- 값이 입력되기 \u0026#39;전\u0026#39;에 -- 점수가 \u0026#39;\u0026#39; 으로 입력되는 것에 대해서 \u0026#39;0\u0026#39;으로 바꿔준다. -- 점수를 바꿔준 후 INSERT 한다.(?) CREATE OR REPLACE TRIGGER oracle_trigger BEFORE INSERT ON oracleStudy REFERENCING NEW TABLE AS new_trigger FOR EACH ROW WHEN new_trigger.점수 = \u0026#39;\u0026#39; BEGIN SET new_table.점수 = \u0026#39;0\u0026#39;; END; Trigger 관리 명령어 # -- 트리거 활성화/비활성화 ALTER TRIGGER 트리거명 [ENABLE|DISABLE] -- 테이블에 속한 트리거 활성화/비활성화 ALTER TABLE 테이블명 [ENABLE|DISABLE] ALL TRIGGER -- 트리거 수정 후 재컴파일 ALTER TRIGGER 트리거명 COMPILE; -- 트리거 삭제 DROP TRIGGER 트리거명 -- 트리거 조회 SELECT * FROM USER_TRIGGERS; "},{"id":104,"href":"/docs/ETC/04.-Docker-multi-arch/","title":"04. Docker (Multi Arch)","section":"ETC","content":" Multi-platform images # 도커 이미지는 여러 플랫폼(아키텍처)를 지원할 수 있다. 즉 하나의 단일 이미지는 여러 개의 아키텍처, OS 환경에서 동작할 수 있다.\n(멀티 아키텍처의 이미지는) 이미지가 실행될 때, 자동적으로 맞는 OS, 아키텍처를 선택하여 구동된다.\nDocker images can support multiple platforms, which means that a single image may contain variants for different architectures, and sometimes for different operating systems, such as Windows.\nWhen running an image with multi-platform support, docker automatically selects the image that matches your OS and architecture.\ndocker build # Docker 엔진은 client-server 아키텍처를 사용한다. (\u0026hellip;중략) 이 CLI는 도커 엔진에 build 를 실행하라고 요청한다.\nEngine uses a client-server architecture and is composed of multiple components and tools. The most common method of executing a build is by issuing a docker build command. The CLI sends the request to Docker Engine which, in turn, executes your build.\ndocker buildx # 새로운 명령어 docker buildx 는 docker 커맨드를 확장하는 플러그인(CLI)이다.\nThe new client Docker Buildx, is a CLI plugin that extends the docker command with the full support of the features provided by BuildKit builder toolkit.\ndocker buildx build는 docker build와 동일하게 사용할 수 있다. 기존의 build 기능에 추가적인 기능을 더 사용할 수 있다고 보면 된다. 이때 플랫폼(아키텍처)도 지정할 수 있다.\ndocker buildx build provides the same user experience as docker build with many new features like creating scoped builder instances, building against multiple nodes concurrently, outputs configuration, inline build caching, and specifying target platform. In addition, Buildx also supports new features that are not yet available for regular docker build like building manifest lists, distributed caching, and exporting build results to OCI image tarballs.\n상세한 내용은 아래를 참고하자.\nOverview of Docker Build Multi-platform images "},{"id":105,"href":"/docs/ETC/05.-FTP-active-vs-passive/","title":"05. FTP Active vs Passive","section":"ETC","content":" FTP active vs passive # FTP 는 2개의 포트를 사용한다.\nCommand 포트: 주로 21번 포트를 사용하며, 연결 시에 사용되는 포트 Data 포트: 주로 20번 포트를 사용하며, 데이터 전송 시에 사용되는 포트 Active 모드 # Client -\u0026gt; Server: 연결 시도 (21번 포트) Server -\u0026gt; Client: OK 응답 Server -\u0026gt; Client: Data 채널 연결 요청 \u0026lt;\u0026mdash; active Client -\u0026gt; Server: OK 응답 흔히, Client -\u0026gt; Server 로 연결을 시도하는 방식과 달리, Server -\u0026gt; Client 로 연결을 시도한다. (Active) (20번 포트에 대한 Server의 아웃바운드 규칙, Client의 인바운드 규칙의 설정이 필요하다.)\nPassive 모드 # Client -\u0026gt; Server: 연결 시도 (21번 포트) Server -\u0026gt; Client: OK 응답 Client -\u0026gt; Server: Data 채널 연결 요청 \u0026lt;\u0026mdash; passive Server -\u0026gt; Client: OK 응답 20번 포트를 사용하지 않고, 잘 알려진 포트(1024번) 이후의 임의의 포트를 사용한다. 이때, 데이터 채널 포트의 범위를 지정하지 않으면 모든 포트에 대해 허용해야 하는 문제가 있다. (임의로 설정되기 때문에)\n"},{"id":106,"href":"/docs/ETC/06.-Lettuce-ReadFrom/","title":"06. Lettuce ReadFrom","section":"ETC","content":" ReadFrom # Defines from which Redis nodes data is read.\nread 커맨드, write 커맨드 식별 방법 # io.lettuce.core.cluster.ReadOnlyCommands 클래스 참고\nredis 커맨드를 기준으로 식별한다.\nlua script # 스크립트는 eval, evalsha 커맨드로 실행 -\u0026gt; read 커맨드로 판단한다.\nREPLICA_PREFERRED vs MASTER_PREFERRED # master(write)커넥션, replica(reader)커넥션을 리스트에 저장한다. reader 커넥션을 가져올 때 1번의 리스트 중 0번째 인덱스에서 가져온다. 분류 컬렉션 내 커넥션 순서 REPLICA_PREFERRED 0번째 인덱스 : reader 1번째 인덱스 : writer MASTER_PREFERRED 0번째 인덱스 : writer 1번째 인덱스 : reader MASTER_PREFERRED\nREPLICA_PREFERRED\n"},{"id":107,"href":"/docs/ETC/07.-LocalDate-OpenJDK-Suggestion/","title":"07. LocalDate (OpenJDK Suggestion)","section":"ETC","content":" SUGGESTION # A DESCRIPTION OF THE PROBLEM : I think a lot of people write the following code to get tomorrow and yesterday.\nLocalDate tomorrow = LocalDate.now().plusDays(1); LocalDate yesterday = LocalDate.now().minusDays(1); I think supporting tomorrow() and yesterday() functions will make it more convenient, meaningful, and more readable.\nFor example we can get \u0026rsquo;tomorrow\u0026rsquo;, \u0026lsquo;yesterday\u0026rsquo; like following code.\nLocalDate tomorrow = LocalDate.tomorrow(); // or LocalDate.tomorrow(zone); or LocalDate.tomorrow(clock); LocalDate yesterday = LocalDate.yesterday(); // or LocalDate.yesterday(zone); or LocalDate.yesterday(clock); Please review about this report.\nDISCUSSION # This was not included in JSR-310 as it increases the potential for logical race conditions. Consider a method: boolean noTimeTravel() { return LocalDate.tomorrow.equals(LocalDate.today()); } This method can sometimes return true! The call to `tomorrow()` at 1ns before midnight will return tomorrows date (eg. 2022-06-02), but by the time `today()` is called it is now midnight and the date has changed thus `today()` returns 2022-06-02 as well. Since they are equal, true is returned. In cases like this, developers are supposed to call `now()` only once per method (ideally once per logical unit of behaviour, such as a web request). By having a single method on each class that queries \u0026#34;now\u0026#34;, it makes it easier to rationalise about the behaviour. Thus, this suggestion should be rejected. BUG DATABASE URL # JDK-8285775 : How about support LocalDate.tomorrow() and LocalDate.yesterday()\n"},{"id":108,"href":"/docs/ETC/08.-Locale-vs-TimeZone/","title":"08. Locale vs TimeZone","section":"ETC","content":" Locale TimeZone The place where something happens. The set of settings related to the language and region in which a computer program executes. Examples are language, paper format, currency and time formats, character encoding etc. 프로그램이 실행되는 언어(language), 지역(region)과 관련된 설정\n(예시) 언어, 통화, 시간 형식, 문자 인코딩 등 A vertical region of the globe that somewhat corresponds to longitude, that uses the same time. 출처 : https://wikidiff.com/timezone/locale\nLOCALE # 프로그램이 실행되는 언어(language), 지역(region)과 관련된 설정\n(예시) 언어, 통화, 시간 형식, 문자 인코딩 등\nFormat # 언어 지역 문자셋(인코딩) language_territory.codeset 예시 : ko_KR.UTF-8 TimeZone # 그리니치 천문대(본초 자오선, 경도 0도, 0시) 기준으로 지역에 따른 시간의 차이\n지구의 지역 사이에 생기는 낮과 밤의 차이를 인위적으로 조정하기 위해 고안된 시간의 구분선을 의미한다.\nFormat # Z 또는 +/- 기호 사용 UTC+0 시간대 (2022년 1월 1일 00시) 2022-01-01T00:00Z 20220101T0000Z UTC+9 시간대 (2022년 1월 1일 00시) 2022-01-01T00:00+09:00 2022-01-01T00:00+0900 + : 2022-01-01T0900+09:00 == 2022-01-01T0000Z - : 2022-01-01T0000-09:00 == 2022-01-01T0900Z\nISO8601 # 날짜, 시간 표기에 대한 국제 표준 규격\n나라마다 날짜, 시간 표기가 다른 문제를 해결하기 위한 공통 규격\nhttps://en.wikipedia.org/wiki/ISO_8601\nRFC3339 (Date and TIme on the Internet : Timestamps) # 인터넷 프로토콜 상에서 ISO8601의 프로파일(내용?)을 사용하여 날짜, 시간 형식을 정의한 문서\nISO8601 은 ISO에서 정한 공통 규격일 뿐, 인터넷과 아무 관계가 없다고 한다.\n개념적으로 거의 비슷해서, 혼용되어 사용되기도 한다고 한다.\nhttps://datatracker.ietf.org/doc/html/rfc3339\n참고 # https://velog.io/@kerri/TimeZone-Locale-DateFormat "},{"id":109,"href":"/docs/ETC/09.-MQTT/","title":"09. MQTT","section":"ETC","content":" MQTT (Message Queueing Telemetry Transport) # Telemetry : 원격 측정(법)\n다음과 같은 상황에서 사용될 수 있는 메시지 송/수신 프로토콜이다.\n(1) 작은 코드 공간에서 동작하기 위해서 (2) 제한된 네트워크 대역폭에서 동작하기 위해서 (ex: IoT) (3) 대규모 트래픽 전송을 위해서\nTCP/IP 위에서 동작하지만 굉장히 가볍고, 많은 통신 제약들을 해결해준다고 한다.\nMQTT 는 Bluetooth, Zigbee 처럼 별도의 모듈 / 별도의 대역폭을 갖는 통신 규약이 아닌, WiFi와 같은 인터넷을 통해 TCP/IP 기반의 메시지 송수신 프로토콜이다. (Message가) 가벼운 만큼, QoS(서비스 품질)에는 제약이 있다고 한다. IoT 환경에서 메인으로 사용되는 프로토콜이라고 한다. \u0026quot; 이러한 장점들 때문에 Facebook Messenger가 MQTT를 채택했고, 우아한형제들(배달의 민족 서비스 기업)에서도 중계 시스템 개선을 위해 MQTT를 도입하려 시도한 적이 있었다. (해당 이야기는 후술) \u0026quot; [통신 이론] MQTT, MQTT Protocol (MQTT 프로토콜) 이란? - 1 (이론편)\n구조 # Kafka 와 비슷하게, Pub/Sub (w. Broker) 구조인 것 같다.\npub --- broker(topic) --- sub MQTT vs Kafka # Kafka 의 경우,\n대용량의 데이터를 안전하게 disk에 저장하고, real-time or later 소비할 수 있도록 하는 것에 집중한다. 참고 : https://stackoverflow.com/a/37407079 Pub/Sub Messaging + Streaming Processing, Data Integration, \u0026hellip; MQTT : Pub/Sub (only) 기타 내용(차이점)은 여기 (Apach Kafka and MQTT : Overview)를 참고한다.\n참고 # [통신 이론] MQTT, MQTT Protocol (MQTT 프로토콜) 이란? - 1 (이론편) Apach Kafka and MQTT : Overview "},{"id":110,"href":"/docs/ETC/10.-non_blocking_vs_blocking/","title":"10. Non_blocking_vs_blocking","section":"ETC","content":" https://nodejs.org/ko/docs/guides/blocking-vs-non-blocking/\nhttps://velog.io/@codemcd/Sync-VS-Async-Blocking-VS-Non-Blocking-sak6d01fhx\nhttp://homoefficio.github.io/2017/02/19/Blocking-NonBlocking-Synchronous-Asynchronous/\n"},{"id":111,"href":"/docs/ETC/11.-OKR/","title":"11. OKR","section":"ETC","content":" \u0026quot; OKR이 간단해 보이지만 헷갈리는 이유는 \u0026lsquo;이니셔티브\u0026rsquo;를 구분하지 않기 떄문입니다. \u0026ldquo;\nObjectives (목표) # = 이루고자 하는 \u0026lsquo;목표(목적)\u0026rsquo;\n목표는 영감을 주어야하며, 회사의 우선순위에 부합해야 한다. 목표는 수치보다 정성적 문구로 표현하여 구성원의 동기를 부여한다. 책마다, 글마다 의견이 다른 것 같기도하다. (아래 예시처럼 책에서는 구체적인 수치를 제시한다.)\n예시 # O1. 온라인 판매의 매출 신기록을 세운다.\nO2. 하루 시청 시간을 10억 시간으로 늘린다. (2016년까지)\nO3. 2040년까지 전 세계 말라리아 퇴치한다.\nKey Results (핵심 결과) # = 목표를 이루기 위해 얻어야하는 \u0026lsquo;결과\u0026rsquo;\n목표(Objectives)가 구체적으로 어떤 것을 의미하는지 설명한다. 개인이 제어할 수 있는 행동이 아닌, 제어할 수 없는 결과를 측정 가능한 숫자로 표현한다. 책마다, 글마다 의견이 다른 것 같기도하다.\n예시 # O1. 온라인 판매의 매출 신기록을 세운다. KR. 1분기에 매출 1억원을 달성한다.\nO2. 하루 시청 시간을 10억 시간으로 늘린다. (2016년까지) KR1. 검색팀 + 주요 앱(XX% 증가), 거실 TV(+XX% 증가) KR2. 참여 및 게임 시청 시간 증가시킨다. (하루 X시간) KR3. 유튜브 VR 서비스를 실시하고, VR 목록을 X에서 Y로 확대한다.\nO3. 2040년까지 전 세계 말라리아 퇴치한다. KR1. 기본적인 접근 방식이 실질적인 효과가 있음을 전 세계에 입증한다. KR2. SERCAP와 같은 필수 방안을 확보함으로써 확장에 준비한다. KR3. 세계적인 흐름을 유지함으로써 박멸 캠페인에 기여한다.\nInitiatives (이니셔티브) # = 목표를 달성하기 위해 해야하는 핵심적인 일들\n이니셔티브는 목표를 달성하기 위해 해야하는 필수적인 행동이다. (다른 사람, 상황에 의존적이지 않고) 개인이 제어할 수 있어야한다. 진척도를 추적할 수 있는 프로젝트 단위가 적당하다. 예시 # O1 온라인 판매의 매출 신기록을 세운다. KR 1분기에 매출 1억원을 달성한다. INI 소규모 고객을 대상으로 ‘친구 추천’ 캠페인을 시작한다.\nO2 간단하면서도 강력한 웹 사이트를 만든다. KR 웹 사이트에 머무르는 평균 시간이 35% 증가한다. INI A/B 테스트를 통해 공통적인 문제를 찾는다.\n책을 읽고 위 내용을 다시 수정해보자.\n참고 # OKR과 Initiative(이니셔티브) 개념 및 간단 예시 "},{"id":112,"href":"/docs/ETC/12.-Pinpoint/","title":"12. Pinpoint","section":"ETC","content":" Pinpoint # 대규모 분산 시스템 추적 플랫폼, Pinpoint\n\u0026quot; 다양한 도구와 APM(application performance management)을 사용하고 있었으나 이것으로는 부족했다. 결국 시스템 복잡도가 높아지며 발생하는 문제를 해결하기 위해 n계층 아키텍처를 효과적으로 추적할 수 있는 새로운 플랫폼을 개발하기로 했다. \u0026ldquo;\n분산 시스템에서 (1)성능을 분석하고, (2)문제를 진단, 처리하는 플랫폼이다.\n다음과 같은 특징/기능이 있다.\n특징 / 기능 설명 분산 트랜잭션 추적 분산 애플리케이션에서 메시지를 추적할 수 있다. 애플리케이션 토폴로지 자동 발견 애플리케이션의 구성을 자동으로 파악할 수 있다. 확장성 대규모 서버군을 지원할 수 있다. 문제 발생 지점, 병목 구간 확인 코드 수준의 가시성을 제공해 문제 발생 지점과 병목 구간을 쉽게 발견할 수 있다. Bytecode instrumentation 기법 코드를 수정하지 않고 원하는 기능을 추가할 수 있다. Google Dapper 스타일의 분산 트랜잭션 추적 # Google Dapper 스타일의 추적 방식을 사용해, 분산된 요청을 트랜잭션으로 추적한다.\nGoogle Dapper 의 분산 트랜잭션 추적 방법 # Node 1 에서 Node 2로 메시지를 전송했을 때, Node 1 과 Node 2가 처리한 메시지의 관계를 찾아내는 것이다.\n이때, (관계를 찾아내기 위해)애플리케이션 레벨에서 메시지에 (식별을 위한)태그를 추가했다.\nPinpoint 는 이 추적 방식을 변형해 호출 추적에 사용한다. 태그 데이터는 Key의 집합으로 구성되며, 이 집합을 TraceId라고 정의한다.\nPinpoint의 자료 구조 # Pinpoint 의 핵심 자료구조는 Span, Trace, TraceId 로 이뤄져 있다.\n자료구조 설명 Span RPC 추적을 위한 기본 단위 RPC가 도착했을 때 처리한 작업을 나타내며 추적에 필요한 데이터가 들어가 있다. 코드 수준의 가시성을 확보하기 위해 Span의 자식으로 SpanEvent 라는 자료구조를 갖고 있다. Span은 TraceId를 갖고 있다. Trace Span의 집합 연관된 RPC의 집합으로 구성된다. Span의 집합은 TransactionId가 같다. Trace는 SpanId와 ParentSpanId를 통해 트리 구조로 정렬된다. TraceId TransactionId, SpanId, ParentId 로 이뤄진 키의 집합 TransactionId 는 메시지의 아이디, SpanId, ParentId 는 RPC의 부모 자식 관계를 나타낸다. 위 그림에서 TxId(TransactionId)는 3개의 RPC가 하나의 연관된 트랜잭션이라는 것을 표현한다. 하지만 TxId만으로는 각 RPC 간의 관계를 정렬할 수 없다. (즉 뭐가 먼저고, 뭐가 나중인지 알 수 없다.)\nRCP 간의 정렬을 위해 SpanId와 ParentSpanId가 사용된다.\nPinpoint 는 TxId를 통해 연관된 N개의 Span을 찾아낼 수 있다. SpanId, ParentSpanId로 N개의 Span을 트리로 정렬할 수 있다.\nSpanId, ParentSpanId 는 (1)64bit long 형 정수이다. (2)임의로 생성되는 값이라 충돌할 수 있지만 (64비트라)확률은 낮다. (3)키가 충돌했을 때, Google Dapper와 Pinpoint 는 충돌을 해결하지 않고 충돌 여부를 알려주는 방법을 사용한다.\nTransactionId는 AgentId, JVM 시작시간, SequenceNumber 로 구성된다.\nAgentId : JVM 실행 시 사용자가 임의로 정하는 ID, AgnetId는 Pinpoint가 설치되는 전체 서버군에서 중복되는 것이 없어야 한다. AgentId의 유일성을 보장하는 쉬운 방법은 호스트 이름($HOSTNAME)을 사용하는 것이다. 서버 안에 JVM을 여러 개 기동해야 한다면, 호스트 이름에 접미어(postfix)를 추가해 아이디 중복을 피할 수 있다.\nJVM 시작 시간 : 0부터 시작하는 SequenceNumber의 유일성을 보장하기 위해 JVM의 시작시간이 필요하다. 이 값은 사용자의 실수로 동일한 AgentId가 설정됐을 경우 ID의 충돌 확률을 줄이는 역할도 한다.\nSequenceNumber : Pinpoint Agent가 내부적으로 발급하는 ID, 0부터 순차적으로 증가하는 값이다. 개별 메시지마다 발급한다.\nGoogle Dapper나 Twitter의 분산 트랜잭션 추적 플랫폼인 Zipkin은 TraceId를 임의로 발급하고, 이 키가 충돌하는 것은 자연스러운 상황으로 판단한다. 그러나 Pinpoint 에서는 TransactionId의 충돌 확률을 낮추고 싶었기에 위와 같이 구성했다. 데이터의 양은 적지만 충돌 확률이 높은 방식과 데이터의 양은 많지만 충돌 확률이 낮은 방식 중에서 후자를 선택한 것이다.\n\u0026rdquo; Pinpoint보다 더 좋은 방식도 존재할 수 있다. TransactionId 구현 후보에는 중앙 키 서버에서 키를 발급하는 방식도 있었다. 이렇게 중앙 서버에서 키를 발급하면 성능 문제와 네트워크 오류 문제가 있을 수 있어 벌크 형태로 발급받는 것까지 고려했다. 나중에 이러한 방식으로 변경할 수도 있지만 현재는 단순한 방식을 채택했다. Pinpoint는 TransactionId를 충분히 변경할 수 있는 데이터로 판단하고 있다. \u0026ldquo;\nBytecode instrumentation # 위에서 언급한 \u0026lsquo;분산 트랜잭션 추적\u0026rsquo;을 구현하기 위해, 개발자가 직접 코드를 수정하는 방법이 있다. 개발자가 RPC 호출 시 태그 정보를 직접 추가하도록 개발하는 것이다.\n하지만 분산 트랜잭션 추적이 좋은 기능이라고 해도, 이를 위해 코드를 수정하는 것은 부담스러운 일이다.\nTwitter의 Zipkin은 수정된 라이브러리와 자체 컨테이너(Finagle)를 사용해 분산 트랜잭션 추적 기능을 제공한다. 하지만 필요하면 코드도 수정해야 한다.\nPinpoint는 코드를 수정하지 않고도 분산 트랜잭션 추적 기능을 제공하길 원했고 코드 수준의 가시성을 원했다. 이 문제를 해결하기 위해 bytecode instrumentation 기법을 도입했다. Pinpoint agent는 RPC 호출 코드를 가로채 태그 정보를 자동으로 처리한다.\nBytecode instrumentation의 단점 극복 # Bytecode instrumentation은 수동 방식(라이브러리), 자동 방식 중에서 자동 방식에 해당한다.\n방식 설명 장점 단점 수동 방식 Pinpoint가 API를 제공하고 개발자는 Pinpoint의 API를 사용해 (중요한 지점에 데이터를 추적할 수 있는)코드를 개발한다. - API가 단순하다. 이에 따라 버그 발생 가능성이 낮다. - 사용자가 코드를 수정해야 한다.\n- 추적 수준이 낮다. 자동 방식 Pinpoint가 라이브러리의 어떤 API를 가로챌지 결정해 코드를 개발한다. 이를 통해 개발자가 개입하지 않아도 자동으로 기능이 적용되게 한다. - 사용자가 코드를 수정하지 않아도 된다.\n- 바이트 코드의 정보가 많기 때문에 정밀한 데이터를 수집할 수 있다. - 추적할 라이브러리 코드를 순간적으로 파악해 추적 지점을 판단할 수 있는 수준 높은 개발자가 필요하다. - 난이도가 높은 개발 방법인 bytecode instrumentation을 사용하므로 버그 발생 가능성이 높다. 당장에는 수동 방식의 비용이 낮을 수 있지만, 많은 클라이언트가 사용한다고 가정하면 자동 방식의 비용이 더 낮다는 결론이다.\nBytecode instrumentation 숨은 가치 # Bytecode instrumentation는 위의 비용 측면 외에도 더 많은 가치를 제공한다.\n1. API를 노출하지 않는다.\nAPI를 노출해 제공하면, 이후 API를 쉽게 변경할 수 없다는 제약이 생긴다. (이 제약은 API 제공자에게는 스트레스이다.)\nBytecode instrumentation를 사용하면 API를 사용자에게 노출하지 않아도 되므로 API 의존성 문제를 해소할 수 있다.\n\u0026rdquo; 이를 반대로 생각하면, Pinpoint를 수정해 사용하려는 개발자의 입장에서는 내부 API 변경이 자주 발생할 것이라는 의미이기도 하다. \u0026ldquo;\n2. 손쉬운 적용과 해제\nBytecode instrumentation은 라이브러리의 프로파일링 코드나 Pinpoint 자체에 문제가 생겼을 때 애플리케이션에 영향을 준다는 단점이 있다. 하지만 코드를 변경할 필요가 없으므로 Pinpoint를 쉽게 적용하고 해제할 수 있다.\nJVM 구동 시 JVM 시작 스크립트에 다음과 같은 Pinpoint Agent 설정 3개를 추가하면 쉽게 Pinpoint를 적용할 수 있다.\n\u0026gt; javaagent:$AGENT_PATH/pinpoint-bootstrap-$VERSION.jar \u0026gt; Dpinpoint.agentId= \u0026gt; Dpinpoint.applicationName=\u0026lt;동일 서비스임을 나타내는 이름(AgentId의 집합)\u0026gt; Pinpoint 때문에 문제가 발생했다면 JVM 시작 스크립트에서 Pinpoint Agent 설정을 제거해 Pinpoint 적용을 해제하면 된다.\nBytecode instrumentation의 작동 방법 # Bytecode instrumentation 기술은 Java 바이트 코드를 다루므르 위험하고 생산성이 낮으며, 개발자가 실수하기 쉽다.\nPinpoint는 인터셉터로 추상화해 생산성과 접근성을 높였다.\nPinpoint는 클래스 로드 시점에 애플리케이션 코드를 가로채 성능 정보와 분산 트랜잭션 추적에 필요한 코드를 주입한다. 애플리케이션 코드에 직접 추적 코드가 주입되므로 성능이 좋다.\nPinpoint는 API 인터셉터 부분과 성능 데이터 기록 부분을 분리했다.\n추적 대상 메서드에 인터셉터를 주입해 앞 뒤로 before(), after() 메서드를 호출하게 하고 before(), after() 메서드에 성능 데이터를 기록하는 부분을 구현했다.\nPinpoint Agent는 bytecode instrumentation을 통해 필요한 메서드의 데이터만 기록하므로 생성되는 프로파일링 데이터의 크기가 작다. (\u0026mdash; ?)\n\u0026lsquo;Pinpoint Agent의 성능 최적화\u0026rsquo; 부분은 해당 포스트 글을 다시 읽어본다.\n키워드:\nThrift 가변 길이 인코딩을 통한 최적화된 데이터 기록 (⇿ 고정 길이 인코딩) 상수 테이블 사용 (반복되는 API 정보, SQL, 문자열을 상수로 치환하여 사용) 대량의 요청은 샘플링 처리 UDP 비동기 데이터 전송 참고:\nhttps://d2.naver.com/helloworld/1194202 https://github.com/pinpoint-apm/pinpoint "},{"id":113,"href":"/docs/ETC/13.-PR-%ED%9B%84%EA%B8%B0-Admin2-Free-Admin-Template/","title":"13. PR 후기 : Admin2 Free Admin Template","section":"ETC","content":" PR 을 날려보았다.\n"},{"id":114,"href":"/docs/ETC/14.-Trigger-vs-ApplicationBusiness-Logic/","title":"14. Trigger vs Application(Business) Logic","section":"ETC","content":" 트리거 vs Application Logic 비교해보기\n인터넷들의 글/댓글들을 읽어 종합해본 내용입니다.\nTrigger # 개발자 입장에서 유지보수가 어렵다.\n(반대로) 예전 글(2010년대 초반)을 보면 Trigger 가 유지보수가 더 쉽다는 의견/글들이 있는 것 같다.\n빌드/배포 시간에 제약이 없다.\nApplication -\u0026gt; DB call 횟수가 줄어든다.\n성능(처리율, 속도) 우수하다.\n(Application Logic 반대 의견) (한 액션 시 여러 개의 DB Table 에 삽입/수정 등이 이뤄질 때) Application Logic 으로 관리하면 Exception, Transaction 등을 신경써줘야 한다.\nApplication Logic # 개발자 입장에서 유지보수가 쉽다.\nTrigger 의 경우 위험이 크다.\n비즈니스 로직이 크다면 Application 이 더 나을 수 있다.\n꼭 필요한 경우에는 Trigger 에 로직이 들어가는 것은 찬성, 그러나 기본적인 로직들은 Application 단에서 이뤄지는 것이 맞다. (단순한 로직, Performance 의 비약적인 향상 등도 Trigger 찬성)\nH/W 사양 변경, 유지보수 등의 문제가 많이 있다.\n결론 # 여러 글을 읽어보니 개개인의 취향에 따라 의견이 다양한 것 같다. 나의 경우에는 아직은 트리거와 익숙하지 않아서 그런지 Application 단에서 로직을 작성하는 것이 관리, 유지보수 측면에서 더욱 용이하지 않을까라고 생각이 드는 것 같다. 조금 더 직접 경험해보고 비교해보면 더 잘 알 수 있을 것 같다.\n참고 # http://gurubee.net/article/68704 (2016년 글) "},{"id":115,"href":"/docs/ETC/15.-Useful-Tips-for-naming-variables/","title":"15. Useful Tips for Naming (Variables)","section":"ETC","content":" https://medium.com/better-programming/useful-tips-for-naming-your-variables-8139cc8d44b5\n"},{"id":116,"href":"/docs/ETC/16.-UTF/","title":"16. UTF","section":"ETC","content":"평면(Plain)\n0 ~ 2^16 범위를 표현하는 코드표(세트) 총 17개(0 ~ 16개)의 평면(plaon) 존재 BMP(Basic multilingual plane) : 0번째 평면(plain) 거의 대부분의 문자는 BMP 에 속함 다만 이모지와 같은 최근에 사용되기 시작한 문자들은 속하지 않음 UCS-2 (Universal Character Set) # BMP(기본 다국어 평면)만 인코딩 (고정 사이즈) 문자당 2byte 표현 \u0026lsquo;평면\u0026rsquo; 을 구분하는데 2byte가 사용되는데, UCS-2는 BMP 고정이기 때문에 평면 구분 byte가 없어도 됨 BMP 외의 문자는 표현할 수 없음 UTF-32 (Unicode Transformation Format) # (고정 사이즈) 4byte 인코딩 방식 : 평면 구분(2byte) + 문자(2byte) 모든 유니코드 문자 표현할 수 있음 (단점) 용량 차지 1byte로 표현할 수 있는 것도 4byte 고정 거의 사용되고 있지 않음 UTF-16 # 가변 사이즈(2byte, 4byte) 인코딩 2byte : BMP 4byte : BMP 외의 유니코드 문자 (UTF32 와 같은 형태가 아님에 주의!!) Surrogate(서러게이트)영역 문자를 구분하기 위해 (조금 복잡한?) 인코딩 규칙이 있음 Java 의 인코딩 방식 단점 : 아스키 코드(1byte) 호환되지 않음 \u0026quot; Surrogate pair는 UTF-16 인코딩을 위해서만 사용하도록 지정된 유니코드 영역으로, U+D800 ~ U+DBFF(high surrogates)와 U+DC00 ~ U+DFFF(low surrogates)가 존재합니다. BMP 영역을 벗어나는 문자(supplementary plane 영역)는 UTF-16에서 high surrogate와 low surrogate의 조합으로 표현됩니다. (두 surrogate가 짝이 맞지 않는다면 인코딩이 잘못된 것입니다.) \u0026quot;\nhttp://klutzy.github.io/blog/2014/06/20/unicode/\n\u0026quot; 그렇기 때문에 UTF-16의 앞의 6비트를 확인했을 때 110110이나 110111로 시작하지 않는다면 거기서부터 2바이트는 무조건 기본 다국어 평면 상에 있는 문자라고 확신할 수 있게 됩니다. 만약 반대로 110110으로 시작한다면 기본 다국어 평면 외의 문자라고 단언할 수 있게 됩니다. 위의 110110으로 시작하는 문자나, 110111로 시작하는 문자를 서러게이트(Surrogate) 영역 문자라고 합니다. \u0026quot;\nhttps://dingue.tistory.com/16\nBMP 는 2byte 로 표현되는데, BMP 가 아닌 것을 인지하기 위해 사용되는 부분인 것 같다. 때문에 BMP에서 사용되지 않는 영역(110110, 110111)이 사용되는 것으로 이해\nUTF-8 # 가변 사이즈(1byte ~ 4byte) 1byte : ASCII 2byte : 아랍, 히브리, 유럽계 문자 3byte : 1,2 byte 외의 BMP 문자 4byte : BMP 외 문자 (e.g. 한글) 인코딩 시 헤더값으로 붙는 것들이 있기 때문에 BMP 3byte 표현됨 아스키 코드 호환 OK 인코딩 시 아래와 같은 규칙을 가진다. Byte1 Byte2 Byte3 Byte4 0xxxxxxx - - - 110xxxxx 10xxxxxx - - 1110xxxx 10xxxxxx 10xxxxxx 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 기타 # 엔디안 방식에 따라, 문자가 다르게 표현될 수 있음 -\u0026gt; BOM(Byte Order Mark)를 파일 첫 부분에 명시(엔디안 방식 명시) 참고 # 아스키 코드, 유니코드 그리고 UTF-8, UTF-16 http://klutzy.github.io/blog/2014/06/20/unicode/ "},{"id":117,"href":"/docs/ETC/17.-UTF8-4byte-%EB%AC%B8%EC%9E%90-%EC%B2%B4%ED%81%AC%ED%95%98%EA%B8%B0/","title":"17. UTF8 4byte 문자 체크하기","section":"ETC","content":" [DB] Charset \u0026amp; Collation 글과 연관이 있습니다.\nMysql UTF8의 경우 3byte로 디자인되었다. 4byte 문자를 처리하기 위해서는 아래와 같은 방법이 있다.\nDB 스키마 변경 : charset/collation (e.g. utf8mb4) Application 처리 : (utf8)4byte 문자 확인 / 제거 등 이번 글에서는 2번의 방법을 살펴본다.\n(UTF8) 4byte 문자의 종류 # UTF8 4byte로 된 문자는 아래 링크에서 확인할 수 있다.\nhttps://design215.com/toolbox/utf8-4byte-characters.php\n이모지, musical symbols 등의 다양한 문자가 있다.\n(UTF8) 4byte 문자를 체크하는 방법 # 간단하게는, BMP 영역에 있는지를 체크하면 된다.\n아래 링크를 보면 utf8에서 4byte 문자의 코드범위를 확인할 수 있다.\nhttps://docs.oracle.com/cd/E24693_01/server.11203/e10729/appunicode.htm#CACHBDGH\n이것을 대략적으로 UTF8 인코딩 규칙과 비교해보면,\nByte1 Byte2 Byte3 Byte4 0xxxxxxx - - - 110xxxxx 10xxxxxx - - 1110xxxx 10xxxxxx 10xxxxxx 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 1 Byte : F0 = 11110000 ~ F4 = 11110100 2, 3, 4 Byte : 80 = 10000000 ~ BF = 10111111 또, 코드 범위를 정규표현식으로 표현해보면,\n\\xF0[\\x90-\\xBF][\\x80-\\xBF]{2} [\\xF1-\\xF3][\\x80-\\xBF]{3} \\xF4[\\x80-\\x8F][\\x80-\\xBF]{2} 참고 # JAVA(UTF16) 에서는 아래와 같이 체크할 수 있다.\nCharacter.isSurrogate(ch) // true : BMP 외, false : BMP public static boolean isSurrogate(char ch) { return ch \u0026gt;= MIN_SURROGATE \u0026amp;\u0026amp; ch \u0026lt; (MAX_SURROGATE + 1); } // MIN_SURROGATE = \u0026#39;\\uD800\u0026#39;; // MAX_SURROGATE = \u0026#39;\\uDFFF\u0026#39;; \u0026quot; Surrogate pair는 UTF-16 인코딩을 위해서만 사용하도록 지정된 유니코드 영역으로, U+D800 ~ U+DBFF(high surrogates)와 U+DC00 ~ U+DFFF(low surrogates)가 존재합니다. BMP 영역을 벗어나는 문자(supplementary plane 영역)는 UTF-16에서 high surrogate와 low surrogate의 조합으로 표현됩니다. (두 surrogate가 짝이 맞지 않는다면 인코딩이 잘못된 것입니다.) \u0026quot;\nhttp://klutzy.github.io/blog/2014/06/20/unicode/\n"},{"id":118,"href":"/docs/ETC/18.-WebSocket%EA%B3%BC-Socket.io/","title":"18. WebSocket과 Socket.io","section":"ETC","content":" WebSocket과 Socket.io 내용을 정리합니다.\n웹 소켓의 등장 배경 # 전형적인 브라우저 상의 동작 방식, 서비스 제공 방식은 (1) 클라이언트 요청 -\u0026gt; (2) 서버 응답 (Client-Server 구조) 의 방식에서 벗어나지 않았다.\n(시간이 지남에 따라, 더 나은 상호작용을 위해)Polling, Long Polling 등의 방법을 사용했지만 모두 클라이언트가 요청을 보내고 서버가 응답하는 \u0026lsquo;단방향 통신\u0026rsquo; 이다. (= 상호작용하는 서비스를 만들기 위해 복잡하고 어려운 코드를 구현해야 했다.)\n보다 쉽게 상호작용할 수 있는 서비스, 기능을 제공하기 위해 \u0026lsquo;양방향 통신\u0026rsquo; 이 필요했고, WebSocket이 등장했다.\n웹 소켓 프로토콜 # 표준 WebSocket API는 W3C에서 관장하고, 프로토콜은 IETF에서 관장한다.\n웹 소켓은 다른 HTTP 요청과 마찬가지로 80포트를 사용한다. Upgrade 헤더를 포함하여 웹 서버에 요청한다. (Upgrade: WebSocket) 클라이언트(브라우저), 웹 서버 모두 WebSocket 기능을 지원해야 한다. 아래와 같은 과정으로 WebSocket 핸드쉐이킹이 이뤄진다.\n(브라우저) \u0026ldquo;Upgrade: WebSocket\u0026rdquo; 헤더 + 랜덤 키를 서버에 보낸다. (서버) 이 키(랜덤 키)를 바탕으로 토큰을 생성한 후 브라우저에 보낸다. 핸드쉐이킹 후 Protocol Overhead 방식으로 웹 서버와 브라우저가 데이터를 주고 받는다.\n이러한 방식을 사용하기 때문에 방화벽이 있는 환경에서도 무리 없이 WebSocket을 사용할 수 있다고 한다.\nProtocol Overhead 방식 여러 TCP 커넥션을 생성하지 않고, 하나의 80 포트 TCP 커넥션을 이용한다. 별도 헤더 등으로 (논리적인 데이터 흐름 단위를 이용하여) 여러 개의 커넥션을 맺는 효과를 낸다. 웹 소켓 지원 브라우저 # https://caniuse.com/\nSocket.io # Socket.io는 JavaScript를 이용해서 브라우저 종류에 관계없이 실시간 웹을 구현할 수 있도록 한 기술이다.\nWebSocket, FlashSocket, Ajax Long Poliing, Ajax Multi part Streaming, IFrame, Json polling 등을 하나의 API로 추상화한 것이다. (\u0026lt;\u0026ndash; 이 문장을 보니 조금 이해가 되었다.)\n즉, 브라우저와 웹 서버의 종류와 버전을 파악하여 가장 적절한 기술을 선택하여 사용하는 방식이다. (예를 들어, 브라우저에서 FlashSocket을 사용할 수 있으면 사용하고, 사용할 수 없으면 Ajax Long Polling 을 사용)\nSocket.io는 표준 기술이 아니고 Node.js 모듈로서 오픈소스다.\n참고 : https://socket.io\n"},{"id":119,"href":"/docs/ETC/19.-%EB%AC%B4%EC%96%B4%EC%9D%98-%EB%B2%95%EC%B9%99/","title":"19. 무어의 법칙","section":"ETC","content":" 무어의 법칙을 상기한다.\n출처 : https://www.epnc.co.kr/news/articleView.html?idxno=200319\n무어의 법칙 : 2년 혹은 18개월 마다 반도체의 집적도는 2배가 된다. # 사실 \u0026lsquo;법칙\u0026rsquo;이라는 말이 조금 어색하다고 한다.\n반도체 업계에서 무어의 법칙은 경쟁에서 살아남기 위해 달성해야 하는 \u0026lsquo;규칙\u0026rsquo;으로 받아들였다고 한다.\n다만, 최근 들어(약 2016년 이후) 인텔은 무어의 법칙(규칙) 개발 방식을 폐기했다.\n2년 주기의 틱톡(TICK-TOCK) 개발 전략을 폐기하고, 3년 주기의 개발 사이클을 추진할 것이라고 발표했다고 한다.\n참고로, 무어는 인텔 공동 설립자이다.\n이유 : 기술의 한계 + 돈 # 업계에서 무어의 법칙이 더 이상 받아들여지지 않는 이유는 \u0026lsquo;기술의 한계\u0026rsquo;와 \u0026lsquo;돈\u0026rsquo;이다.\n작아질대로 작아진 반도체에 2년마다 거대한 돈(기술)을 투자해 무어의 법칙(규칙)을 달성하는 것은, 더 이상 큰 이익이 되지 않는 것이다.\n"},{"id":120,"href":"/docs/ETC/20.-%EC%82%AC%EB%82%B4%EC%97%90%EC%84%9C-%EC%82%AC%EC%84%A4-%EC%9D%B8%EC%A6%9D%EC%84%9C%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%98%EB%8A%94-%EC%9D%B4%EC%9C%A0/","title":"20. 사내에서 사설 인증서를 사용하는 이유","section":"ETC","content":" 개요 # (사내)로컬 환경에서 개발을 할 때, HTTP 통신과 관련된 부분에서 종종 \u0026lsquo;SSL 인증서가 유효하지 않다\u0026rsquo; 라는 오류가 발생하곤 한다.\n그때마다 1. HTTPS(443)통신을 HTTP(80)통신으로 수정한다거나 2. (HTTP API Library 에서 제공하는) Certification Verification 체크를 하지 않는다거나 3. 혹은 운이 좋게도 다른 분들이 먼저 설정해놓은 설정 값들이 있다면 그것들을 가져와 그대로 사용하곤 했다.\n이번에도 동일한 문제가 발생했는데, 이번에는 이 부분에 대해서 정확히 이해하고 싶었다.\n\u0026lsquo;여기\u0026rsquo;에서 관련된 내용이 너무나도 상세히 잘 설명되어 있다!\n사내 인증서는 왜 사용되어야할까? # 당연하게도 \u0026lsquo;보안\u0026rsquo; 의 목적으로 사용한다고 한다.\n우선 SSL을 사용하는 이유를 알아야 한다. SSL 을 사용함으로써 얻는 이점은\n데이터 통신 시 암호화가 적용되는 것 신뢰할 수 있는 사이트라고 보장할 수 있는 것 과 같은 이유가 있을텐데, 이것들을 사내에서 통신을 할 때에도 적용시키기 위한 것이다.\n즉,\n내부에서 통신을 할 때는 (사설 인증서를 통해)암호화가 적용된 상태로 통신을 하고\n외부로 데이터가 나가야 한다면, 이 암호화된 데이터를 복호화하여 내보내면 되는 것이다. 사내에서 사설 인증서를 사용하는 이유는 위와 같고, 개발 시에 어떻게 해결해야하는지에 대해서는 \u0026lsquo;여기\u0026rsquo; 글에서 조금 더 살펴볼 수 있다.\n"},{"id":121,"href":"/docs/ETC/21.-%EC%95%94%EB%8B%AC%EC%9D%98-%EB%B2%95%EC%B9%99/","title":"21. 암달의 법칙","section":"ETC","content":" 암달의 법칙을 상기한다.\n[출처]\nhttps://ko.wikipedia.org/wiki/%EC%95%94%EB%8B%AC%EC%9D%98_%EB%B2%95%EC%B9%99 https://namu.wiki/w/%EC%95%94%EB%8B%AC%EC%9D%98%20%EB%B2%95%EC%B9%99 암달의 법칙 : 컴퓨터 시스템의 일부를 개선했을 때 전체적으로 얼마만큼의 최대 성능 향상이 있었는지 계산하는 공식이다. # 전체 시스템 중 P%의 부분에서 S배의 성능 향상이 되었을 때, 전체 시스템의 성능 향상은 다음과 같다.\n1 ----------------- (1 - P) + (P / S) 개선에 의해 영향을 받는 실행 시간 개선 후 실행시간 = ---------------------------------- 성능 향상 비율 + 영향을 받지 않는 실행 시간 \u0026lsquo;병목 현상\u0026rsquo;을 설명하기 위한 공식으로도 사용될 수 있다. # (아래 예시 처럼)전체 40% 부분이 2배 향상되었을 때, 전체 성능은 1.25배 향상된다. 40% 부분이 2배가 아닌 무한배 향상되더라도 1.66 배 이상 향상될 수 없다.\n즉, 일부분이 무한히 향상된다고 해도 전체 성능은 x배 이상 향상될 수 없다. 쉬운 예시로, 일부분(CPU, 혹은 GPU, 혹은 일부 코드)만 성능 향상이 많이 되어도 한계가 있다. 즉, 전체 성능 개선을 위해서, 비중(P%)이 큰 작업부터 개선하면 좋다. 예시 # 예를 들어, 전체 시스템의 40%에 부분에 대해서 2배의 성능 개선이 있었다면 다음과 같이 계산할 수 있다.\n1 --------------------- = 1.25 (1 - 0.4) + (0.4 / 2) 병렬 컴퓨팅(Parallel) 관련 # 병렬 컴퓨팅(코어)의 수가 아무리 많아져도, 일부분(sequential 한 부분)에 의해 성능 향상에 한계가 있다.\n\u0026quot; 병렬 컴퓨팅에서 멀티 프로세서를 사용할 때 프로그램의 성능향상은 프로그램의 순차적인 부분에 의해 제한된다. 예를 들면, 프로그램의 95%가 병렬화 할 수 있다면 이론적인 최대 성능 향상은 아무리 많은 프로세서를 사용하더라도 최대 20배로 제한된다. \u0026ldquo;\n"},{"id":122,"href":"/docs/ETC/22.-%EC%95%95%EC%B6%95Compression/","title":"22. 압축(Compression)","section":"ETC","content":" 압축 (Compression) # HTTP 압축 (1) : 성능 향상을 위한 다른 접근 기법 글을 읽어보면, 왜 압축이 필요한지? 어떤 상황에서 적절한지? 등에 대해 이해할 수 있다.\n간단하게 요약하면,\n압축을 적용하는 것이 모든 상황에서 이점을 주지 않을 수 있다. (최근에는 옛날에 비해 네트워크 환경이 좋아지면서 압축의 중요성이 떨어질 수도 있으려나..? 싶다.) 다만, (성능 향상을 위해) 충분히 고려해볼만한 요소이다. HTTP 압축 (2) : HTTP 압축 작동 원리 글을 읽어보면, (서버-클라이언트 사이에서의) \u0026lsquo;압축\u0026rsquo;에 대한 협상 과정을 살펴볼 수 있다. 크게 어려운 부분은 없다.\nAccept-Encoding 헤더를 통해, 클라이언트(주로 디바이스, 브라우저일 것이다.)는 자기가 처리할 수 있는 압축 알고리즘을 서버에게 전달한다.\nContent-Encoding 헤더를 통해, 서버가 선택한 알고리즘을 확인할 수 있다.\nfiddler를 통해 직접 확인해볼 수 있다고 한다. (사용해보자.)\nRLE (Run Length Encoding) # 예전에 사용되었던 인코딩 방식이라고 한다.\n예전에 그래픽을 처리하기 위해 사용된 인코딩 방식이라고 한다. 이전 그래픽(이미지)의 경우에는 주변에 비슷한 색(값)들이 활발히 사용되었다. 연속된 동일 문자를 횟수로 축약하는 방식이다. (따라서, 연속되지 않은 글자가 많다면 효율이 떨어진다.)\nAAAAABBCCD 5A2B2C1D deflate # deflate : 압축 알고리즘 inflate : 압축 해제 알고리즘\n# deflate Raw Data ---\u0026gt; (LZ Encoder) ---\u0026gt; LLD ---\u0026gt; (Huffman Encoder) ---\u0026gt; Compressed Data # inflate Raw Data \u0026lt;--- (LZ Encoder) \u0026lt;--- LLD \u0026lt;--- (Huffman Encoder) \u0026lt;--- Compressed Data deflate(inflate) 는 \u0026lsquo;허프만 코딩\u0026rsquo; 과 \u0026lsquo;LZ 인코딩(LZ77, LZSS)\u0026rsquo; 알고리즘이 핵심인 압축 방식이라고 한다.\nLZ77으로 압축하면 LLD(literal, length, distance)가 나오고, 이것을 허프만 코딩으로 압축하는 것이다.\ngzip # br # Huffman Code # 심볼의 \u0026lsquo;빈도 수\u0026rsquo;와 관련된 인코딩 기법\n심볼이 나타나는 빈도(확률)에 따라, 사용하는 비트를 결정하고 압축한다. (= 엔트로피 부호화)\n예를 들어, AAAAABBCCD 문자가 있을 때 다음과 같이 심볼/확률을 표기할 수 있다.\n심볼 확률 A 0.5 (5/10) B 0.2 (2/10) C 0.2 (2/10) D 0.1 (1/10) 위 확률을 오름차순으로 정렬하고, 앞에서부터(낮은 확률부터)(확률 값을 합산해나가면서)트리를 생성해나간다.\n트리를 만든 후엔, 위에서부터 0, 1 비트를 주어 표현한다. 즉, 확률이 높은, 빈도수가 높은 심볼부터 작은 비트로 표현할 수 있게 된다.\n자세한 내용은 이후에 더 찾아보자.\nLZ77 # 심볼의 \u0026lsquo;반복\u0026rsquo;과 관련된 인코딩 기법\nLZ77 은 1977년에 만들어져 LZ77이라고 한다. (LZ1 으로 표현되기도 한다.)\n(반복되는)중복된 문자열을 제거한다. 슬라이딩 윈도우가 특징이다. 반복되는 문자열이 슬라이딩 윈도우보다 길 경우 압축할 수 없다. 다만, 일반적으로는 거의 다 압축된다고 한다. (즉, LZ77로도 거의 충분하다고 한다.) LLD(Literal, Length, Distance)\n단어 설명 Literal 일치하지 않는 첫 번째 글자 Length 일치하는 문자열의 길이 Distance View 에서부터의 거리 참고 # https://youtu.be/Yc_orrKXn1I https://www.siteground.com/blog/brotli-vs-gzip-compression/ "},{"id":123,"href":"/docs/ETC/23.-%EC%9C%A0%EB%8B%89%EC%8A%A4-%EC%8B%9C%EA%B0%84/","title":"23. 유닉스 시간","section":"ETC","content":" 철도 시간표가 유닉스 시간이 되기까지 글을 읽고 정리한 내용\nGMT # 19세기 초 지역마다 각자의 지방 평균시(Local Mean Time, LMT)를 사용했다.\n지방 평균시란,\n각자의 지역에서 태양이 최고 고도에 이르는 시각을 기준으로 삼는 시간 체계이다.\n지방 평균시의 경우, 지역에 따라 시간이 달라질 수 있다.\n(다양한 이유가 있겠지만, 글을 기반으로 하여) 철도 이슈로 인해 GMT 를 사용하자고 권고했다. (이렇게 GMT가 표준으로써 사용되기 사작한다.)\nGMT 는 그리니치 천문대에서 관측한 평균시다.\n본초 자오선은 그리니치를 지나는 자오선을 의미한다. 본초 자오선을 기준으로 15도마다 1시간 차이가 발생한다. 우리나라는 8시간 30분(GMT+08:30) 차이가 있다고 하는데, 127.5도 정도 차이가 발생하나보다. 자연스럽게 GMT는 세계시(Universal Time)의 기준이 되었다. 평균시라는 말을 쓰는 이유는, 태양시 기준으로 하루(오늘 태양 최고 고도 ~ 다음날 태양 최고 고도)가 정확하게 24시간이 걸리지 않기 때문이다. (지구 공전 등의 이유로)n 초 정도의 차이가 있다고 한다. 이러한 오차를 보정하기 위해 태양시의 평균을 낸 시간 쳬게를 평균시라고 한다.\n즉, 하루가 24시간이라는 말은 하루가 \u0026lsquo;평균적으로 24시간\u0026rsquo; 이라는 의미라고 한다.\n태양시(Solar Time)\n태양(태양의 고도)을 기준으로 측정하는 시간 체계\n태양시 -\u0026gt; 원자시 # 20세기 초에 지구의 자전 속도가 불규칙하다는 사실을 알게 된다. (= 1초의 기준이 불규칙하다는 것을 발견한다.)\n\u0026quot; 이전까지는 지구가 태양 주위를 한 바퀴 도는 시간인 31,556,992초를 기준으로 1 / 31556992를 1초의 정의로 사용했는데, 그 정의가 불규칙하다는 뜻이 된다. \u0026ldquo;\n20세기 중반에 \u0026lsquo;원자를 기준으로 하는 1초\u0026rsquo; 를 정의했다. 이를 원자시(Atomic Time)라고 한다. 원자시를 바탕으로 국제 원자시(International Atomic Time, TAI)표준을 정한다.\nUTC # 1초의 기준이 태양시가 아닌 원자시로 변경됨에 따라 세계시의 기준도 GMT -\u0026gt; 원자시를 기반으로 한 협정 세계시(UTC) 로 변경되었다.\nGMT vs UTC # GMT와 UTC는 소수점 단위 정도의 차이만 발생할 뿐만 아니라, UTC도 그리니치 자오선과 거의 차이가 없는 자오선을 본초 자오선으로 삼고 있기 때문에 거의 차이가 없다.\n때문에 일상에서는 UTC와 GMT를 혼용해서 사용한다.\n시간대 # 서울은 UTC+08:30(GMT+08:30) 시간대에 놓인다.\n하지만 각국의 시간대는 위 시간대를 그대로 따르지 않고 각자의 결정권에 따라 채택하여 사용한다.\n서울은 UTC+08:30 시간대에 있지만 UTC+9(= Korean Standard Time, KST)를 사용한다. 파리는 UTC+0이 시간대에 있지만 UTC+1(= 중앙 유럽 표준시, Central European Time, CET)를 사용한다. 서머 타임(Summer Time) 혹은 일광절약시간제(Daylight Saving Time, DST)를 사용하는 국가에서는 계절에 따라 다른 시간대를 사용한다.\n윤초 (Leap Second) # 태양시를 기준으로 하는 GMT와 원자시를 기준으로 하는 UTC 사이에는 오차가 발생함을 알게 됐다.\n국제지구자전좌표국(IERS)은 태양시와 원자시 사이의 오차가 0.9초를 넘으면 이를 보정하기 위해 UTC에 1초를 더하거나 빼주어 보정한다. 이를 \u0026lsquo;윤초\u0026rsquo; 라고 한다.\n\u0026ldquo;태양시를 중심으로 사용하던 과거에는 지구의 자전 속도에 따라 시간 체계가 통째로 영향을 받았지만, 이제는 자전 속도가 변한만큼 윤초를 이용해 시간을 보정할 수 있게 된 것이다.\u0026rdquo;\n윤초는 UTC 기준으로 6월 30일 23시 59분 59초 또는 12월 31일 23시 59분 59초에 적용한다. 1초 뒤를 0시 0분 0초가 아닌 23시 59분 60초로 표현하는 방식으로 적용한다. (IERS 는 통상 6개월 전에 윤초 적용을 예고한다.)\n운영체제 시간 # RTC # 컴퓨터는 RTC(Real Time Clock)라는 하드웨어 장치를 이용해 시간을 측정한다. (오늘날 시간 정보가 필요한 대부분의 전자기기에는 RTC가 들어있다.)\n\u0026ldquo;대부분의 RTC는 수정 발진기(Quartz oscillator)를 사용하는데, 석영 결정에 전압을 걸었을 때 32.768kHz 주파수로 진동하는 것을 1초의 기준으로 삼는 원리다. 전원이 분리되어 있어서 컴퓨터가 꺼져도 RTC는 꾸준히 시간을 측정할 수 있다.\u0026rdquo;\n유닉스 시간 # 운영체제 수준에서는 컴퓨터 시스템 전역에 설정된 시간을 **시스템 시간(System Time)**이라고 한다.\n유닉스 계열의 운영체제는 UTC 기준 1970년 1월 1일 0시 0분 0초로부터 몇 초가 지났는지를 기준으로 시스템 시간을 관리한다. 이를 유닉스 시간, POSIX 시간, 에포크 시간(Epoch Time)이라고 한다.\n에포크(Epoch)는 UTC 기준 1970년 1월 1일 자정을 일컫는다.\n왜 \u0026ldquo;1970년 1월 1일\u0026rdquo; 일까?\n이유는 대단하지 않다. 벨 연구소에서 유닉스 시스템을 개발한 데니스 리치가 당분간 오버플로우가 발생하지 않을마한 기원 날짜를 정했는데, 그게 1970년 1월 1일이었다고 한다.\n유닉스 시간은 일반적으로 초 또는 밀리초 단위의 **타임스탬프(Timestamp)**로 표현한다. 예를 들어, UTC 기준 2022년 1월 1일 0시 0분 0초의 타임스탬프는 1640995200 이다.\n이 타임스탬프(1640995200)는 시간대에 상관없이 **특정 순간(Instant)**을 표현하기 때문에 여러 시간에 대응될 수 있다.\n시간대 1640998800 UTC 2022년 1월 1일 1시 0분 0초 CET (UTC+1) 2022년 1월 1일 2시 0분 0초 KST (UTC+9) 2022년 1월 1일 10시 0분 0초 \u0026ldquo;날짜, 시간 데이터에 대한 표준 규격은 ISO 8601에서 정의하고 있으며, 인터넷 표준으로는 RFC 3339에서 ISO 8601을 기반으로 정의하고 있다.\u0026rdquo;\n\u0026ldquo;32비트 정수형을 사용하는 유닉스 시간은 2,147,483,647까지 밖에 표현할 수 없는데, 이로 인해 UTC 기준 2038년 1월 19일 3시 14분 7초를 지나면 오버플로우가 발생한다. 이를 2038년 문제(Year 2038 Problem, Y2K38)라고 한다. 64비트 시스템에서는 이미 유닉스 시간에 64비트 정수형을 사용하고 있지만, 구형 시스템은 조치가 필요하다.\u0026rdquo;\n\u0026ldquo;다행히 대부분 언어의 표준 라이브러리는 단조 시계(Monotonic clock)를 사용할 수 있는 API를 제공한다. 단조 시계는 현재 시각을 가리키는 것이 아니라, 일반적으로 운영체제 구동 이후 몇 초가 지났는지를 가리키기 때문에 시간이 역행하지 않음을 보장한다. 파이썬의 표준 라이브러리 모듈 time에는 monotonic 함수가 있다.\u0026rdquo;\n네트워크 타임 프로토콜(Network Time Protocol, NTP)을 이용해 원자 시계와 동기화된 서버로부터 시간을 가져와 동기화 하는 것도 가능하다. 여기에는 윤초도 적용될 것이며, 실제로 리눅스는 윤초를 처리하기 위해 NTP를 사용하고 있다.\nNTP는 네트워크 지연 시간에 굉장히 민감할 것이다. (이 부분이 참 신기하다.)\nNTP 시스템은 네트워크 지연을 최소화하기 위해 계층 구조를 이룬다. 0계층(Stratum 0)원자 시계와 직접 동기화되는 1계층 NTP 서버가 있고, 1계층과 동기화되는 2계층 NTP 서버가 있다. 한국에서는 한국표준과학연구원, 포항공과대학교 등에서 1계층 NTP 서버를 운영하고 있다.\n애플리케이션 시간 # 불특정 다수에게 서비스할 때는 클라이언트가 어떤 시간대를 사용하고 있을지 특정할 수 없다. 다양한 시간대와 시간 표현을 고려해야 한다. 사용자는 UTC+0 시간대를 사용할 수 있고, UTC+9 시간대를 사용할 수도 있다. (또 어떤 사용자는 DST가 적용된 시간대를 사용할 수도 있다.)\n이들 모두에게 효율적으로 서비스하기 위해, 서버 시간대는 보통 UTC+0으로 설정하면 좋을 것이다. (서버와 클라이언트 사이에 사용하는 API도 UTC+0 시간대를 전제로 하면 좋을 것이다.)\nAPI를 통해 서버와 클라이언트가 시간 데이터를 주고받을 때는 몇 가지 고려사항이 있다.\n연호를 사용하는 일본력은 어떻게 표현할 지 1970년 이전에 태어난 사람의 생일은 어떻게 표현할 지 \u0026hellip; 마이크로소프트 REST API 가이드라인은 ECMAScript 언어 명세에서 정의한 YYYY-MM-DDTHH:mm:ss.sssZ 포맷을 사용하는 DateLiteral 형식이나 시간의 종류(kind)나 값(value)을 함께 제공할 수 있는 StructuredDateLiteral 형식을 제시하고 있다.\n현대의 대부분의 프로그래밍 언어들은 효과적으로 시간을 다루기 위한 타입 시스템을 갖추고 있다.\nJava, Kotlin 의 경우 아래와 같은 클래스들이 제공된다.\n에포크 시간의 타임스탬프를 다루는 Instant 클래스 기간을 다루는 Duration 클래스 시간대 정보가 없는 LocalDateTime 클래스 시간대 정보를 지닌 ZonedDateTime 클래스 만약 시간대 정보가 없는 LocalDateTime 클래스를 Instant 객체로 변환하고 싶다면 시간대 정보가 필요하다.\nLocalDateTime.of(2022, 1, 1, 0, 0, 0).toInstant(ZoneOffset.of(\u0026#34;+0900\u0026#34;)) LocalDateTime을 사용한다면 항상 UTC+0 기준임을 전제하는 것이 혼란을 줄이는 데 도움이 된다.\n마찬가지로 LocalDateTime 시각을 특정 시간대의 시각으로 변환할 때, 취급할 시간대 정보를 명시해야 한다.\nfun LocalDateTime.toKST(zoneId: ZoneId = ZoneId.of(\u0026#34;UTC\u0026#34;)) = ZonedDateTime.of(this, zoneId) .withZoneSameInstant(ZoneId.of(\u0026#34;Asia/Seoul\u0026#34;)) .toLocalDateTime() \u0026ldquo;UTC 시각을 KST 시각으로 바꾸기 위해 plusHours(9)를 적용하는 것보다 훨씬 우아하다.\u0026rdquo;\n\u0026ldquo;한 국가의 표준시는 정치적, 사회적 이유로 언제든 변경될 수 있다. 한국은 1954년에 표준시를 GMT+9에서 GMT+08:30으로 변경했다가 1961년부터 다시 GMT+9(UTC+9)를 쓰고 있다. 2013년에는 표준시를 UTC+08:30으로 변경하는 표준시법 개정안이 발의되기도 했다. 또한 1948년부터 60년까지, 그리고 87년부터 88년까지 DST를 시행했다. 많은 시스템이 과거와 현재, 그리고 미래의 시간대 정보까지 정확하게 보장받기 위해 별도의 표준 데이터베이스인 TZDB(IANA Time Zone Database)를 참조한다. TZDB는 엔지니어, 역사학자 커뮤니티가 운영하고 있어 상당히 신뢰도가 높다.\u0026rdquo;\n"},{"id":124,"href":"/docs/ETC/24.-%EC%9D%B8%EC%BD%94%EB%94%A9-%EC%A0%95%EA%B7%9C%ED%99%94/","title":"24. 인코딩-정규화","section":"ETC","content":" 개요 # (최근에 회사 업무 중에) 고객이 업로드한 파일 이름의 자모음이 분할되어 저장되는 문제가 있었다. Mac 환경의 클라이언트가 해당 기능을 사용할 때 한글이 분할되는 현상이었다.\n예를 들어, 클라이언트에서 가나다라.jpg 라는 파일을 업로드하면 ㄱㅏㄴㅏㄷㅏㄹㅏ.jpg의 이름으로 저장이 되었다.\n관련된 내용을 찾아보니 인코딩, 정규화와 같은 키워드로 많은 내용이 있었다. 이것들을 읽고 내용을 정리해보고자 한다!\n문자코드표, 문자인코딩 # 컴퓨터는 데이터를 바이트(혹은 숫자) 단위로 처리한다. 그러므로 \u0026lsquo;문자/글자\u0026rsquo;를 나타내려면 바이트/숫자 \u0026lt;\u0026ndash;\u0026gt; 문자/글자를 매칭시켜줘야한다. 어떤 기준으로, 어떻게 매칭시켜야 할 지에 대해 규칙을 정해놓은 것들이 ASCII, Unicode, UTF-8, EUC-KR 등인 것이다.\n이런 것들을 통틀어 인코딩 규약 이라고 한다..?\n위키백과{:target=\u0026quot;_blank\u0026quot;}에서는 인코딩을 \u0026ldquo;정보의 형태나 형식을 변환하는 처리나 처리 방식\u0026rdquo; 라고 설명하고 있다.\n\u0026lsquo;문자 인코딩이란?\u0026rsquo; 여기의 글을 읽었는데 단번에 이해되었다. 블로그의 글을 조금 요약해보면, 다음과 같다.\n문자코드표 : 인코딩할 때 사용되는 매칭표(코드표). 대표적으로는 ASCII코드표, Unicode표가 있음. 모든 곳에서 동일하게 사용하기 위해 만든 것. 문자인코딩: 문자코드표를 어떤 방식으로 변환할지에 대한 방법, 동일한 문자코드표를 사용해도 변환(처리)하는 방식이 다를 수 있음. 이유는 \u0026lsquo;효율성\u0026rsquo;을 위해서. 대표적으로 UTF-8, UTF-16, EUC-KR 등의 인코딩 방식이 있음. 문자코드표 (문자코드) # ASCII(American Standard Code for Information Interchange, 정보 교환을 위한 미국 표준 코드)\n(풀네임을 읽어보면) American Standard Code, 즉 영어(알파벳 + 일부 문자)를 위해 사용되는 표준 코드(표)이다.\n7bits 표현 방식으로 알파벳, 숫자, 간단한 문장부호 등 128개의 글자를 나타낼 수 있다. (2^7 = 128) 알파벳(영어대소문자) 52개 + 숫자 10개 + 특수문자 33개 + 제어문자 33개로 총 128개이다. 이 중 printable 문자(출력 가능한 문자)는 알파벳, 숫자, 특수문자로 95개(32 ~ 126)이다. Non-printable 문자(출력 불가능한 문자)는 제어문자로 33개(0 ~ 31, 127)이다.\nUnicode\n영어(ASCII)를 포함하여 전세계의 언어, 다양한 문구/부호를 표현하기 위해 사용되는 코드표이다.\n다양한 방식으로 구현이 가능하다. 대표적인 방식으로 UTF-8, UTF-16의 방법이 있다. (유니코드를 실제 파일 등에 어떻게 기록할 것인지를 표준화한 것이다. 유니코드는 문자를 각 숫자에 대응시킨 코드표에 불과하고 이를 실제 비트로 어떻게 표현할지에 대한 방법은 다양한 것이다.)\n문자인코딩 # UTF-8 / UTF-16\nUTF-8 1~4 Bytes 를 사용한다. UTF-16 2~4 Bytes 를 사용한다. 이렇게 여러가지 방식이 존재하는 이유는 앞서 말했듯이, 효율성을 위함이다. 표현할 문자에 따라 1byte로 표현할 수도, 2~3byte로 표현할 수도 있다. 즉, 가변적인 것이다. 예들 들어, 서구권 언어(알파벳/ASCII 등)에서는 대부분의 문자를 1byte 만으로 표현할 수 있어서 UTF-8 을 사용하는 것이 효율적이지만, 아시아권의 문자(특히 한중일)를 나타낼 때는 UTF-16 을 사용할 때 더 효율적이다.\n* UTF-8의 경우 ASCII 코드표와도 호환이 되며, 최근에 가장 많이 사용되는 인코딩 방식이다.\nText : 가 Binary : 11101010 10110000 10000000 UTF-8: \\xEA\\xB0\\x80 (3byte) UTF-16 : \\uac00 (2byte) EUC-KR (Extended Unix Code - Korea)\n한글 지원을 위해 사용되는 인코딩 방식이다. 2bytes 형태의 완성형 코드표를 매칭시킨다.\nCP949 (Code Page 949)\n한글 지원을 위해 사용되는 인코딩 방식이다. EUC-KR (2bytes) 로 표현할 수 없는 문자를 표현하기 위해 MS사에서 개선/확장된 인코딩 방식이다. 따라서 EUC-KR 과 호환 가능하다. MS949라고 부르기도 한다고 한다.\n유니코드 정규화 ? # 아래 블로그들에 정말 쉽고, 상세히 정리되어 있다.\n[Unicode] Unicode란? (문자세트, 인코딩, 코드 포인트, 평면, 정규화) 유니코드 문자열을 정규화 해야하는 이유 다시 처음 문제였던 한글 자모음이 분리되는 문제로 돌아와서, 이 문제는 뭐일까 검색해보니 \u0026lsquo;유니코드 정규화\u0026rsquo; 라는 키워드에 대해 알 수 있었다.\n유니코드에서 \u0026lsquo;결합문자\u0026rsquo; 라는 개념이 있다. 예를 들어 \u0026lsquo;a\u0026rsquo;라는 문자와 \u0026rsquo;e\u0026rsquo;라는 문자를 결합해서 \u0026lsquo;ae\u0026rsquo;의 하나의 문자가 되는 것이 결합문자이다. 근데 이 결합문자를 만들 때에도 어떻게 만들지에 대한 방법/방식이 4개가 있다. 이 방식을 정규화(normalization)라고 한다. 인코딩 방식이 다르면 문자가 깨지는 것 처럼, 정규화 방식이 다르면 의도하지 않은 문자로 보이게 되는 것이다.\n정규화는 문자열을 분해/결합 + 정준/호환 의 방법이 조합되어 4가지 방법이 있다고 한다. (간단하게 말하면 어떻게 분해하고 어떻게 결합할 건지에 대한 방법인 것이다.)\n유니코드는 텍스트를 한 가지 규칙을 이용하여 정규화하여 저장하는 것을 권장한다고 한다.\n정규화 규칙에는 아래 4개의 방식이 존재한다.\nNFC: Normalization Form Canonical Composition : 모든 글자를 분해한 후에, (표준에 명시된 순서에 따라) 다시 합치는 방식이다. 다만, 옛 한글 자모의 결합은 결합하지 못한다. NFC는 많은 GNU/Linux 시스템, Windows에서 주로 사용한다. NFD: Normalization Form Canonical Decomposition : 모든 글자를 분해하여 저장한다. NFD는 macOS 시스템에서 주로 사용한다. NFKC: Normalization Form Compatibility Composition NFKD: Normalization Form Compatibility Decomposition NFKC와 NFKD는 한글자모/한글음절 영역 이외의 한글 유니코드 영역을 처리할 때 유용하게 사용할 수 있다고 한다.\n결론 # 결론적으로 Mac OS 와 Windows/Linux 환경에서 사용하는 정규화 방식이 다르기 때문에 한글 자모음이 분리되어 보여지는 현상이 나타난다.\nPHP 에서는 이 정규화 방식에 대해 처리할 수 있는 \u0026lsquo;Normalizer 클래스\u0026rsquo;를 제공한다.\n참고 # ASCII Wiki 한글과 유니코드 ASCII \u0026amp; Unicode (아스키코드와 유니코드) 문자열 인코딩 개념 정리(ASCII/ANSI/EUC-KR/CP949/UTF-8/UNICODE) UNICODE 특장점, 유니코드 변환 방식(UTF-8과 UTF-16 특장점, 비교, 표현방법) / 한글 유니코드 [Unicode] Unicode란? (문자세트, 인코딩, 코드 포인트, 평면, 정규화) 유니코드 문자열을 정규화 해야하는 이유 "},{"id":125,"href":"/docs/ETC/25.-%ED%8E%98%EC%9D%B4%EC%A7%80-%EB%A1%9C%EB%94%A9-%EC%86%8D%EB%8F%84-%EA%B0%9C%EC%84%A0/","title":"25. 페이지 로딩 속도 개선","section":"ETC","content":" 개요 # 고객이 메시지를 발송하면 그 기록을 관리툴에서 보여준다. 대략적으로 아래와 같이 생겼다.\n발송 결과 리스트페이지\n발송 결과 상세페이지\n문제 # 특정 고객이 \u0026lsquo;발송 결과 상세페이지\u0026rsquo;에 접근할 때 20~40초 가량의 로딩 시간이 걸린다는 문의가 접수되었다.\n급히 해당 부분에 대한 로직을 살펴보았는데 불필요한 for-loop, method 호출 등 많은 부분들에서 개선이 필요해보였다. 이 중 가장 효과적인 수정이 어떤 것일지 고민했다.\n우선 쿼리부터 확인했다. 쿼리는 인덱스 힌트를 통해 인덱스를 탈 수 있도록 되어 있었다. 처음에는 인덱스를 잘 타고 있으니 별 문제가 없겠거니 생각했는데, 실제로 쿼리를 자세히 살펴보니 그렇지 않았다.\n해당 쿼리는 2곳(이하 A, B)에서 호출되고 있었는데, A에서 호출될 때와 B에서 호출될 때의 select, where 절이 달랐다. 위에서 언급한 인덱스 힌트는 A에서 호출할 때에는 적절한 힌트가 되었지만, B에서 호출할 때에는 오히려 적절한 인덱스를 타지 않도록 하고 있었다.\n단순화하면 다음과 같다.\n-- A에서 호출할 때 (인덱스 힌트는 고정) select name from log use index(name_idx) where name = ? -- B에서 호출할 때 (인덱스 힌트는 고정) select name from log use index(name_idx) where id = ? 즉, 인덱싱 처리가 제대로 되고 있지 않았다.\n해결 # 결론적으로 인덱스 힌트를 수정하여 로딩 시간을 0.1 ~ 3초 정도로 줄일 수 있었다.\n-- A에서 호출할 때 select name from log use index(name_idx) where name = ? -- B에서 호출할 때 (* 실제로는 B에서 호출할 때에는 인덱스 힌트를 주지 않고, optimizer에 의해 선택될 수 있도록 했다.) select name from log use index(id_idx) where id = ? 아래는 인덱스 힌트 수정 전/후의 실행계획을 살펴본 내용이다.\n실제 실행계획 결과는 조금 다르다. 예시를 들기 위해 일부 내용을 수정했다.\n{ \u0026#34;id\u0026#34;: 1, \u0026#34;select_type\u0026#34;: \u0026#34;SIMPLE\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;r\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;ref\u0026#34;, ... \u0026#34;key\u0026#34;: \u0026#34;IDX_id\u0026#34;, ... \u0026#34;rows\u0026#34;: 880, \u0026#34;filtered\u0026#34;: 1.99, \u0026#34;Extra\u0026#34;: \u0026#34;Using index condition; Using where\u0026#34; } { \u0026#34;id\u0026#34;: 1, \u0026#34;select_type\u0026#34;: \u0026#34;SIMPLE\u0026#34;, \u0026#34;table\u0026#34;: \u0026#34;r\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;ref\u0026#34;, ... \u0026#34;key\u0026#34;: \u0026#34;IDX_name\u0026#34;, ... \u0026#34;rows\u0026#34;: 2730685, \u0026#34;filtered\u0026#34;: 0, \u0026#34;Extra\u0026#34;: \u0026#34;Using index condition; Using where;\u0026#34; } "},{"id":126,"href":"/docs/ETC/26.-%ED%95%98%EC%9D%B4%ED%8D%BC%EB%B0%94%EC%9D%B4%EC%A0%80/","title":"26. 하이퍼바이저","section":"ETC","content":" 개요 # 호스트 컴퓨터에서 다수의 운영 체제를 동시에 실행시키기 위한 기술(플랫폼) 단일 하드웨어에서 여러 개의, 다른 가상 머신을 실행시킬 수 있는 프로그램 게스트 운영 체제(Guest)에 가상 운영 플랫폼을 제공/관리하는 역할 예를 들어, 물리적인 리소스(CPU/Processor, RAM) 등을 분리/제공/관리 2가지의 종류 : Natvie/Bare-Metal , Hosted \u0026lsquo;VMM\u0026rsquo; 이라 불리우기도 한다. 가상화 머신 모니터(Virtual Machine Monitor) 가상화 머신 매니저(Virtual Machine Manager) 하이퍼바이저 유형 1 : Natvie / Bare-Metal # 하드웨어에 직접 설치되는 구조 호스트 OS 없음 즉, 하이퍼바이저가 호스트 OS 에 종속되지 않음 VM에 설치된 게스트 OS 들은 하드웨어 바로 위에서 구동 유형 2(Type2)보다는 성능 향상 다만, 유형 2(Type2) 보다는 설치, 구성 불편 (하드웨어 드라이버 세팅\u0026hellip;? 같은 것들이 필요하다고 한다.) Xen, Oracle VM Server for ~~~, Microsoft Hyper-V 등 가상화 방식 설명 전가상화 하드웨어 전체를 가상화하는 방식\n- Guest OS 는 자신이 가상화 위에 동작하고 있다는 것을 인식할 수 없음\n- Guest OS 는 하드웨어 물리자원에 직접 접근할 수 없음\n- 각각 다른 Guest OS 들의 명령어 방식을 하드웨어가 이해할 수 있도록 하이퍼바이저가 번역/전달\n- (하이퍼바이저가)하드웨어 리소스(명령의 결과)를 Guest OS 에게 제공 반가상화 - Guest OS 는 자신이 가상화 위에 동작하고 있다는 것을 인식할 수 있음\n- Guest OS 는 하드웨어 물리자원에 직접 접근할 수 있음\n- 각각 다른 Guest OS 들의 명령어 방식을 하드웨어가 이해할 수 있도록 가상머신이(직접) 번역/전달 (하이퍼바이저 X)\n- (하이퍼바이저가)하드웨어 리소스(명령의 결과)를 Guest OS 에게 제공 |---- Guest OS | HardWare --- Hypervisor ---|---- Guest OS | |---- Guest OS 하이퍼바이저 유형 2 : Hosted(호스트형 가상화) # 내가 사용해왔던 VirtualBox 등을 사용한 것이라고 이해한다.\n호스트 OS 위에서 하이퍼바이저 실행 즉, 호스트 OS 가 존재 호스트 OS 문제 =\u0026gt; 전체 Guest OS 에 영향을 끼친다. 호스트 OS 입장에서는 일반적인 프로그램을 실행하는 것과 같다. 유형 1(Type1)보다는 설치, 구성 편리 다만, 유형 1(Type1) 보다는 성능 낮음 VMware Workstation, VirtualBox 등 |---- Guest OS | HardWare --- Host OS --- Hypervisor ---|---- Guest OS | |---- Guest OS (Type1) 전가상화 방식의 전제하에 아래 내용도 참고합니다. # 여러 개의, 다른 OS를 운영하기 위해서 각각의 (Guest)OS마다 \u0026lsquo;커널\u0026rsquo;이 존재한다.\n커널은 리소스 관리, 명령어 해석 등의 역할을 수행한다.\n다만, OS 마다 리소스를 관리하는, 명령어를 해석하는 방법이 다르다.\n1. 이들을 하이퍼바이저가 통일된, 하나의 명령어로 관리해주는 것이라고 한다.\n2. 또, 각각의 OS에게 리소스를 나누어주며 관리해주는 역할도 한다고 한다.\n이렇듯 가상화를 구현하기 위해 기초가 되는 기술이 \u0026lsquo;하이퍼바이저\u0026rsquo;이다.\n참고 # https://pearlluck.tistory.com/121 https://dora-guide.com/하이퍼바이저/ "},{"id":127,"href":"/docs/ETC/27.-netty-resolver-dns-native-macos/","title":"27. Netty-Resolver-Dns-Native-Macos","section":"ETC","content":" 로컬 환경 : m1 arm64\nCaused by: java.io.FileNotFoundException: META-INF/native/libnetty_resolver_dns_native_macos_aarch_64.jnilib # Spring Cloud Gateway + Mock API 구성 후 간단한 테스트 시 다음과 같은 오류가 발생한다.\njava.lang.reflect.InvocationTargetException: null at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:na] at java.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62) ~[na:na] ... at io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74) ~[netty-common-4.1.78.Final.jar:4.1.78.Final] at io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30) ~[netty-common-4.1.78.Final.jar:4.1.78.Final] at java.base/java.lang.Thread.run(Thread.java:829) ~[na:na] Caused by: java.lang.UnsatisfiedLinkError: failed to load the required native library at io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider.ensureAvailability(MacOSDnsServerAddressStreamProvider.java:110) ~[netty-resolver-dns-classes-macos-4.1.78.Final.jar:4.1.78.Final] at io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider.\u0026lt;init\u0026gt;(MacOSDnsServerAddressStreamProvider.java:120) ~[netty-resolver-dns-classes-macos-4.1.78.Final.jar:4.1.78.Final] ... 125 common frames omitted Caused by: java.lang.UnsatisfiedLinkError: could not load a native library: netty_resolver_dns_native_macos_aarch_64 at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:239) ~[netty-common-4.1.78.Final.jar:4.1.78.Final] at io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider.loadNativeLibrary(MacOSDnsServerAddressStreamProvider.java:92) ~[netty-resolver-dns-classes-macos-4.1.78.Final.jar:4.1.78.Final] at io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider.\u0026lt;clinit\u0026gt;(MacOSDnsServerAddressStreamProvider.java:77) ~[netty-resolver-dns-classes-macos-4.1.78.Final.jar:4.1.78.Final] at java.base/java.lang.Class.forName0(Native Method) ~[na:na] at java.base/java.lang.Class.forName(Class.java:398) ~[na:na] at io.netty.resolver.dns.DnsServerAddressStreamProviders$1.run(DnsServerAddressStreamProviders.java:50) ~[netty-resolver-dns-4.1.78.Final.jar:4.1.78.Final] at java.base/java.security.AccessController.doPrivileged(Native Method) ~[na:na] at io.netty.resolver.dns.DnsServerAddressStreamProviders.\u0026lt;clinit\u0026gt;(DnsServerAddressStreamProviders.java:46) ~[netty-resolver-dns-4.1.78.Final.jar:4.1.78.Final] ... 120 common frames omitted Suppressed: java.lang.UnsatisfiedLinkError: could not load a native library: netty_resolver_dns_native_macos at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:239) ~[netty-common-4.1.78.Final.jar:4.1.78.Final] at io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider.loadNativeLibrary(MacOSDnsServerAddressStreamProvider.java:95) ~[netty-resolver-dns-classes-macos-4.1.78.Final.jar:4.1.78.Final] ... 126 common frames omitted Caused by: java.io.FileNotFoundException: META-INF/native/libnetty_resolver_dns_native_macos.jnilib at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:181) ... 127 common frames omitted Suppressed: java.lang.UnsatisfiedLinkError: no netty_resolver_dns_native_macos in java.library.path: [/Users/leehyunjae/Library/Java/Extensions, /Library/Java/Extensions, /Network/Library/Java/Extensions, /System/Library/Java/Extensions, /usr/lib/java, .] at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2673) at java.base/java.lang.Runtime.loadLibrary0(Runtime.java:830) at java.base/java.lang.System.loadLibrary(System.java:1873) at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38) at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:391) at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:161) ... 127 common frames omitted Suppressed: java.lang.UnsatisfiedLinkError: no netty_resolver_dns_native_macos in java.library.path: [/Users/leehyunjae/Library/Java/Extensions, /Library/Java/Extensions, /Network/Library/Java/Extensions, /System/Library/Java/Extensions, /usr/lib/java, .] at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2673) at java.base/java.lang.Runtime.loadLibrary0(Runtime.java:830) at java.base/java.lang.System.loadLibrary(System.java:1873) at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:425) at java.base/java.security.AccessController.doPrivileged(Native Method) at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:417) at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:383) ... 128 common frames omitted Caused by: java.io.FileNotFoundException: META-INF/native/libnetty_resolver_dns_native_macos_aarch_64.jnilib at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:181) ~[netty-common-4.1.78.Final.jar:4.1.78.Final] ... 127 common frames omitted Suppressed: java.lang.UnsatisfiedLinkError: no netty_resolver_dns_native_macos_aarch_64 in java.library.path: [/Users/leehyunjae/Library/Java/Extensions, /Library/Java/Extensions, /Network/Library/Java/Extensions, /System/Library/Java/Extensions, /usr/lib/java, .] at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2673) ~[na:na] at java.base/java.lang.Runtime.loadLibrary0(Runtime.java:830) ~[na:na] at java.base/java.lang.System.loadLibrary(System.java:1873) ~[na:na] at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38) ~[netty-common-4.1.78.Final.jar:4.1.78.Final] at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:391) ~[netty-common-4.1.78.Final.jar:4.1.78.Final] at io.netty.util.internal.NativeLibraryLoader.load(NativeLibraryLoader.java:161) ~[netty-common-4.1.78.Final.jar:4.1.78.Final] ... 127 common frames omitted Suppressed: java.lang.UnsatisfiedLinkError: no netty_resolver_dns_native_macos_aarch_64 in java.library.path: [/Users/leehyunjae/Library/Java/Extensions, /Library/Java/Extensions, /Network/Library/Java/Extensions, /System/Library/Java/Extensions, /usr/lib/java, .] at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2673) at java.base/java.lang.Runtime.loadLibrary0(Runtime.java:830) at java.base/java.lang.System.loadLibrary(System.java:1873) at io.netty.util.internal.NativeLibraryUtil.loadLibrary(NativeLibraryUtil.java:38) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at io.netty.util.internal.NativeLibraryLoader$1.run(NativeLibraryLoader.java:425) at java.base/java.security.AccessController.doPrivileged(Native Method) at io.netty.util.internal.NativeLibraryLoader.loadLibraryByHelper(NativeLibraryLoader.java:417) at io.netty.util.internal.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:383) ... 128 common frames omitted 참고 : https://github.com/netty/netty/issues/11020\nlibnetty_resolver_dns_native_macos_aarch_64.jnilib 파일이 없다고 하니 추가해주면 될 것 같다.\nlibnetty_resolver_dns_native_macos_aarch_64 의존성 추가 # implementation(\u0026#34;io.netty:netty-resolver-dns-native-macos:4.1.79.Final:osx-aarch_64\u0026#34;) 의존성 추가 전\n의존성 추가 후\n참고 # https://github.com/netty/netty/blob/4.1/resolver-dns-native-macos/pom.xml https://github.com/netty/netty/blob/4ebc4ee66f9202c5b49e4f403cc19a719444d0d9/resolver-dns-native-macos/pom.xml#L217 기본적으로 arm64 아키텍처의 경우, 다음과 같이 oxs-aarch_64 의존성이 추가되게끔 설정되어 있다.\n... if (!\u0026#34;$nettyVersion\u0026#34;.endsWithAny(\u0026#34;SNAPSHOT\u0026#34;)) { if (osdetector.classifier == \u0026#34;osx-x86_64\u0026#34; || osdetector.classifier == \u0026#34;osx-aarch_64\u0026#34;) { api \u0026#34;io.netty:netty-resolver-dns-native-macos:$nettyVersion$os_suffix\u0026#34; } else { api \u0026#34;io.netty:netty-resolver-dns-native-macos:$nettyVersion:osx-x86_64\u0026#34; } } else { // MacOS binaries are not available for Netty SNAPSHOT version api \u0026#34;io.netty:netty-resolver-dns-native-macos:$nettyVersion\u0026#34; } ... 참고 : https://github.com/reactor/reactor-netty/blob/4251a324a967ffdc6a3ceee4830814662b114060/reactor-netty-http/build.gradle#L67\nos_suffix 는 다음 코드에서 설정된다.\n... os_suffix = \u0026#34;\u0026#34; if (osdetector.classifier in [\u0026#34;linux-x86_64\u0026#34;] || [\u0026#34;osx-x86_64\u0026#34;] || [\u0026#34;osx-aarch_64\u0026#34;] || [\u0026#34;windows-x86_64\u0026#34;]) { os_suffix = \u0026#34;:\u0026#34; + osdetector.classifier } ... osdetector\nosdetector.classifier 를 확인하면, osx-x86_64 값이 나온다. = 즉, 아키텍처 디텍딩에서 오류\n참고 : https://github.com/google/osdetector-gradle-plugin\nkr.motd.maven:os-maven-plugin:1.7.0\nosdetector(google) -\u0026gt; os-maven-plugin (trustin) 참고 : https://github.com/trustin/os-maven-plugin\n... protected void detect(Properties props, List\u0026lt;String\u0026gt; classifierWithLikes) { log(\u0026#34;------------------------------------------------------------------------\u0026#34;); log(\u0026#34;Detecting the operating system and CPU architecture\u0026#34;); log(\u0026#34;------------------------------------------------------------------------\u0026#34;); final String osName = systemPropertyOperationProvider.getSystemProperty(\u0026#34;os.name\u0026#34;); final String osArch = systemPropertyOperationProvider.getSystemProperty(\u0026#34;os.arch\u0026#34;); final String osVersion = systemPropertyOperationProvider.getSystemProperty(\u0026#34;os.version\u0026#34;); ... } ... 참고 : https://github.com/trustin/os-maven-plugin/blob/6bd9cfa16757ac8b81ab1a7f380b0aabc0295c97/src/main/java/kr/motd/maven/os/Detector.java#L72\nprivate final class ConfigurationTimeSafeSystemPropertyOperations implements SystemPropertyOperationProvider { @Override public String getSystemProperty(String name) { return getProviderFactory().systemProperty(name).forUseAtConfigurationTime().getOrNull(); // getProviderFactory() : org.gradle.api.internal.provider.DefaultProviderFactory_Decorated@a046f6c // getProviderFactory().systemProperty(name) : Provider\u0026lt;String\u0026gt; (DefaultValueSourceProviderFactory.NonConfigurationTimeProvider) } ... // DefaultValueSourceProviderFactory.class public Provider\u0026lt;T\u0026gt; forUseAtConfigurationTime() { return new ConfigurationTimeProvider(this.value); } // AbstractMinimalProvider.class public T getOrNull() { return this.calculateOwnValue(ValueConsumer.IgnoreUnsafeRead).orNull(); } // DefaultValueSourceProviderFactory.class protected ValueSupplier.Value\u0026lt;? extends T\u0026gt; calculateOwnValue(ValueSupplier.ValueConsumer consumer) { this.vetoAtConfigurationTime(); return Value.ofNullable(this.value.obtain().get()); } public Try\u0026lt;T\u0026gt; obtain() { if (this.obtainValueForThe1stTime()) { DefaultValueSourceProviderFactory.this.valueObtained(this.obtainedValue()); } return this.value; } 위 코드 진입 시 this.value(org.gradle.internal.Try) 설정된다.\nDefaultProviderFactory\n... public Provider\u0026lt;String\u0026gt; systemProperty(Provider\u0026lt;String\u0026gt; propertyName) { return this.of(SystemPropertyValueSource.class, (spec) -\u0026gt; { ((AbstractPropertyValueSource.Parameters)spec.getParameters()).getPropertyName().set(propertyName); }); } DefaultValueSourceProviderFactory\npublic abstract static class ValueSourceProvider\u0026lt;T, P extends ValueSourceParameters\u0026gt; extends AbstractMinimalProvider\u0026lt;T\u0026gt; { protected final LazilyObtainedValue\u0026lt;T, P\u0026gt; value; public ValueSourceProvider(LazilyObtainedValue\u0026lt;T, P\u0026gt; value) { this.value = value; // } ... public ValueSupplier.ExecutionTimeValue\u0026lt;T\u0026gt; calculateExecutionTimeValue() { return this.value.hasBeenObtained() ? ExecutionTimeValue.ofNullable(this.value.obtain().get()) : ExecutionTimeValue.changingValue(this); } protected ValueSupplier.Value\u0026lt;? extends T\u0026gt; calculateOwnValue(ValueSupplier.ValueConsumer consumer) { this.vetoAtConfigurationTime(); return Value.ofNullable(this.value.obtain().get()); } protected abstract void vetoAtConfigurationTime(); } org.gradle.api.provider org.gradle.api.internal.provider\norg.gradle.api.internal.provider.sources.SystemPropertyValueSource\n"},{"id":128,"href":"/docs/ETC/28.-serverless-framework/","title":"28. Serverless Framework","section":"ETC","content":"serverless frameowkr 의 전반적인 컨셉과 내용은 Serverless Framework Concepts 문서를 참고한다.\n작성 방법에 대한 예시는 Usage 문서 하위 내용을 참고하면 좋다. (+ Serverless.yml Reference)\n"},{"id":129,"href":"/docs/ETC/29.-terraform/","title":"29. Terraform","section":"ETC","content":" Terraform # Infrastructure as Code ( = Infrastructure 관리 도구 )\ntfenv # 테라폼 버전 매니저\nnvm 같은 버전 매니저\n기본 개념 # 프로비저닝\n프로세스, 서비스를 실행하기 위한 준비 단계\n네트워크, 컴퓨팅 자원 준비 작업 (준비된 컴퓨팅 자원에) 사이트 패키지, 애플리케이션 의존성 준비 작업 명확한 경계는 불분명하지만 테라폼은 주로 전자(네트워크, 컴퓨팅 자원 준비)를 주로 다룬다.\n프로바이더\n테라폼 ⇿ 외부 서비스(프로바이더) 연결해주는 모듈\n예를 들어, 테라폼으로 AWS 컴퓨팅 자원을 생성한다면 \u0026lsquo;aws 프로바이더\u0026rsquo; 프로바이더 종류 분류 AWS 클라우드 서비스 GCP 클라우드 서비스 Azure 클라우드 서비스 Github 특정 기능을 제공하는 서비스 Datadog 특정 기능을 제공하는 서비스 DNSimple 특정 기능을 제공하는 서비스 MySQL 로컬 서비스 RabbitMQ 로컬 서비스 Docker 로컬 서비스 \u0026hellip; \u0026hellip; 리소스(자원)\n프로바이더가 제공해주는 조작 가능한 대상의 최소 단위\nAWS 프로바이더는 aws_instance 리소스 타입을 제공 → EC2 가상 머신 리소스를 선언/조작 가능 EC2 인스턴스, 시큐리티 그룹, 키 페어 등 HCL\n테라폼에서 사용하는 설정 언어\n모든 설정, 리소스 선언은 HCL 을 사용 HCL 파일 확장자 : .tf 계획(Plan)\n테라폼 프로젝트 디렉토리 아래의 모든 .tf 파일 내용에 대한 작업 계획 확인 (+ 실제로 적용 가능한지 확인)\n명령어 : terraform plan 어떤 리소스가 생성, 수정, 삭제될 지에 대한 계획 확인 적용(Apply)\n테라폼 프로젝트 디렉토리 아래의 모든 .tf 파일 내용 적용\n명령어 : terraform apply 리소스 생성, 수정, 삭제 작업 적용 단계 요약 # 1. .tf 파일 작성 (with HCL) : 리소스 선언 2. plan : 리소스 계획 확인 (terraform plan) 3. apply : 리소스 적용 (terraform apply) + destory : 리소스 제거\n이후에는 테라폼(Terraform) 기초 튜토리얼 : AWS 프로바이더 정의 페이지의 실습 부분에서 상세히 확인할 수 있다.\n참고 # 테라폼(Terraform) 기초 튜토리얼 좌충우돌 Terraform 입문기 "},{"id":130,"href":"/docs/ETC/30.-Prometheus-PromQL/","title":"30. Prometheus PromQL","section":"ETC","content":"프로메테우스는 실시간으로 시계열 데이터를 선택해 집계할 수 있는 PromQL(함수형 쿼리 언어)를 제공한다.\nType (Expression Language Data Types) # 프로메테우스의 표현식 언어에서, 표현식 또는 하위 표현식은 다음 타입 중 하나로 평가될 수 있다.\nInstant vector : 같은 타임스탬프 상에 있는 시계열 셋으로, 각 시계열마다 단일 샘플을 가지고 있다. Range vector : 특정 시간 범위에 있는 시계열 셋으로, 각 시계열마다 시간에 따른 데이터 포인트들을 가지고 있다. Scalar : 간단한 부동 소수점 숫자 String : (현재 사용 X) 간단한 문자열 값 표현식을 사용하는 방식(e.g., 그래프 표현, 데이터 출력 등)에 따라 정의할 수 있는 타입은 제한돼있다.\nInstant Vector Selectors # Instant Vector (셀렉터)를 사용하면 지정한 타임스탬프(instant)에서 시계열 셋을 선택해, 각 시계열마다 단일 샘플 값을 가져올 수 있다.\n가장 간단하게는 메트릭 이름만 지정할 수 있다. 메트릭명을 가진 모든 시계열 요소들을 갖고 있는 instant 벡터가 생성된다.\n예시 - http_requests_total\nhttp_requests_total{job=\u0026#34;~~~\u0026#34;,group=\u0026#34;~~~\u0026#34;} http_requests_total 시계열 중에서 job, group에 매칭되는 모든 시계열을 가져온다.\nRange Vector Selectors # Range Vector (셀렉터)는 range(범위)의 샘플을 가져온다는 점을 제외하고 instant vector 와 유사하게 동작한다.\nRange Vector Selector 의 경우 끝에 대괄호[]를 사용해 범위(range)를 추가한다.\n예시 - http_requests_total\nhttp_requests_total{job=\u0026#34;~~~\u0026#34;,group=\u0026#34;~~~\u0026#34;}[5m] http_requests_total 시계열 중에서 job, group에 매칭되는 현재 ~ 지난 5분 이내의 모든 시계열을 가져온다.\nFunctions # idelta() # idelta(v ragne-vector)는 (range 벡터)v에 있는 마지막 두 샘플의 차이를 계산하고, 계산한 델타 값을 레이블과 함께 instant 벡터로 반환한다.\nidelta 에선 게이지(gauge)만 사용해야 한다.\nincrease() # increase(v range-vector)는 range 벡터 안에 있는 시계열의 증분을 계산한다.\nrange 벡터 셀렉터에 지정된 시간 범위를 커버하기 위해 어림잡아 증분을 계산한다. 때문에, 실제 결과 값에 차이가 있을 수 있다. 예를 들어, 카운터 값이 정수 단위로만 증가하더라도 결과는 정수가 아닐 수 있다.\n// 지난 5분 동안의 http 요청 수를 반환한다. increase(http_requests_total{job=\u0026#34;~~~\u0026#34;}[5m]) increase 는 카운터에만 사용해야 한다.\nincrease 는 단순히 rate(v) 함수에 지정한 time range 만큼 초(sec)를 곱한 함수일 뿐이다.\n주로 가독성이 요구될 때만 사용하는 게 좋다. recording rule 에는 증분을 지속적으로 초 단위로 추적할 수 있도록 rate 를 사용하는 것이 좋다.\nirate() # irate(v range-vector)는 range 벡터 안에 있는 시계열의 초당 순간 변화율을 계산한다. 변화율은 마지막 데이터 포인트 2개를 사용해 계산한다.\n// 지난 5분 동안의 http 요청 수를 조회하고, 가장 최근 데이터 포인트 2개를 통해 초당 HTTP 요청 비율을 계산한다. irate(http_requests_total{job=\u0026#34;~~~\u0026#34;}[5m]) irate 는 변덕스럽고 빠르게 변화하는 카운터를 그래프로 표현할 때만 사용하는 것이 좋다. alert 혹은 느리게 변화하는 카운터에는 rate를 사용하는 것이 좋다. irate 는 비율이 잠깐 변경되어도 FOR 절을 리셋할 수 있고, 그래프 전체를 드문드문 스파이크로 만들 수 있기 때문이다. (= 보기 어렵게 한다.)\nrate() # rate(v rage-vector)는 range 벡터 안에 있는 시계열의 초당 평균 변화율을 계산한다.\n시간 범위의 양 끝은 어림잡아 계산한다. 때문에, 스크랩 일부가 누락되어도 문제가 없으며, range 의 기간과 스크랩 주기가 정확히 일렬로 정렬되지 않아도 괜찮다.\n// 지난 5분 동안 초당 HTTP 요청 비율 rate(http_requests_total{job=\u0026#34;~~~\u0026#34;}[5m]) rate 는 카운터에만 사용해야 한다. alert 정의, 느리게 변화하는 카운터를 그래프로 표현할 땐 rate가 가장 적합하다.\nrate vs increase # rate increase 범위 시간당 초당 호출량 범위 시간당 증가율 rate # rate 는 초당 호출량을 특정 기간을 기준으로 측정하는 것이다.\n만약 1분 동안 호출이 60번 됐다면 (1tps), 아래 쿼리의 결과는 1이다.\nrate(http_request_count_total[1m]) // 1 tps 를 원할 때, rate 를 사용하면 되겠다.\n기준이 초 라는 것이 중요하다.\nincrease # 호출 횟수를 그래프로 그리고, 표현하고 싶을 때는 increase를 사용하면 된다.\n1분 동안 호출이 60번 됐다면, 아래 쿼리의 결과는 60이다.\nincrease(http_request_count_total[1m]) 단순히 range 동안 증분한 결과로 보면 되겠다.\nincrease 를 사용해 그래프를 표현할 때 Min time interval을 단위 시간(위에서는 1m)과 동일하게 맞춰줘야 한다. 그래야 단위 시간 기준으로 정확한 데이터(min, max, avg)를 얻을 수 있다.\n참고 # https://blog.voidmainvoid.net/449 https://godekdls.github.io/Prometheus "},{"id":131,"href":"/docs/ETC/31.-Prometheus/","title":"31. Prometheus","section":"ETC","content":" https://prometheus.io/docs/prometheus/latest/storage/#storage\n"},{"id":132,"href":"/docs/ETC/99.-%EA%B7%B8%EB%A0%88%EC%9D%B4%EB%93%A4/","title":"99. 그레이들","section":"ETC","content":" :zap: compilePath \u0026amp; runtimeClasspath # :zap: testCompilePath \u0026amp; testRuntimeClasspath # \u0026quot; Configuration inheritance is heavily used by Gradle core plugins like the Java plugin. For example the testImplementation configuration extends the implementation configuration. \u0026ldquo;\n출처 : Configuration inheritance and composition\n:zap: example # dependencies { ... implementation \u0026#39;org.springframework.boot:spring-boot-starter-data-jpa\u0026#39; ... compileOnly \u0026#39;org.projectlombok:lombok\u0026#39; ... runtimeOnly \u0026#39;com.h2database:h2\u0026#39; runtimeOnly \u0026#39;mysql:mysql-connector-java\u0026#39; ... annotationProcessor \u0026#39;org.projectlombok:lombok\u0026#39; ... testImplementation \u0026#39;org.springframework.security:spring-security-test\u0026#39; ... } 참고 # [Spring] Gradle 파일 implementation, api, runtimeOnly, compileOnly\u0026hellip; 등에 대해 [Gradle] build.gradle의 dependencies 블록 한 번에 정리하기. implementation, testImplementation의 차이와 라이브러리 구성 "},{"id":133,"href":"/docs/KAFKA/KAFKA-Kafka-Connect-Intro/","title":"[KAFKA] Kafka Connect (Intro)","section":"KAFKA","content":" Kafka Connect Cluster: An Introduction 글을 읽고, 요약한 내용\nKafka 를 사용하다보면, 카프카 클러스터에 없는 데이터를 처리해야하는 경우가 많이 있다.\n예를 들어, 아래와 같은 곳에 존재하는 데이터를 처리해야하는 경우이다.\nDB 외부 파일 외부 스토리지 ---\u0026gt; Kafka 외부 스토리지 \u0026lt;--- Kafka 이를 처리하기 위한 2가지 방법이 있다. # 1. 카프카 Producer 애플리케이션을 작성한다.\n애플리케이션 생성 코드 작성 실패 처리 (해야한다.) scalability, polling 2. Kafka Connect 를 사용한다.\n1번과 동일한 기능을 한다.\n코드 작성 X 실패 처리 (해준다.) scalable 외부 스토리지 ---\u0026gt; Kafka Connect ---\u0026gt; Kafka 외부 스토리지 \u0026lt;--- Kafka Connect \u0026lt;--- Kafka 외부 저장소에서 카프카 클러스터로 데이터를 옮기는 문제가 워낙 일반적인 문제여서, Kafka Connect 가 만들어졌다고 한다.\n\u0026quot; The process of copying data from a storage system and move it to Kafka Cluster is so common that Kafka Connect tool is created to address this problem. \u0026ldquo;\nKafka Connect Concepts # worker # Kafka Connect 는 데이터를 처리(for moving data)하기 위해 worker 를 사용한다. 즉, 직접적인 \u0026lsquo;처리\u0026rsquo;를 담당하는 worker 가 있다. worker 는 단순한 process worker 는 physical concept \u0026rdquo; Workers are a physical concept. They are actually processes that run inside JVM \u0026ldquo;\nworker 클러스터를 만들 수 있다. (= worker 여러 개를 생성 가능하다.)\nworker 는 worker 의 상태, 데이터 처리(읽기) 상태 등등의 정보를 저장해야 한다.\n이때 내부적으로 Kafka 를 사용한다. (as storage) MODE 설명 Distributed Mode worker 가 여러 개 - scalability : O - fault tolerance : O Standalone Mode worker 한 개 connector # (Kafka connect 내에서) 우리들의 Job 을 connector 라고 부른다.\n예를 들어 아래와 같은 connector 가 있을 수 있다.\nDB table -\u0026gt; Kafka cluster (source connector) Kafka cluster -\u0026gt; DB table (sink connector) 종류 설명 source connector 외부 저장소 -\u0026gt; Kafka sink connector Kafka -\u0026gt; 외부 저장소 많은 외부 저장소가 있기 때문에, Kafka connect 는 그 외부 저장소에 \u0026lsquo;동작 방식(읽기, 쓰기)\u0026rsquo; 을 알아야한다.\n이를 위해 connector plugin 을 사용한다. \u0026rdquo; Because there are many storage systems, Kafka Connect must know somehow, how to copy data from one source to Kafka or vice versa \u0026ldquo;\nconnector plugin\n하나 이상의 jar file 이다.\n어떻게 데이터를 처리하는지(읽기, 쓰기)에 대한 방식을 아는 애다.\n예를 들어 \u0026lsquo;RDB -\u0026gt; Kafka\u0026rsquo; 일 떄 JDBC connector plugin 을 사용할 수 있다.\n이후 설치 / 테스트하는 내용이 포함되어 있음\n참고 # Kafka Connect Cluster: An Introduction "},{"id":134,"href":"/docs/KAFKA/KAFKA-Schema-Registry/","title":"[KAFKA] Schema Registry","section":"KAFKA","content":" https://docs.confluent.io/platform/current/ schema-registry/index.html#schemas-subjects-and-topics\nApache Avro # \u0026quot; Apache Avro™ is the leading serialization format for record data, and first choice for streaming data pipelines. It offers excellent schema evolution, and has implementations for the JVM (Java, Kotlin, Scala, …), Python, C/C++/C#, PHP, Ruby, Rust, JavaScript, and even Perl. \u0026ldquo;\n\u0026rdquo; Apache Avro™ is a data serialization system.\u0026quot;\nCompatibility # https://medium.com/@gaemi/kafka-%EC%99%80-confluent-schema-registry-%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%9C-%EC%8A%A4%ED%82%A4%EB%A7%88-%EA%B4%80%EB%A6%AC-1-cdf8c99d2c5c\n참고 # https://medium.com/@gaemi/kafka-%EC%99%80-confluent-schema-registry-%EB%A5%BC-%EC%82%AC%EC%9A%A9%ED%95%9C-%EC%8A%A4%ED%82%A4%EB%A7%88-%EA%B4%80%EB%A6%AC-1-cdf8c99d2c5c "},{"id":135,"href":"/docs/LANGUAGES/CPP/99.-unordered_map-vs-map/","title":"99. Unordered_map vs Map","section":"CPP","content":" 결론 # 데이터가 많다면 unordered_map 을 사용하자. 대게 unordered_map 이 우수하다. 개념 # map\nRed-Black Tree (RB Tree) 기반 key 정렬 키 값이 고르지 못할 경우, balancing 비용 커짐 O(logN) unordered_map\nHash Table 기반 O(1) 비교 # 대소비교 비용, 해싱 비용을 비교하여 예상할 수 있다.\nKey 타입: 숫자\n성능: unordered_map \u0026gt; map\nKey 타입: 문자열\n성능: unordered_map ?? map\n문자열 비교 vs 문자열 해싱의 경우 문자열 비교의 비용이 클 수도, 작을 수도 있다.\n문자열의 대소 비교가 쉽다면, map 의 정렬 비용이 적다. (map 이 우수할 수 있다.) 문자열의 길이가 짧다면 unordered_map 의 해싱 비용이 적다. (unordered_map 이 우수할 수 있다.) 출처 # C++ map vs hash_map(unordered_map)\n"},{"id":136,"href":"/docs/LANGUAGES/JAVA/JAVA-Acquire-a-Lock-by-a-Key-in-Java/","title":"[JAVA] Acquire a Lock by a Key in Java","section":"JAVA","content":" https://www.baeldung.com/java-acquire-lock-by-key\n1. Simple Mutex Lock Example # public class MyLockClass { private static Set\u0026lt;String\u0026gt; usedKeys = ConcurrentHashMap.newKeySet(); public boolean tryLock(String key) { return usedKeys.add(key) } public void unlock(String key) { usedKeys.remove(key); } } String key = \u0026#34;key\u0026#34;; MyLockClass lock = new MyLockClass(); try { lock.tryLock(key); // 처리해야 할 코드 } catch(Exception e) { } finally { lock.unlock(key); } 2. Simple Mutex Lock Example V2 (not refuse, wait until release the lock) # The application flow will be:\nthread 1 asks for a lock on a key: it acquires the lock on the key thread 2 asks for a lock on the same key: thread 2 is told to wait thread 1 releases the lock on the key thread 2 auqires the lock on the key and execute its action public class MyLockClass { private static class LockWrapper { private final Lock lock = new ReentrantLock(); private final AtomicInteger numberOfThreadsInQueue = new AtomicInteger(1); private LockWrapper addThreadInQueue() { numberOfThreadsInQueue.incrementAndGet(); return this; } private int removeThreadInQueue() { return numberOfThreadsInQueue.decrementAndGet(); } } private static ConcurrentHashMap\u0026lt;String, LockWrapper\u0026gt; locks = new ConcurrentHashMap\u0026lt;String, LockWrapper\u0026gt;(); public void lock(String key) { LockWrapper lockWrapper = locks.compute(key, (k, v) -\u0026gt; v == null ? new LockWrapper() : v.addThreadInQueue()); lockWrapper.lock.lock(); } public void unlock(String key) { LockWrapper lockWrapper = locks.get(key); lockWrapper.lock.unlock(); if(lockWrapper.removeThreadFromQueue() == 0) { locks.remove(key, lockWrapper); } } } String key = \u0026#34;key\u0026#34;; MyLockClass lock = new MyLockClass(); try { lock.lock(key); } finally { lock.unlock(key); } \u0026quot; In brief, a Lock is an object used for thread synchronization that allows blocking threads until it can be acquired. \u0026ldquo;\n3. Simple Semaphore Example # The application flow will be:\nthread 1 wants to acquire the lock on the key: it will be allowed to do so thread 2 wants to acquire the lock on the key: it will be allowed to do so thread 3 requests a lock on the same key: it will have to queue until one of the first two threads releases its lock public class MyLockClass { private static final int ALLOWED_THREADS = 2; private static ConcurrentHashMap\u0026lt;String, Semaphore\u0026gt; semaphores = new ConcurrentHashMap\u0026lt;String, Semaphore\u0026gt;(); public void lock(String key) { Semaphore semaphore = semaphores.compute(key, (k, v) -\u0026gt; v == null ? new Semaphore(ALLOWED_THREADS) : v); semaphore.acquireUninterruptibly(); // Acquires a permit from this semaphore, blocking until one is available. } public void unlock(String key) { Semaphore semaphore = semaphores.get(key); semaphore.release(); if (semaphore.availablePermits() == ALLOWED_THREADS) { semaphores.remove(key, semaphore); } } } String key = \u0026#34;key\u0026#34;; MyLockClass lock = new MyLockClass(); try { lock.lock(key); } finally { lock.unlock(key); } "},{"id":137,"href":"/docs/LANGUAGES/JAVA/JAVA-Callable-vs-Runnable/","title":"[JAVA] Callable vs Runnable","section":"JAVA","content":" Callable, Runnable 에 대해서 이해해보기\nJava는 Multi-Threading 이라는 기술(기능)을 제공한다.\nRunnable, Callable 인터페이스를 통해 Multi-Threading 기능을 설계할 수 있다.\nRunnable : Multi-Threading 을 위해 제공되는 interface 이다. Callable : Runnable의 개선된 버전이다. (자바 5에서 추가) 두 인터페이스 모두 Multi-Threading 을 위한 것이다.\n특징 Runnable Callable RETURN 리턴 타입 X 리턴 타입 O EXCEPTION Exception 발생 X Exception 발생 O 비고 Multi-Threading 을 위해 제공되는 interface 이다.\nThread, ExecutorService 클래스 등을 통해 사용될 수 있다. Runnable의 개선된 버전이다. (자바 5에서 추가)\nExecutorService, FutureTask 클래스 등을 통해 사용될 수 있다. Callable # /** * 1. Return 타입이 존재한다. * 2. Exception 을 발생시킨다. */ public interface Callable\u0026lt;V\u0026gt; { V call() throws Exception; } public Example { public class MyCallable implements Callable\u0026lt;String\u0026gt; { // (String)Return Type 이 존재한다. @Override public String call() throws Exception { // Exception 을 발생시킨다. return \u0026#34;Hello!\u0026#34;; } } } Runnable # /** * 1. Return 타입이 없다. * 2. Exception 이 없다. */ public interface Runnable { public abstract void run(); } public Example { public class MyRunnable implements Runnable { @Override public void run() { // (void)Return Type 이 없고, Exception 을 발생시키지 않는다. System.out.println(\u0026#34;Hello!\u0026#34;); } } } 참고 # Java - Runnable과 Callable의 차이점 이해하기 Runnable vs Callable in Java "},{"id":138,"href":"/docs/LANGUAGES/JAVA/JAVA-Future/","title":"[JAVA] Future","section":"JAVA","content":" Future # (미래에) 결국에는 반환받을 결과를 표현하기 위해 사용되는 인터페이스이다.\n\u0026quot; The Future interface is an interface that represents a result that will eventually be returned in the future. \u0026ldquo;\npackage java.util.concurrent; public interface Future\u0026lt;V\u0026gt; { boolean cancel(boolean var1); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long var1, TimeUnit var3) throws InterruptedException, ExecutionException, TimeoutException; } 메서드 설명 get() 결과를 가져온다. 결과가 아직 반환되지 않았다면, 기다린다. 결과를 받기 전에 get() 호출하여 기다리게 된다면, 결과를 받을 때까지 \u0026lsquo;block\u0026rsquo; 한다. 결과를 기다리는 것에 시간 제한을 적용시킬 수 있다. cancel() 현재 task 를 중단한다. 이미 task 가 완료되었다면, 이 명령어는 실패한다. isDone() task 의 현재 상태(done)를 확인한다. isCancelled() task 의 현재 상태(cancel)를 확인한다. 구현체 # CompletableFuture ForkJoinTask \u0026hellip; 예시 코드 # public static void main(String[] args) throws InterruptedException, ExecutionException { ExecutorService executorService = Executors.newFixedThreadPool(2); Future\u0026lt;String\u0026gt; dataReadFuture = executorService.submit(() -\u0026gt; { System.out.println(\u0026#34;Reading data...\u0026#34;); TimeUnit.SECONDS.sleep(5); return \u0026#34;Data reading finished\u0026#34;; }); Future\u0026lt;String\u0026gt; dataProcessFuture = executorService.submit(() -\u0026gt; { System.out.println(\u0026#34;Processing data...\u0026#34;); TimeUnit.SECONDS.sleep(5); return \u0026#34;Data is processed\u0026#34;; }); while (!dataReadFuture.isDone() \u0026amp;\u0026amp; !dataProcessFuture.isDone()) { System.out.println(\u0026#34;Reading and processing not yet finished.\u0026#34;); // Do some other things that don\u0026#39;t depend on these two processes // Simulating another task TimeUnit.SECONDS.sleep(1); } System.out.println(dataReadFuture.get()); System.out.println(dataProcessFuture.get()); } // [결과 출력 : 5sec 39ms] // Reading data... // Processing data... // Reading and processing not yet finished. // Reading and processing not yet finished. // Reading and processing not yet finished. // Reading and processing not yet finished. // Reading and processing not yet finished. // Data reading finished // Data is processed 중요 포인트 : isDone() # while(isDone()) 구문은 사용해도 되고, 사용하지 않아도 된다.\n하지만 위의 예시에서 while(isDone()) 을 사용하지 않고, 곧바로 get()을 호출하면 대략 5초 간의 Blocking 상태를 맞이하게 될 것이다. (= 자원의 낭비가 될 수 있다.)\n\u0026rdquo; What\u0026rsquo;s important here is the usage of the isDone() method. If we didn\u0026rsquo;t have the check, there wouldn\u0026rsquo;t be any guarantee that the results were packed in the Futures before we\u0026rsquo;ve accessed them. If they weren\u0026rsquo;t, the get() methods would block the application until they did have results. \u0026ldquo;\nCompletableFuture # 목적 1. 비동기 처리 후 (Future) 2. 다음 로직 실행 + Error 핸들링 (CompletionStage)\npublic class CompletableFuture\u0026lt;T\u0026gt; implements Future\u0026lt;T\u0026gt;, CompletionStage\u0026lt;T\u0026gt; { ... } 예시 코드 # CompletableFuture.supplyAsync(() -\u0026gt; { // Supplier::get() log.info(\u0026#34;Supplier::get()\u0026#34;); return \u0026#34;First\u0026#34;; }).thenApplyAsync(s -\u0026gt; { // Function::apply() log.info(\u0026#34;Function::apply() \u0026#34; + s); return s + \u0026#34; \u0026#34; + \u0026#34;Second\u0026#34;; }).thenAcceptAsync(s -\u0026gt; { // Consumer::accept() log.info(\u0026#34;Consumer::accept() \u0026#34; + s); }).exceptionally(e -\u0026gt; { // Function\u0026lt;Throwable, ? extends T\u0026gt;::apply() e.printStackTrace(); return null; }); // [결과 출력] // [ForkJoinPool.commonPool-worker-3] INFO com.example.demo.future.FutureTest - Supplier::get() // [ForkJoinPool.commonPool-worker-5] INFO com.example.demo.future.FutureTest - Function::apply() First // [ForkJoinPool.commonPool-worker-5] INFO com.example.demo.future.FutureTest - Consumer::accept() First Second 참고 # https://stackabuse.com/guide-to-the-future-interface-in-java/ https://umanking.github.io/2020/10/15/java-completable-future/ "},{"id":139,"href":"/docs/LANGUAGES/JAVA/JAVA-Garbage-Collection-%EA%B8%B0%EB%B3%B8/","title":"[JAVA] Garbage Collection (기본)","section":"JAVA","content":" Garbage Collection # 사용 중이지 않은 객체(= Garbage)를 식별하여 정리(= 메모리 해제)\n종류 # Serial GC Parallel GC \u0026hellip; CMS(Concurrent Mark Sweep) GC G1GC ZGC Mark \u0026amp; Sweep # Mark # 사용되는 메모리(객체)와 사용되지 않는 메모리(객체)를 식별하는 작업 (= reachability 를 판별하는 작업)\nroot set(객체에 대한 최초의 참조) 가 될 수 있는 요소\nJava Stack (지역변수, 파라미터 등) Java Native Interface(= Native Stack) JNI에 의해 생성된 객체들이 있을 때 Method(Staic) Area (정적 변수) root set으로부터 시작해서 참조로 연결되어 있는 모든 객체들을 탐색한다.\n하나의 객체에 대한 참조의 개수, 타입은 다양하게 될 수 있다. (주로)참조의 타입에 따라 해당 객체의 reachability가 결정된다.\nreachability 의 종류 (5가지)\n종류 설명 strongly reachable root set부터 시작해서 해당 객체에 도달하기까지 어떠한 reference object도 없다. softly reachable (strongly reachable 객체가 아닌 객체 중에서) 해당 객체에 도달하기까지 weak reference, phantom reference 없이 soft reference 가 하나라도 존재한다. weakly reachable (strongly reachable, softly reachable 객체가 아닌 객체 중에서) 해당 객체에 도달하기까지 phantom reference 없이 weak reference 가 하나라도 존재한다. phantomly reachable (strongly reachable, softly reachable, weakly reachable 객체 모두 해당되지 않는 객체이다. 이 객체는 finalize 되었지만 아직 메모리가 회수되지 않은 상태이다. unreachable root set으로부터 도달할 수 없는 객체 Sweep # (Mark 단계에서 사용되지 않는 메모리로 식별된) 메모리를 해체하는 작업\n단, 회수 대상 객체를 처리(finalization)하는 것과 메모리를 회수하는 작업은 다르다는 것을 인지해야 할 것 같다.\n→ Marking 은 후자만을 의미하는 건가?\nSTW 를 통해 모든 작업이 중단되고나면, GC는 메모리를 스캔하면서 Marking 작업을 한다. Sweeping 작업을 한다. Softly Reachable (SoftReference)\nsoftly reachable 객체는 힙(heap)에 \u0026lsquo;남아있는 메모리 크기\u0026rsquo; 와 \u0026lsquo;해당 객체의 사용 빈도\u0026rsquo; 에 따라 GC 여부가 결정된다.\nweakly reachable 객체와 달리 GC가 동작할 때마다 회수되지 않는다. 자주 사용될수록 오래 살아남는다.\nOracle HotSpot VM 에서 Softly reachable 객체의 GC를 조절하는 옵션 : -XX: SoftRefLRUPolicyMSPerMB=\u0026lt;N (기본값 : 1000)\u0026gt;\nWeakly Reachable (WeakReference)\n특별한 정책에 의해 GC 여부가 결정되는 SoftReachable 과 달리 GC를 수행할 때마다 회수 대상이 된다.\n그러나 GC가 실제로 언제 객체를 회수할지는 GC 알고리즘에 따라 모두 다르므로, GC가 수행될 때마다 반드시 메모리까지 회수된다고 보장하지는 않는다. 이는 soflty reachable 객체는 물론 unreachable 객체도 마찬가지다.\nLRU 캐시와 같은 구현을 위해서는 SoftReference 보다 WeakReference 객체가 유리하다.\n→ 왜지? 최근에 사용되는 객체는 남아있어야 하는거라면 SoftReference 도 적절한 거 아닌가?\n→ SoftReference 는 힙에 남아있는 메모리가 많을수록 회수 가능성이 낮기 때문에, 다른 비즈니스 로직 객체들을 위한 공간들이 SoftReference 객체에 점유되는 특징이 있다. 따라서 전체 메모리 사용량이 높아지고 GC가 더 자주 일어나며 GC에 걸리는 시간도 상대적으로 길어지는 문제가 발생한다.\n\u0026quot; GC가 Marking 하는 작업과 Sweeping 하는 작업은 즉각-연속적으로 발생하는 작업이 아니며, GC 대상 객체의 메모리를 한번에 모두 회수하지도 않는다. \u0026ldquo;\nPhantomly Reachable (PhantomReference) + ReferneceQueue\nhttps://d2.naver.com/helloworld/329631\nGeneration # HotSpot VM 에서는 물리 공간을 크게 2개로 나누었다.\nYoung Generation Old Generation Card Table\n512 Byte의 Chunk Old Generation → Young Generatoin 으로 참조하는 경우에 대해서는 Card Table 이라는 것으로 관리한다. Minor GC가 발생할 때 Old 영역을 모두 탐색하는 것을 피하고, Card Table 만 확인하도록 하기 위함이다. write barrier 를 사용하여 관리한다. Minor GC를 빠르게 할 수 있도록 하는 장치이다. 약간의 오버헤드는 발생하지만 전반적인 GC 시간은 줄어들게 된다. (= 바로 위 내용인, old → young 을 참조할 때 card table 에 기록하는 것을 의미한다.) Minor GC # Young 영역에 대해서 GC가 동작한다.\nYoung 영역 # Eden 영역 새로 생성된 객체가 할당(Allocation)되는 영역 Survivor 영역 최소 1번의 Minor GC 에서 살아남은 객체가 존재하는 영역 (→ Eden 영역에서 Survivor 영역으로 옮겨지는 것) Survivor 영역에서 Minor GC 발생 시, 다른 Survivor 영역으로 이동 (→ 즉, 여러 Survivor 영역에 번갈아가며(?) 계속해서 이동) 새로 생성된 객체 → Eden 영역 할당 Eden 영역이 꽉 차면 Minor GC 발생 사용되지 않는 메모리는 해제 사용중인 객체 → Survivor 영역으로 옮김 Survivor 영역은 2개, 반드시 1곳에만 데이터가 존재해야 함 Survivor 2곳 중 1곳은 반드시 빈 영역이 존재 (즉, 꽉 차지 않음) Survivor 한 곳이 꽉 차면 다른 한 Survivor 영역으로 이동 1 ~ 2번 반복 → 계속해서 살아남은 객체는 Old 영역으로 이동 (= Promotion) 알아둘 점\nMinor GC (Young 영역)에서 살아남은 횟수(age)를 Object Header 에 기록한다. → 이 age 값을 보고 promotion 여부를 결정한다.\nSurvivor 영역 중 1곳은 반드시 사용되어야 한다.\n→ 만약 하나의 데이터가 두 Survivor 영역에 모두 존재하거나, 두 Survivor 의 사용량이 0이라면 비정상적인 상황임을 인지할 수 있다.\nBump the pointer # \u0026rdquo; HotSpot JVM 에서는 Eden 영역에 객체를 빠르게 할당(Allocation)하기 위해 Bump the pointer와 TLABs라는 기술을 사용하고 있다. \u0026ldquo;\nEden 영역에 마지막으로 할당된 객체의 주소를 캐싱해두는 기술\n새로운 객체를 할당할 때, 빈 공간(유효한 메모리 공간)을 탐색해야하는데 이 탐색 비용을 없애줄 수 있는 것이다. (→ 마지막 주소의 다음 주소를 사용하게 한다.) 새로운 객체를 할당할 때 객체의 크기가 Eden 영역에 적합한지만 판별하면 된다. (→ 객체의 크기가 크면 어디에 저장될까?) TLABs (Thread-Local Allocation Buffers) # \u0026rdquo; HotSpot JVM 에서는 Eden 영역에 객체를 빠르게 할당(Allocation)하기 위해 Bump the pointer와 TLABs라는 기술을 사용하고 있다. \u0026ldquo;\n각각의 쓰레드마다 Eden 영역에 객체를 할당하는 공간(메모리 Base 주소 처럼?)을 부여함으로써, (멀티쓰레드 환경에서)동기화 작업 없이 빠르게 메모리를 할당하는 기술\n각 쓰레드는 자기만의 공간에만 할당한다. (싱글스레드 환경은 문제가 없다.) 멀티스레드 환경에서 Eden 영역에 객체를 할당할 때 Lock을 걸어 동기화를 해주어야 한다. → 이때 성능 문제를 해결하기 위해 사용된다. Major GC (Full GC) # Old 영역에 대해서 GC가 동작한다.\nMinor GC에서 계속 Promotion되어 Old 영역의 메모리가 부족해지면 발생한다.\n(Old 영역에 비해)Young 영역은 크기가 작기 때문에 대게 적은 시간(ex. ~~~ms)으로 수행된다. Old 영역은 크며, Young 영역을 참조할 수 있다. → (Minor GC의)~~배 이상의 시간으로 수행된다. 참고 # https://mangkyu.tistory.com/119 https://d2.naver.com/helloworld/1329 https://d2.naver.com/helloworld/37111 https://d2.naver.com/helloworld/329631 "},{"id":140,"href":"/docs/LANGUAGES/JAVA/JAVA-Garbage-Collection-%EC%A2%85%EB%A5%98/","title":"[JAVA] Garbage Collection (종류)","section":"JAVA","content":" Garbage Collection 종류 # Serial GC (-XX:+UseSerialGC) # Marking → Sweeping → Compaction 싱글 코어(쓰레드)를 위한 GC 절대 사용하지 않는 것을 권장 Parallel GC (Throughput GC) (-XX:+UseParallelGC) # Serial GC 알고리즘 동일 Serial GC 알고리즘 + 멀티 쓰레드 메모리가 충분, 코어 수가 많을 때 유리 Parallel Old GC (-XX:+UseParallelOldGC) # Marking → Summary → Compaction Parallel GC와 비교하여 Old 영역의 GC 알고리즘만 다르다. Summray 단게는 앞서 GC를 수행한 영역에 대해서 별도로 살아있는 객체를 식별한다? 약간 더 복잡하다. (찾아볼 것) CMS GC (Low Latency GC) (-XX:+UseConcMarkSweepGC) # Marking(Initial Mark, Concurruent Mark, Remark) → Concurrent Sweeping STW 시간이 매우 짧다. 모든 애플리케이션의 응답 속도가 매우 중요할 때 사용할 수 있다. (= Low Latency GC) 다른 GC 방식보다 자원(메모리/CPU)를 더 많이 사용한다. (단점) Compaction 단계가 기본적으로 없다. (단점) 조각난 메모리가 많아져 이후 Compaction 작업을 실행하면 다른 GC STW 시간보다 (STW 시간이) 더 길어질 수 있다. (얼마나 자주, 오랫동안 수행되는지 꼭 확인이 필요하다.) Initial Mark\n클래스 로더에서 가장 가까운 객체 중 살아있는 객체만 찾는 것으로 끝낸다. (= 매우 짧은 시간) Concurruent Mark\nInitial Mark 단게예서 살아있다고 확인한 객체에 대해서 참조를 따라가면서 확인한다. 다른 쓰레드가 실행 중인 상태에서 동시에 실행된다. (concurrent) Remark\nConcurrent Mark 단계에서 새로 추가되거나 참조가 끊긴 객체를 확인한다. (= Concurruent 에 의해 발생할 수 있는 변경 사항을 확인한다.) Concurrent Sweep\nConcurrent Sweeping 을 진행한다. G1 GC # CMS GC를 대체하기 위해 만들어졌다고 한다.\njdk11 부터 기본 GC 알고리즘으로 적용되었다.\nHW 발전 → 대용량 메모리에 적합한 솔루션을 제공하기 위해 고안되었다.\nRegion 개념 도입 Eden, Survivor, Old 영역이 존재하지만, 고정된 크기가 아니며 전체 Heap 메모리 영역을 Region 이라는 특정한 크기로 나눴다. Region 은 상태에 따라 역할(Eden, Survivor, Old)이 동적으로 변경된다. Default size = 전체 Heap 메모리 / 2048 Humonogous\n(Region 크기의 50%를 초과하는) 큰 객체를 저장하기 위한 공간\nAvailable/Unused\n아직 사용되지 않은(사용 가능한) Region\nZGC # 유의 사항 # \u0026quot; 어떤 서비스에서 A라는 GC 옵션을 적용해서 잘 동작한다고 그 GC 옵션이 다른 서비스에서도 훌륭하게 적용되어 최적의 효과를 볼 수 있다고 생각하지 말라는 것이다. \u0026ldquo;\n\u0026rdquo; 각 서비스의 WAS에서 생성하는 객체의 크기와 생존 주기가 모두 다르고, 장비의 종류도 다양하다. WAS의 스레드 개수와 장비당 WAS 인스턴스 개수, GC 옵션 등은 지속적인 튜닝과 모니터링을 통해서 해당 서비스에 가장 적합한 값을 찾아야 한다. \u0026ldquo;\n참고 # https://mangkyu.tistory.com/119 https://d2.naver.com/helloworld/1329 https://d2.naver.com/helloworld/37111 https://d2.naver.com/helloworld/329631 "},{"id":141,"href":"/docs/LANGUAGES/JAVA/JAVA-Interface-default-method/","title":"[JAVA] Interface Default Method","section":"JAVA","content":"Java 8 부터 Interface 에서 default method 를 구현할 수 있게 되었다.\n추상 클래스와의 차이점 ?? # 용도/목적이 다르다.\nabstract class 는 말 그대로 \u0026lsquo;클래스\u0026rsquo; 이다. extends 하는 것이다. 멤버변수, 접근제어 등의 기능을 갖는다. interface 는 말그대로 \u0026lsquo;인터페이스\u0026rsquo;이다. implements 하는 것이다. 인터페이스 다중 구현에서 Default 메서드가 중복일 때 # A 라는 클래스가 Interface1, Interface2 를 다중 구현하고 있는데, Interface1, Interface2 가 동일한 이름의 default 메소드를 갖고있다면 어떻게 될까.\n결론 : (컴파일)에러가 난다.\nA inherits unrelated defaults for watchTv() from types Man and Woman\n// Man Interface public interface Man { void playGame(); default void watchTv() { System.out.println(\u0026#34;Man is watching tv\u0026#34;); } } // Woman Interface public interface Woman { void playGame(); default void watchTv() { System.out.println(\u0026#34;Woman is watching tv\u0026#34;); } } // A class public class A implements Man, Woman{ @Override public void playGame() { System.out.println(\u0026#34;A is playing game\u0026#34;); } } 해결 방법\nA class 중복이 되는 default 메서드(watchTv())를 오버라이딩, 구현한다.\n인터페이스들 중 default 메소드를 제거하여 중복을 제거한다.\n"},{"id":142,"href":"/docs/LANGUAGES/JAVA/JAVA-Java-ClassPath/","title":"[JAVA] Java ClassPath","section":"JAVA","content":" classpath 에 대해 정리해보기\nCLASSPATH # (Windows의 시스템 환경 변수 처럼) Java 실행 시 클래스 파일들(.class)의 위치/경로 classpath에 실행하고자 하는 패키지(클래스)의 루트를 등록 예시 # /home/user/me/com/example/Test.class 를 실행하고자 할 때, 이 클래스가 위치한 경로로 찾아가지 않고 (java Teset 명령어를 통해)아무곳에서나 사용하고 싶다.\n\u0026gt; vim .zshrc CLASSPATH=\u0026#34;/home/user/me/com/example\u0026#34; \u0026gt; java Test Hello, World! "},{"id":143,"href":"/docs/LANGUAGES/JAVA/JAVA-Java-Stream/","title":"[JAVA] Java Stream","section":"JAVA","content":" Stream 에 대해 정리해보기\nStream # Java8 에서 java.util.stream 패키지에 Stream API 추가\n다양한 데이터 소스(source)를 표준화된 방법으로 다루기 위한 기술\nStream API 의 특징은 다음과 같다. # 데이터(컬렉션, 배열 등)을 표준화된/하나의 방법을 통해 연산, 조작할 수 있다.\n데이터를 스트림으로 만들고 나면 표준화된(하나의) 방법으로 조작할 수 있다. 내부 반복(internal interation) 을 통해 작업을 수행한다.\n스트림은 일회용이다.\n최종 연산(소모)을 통해 스트림이 끝났다면, 다시 스트림 생성/조작해야 한다. 원본 데이터(original data)를 변경하지 않는다.\n지연(Lazy) 연산을 통해 불필요한 연산을 피한다.\n쉽게 병렬 처리 기능을 지원한다.\nparallelStream(), parallel() 등 스트림의 처리 단계는 다음과 같다.\n스트림의 생성 스트림의 중개/중간 연산(스트림의 변환 : filter, map, \u0026hellip;) 스트림의 최종 연산(스트림 사용, 스트림 요소 소모 : reduce, collect, \u0026hellip;) 중간 연산 : 연산 결과 -\u0026gt; stream 최종 연산 : 연산 결과 -\u0026gt; stream X, 스트림 소모하는 방식이라 단 한번만 가능 기본형(Primitive) 스트림을 지원한다. (IntStream, LongStream, DoubleStream 등)\nStream\u0026lt;Integer\u0026gt; 대신 IntStream 을 사용함으로써 오토박싱\u0026amp;언박싱 비효율 제거 Stream\u0026lt;T\u0026gt; 보다 숫자와 관련된 유용한 기능을 더 제공 (Stream\u0026lt;T\u0026gt;는 숫자를 위한 것이 아니고 참조타입을 위한거니까) 성능 개선에 고려할 수 있다. * 스트림으로 연산(중개연산, 최종연산)을 할 때 대부분 \u0026lsquo;함수형 인터페이스 매개변수\u0026rsquo;를 갖는다. 즉, 람다식을 사용할 수 있다.\n// 스트림을 생성하는 다양한 방법들 Collection.stream(); Stream.of(); Stream.iterate(); Stream.generate(); // 중개/중간 연산 종류들 filter(); distinct(); sort(); limit(); ... // 최종 연산 종류들 count(); forEach(); ... Lazy 연산 vs Eager 연산 # List\u0026lt;Integer\u0026gt; list = Arrays.asList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10); list.stream() .filter(i -\u0026gt; i\u0026lt;6) // --- (1) .filter(i -\u0026gt; i%2==0) // --- (2) .map(i -\u0026gt; i*10) // --- (3) .collect(Collectors.toList()) // 출처: https://dororongju.tistory.com/137 [웹 개발 메모장] Lazy 연산\n1 번째 연산에 대해 계산 : (2)까지 계산 후 연산 종료 2 번째 연산에 대해 계산 : (3)까지 계산 3 번쨰 연산에 대해 계산 : (2)까지 계산 후 연산 종료 n 번째 연산에 대해 계산 : \u0026hellip; 10 번째 연산에 대해 계산 : (1)까지 계산 후 연산 종료 Eager 연산\n1~10번째에 대해서 (1) 연산 실행 1번에서 구한 요소들에 대해 (2) 연산 실행 2번에서 구한 요소들에 대해 (3) 연산 실행 병렬 스트림 # Stream API 에는 \u0026lsquo;병렬 스트림\u0026rsquo;을 생성할 수 있는 API 를 제공한다.\n병렬 스트림이란, 각각의 스레드에서 처리할 수 있도록 Stream 의 요소(element)를 여러 chunk 로 분할한 스트림이다. 이 chunk 를 멀티코어 CPU 가 처리하도록 할당할 수 있다. (* 병렬 스트림은 내부적으로 ForkJoinPool 을 사용한다.)\n* 병렬 처리가 항상 향상된 성능으로 동작하는 것은 아니다.\n* 어떤 알고리즘을 병렬화 하는 것보다 어떤 자료구조를 선택할 지 고민하는 것이 중요하기도 하다. (예를 들어, 불필요한 박싱/언박싱 제거)\n많은 글들에서 스트림은 \u0026ldquo;내부 반복\u0026rdquo; 을 통해 병렬 처리를 쉽게할 수 있다고 한다. 그렇다면 왜 내부 반복을 사용하면 병렬 처리를 쉽게 할 수 있을까? 내가 생각한 결론은 \u0026ldquo;병렬 처리를 위해 요소들을 chunk 단위로 분할할 때, 개발자가 직접 분할하지 않고 내부에서 알아서 분할해줄 수 있기 때문에\u0026rdquo; 이다.\n병렬 처리를 할 때 아래의 것들에 대해 고려해봐야 한다.\n병렬 처리의 동작 방식에 대해 정확히 알고 사용하자.\n멀티코어 간의 데이터 이동 비용과 작업(로직)의 비용을 비교하자.\n공유 자원이 연관된 작업에 대해서는 병렬화의 이점이 없을 수 있다. (공유 자원에 대해 관계가 없을 때 사용하는 것이 바람직하다.)\n전체 스트림 파이프라인 처리 비용 = N * Q (N = 처리해야할 요소의 수, Q = 하나의 요소를 처리할 때 발생하는 비용)일 때, Q 가 높다면 병렬 스트림으로 성능을 개선할 수 있는 가능성이 있다.\nN 이 커도 개선할 수 있는 가능성이 있다. \u0026lsquo;최종 연산\u0026rsquo; 의 병합 비용을 고려한다.\n병합 비용이 비싸다면, 이득이 없을 수 있다. 소량의 데이터에서는 병렬 스트림의 이득이 크지 않다.\nFork/Join Framework (포크/조인 프레임워크) 란? # Fork/Join 프레임워크는 작업을 작은 작업으로 분할하고, (sub task)각각의 결과를 합쳐 전체 결과를 만들도록 설계되었다.\n서브태스크(sub task)를 ForkJoinPool의 작업 스레드에 분산하여 할당하는 ExcutorService 인터페이스를 구현한다.\n참고 # 자바의 정석 - 기초편, 스트림, 스트림의 특징 스트림 API 병렬 데이터 처리와 성능(병렬 스트림) Lazy Evaluation 이란? "},{"id":144,"href":"/docs/LANGUAGES/JAVA/JAVA-Java-String-Pool/","title":"[JAVA] Java String Pool","section":"JAVA","content":" String Pool 에 대해 이해해보기\nJava에서 String 객체를 생성하는 2가지 방법 # new 연산자 String str = new String(\u0026quot;안녕하세요\u0026quot;); String Literal String str = \u0026quot;안녕하세요\u0026quot; 두 방식 모두 Heap 에 생성되지만, 차이점도 존재한다고 한다.\nnew 연산자 # (값이 같아도, 달라도) 서로 다른 주소(reference value)를 가진다. 즉, 계속해서 새롭게 생성한다. String str1 = new String(\u0026#34;안녕하세요\u0026#34;); // Heap 영역에 \u0026#34;안녕하세요\u0026#34; 라는 객체가 새롭게 저장된다. String str2 = new String(\u0026#34;안녕하세요\u0026#34;); // Heap 영역에 \u0026#34;안녕하세요\u0026#34; 라는 객체가 새롭게 저장된다. String Literal # (값이 같다면) 서로 같은 주소(reference value)를 가진 객체이다. 즉, 재사용된다. Heap 내부에 String Pool 이라는 공간이 있고, 생성한 문자열의 값(e.g. \u0026ldquo;안녕하세요\u0026rdquo;)이 저장된다. 이후에 동일한 값(e.g. \u0026ldquo;안녕하세요\u0026rdquo;)으로 생성되는 String은 이미 Stirng Pool에 있는 객체를 가르킨다.\nString str1 = \u0026#34;안녕하세요\u0026#34; // String Pool 에 \u0026#34;안녕하세요\u0026#34; 라는 애가 String pool 에 저장된다. String str2 = \u0026#34;안녕하세요\u0026#34; // 위에서 생성된 \u0026#34;안녕하세요\u0026#34;를 가르킨다. 알아두기 # Java6 이전 : String Pool은 PermGen 이라는 (fixed size)Space 안에 있었다고 한다. 사이즈가 고정되었고, 런타임에 동적으로 확장할 수도 없어서 OutOfMemory 가 발생할 여지가 컸다고 한다. (Garbage Collection 구조에도 적합하지 않았다고 한다.)\nJava7 부터 : String Pool은 Heap 공간 안에 위치했고 (Heap 영역에 위치했다는 것은 Garbage collected 됨을 의미하기에) OutOfMemory 리스크가 줄었다고 한다.\n또, String Pool의 사이즈는 1009 buckets -\u0026gt; 60013(size?) -\u0026gt; 65536(size?) 로 변경되었다고 한다.\nPrior to Java 7u40, the default pool size was 1009 buckets but this value was subject to a few changes in more recent Java versions. To be precise, the default pool size from Java 7u40 until Java 11 was 60013 and now it increased to 65536.\n(+ 추가적으로 읽어보면 좋은 내용) Until Java 8, Strings were internally represented as an array of characters – char[], encoded in UTF-16, so that every character uses two bytes of memory. With Java 9 a new representation is provided, called Compact Strings. This new format will choose the appropriate encoding between char[] and byte[] depending on the stored content. Since the new String representation will use the UTF-16 encoding only when necessary, the amount of heap memory will be significantly lower, which in turn causes less Garbage Collector overhead on the JVM.\n결론 # String Literal 을 사용하면 객체를 재사용할 수 있다.\n참고 # Guide to Java String Pool "},{"id":145,"href":"/docs/LANGUAGES/JAVA/JAVA-JVM-%EC%9D%B8%EC%A6%9D%EC%84%9C-%EC%A0%81%EC%9A%A9/","title":"[JAVA] JVM 인증서 적용","section":"JAVA","content":" JVM 에 신뢰할 수 있는 인증서 추가하기\n개요 # \u0026lsquo;사내(사설) SSL을 사용하는 이유\u0026rsquo; 글에서 잠깐 적었는데, (로컬 환경)개발을 하면서 이 사내 인증서 때문에 통신 문제가 발생했다.\n원인 # 테스트하고자 하는 작업의 흐름은 간단하게 다음과 같다.\nException 이 터진다. Exception 에 대한 내용을 (사설 인증서가 적용된)Sentry 쪽으로 보낸다. Sentry 에 내용이 쌓이고, 사용자(개발자)에게 알림을 보내준다. 위의 2번의 과정에서 오류가 발생했고, 내가 이해한 원인은 다음과 같다.\n(외부에서 받아온)JVM 은 당연히도 사내에서 사용하고 있는 사설 인증서 정보를 가지고 있지 않다. JVM은 공식적으로 인정된 인증서의 리스트만 갖고 있을 것이기 때문이다. 때문에 이 JVM을 통해 (사설 인증서가 적용된)Sentry 와 통신을 하면 \u0026lsquo;유효하지 않은 인증서\u0026rsquo;로 취급되어 오류가 발생한다.\n해결 # 다양한 방법이 있겠지만, 이번에 작성할 내용은 JVM에 인증서를 등록하는 방법이다.\n1. 먼저 JDK 를 설치한 폴더에 접근한다.\ncd $JAVA_HOME\n그러면 lib/security 폴더가 보일텐데, 이 폴더에 들어가보면 다음과 같은 파일들이 있다.\nblacklisted.certs cacerts default.policy ... 2. 여기서 cacerts 파일을 수정해준다.\n\u0026lsquo;여기\u0026rsquo;에서도 알 수 있듯이, cacerts 는 신뢰할 수 있는 인증서 리스트 파일이다. 여기에 (사내에서 사용 중인) 사설 인증서를 등록해주면 신뢰할 수 있다고 보는 것이다.\ncacerts 파일을 변경하는 방법이나 구체적인 해결 방법은 \u0026lsquo;여기\u0026rsquo;를 참고하면 된다.\n"},{"id":146,"href":"/docs/LANGUAGES/JAVA/Java-JVM/","title":"[Java] JVM","section":"JAVA","content":" JVM # 자바 가상 머신(Java Virtual Machine)이다. (스택 기반의 가상 머신이다.)\n* 여기서 가상 머신이란? 프로그램을 실행하기 위해 물리적인 기계(머신)와 유사한 (논리적인? 가상의?) 머신을 소프트웨어로 구현한 것이다.\nJava Application 을 클래스 로더를 통해 읽어 들이고, Java API 와 함께 실행한다.\nJava 와 OS 사이에서 중개 역할을 한다. Java 가 OS 에 구애받지 않고 사용할 수 있는 환경을 제공한다.\n이 외 메모리 관리, GC 을 수행한다.\n자바 프로그램의 실행 과정 # 프로그램이 실행되면 JVM 이 OS 로부터 메모리를 할당 받는다. 용도에 따라 메모리 영역을 나눈다.\njavac(자바 컴파일러)가 자바 소스코드(.java)를 자바 바이트코드(.class)로 변환한다.\n클래스 로더(Class Loader) 를 통해 바이트코드(.class) 를 로딩한다.\n로딩된 바이트 코드(파일)들은 Execution (엔진) 을 통해 해석된다.\n해석된 바이트 코드(파일)들은 Runtime Data Area 영역에 배치되어 실행된다.\n실행 중간중간 JVM이 GC, Thread Sync 와 같은 작업을 수행한다.\nJVM 구성 # 클래스 로더 (Class Loader)\nJVM 내로 바이트코드(파일, .class)을 로딩한다.\nRuntime 시에 동적으로 클래스를 로드한다.\njar 파일 내에 저장된 클래스들을 jvm 위에 올리고 사용하지 않는 클래스들은 메모리에서 삭제한다.\nJava 는 클래스를 처음으로 참조할 때, 해당 클래스를 로드(링크)한다. 즉 런타임 시에 참조한다. (이 역할을 클래스 로더가 한다.)\n실행 엔진 (Execution Engine)\n클래스를 실행시킨다.\n클래스 로더가 JVM 내의 Runtime Data Area 에 클래스(.class)를 배치시키는데, 이것들은 Execution Engine 에 의해 실행된다.\n클래스 로더가 배치한 .class(자바 바이트코드)는 비교적 인간 지향적인 언어이다. 즉 완벽한 기계어가 아니라고 한다. Execution Engine 은 이 바이트 코드를 기계가 실행할 수 있도록 변환해준다. 이때 사용될 수 있는 방법은 1. Interpreter, 2. JIT(Just-In-Time) 이다.\nInterpreter (인터프리터)\n바이트 코드를 명령어 단위로 읽어서 실행한다. 말 그대로 인터프리터이다. 한 줄씩 수행하기 때문에 느릴 수 있다. JIT (Just-In-Time)\n인터프리터 방식의 단점을 보완하기 위해 도입된 JIT 컴파일러이다. 인터프리터 방식으로 실행하다가 적절한 시점에 바이트코드 전체를 컴파일하여 native 코드로 변환한다. 이후에는 더 이상 인터프리터를 사용하지 않고 native 코드로 직접 실행한다. native 코드는 캐싱되기 때문에 한 번 컴파일된 코드는 빠르게 수행하게 된다. JIT 컴파일러가 전체 바이트 코드를 컴파일 하는 것은 시간이 오래걸린다. 한 번만 실행되는 코드라면 컴파일하지 않고 인터프리팅 하는 것이 유리하다. 따라서 JIT 컴파일러를 사용하는 JVM은 내부적으로 해당 메서드가 얼마나 자주 수행되는지 체크하고 일정한 수준을 넘을 때에만 JIT 컴파일을 수행한다. GC\nGC를 수행하는 모듈(Thread)이 있다.\nRuntime Data Area\n프로그램을 수행하기 위해 OS 로부터 할당받은 메모리 공간이다.\n아래는 SpringBoot 프로젝트(gg-pigs) 의 build jar 를 해제했을 때 생기 폴더/파일이다.\nBOOT-INF\nBOOT-INF/classes : 작성한 코드들이 바이트코드(.class) 형태로 존재한다. BOOT-INF/lib : 외부 라이브러리(jar)들이 존재한다. META-INF\nMETA-INF/MANIFEST.MF : Start-Class, Spring-Boot-Classes, Spring-Boot-Lib, Spring-Boot-Version, Main-Class 등의 정보가 기술되어 있다. org.springframework.boot.loader\nLauncher, Loader, Runner 등이 존재한다. Reference\nhttps://asfirstalways.tistory.com/158 "},{"id":147,"href":"/docs/LANGUAGES/JAVA/JAVA-Lock/","title":"[JAVA] Lock","section":"JAVA","content":" https://www.baeldung.com/java-concurrent-locks\n"},{"id":148,"href":"/docs/LANGUAGES/JAVA/JAVA-Map/","title":"[JAVA] Map","section":"JAVA","content":" Map # 흔히 사용되는 구현체\nHashMap LinkedHashMap HashTable ConcurrentHashMap TreeMap HashMap # // jdk 11 기준 public class HashMap\u0026lt;K, V\u0026gt; extends AbstractMap\u0026lt;K, V\u0026gt; implements Map\u0026lt;K, V\u0026gt;, Cloneable, Serializable { private static final long serialVersionUID = 362498820763181265L; static final int DEFAULT_INITIAL_CAPACITY = 16; // \u0026lt;-- 초기 사이즈 ... final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { HashMap.Node[] tab; int n; if ((tab = this.table) == null || (n = tab.length) == 0) { n = (tab = this.resize()).length; } Object p; int i; if ((p = tab[i = n - 1 \u0026amp; hash]) == null) { // 대부분의 정상적인 경우, key (해시) 충돌 없을 때 tab[i] = this.newNode(hash, key, value, (HashMap.Node)null); } else { Object e; Object k; if (((HashMap.Node)p).hash == hash \u0026amp;\u0026amp; ((k = ((HashMap.Node)p).key) == key || key != null \u0026amp;\u0026amp; key.equals(k))) { // 대부분의 정상적인 경우, key (해시) 값이 같고, 동일성(==) 혹은 동등성(equals)일 때 // value 를 overwrite 한다. // * 동일/동등하기 때문에 해시 충돌이라고 판단하지 않고 그냥 overwrite 하는 것 같다. e = p; } else if (p instanceof HashMap.TreeNode) { e = ((HashMap.TreeNode)p).putTreeVal(this, tab, hash, key, value); } else { // 해시 충돌 (동일 X , 동등 X) : 동일, 동등하지 않은데 해시는 같음 =\u0026gt; 해시 충돌 // e.g. // 1. key 값은 다른데, (해시 func로 계산된) 해시가 같다. // 2. key 값은 같은데, 해시가 다르다. (\u0026lt;-- 일반적인 경우는 아님. 중간에 해시 함수가 변경되어야 나타날수 있는 케이스) // --\u0026gt; OpenAddressing : 선형 탐색 int binCount = 0; while(true) { // Loop // 다음 노드가 null 이면, 새 노드 삽입 // -\u0026gt; 즉 키가 같은데 , 데이터는 두 개가 됨 (overwrite 안됨) if ((e = ((HashMap.Node)p).next) == null) { ((HashMap.Node)p).next = this.newNode(hash, key, value, (HashMap.Node)null); if (binCount \u0026gt;= 7) { this.treeifyBin(tab, hash); } break; } // 해시 충돌난 것들 중에서도 해시 같은 것(overwrite) 체크 if (((HashMap.Node)e).hash == hash \u0026amp;\u0026amp; ((k = ((HashMap.Node)e).key) == key || key != null \u0026amp;\u0026amp; key.equals(k))) { break; } p = e; ++binCount; } } if (e != null) { V oldValue = ((HashMap.Node)e).value; if (!onlyIfAbsent || oldValue == null) { ((HashMap.Node)e).value = value; } this.afterNodeAccess((HashMap.Node)e); return oldValue; } } ... } // hashcode : 충돌 // equals : 구현 public class MyTest { class Node { public String key; public Node(String key) { this.key = key; } @Override public int hashCode() { return 1; } @Override public boolean equals(Object obj) { Node node = (Node) obj; return this.key == node.key; } @Override public String toString() { return \u0026#34;Node{\u0026#34; + \u0026#34;key=\u0026#39;\u0026#34; + key + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } @Test public void test() { HashMap\u0026lt;Node, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(new Node(\u0026#34;1\u0026#34;), \u0026#34;value1\u0026#34;); map.put(new Node(\u0026#34;2\u0026#34;), \u0026#34;value2\u0026#34;); // 1번 데이터와 해시 같고, 동등(equals)하지 않음 =\u0026gt; 해시 충돌 (새로운 데이터로 삽입) map.put(new Node(\u0026#34;2\u0026#34;), \u0026#34;value3\u0026#34;); // 2번 데이터와 해시 같고, 동등함 =\u0026gt; overwrite for (Map.Entry\u0026lt;Node, String\u0026gt; m: map.entrySet()) { System.out.println(m.getKey()); System.out.println(m.getValue()); } /** * Node{key=\u0026#39;1\u0026#39;} * value1 * Node{key=\u0026#39;2\u0026#39;} * value3 */ } } // hashcode : 충돌 // equals : 구현 X public class MyTest { class Node { public String key; public Node(String key) { this.key = key; } @Override public int hashCode() { return 1; } @Override public String toString() { return \u0026#34;Node{\u0026#34; + \u0026#34;key=\u0026#39;\u0026#34; + key + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#39;}\u0026#39;; } } @Test public void test() { HashMap\u0026lt;Node, String\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); map.put(new Node(\u0026#34;1\u0026#34;), \u0026#34;value1\u0026#34;); map.put(new Node(\u0026#34;2\u0026#34;), \u0026#34;value2\u0026#34;); // 1번 데이터와 해시 충돌 -\u0026gt; 새로운 값 삽입 map.put(new Node(\u0026#34;2\u0026#34;), \u0026#34;value3\u0026#34;); // 2번 데이터와 해시 충돌 -\u0026gt; 새로운 값 삽입 for (Map.Entry\u0026lt;Node, String\u0026gt; m: map.entrySet()) { System.out.println(m.getKey()); System.out.println(m.getValue()); } /** * Node{key=\u0026#39;1\u0026#39;} * value1 * Node{key=\u0026#39;2\u0026#39;} * value2 * Node{key=\u0026#39;2\u0026#39;} * value3 */ } } * HashMap 에서는 hashcode(), equals() 둘 다 사용\n어떻게, 어떤 것을 구현했냐에 따라 결과 값이 달라짐 * 충돌 해결 방법 : OpenAddressing 선형 탐색\nNode 가 next 속성을 가지고 있음 HashTable # HashMap + 동기화(synchrosized) Thread-Safe (synchronized) value 에 null 값 불가 : NullPointerException * 아래와 같이 대부분의 메소드에 synchronized 키워드가 적용\n* value == null 이면 NullPointerException\npublic class Hashtable\u0026lt;K, V\u0026gt; extends Dictionary\u0026lt;K, V\u0026gt; implements Map\u0026lt;K, V\u0026gt;, Cloneable, Serializable { ... public synchronized V put(K key, V value) { // method (인스턴스) 동기화 if (value == null) { throw new NullPointerException(); // NPE } else { Hashtable.Entry\u0026lt;?, ?\u0026gt;[] tab = this.table; int hash = key.hashCode(); int index = (hash \u0026amp; 2147483647) % tab.length; for(Hashtable.Entry entry = tab[index]; entry != null; entry = entry.next) { if (entry.hash == hash \u0026amp;\u0026amp; entry.key.equals(key)) { V old = entry.value; entry.value = value; return old; } } this.addEntry(hash, key, value, index); return null; } } public synchronized V remove(Object key) { Hashtable.Entry\u0026lt;?, ?\u0026gt;[] tab = this.table; int hash = key.hashCode(); int index = (hash \u0026amp; 2147483647) % tab.length; Hashtable.Entry\u0026lt;K, V\u0026gt; e = tab[index]; for(Hashtable.Entry prev = null; e != null; e = e.next) { if (e.hash == hash \u0026amp;\u0026amp; e.key.equals(key)) { if (prev != null) { prev.next = e.next; } else { tab[index] = e.next; } ++this.modCount; --this.count; V oldValue = e.value; e.value = null; return oldValue; } prev = e; } return null; } public synchronized void putAll(Map\u0026lt;? extends K, ? extends V\u0026gt; t) { ... } LinkedHashMap # (double)연결리스트 (순서 유지) HashMap 의 subclass HashMap 의 예시/출력 동일하다.\npublic class LinkedHashMap\u0026lt;K, V\u0026gt; extends HashMap\u0026lt;K, V\u0026gt; implements Map\u0026lt;K, V\u0026gt; { ... } public void test() { LinkedHashMap\u0026lt;String, Integer\u0026gt; linkedHashMap = new LinkedHashMap\u0026lt;\u0026gt;(); linkedHashMap.put(\u0026#34;1\u0026#34;, 1); linkedHashMap.put(\u0026#34;2\u0026#34;, 2); linkedHashMap.put(\u0026#34;3\u0026#34;, 3); linkedHashMap.put(\u0026#34;1\u0026#34;, 4); for(Map.Entry\u0026lt;String, Integer\u0026gt; entry : linkedHashMap.entrySet()) { System.out.println(entry); // 출력은 아래와 같다. // 1=4 // 2=2 // 3=3 } } TreeMap # Red-Black Tree 로 구현되었다. C++ 에서의 map 과 유사하다. 대소 비교가 가능해야 한다. (Compariable 인터페이스를 구현해야 한다. compareTo()) Red-Black Tree 란? Balacned Binary Search Tree 라고 볼 수 있다.\n* Entry 클래스? # Map 에 사용되는 Key, Value 형태를 다루기 위한 인터페이스 Map 인터페이스의 내부 인터페이스 * 각각의 구현체는 Entry 인터페이스의 구현체 (Node, Entry) 클래스를 가짐, entrySet 을 관리 (entrySet 은 순회등에서 사용)\n// 예시 : HashMap.Node 구현체 static class Node\u0026lt;K, V\u0026gt; implements Entry\u0026lt;K, V\u0026gt; { final int hash; final K key; V value; HashMap.Node\u0026lt;K, V\u0026gt; next; ... } Reference\nhttps://bestalign.github.io/2015/09/20/Java-Map-types-comparison/ https://m.blog.naver.com/PostView.nhn?blogId=sthwin\u0026logNo=220825616965\u0026proxyReferer=https:%2F%2Fwww.google.com%2F "},{"id":149,"href":"/docs/LANGUAGES/JAVA/JAVA-MDC/","title":"[JAVA] MDC","section":"JAVA","content":"다음 내용을 참고하자.\nhttps://mangkyu.tistory.com/266 https://bcho.tistory.com/1316 https://logback.qos.ch/manual/mdc.html 출처: https://bcho.tistory.com/1316\n요약하면, (ThreadLocal 기반으로 동작하며) CorrelationID + 메타 데이터를 Map 형태로 관리할 수 있다.\n관리되는 메타 데이터들을 로깅 시 함께 남겨 애플리케이션 로그 추적을 쉽게 한다. (%X{placeholder} 패턴으로 남길 수 있다.)\n"},{"id":150,"href":"/docs/LANGUAGES/JAVA/JAVA-Multi-Threading/","title":"[JAVA] Multi-Threading","section":"JAVA","content":" HW 관점에서의 Thread # CPU, Core, Thread\ncore : (CPU 내의) 물리적인 코어 thread : 논리적인 코어 \u0026ldquo;동시에 실행가능한 스레드 개수\u0026rdquo; 예시\nCPU 2개 4코어 8스레드 -\u0026gt; 8개의 작업을 동시에 처리할 수 있음 SW(Java) 관점에서의 Thread # 이전부터 (HW 관점에서의)1코어 1스레드 환경에서, Java 는 n 개의 스레드를 사용할 수 있었음 -\u0026gt; \u0026lsquo;동시성\u0026rsquo;과 관련\n\u0026lsquo;동시성\u0026rsquo; : 여러 개의 작업들이 짧은 시간 내에 번갈아 처리됨 -\u0026gt; 동시에 처리되는 것처럼 보여짐 컨텍스트스위칭 발생 \u0026lsquo;병렬성\u0026rsquo; : 작업들이 병렬적으로 처리되는 것 Java Thread 는 \u0026lsquo;동시성\u0026rsquo;을 가지는 것\nN개의 Java Thread 가 (HW)Thread 를 번갈아 가며 사용/작업하는 것\n(어느 한 순간에) Java Thread 의 최대 병렬 작업 개수 = HW Thread 수\n하지만 \u0026lsquo;동시성\u0026rsquo;의 성질을 갖고 있기에, 모든 Java Thread가 동시에 처리되는 것으로 보임\n그래서 \u0026lsquo;Java Multi-Thread\u0026rsquo; 에서는 \u0026lsquo;병렬 프로그래밍\u0026rsquo; 이 아닌, \u0026lsquo;동시성 프로그래밍\u0026rsquo; 이라고 함\n(Java 에서) 동시성 Thread 성질을 통해 얻을 수 있는 것\n== \u0026lsquo;동시성\u0026rsquo; 의 이점\n비용이 크게 소요되는 작업 과 비용이 적게 소요되는 작업이 있을 때, 비용이 크게 소요되는 작업을 다 끝날때 까지 기다리지 않을 수 있음 번갈아 가면서 실행하기 때문에, 위의 상황에서의 비효율성을 해소할 수 있음 Java 에서 Multi-Threading 의 동기화를 지원하기 위한 방법 # volatile synchronized Atomic (CAS) volatile # CPU 캐시가 아닌, 메인 메모리(main memory)에 값 읽고/쓰기\n\u0026lsquo;변수의 가시성\u0026rsquo; 문제를 해결\nCPU 캐시(각각의 HW Core)에 저장하는 것을 방지 -\u0026gt;\n메인 메모리에 저장하도록 하여 여러 개의 Thread 가 동일한 값을 참조할 수 있도록 함.\n여러 개의 Thread 중 (동시에)하나의 쓰레드만 쓰기 작업을 보장한다면, volatile 로 동기화 문제 해소 가능\n변수의 값은 CPU 메모리와 메인 메모리에 저장된다.\n이 값을 CPU 메모리인지 메인 메모리에서 가져오는 지 알 수가 없다는 문제가 변수의 가시성 문제이다.\n출처: https://mygumi.tistory.com/112\nsyncronized # Lock 획득/해제 방식으로 동작.\n주의할 점은, 메소드에 걸었을 경우 해당 인스턴스(객체)에 lock 을 거는 것\na(), b() 메서드가 있을 때 Thread1가 a() 에 걸면 다른 스레드에서 b() 를 호출할 수 없음\nlock 재진입 개념이 가능 (= a() 에서 lock 을 얻었으면, b() 함수도 바로 호출 가능) class MyObject { public synchronized int a() { ... } public synchronized int b() { ... } } class MyObject { public int a() { synchronized(this) { ... } } public int b() { synchronized(this) { ... } } } 이유?\n데드락을 방지하기 위해서 인듯 함. a() 함수 내에서 b() 함수 호출하고,\nb() 함수 내에서 a() 함수 호출하면 데드락이 발생\n단, static method 에 대해서는 클래스에 lock 을 건다.\nstatic method 는 아래와 같다고 함.\nclass MyObject { public static synchronized int a() { ... } public static synchronized int b() { ... } } class MyObject { public static int a() { synchronized(MyObject.class) { ... } } public static int b() { synchronized(MyObject.class) { ... } } } 주의!!\nstatic lock \u0026lt;-\u0026gt; 일반 lock 은 lock 객체가 서로 다름(class vs instance) -\u0026gt; 동기화 처리 되지 않음\n참고\npublic class MyLock { private boolean isLocked = false; public synchronized void lock() throws InterruptedException{ while(isLocked){ wait(); } isLocked = true; } public synchronized void unlock(){ isLocked = false; notify(); } } AtomicXXX (CAS) # lock-free 하되 동기화를 보장하기 위해 사용 (CAS 방식을 통해 동기화를 보장)\n(대게) 동기화 중 가장 빠름\n(값 set 과 같은 어떤 행위를 할 때) 내가 갖고 있었던 \u0026lsquo;값\u0026rsquo;(혹은 메모리 값) 과 기대 값이 같은지 비교.\n-\u0026gt; 같다면, 안전하다고 판단하여 행위를 수행\n-\u0026gt; 다르다면, 정상적이지 않다고 판단하여 처리하지 않음.\n\u0026quot; 그래서 Non-blocking한 방법, Lock-Free한 방법으로 동기화 문제를 해결하기 위한 방법이 바로 Atomic연산이다.\n그리고 이 동작의 핵심 원리는 CAS(Compare And Swap)에 있다. \u0026quot;\n출처 : https://wannabe-gosu.tistory.com/29\npublic boolean cas(int expectedValue, int newValue) { if(this.myValue != expectedValue) { return false; } this.myValue = newValue; return true; } public class AtomicReference\u0026lt;V\u0026gt; implements Serializable { ... public final V updateAndGet(UnaryOperator\u0026lt;V\u0026gt; updateFunction) { V prev = this.get(); V next = null; boolean haveNext = false; while(true) { if (!haveNext) { next = updateFunction.apply(prev); } if (this.weakCompareAndSetVolatile(prev, next)) { return next; } haveNext = prev == (prev = this.get()); } } ... } 참고 # https://javaplant.tistory.com/23 https://badcandy.github.io/2019/01/14/concurrency-01/ "},{"id":151,"href":"/docs/LANGUAGES/JAVA/JAVA-Netty/","title":"[JAVA] Netty","section":"JAVA","content":" Channel # \u0026quot; A nexus to a network socket or a component which is capable of I/O operations such as read, write, connect, and bind. \u0026ldquo;\nI/O(read, write, connect, bind) 작업을 할 수 있는 네트워크 소켓, 컴포넌트와의 연결점이다.\n다음 기능을 제공한다.\nchannel 의 현재 상태 channel 의 구성 파라미터 (configuration parameters) channel 이 지원하는 I/O 작업 (read, write, connect, bind) channel 과 관련된 모든 I/O 이벤트, requests 를 핸들링하는 ChannelPipeline 모든 I/O 작업은 비동기이다.\n따라서, channel 의 I/O 작업은 즉시 응답을 return 한다.\n작업의 성공 여부를 확인할 수 있는 ChannelFuture 객체를 반환한다. (당연하게도) I/O 작업이 성공했다거나, 완료되었음을 보장하지는 않는다. (사용 후에)close(), close(ChannelPromise)를 호출하는 것이 중요하다.\nchannel 사용이 완료되면, 모든 resource 를 해제(release)하기 위해 close(), close(ChannelPromise) 를 호출하는 것이 중요하다.\n모든 리소스는 적절한 방식으로 해제(release)된다.\n\u0026rdquo; It is important to call close() or close(ChannelPromise) to release all resources once you are done with the Channel. This ensures all resources are released in a proper way, i.e. filehandles. \u0026ldquo;\npackage io.netty.channel; ... public interface Channel extends AttributeMap, ChannelOutboundInvoker, Comparable\u0026lt;Channel\u0026gt; { /** * Returns the globally unique identifier of this {@link Channel}. */ ChannelId id(); ... ChannelFuture # Channel I/O 비동기 작업의 결과이다.\nChannelFuture 는 completed, uncompleted 둘 중 하나의 상태이다.\nI/O 작업이 시작될 때, 하나의 ChannelFuture 객체가 생성된다. (uncompleted) I/O 작업이 완료되기 전까지, 성공, 실패, 취소 모두 아니다. I/O 작업이 끝났다면, 해당 상태(성공, 실패, 취소)로 마킹된다. \u0026lsquo;실패\u0026rsquo;, \u0026lsquo;취소\u0026rsquo;도 완료 상태에 속한다는 것을 유의해야 한다. +---------------------------+ | Completed successfully | +---------------------------+ +----\u0026gt; isDone() = true | +--------------------------+ | | isSuccess() = true | | Uncompleted | | +===========================+ +--------------------------+ | | Completed with failure | | isDone() = false | | +---------------------------+ | isSuccess() = false |----+----\u0026gt; isDone() = true | | isCancelled() = false | | | cause() = non-null | | cause() = null | | +===========================+ +--------------------------+ | | Completed by cancellation | | +---------------------------+ +----\u0026gt; isDone() = true | | isCancelled() = true | +---------------------------+ 위 예시처럼(?) 상태(성공, 실패, 취소)를 확인할 수 있는 다양한 메서드를 제공한다.\nChannelFutureListener 인터페이스를 통해 리스너 구현체를 손쉽게 작성할 수 있다. I/O 작업이 완료되었을 때의 이벤트를 수신한다.\nawait 보다 addListener 를 권장한다.\nawait : blocking (thread)dead lock 발생할 수 있다. addListener : non-blocking \u0026rdquo; Prefer addListener(GenericFutureListener) to await() (중략\u0026hellip;)\nMoreover, there\u0026rsquo;s a chance of dead lock in a particular circumstance, which is described below. (중략\u0026hellip;)\nDo not call await() inside ChannelHandler \u0026ldquo;\nawait 가 분명히 편리한 경우도 있다. 그럼에도 I/O thread 에서는 호출하지 마라.\n\u0026rdquo; In spite of the disadvantages mentioned above, there are certainly the cases where it is more convenient to call await(). In such a case, please make sure you do not call await() in an I/O thread. Otherwise, BlockingOperationException will be raised to prevent a dead lock. \u0026ldquo;\n\u0026lsquo;I/O 타임아웃\u0026rsquo;과 \u0026lsquo;await 타임아웃\u0026rsquo; 을 혼동하지 않아야 한다.\n\u0026rdquo; Do not confuse I/O timeout and await timeout \u0026ldquo;\n아래와 같이 await 함수 사용 시 타임아웃을 제한할 수 있다.\nawait(long) await(long, TimeUnit) awaitUninterruptibly(long) awaitUninterruptibly(long, TimeUnit) 다만, 이 타임아웃은 I/O 타임아웃과는 전혀 관련이 없다.\n이 부분은 실제 사용 시 유의해야할 것 같다. (실제 사용 시 한번 더 이해가 필요하다.)\nChannelHandler # I/O 이벤트를 처리(핸들링)하거나, I/O 작업을 가로챈다.(intercept) 그리고 (이벤트)를 (ChannelPipeline 의) 다음 핸들러로 전달한다.\nChannelHandler는 많은 메서드를 제공하지는 않지만, 일반적으로 다음 하위 타입을 구현해야한다.\nChannelInboundHandler : To handle inbound I/O events ChannelOutboundHandler : To handle outbound I/O operations (대안으로) 편의를 위해 다음과 같은 adapter 클래스도 제공한다.\nChannelInboundHandlerAdapter : To handle inbound I/O events ChannelOutboundHandlerAdapter : To handle outbound I/O operations ChannelDuplexHandler : To handle both inbound and outbound events Context Object\nChannelHandler 는 ChannelHandlerContext 객체와 함께 제공된다.\n하나의 ChannelHandler는 이 contect 객체(ChannelHandlerContext)를 통해 자신이 속한 ChannelPipeline 과 상호작용해야 한다.\nContect 객체를 사용해서 다음과 같은 작업을 할 수 있다.\n업스트림, 다운스트림에 이벤트를 전달할 수 있다. Pipeline 을 동적으로 수정할 수 있다. 핸들러에 특정한 정보를 저장할 수 있다. (using AttributeKeys) \u0026rdquo; A ChannelHandler is provided with a ChannelHandlerContext object. A ChannelHandler is supposed to interact with the ChannelPipeline it belongs to via a context object. Using the context object, the ChannelHandler can pass events upstream or downstream, modify the pipeline dynamically, or store the information (using AttributeKeys) which is specific to the handler. \u0026ldquo;\n상태 관리(State Management)\nChannelHandler는 종종 stateful information 을 저장해야 할 필요/니즈가 있다.\n가장 쉽고, 추천하는 방법은 멤버 변수 를 사용하는 것이다.\n아래 예시는 DataServerHandler 라는 핸들러에서 loggedIn 이라는 멤버 변수를 사용하는 예시이다.\npublic class DataServerHandler extends SimpleChannelInboundHandler\u0026lt;Message\u0026gt; { private boolean loggedIn; @Override public void channelRead0(ChannelHandlerContext ctx, Message message) { if (message instanceof LoginMessage) { authenticate((LoginMessage) message); loggedIn = true; // 여기! (stateful information) } else (message instanceof GetDataMessage) { if (loggedIn) { // 여기! (stateful information) ctx.writeAndFlush(fetchSecret((GetDataMessage) message)); } else { fail(); } } } ... } 다만 위와 같이 상태를 갖게한다면, 커넥션 별로 별도의 handler 객체를 생성해야 한다.\nHandler 객체는 하나의 커넥션(one connection)에 전용인 state 변수를 갖는다. 각각의 커넥션 별로 새로운 핸들러 객체를 만들어야 한다. (race condition 을 피하기 위해서) 아래 예시는 Channel 이니셜라이저에 handler 를 등록하는 것을 보여주는 예시같다. = 채널마다 새로운 핸들러 객체를 생성하는 것을 보여주는 것 같다.\n// Create a new handler instance per channel. // See ChannelInitializer.initChannel(Channel). public class DataServerInitializer extends ChannelInitializer\u0026lt;Channel\u0026gt; { @Override public void initChannel(Channel channel) { channel.pipeline().addLast(\u0026#34;handler\u0026#34;, new DataServerHandler()); } } 일반적인 상황에서도 별도의 객체를 생성하는 것을 말하는 건지, 위와 같이 멤버 변수(상태 변수)를 가질 때에만을 말하는 건지 헷갈린다.\n멤버 변수 사용을 원치 않는다면, AttributeKeys 를 사용할 수 있다.\nChannelHandlerContext 에 의해 제공된다.\n@Sharable // 밑에서 살펴볼 어노테이션이다. public class DataServerHandler extends SimpleChannelInboundHandler\u0026lt;Message\u0026gt; { private final AttributeKey\u0026lt;Boolean\u0026gt; auth = AttributeKey.valueOf(\u0026#34;auth\u0026#34;); // 1. AttributeKey 를 만든다. @Override public void channelRead(ChannelHandlerContext ctx, Message message) { Attribute\u0026lt;Boolean\u0026gt; attr = ctx.attr(auth); // 2. ChannelHandlerContext 에서 attribute 를 가져온다. if (message instanceof LoginMessage) { authenticate((LoginMessage) o); attr.set(true); // 3-1. attr 값을 설정한다. (여기서는 boolean 타입이다. true 로 설정한다.) } else (message instanceof GetDataMessage) { if (Boolean.TRUE.equals(attr.get())) { // 3-1. attr 값을 가져온다. (여기서는 boolean 타입이다.) ctx.writeAndFlush(fetchSecret((GetDataMessage) o)); } else { fail(); } } } ... } @Sharable\nHandler 객체를 한 번만 생성할 수 있음을 표시한다.\nRace Condition 없이 여러 개의 ChannelPipeline 에 추가/등록할 수 있음을 표시한다. 이 주석이 없다면 공유되어 사용될 수 없는(race condition 이 발생할 수 있는) 멤버 변수를 갖고 있다는 뜻으로 간주하고, 매 번 새로운 객체를 생성해야 한다.\npackage io.netty.channel; public interface ChannelHandler { /** * Gets called after the {@link ChannelHandler} was added to the actual context and it\u0026#39;s ready to handle events. */ void handlerAdded(ChannelHandlerContext ctx) throws Exception; ... } ChannelPipeline # ChannelHandler 들의 리스트이다.\n\u0026rdquo; A list of ChannelHandlers which handles or intercepts inbound events and outbound operations of a Channel. \u0026ldquo;\nChannelPipeline은 이벤트가 처리되는 방식과 파이프라인의 ChannelHandler가 서로 상호 작용하는 방식을 사용자에게 완전히 제어할 수 있도록 Intercepting Filter 패턴의 고급 형태를 구현합니다.\n(하나의 Pipeline 안에서) 하나의 Event 가 처리되는 방식, ChannelHandler 들이 서로 상호 작용하는 방식에 대한 정보를 갖고 있는 클래스라고 보면 될 것 같다.\nEvent 를 처리하는 방식, Handler들을 적용하는 방식을 구현한다.\n또, 사용자가 이것들을 완전히 컨트롤할 수 있게 해준다.\n약간 FilterChainProxy 같은 느낌일 것 같다.\n파이프라인 생성 (Creation of a pipeline)\n각각의 channel 은 자신만의 파이프라인을 갖는다. (파이프라인에 속하는 느낌인 것 같다.) = 채널이 생성될 때 자동으로 파이프라인이 생성된다. (?)\n\u0026rdquo; Each channel has its own pipeline and it is created automatically when a new channel is created. \u0026ldquo;\n하나의 파이프라인에서 Event Flow (How an event flows in a pipeline)\nI/O Request via Channel or ChannelHandlerContext | +---------------------------------------------------+---------------+ | ChannelPipeline | | | \\|/ | | +---------------------+ +-----------+----------+ | | | Inbound Handler N | | Outbound Handler 1 | | | +----------+----------+ +-----------+----------+ | | /|\\ | | | | \\|/ | | +----------+----------+ +-----------+----------+ | | | Inbound Handler N-1 | | Outbound Handler 2 | | | +----------+----------+ +-----------+----------+ | | /|\\ . | | . . | | ChannelHandlerContext.fireIN_EVT() ChannelHandlerContext.OUT_EVT()| | [ method call] [method call] | | . . | | . \\|/ | | +----------+----------+ +-----------+----------+ | | | Inbound Handler 2 | | Outbound Handler M-1 | | | +----------+----------+ +-----------+----------+ | | /|\\ | | | | \\|/ | | +----------+----------+ +-----------+----------+ | | | Inbound Handler 1 | | Outbound Handler M | | | +----------+----------+ +-----------+----------+ | | /|\\ | | +---------------+-----------------------------------+---------------+ | \\|/ +---------------+-----------------------------------+---------------+ | | | | | [ Socket.read() ] [ Socket.write() ] | | | | Netty Internal I/O Threads (Transport Implementation) | +-------------------------------------------------------------------+ Spring MVC 에서 Filter, Intercept 가 처리되는 방식과 유사하다.\n하나의 이벤트는 (위에서 구현해야한다고 했던)ChannelInboundHandler, ChannelOutboundHandler 구현체들에 의해 처리된다.\n그림에서도 볼 수 있듯이, 아웃바운드 핸들러를 모두 통과하고 나면 해당 channel 과 연결되어 있는 I/O thread 에 의해 처리된다.\nI/O thread 는 실제 작업(write)을 수행한다.\n인바운드 데이터는 대부분 원격지로부터 읽어온다.\n\u0026quot; The inbound data is often read from a remote peer via the actual input operation such as SocketChannel.read(ByteBuffer). \u0026quot;\nOrder of Handlers\n아래와 같은 핸들러들이 있다고 가정하자.\nChannelPipeline p = ...; p.addLast(\u0026#34;1\u0026#34;, new InboundHandlerA()); p.addLast(\u0026#34;2\u0026#34;, new InboundHandlerB()); p.addLast(\u0026#34;3\u0026#34;, new OutboundHandlerA()); p.addLast(\u0026#34;4\u0026#34;, new OutboundHandlerB()); p.addLast(\u0026#34;5\u0026#34;, new InboundOutboundHandlerX()); 인바운드일 때, 핸들러 적용 순서는 다음과 같다.\n1 → 2 → 3 → 4 → 5 1 → 2 → 5 아웃바운드일 때, 핸들러 적용 순서는 다음과 같다.\n5 → 4 → 3 → 2 → 1 5 → 4 → 3 Forwarding an event to the next handler\nHandler 가 다음 Handler 로 이벤트를 전파하기 위해서 다음과 같은 메서드를 사용한다.\nInbound event propagation methods:\nChannelHandlerContext.fireChannelRegistered() ChannelHandlerContext.fireChannelActive() ChannelHandlerContext.fireChannelRead(Object) ChannelHandlerContext.fireChannelReadComplete() ChannelHandlerContext.fireExceptionCaught(Throwable) ChannelHandlerContext.fireUserEventTriggered(Object) ChannelHandlerContext.fireChannelWritabilityChanged() ChannelHandlerContext.fireChannelInactive() ChannelHandlerContext.fireChannelUnregistered() Outbound event propagation methods:\nChannelHandlerContext.bind(SocketAddress, ChannelPromise) ChannelHandlerContext.connect(SocketAddress, SocketAddress, ChannelPromise) ChannelHandlerContext.write(Object, ChannelPromise) ChannelHandlerContext.flush() ChannelHandlerContext.read() ChannelHandlerContext.disconnect(ChannelPromise) ChannelHandlerContext.close(ChannelPromise) ChannelHandlerContext.deregister(ChannelPromise) 사용 예시는 다음과 같다.\npublic class MyInboundHandler extends ChannelInboundHandlerAdapter { @Override public void channelActive(ChannelHandlerContext ctx) { System.out.println(\u0026#34;Connected!\u0026#34;); ctx.fireChannelActive(); } } public class MyOutboundHandler extends ChannelOutboundHandlerAdapter { @Override public void close(ChannelHandlerContext ctx, ChannelPromise promise) { System.out.println(\u0026#34;Closing ..\u0026#34;); ctx.close(promise); } } Building a pipeline\n\u0026rdquo; Be aware that while using DefaultEventLoopGroup will offload the operation from the EventLoop it will still process tasks in a serial fashion per ChannelHandlerContext and so guarantee ordering. Due the ordering it may still become a bottle-neck. If ordering is not a requirement for your use-case you may want to consider using UnorderedThreadPoolEventExecutor to maximize the parallelism of the task execution. \u0026ldquo;\nThread safety\nChannelPipeline 은 Thread-Safe 하다.\nChannelHandler는 언제든지 ChannelPipeline 에 더해지거나 제거될 수 있다. \u0026rdquo; For example, you can insert an encryption handler when sensitive information is about to be exchanged, and remove it after the exchange. \u0026ldquo;\nEventLoop # 일단 등록되면, Channel을 위한 모든 I/O 작업을 처리한다.\n무한 루프(?) 속에서 Event 를 수신하여 처리한다. \u0026quot; Netty는 Channel에서 발생하는 이벤트들을 EventLoop가 처리하는 구조입니다. \u0026quot;\n출처 : Netty의 스레드 모델\n하나의 EventLoop 객체는 일반적으로 하나 이상의 Channel 객체를 처리할 것이다.\nImplementation details, internals 에 따라 다를 수 있다. public interface EventLoop extends OrderedEventExecutor, EventLoopGroup { @Override EventLoopGroup parent(); } public class DefaultEventLoop extends SingleThreadEventLoop { public DefaultEventLoop() { this((EventLoopGroup) null); } ... @Override protected void run() { for (;;) { Runnable task = takeTask(); // taskQueue(이벤트 큐)에서 Task(Event) 를 가져온다. if (task != null) { runTask(task); updateLastExecutionTime(); } if (confirmShutdown()) { break; } } } } public abstract class SingleThreadEventLoop extends SingleThreadEventExecutor implements EventLoop { protected static final int DEFAULT_MAX_PENDING_TASKS = Math.max(16, SystemPropertyUtil.getInt(\u0026#34;io.netty.eventLoop.maxPendingTasks\u0026#34;, Integer.MAX_VALUE)); private final Queue\u0026lt;Runnable\u0026gt; tailTasks; ... public abstract class SingleThreadEventExecutor extends AbstractScheduledEventExecutor implements OrderedEventExecutor { ... private final Queue\u0026lt;Runnable\u0026gt; taskQueue; // EventQueue ... 위 내용을 보면 각각의 EventLoop 가 EvnetQueue 를 가지고 있음을 알 수 있다.\nEventLoopGroup # \u0026quot; Special EventExecutorGroup which allows registering Channels that get processed for later selection during the event loop. \u0026quot;\n이벤트 루프 동안 나중에 선택하기 위해 처리되는 채널을 등록할 수 있는 특수 EventExecutorGroup입니다.\nEventLoop 는 EventLoopGroup 을 상속(확장)한다.\n무슨 의미인지\u0026hellip;?\n\u0026lsquo;나중에 처리할 수 있는 이벤트를 등록할 수 있다\u0026rsquo;는 의미일까?\npublic interface EventLoopGroup extends EventExecutorGroup { /** * Return the next {@link EventLoop} to use */ @Override EventLoop next(); /** * Register a {@link Channel} with this {@link EventLoop}. The returned {@link ChannelFuture} * will get notified once the registration was complete. */ ChannelFuture register(Channel channel); /** * Register a {@link Channel} with this {@link EventLoop} using a {@link ChannelFuture}. The passed * {@link ChannelFuture} will get notified once the registration was complete and also will get returned. */ ChannelFuture register(ChannelPromise promise); /** * Register a {@link Channel} with this {@link EventLoop}. The passed {@link ChannelFuture} * will get notified once the registration was complete and also will get returned. * * @deprecated Use {@link #register(ChannelPromise)} instead. */ @Deprecated ChannelFuture register(Channel channel, ChannelPromise promise); } Note # EventLoop, EventLoopGroup 은 무엇인가?\nEventLoop 가 EventLoopGroup 을 상속한다.\n근데 EventLoopGroup 의 메서드를 보면 뭔가 abstract 클래스의 느낌이 들기도 하는 듯 하다.\n흠\u0026hellip;\nChannel \u0026lt;-\u0026gt; EventLoop 관계는 무엇인가?\n\u0026quot; Netty의 이벤트는 Channel에서 발생합니다. \u0026quot;\n\u0026quot; Netty의 Channel은 하나의 이벤트 루프에 등록됩니다. \u0026quot;\n\u0026quot; 하나의 이벤트 루프 스레드에는 여러 채널이 등록될 수 있습니다. \u0026quot;\n\u0026quot; 각각의 이벤트 루프 객체는 개인의 이벤트 큐를 가지고 있습니다. \u0026quot;\n\u0026quot; Netty는 Channel에서 발생하는 이벤트들을 EventLoop가 처리하는 구조입니다. \u0026quot;\n\u0026quot; 다중 스레드 이벤트 모델에서 이벤트의 실행 순서가 일치하지 않는 근본적인 이유는 이벤트 루프들이 이벤트 큐를 공유하기 때문에 발생하는데 Netty는 이벤트 큐를 이벤트 루프 스레드의 내부에 둠으로써 실행 순서 불일치의 원인을 제거한 것입니다. \u0026quot;\n출처 : Netty의 스레드 모델\n정리하면,\nChannel 에서 Event 가 발생한다. Channel 은 (이미)EventLoop 가 지정되어 있는 상태이다. 하나의 EventLoop 는 여러 Channel 을 처리할 수 있다. EventLoop 내부의 EventQueue 에 Event 가 적재된다. EventQueue 에 쌓인 Event 를 처리한다. Chanele은 EventLoop가 지정되어 있는 상태이다.\npublic interface Channel extends AttributeMap, ChannelOutboundInvoker, Comparable\u0026lt;Channel\u0026gt; { ChannelId id(); EventLoop eventLoop(); ... } public abstract class AbstractChannel extends DefaultAttributeMap implements Channel { ... @Override public EventLoop eventLoop() { EventLoop eventLoop = this.eventLoop; if (eventLoop == null) { throw new IllegalStateException(\u0026#34;channel not registered to an event loop\u0026#34;); } return eventLoop; } EventLoop 가 등록되지 않은 Channel은 IllegalStateException 이 발생한다.\n참고 # \u0026quot; 위의 이벤트 루프 모델을 잘 살펴보면 Netty를 이용하여 개발 할 때 주의해야할 점이 한 가지 있습니다. 바로 이벤트 루프 스레드가 blocking되면 안되는 것인데요. 이벤트 루프 스레드가 blocking되어 버리면 해당 이벤트 루프에 등록된 Channel들에서 발생한 이벤트들이 제때 처리되지못하고 요청들이 밀려버리는 상황이 발생합니다.\n(\u0026hellip; 중략)\nNetty에서는 이런 blocking작업을 어떻게 처리해야할까요? Netty는 이벤트 루프가 blocking되지 않게 blocking구간이 있는 ChannelHandler를 별도의 EventExecutor에서 실행될 수 있도록 지원합니다. \u0026quot;\n출처 : Netty의 스레드 모델\n"},{"id":152,"href":"/docs/LANGUAGES/JAVA/JAVA-Open-JDK/","title":"[JAVA] Open JDK","section":"JAVA","content":" OpenJDK 공식 사이트\n\u0026ldquo;썬 마이크로시스템즈는 라이선스에 문제가 있는 몇몇 모듈을 제외하고 openjdk.org에 JDK 코드 제공하였다. 이 코드는 공개되었다.\u0026rdquo;\nOpenJDK 에는 여러 배급처(Vendor)가 존재한다.\nJCP(Java Community Process) 를 통해 JSR(Java Specification Request) 표준이 정의된다.\nJSR 내용을 기반으로 각 배급처(Vendor)가 구현한다.\nTCK(Technology Compatibility Kit) 를 이용해, JSR 표준에 잘 맞춰져 개발이 되었는지 검증/테스트 한다.\nOpenJDK 종류 # Community / Vendor Product name OSS / Commercial Architecture Description Oracle Oracle JDK Commercial Hotspot - OpenJDK.org OpenJDK OSS Hotspot - RedHat/CentOS OpenJDK OSS Hotspot - AdoptOpenJDK.net OpenJDK OSS Hotspot/Openj9 (?) - Eclipse.org OpenJ9 OSS OpenJ9(IBM) - AZUL Zing Commercial Zing - 참고 # LINE의 OpenJDK 적용기: 호환성 확인부터 주의 사항까지 Java 유료 논쟁(Oracle JDK 와 OpenJDK의 차이 정리) Difference between OpenJDK and Adoptium/AdoptOpenJDK "},{"id":153,"href":"/docs/LANGUAGES/JAVA/JAVA-Optional-orElse-vs-orElseGet/","title":"[JAVA] Optional OrElse vs OrElseGet","section":"JAVA","content":" orElse(T other) vs orElseGet(Supplier\u0026lt;? extends T\u0026gt; other) # 간단 요약 # orElse() : Optional null 여부에 상관없이 메서드를 호출하여 (메서드의) 값을 반환한다.\norElseGet() : Optional null 인 경우에만 메스드를 호출(supplier.get() 호출)하여 (메서드의) 값을 반환한다.\n메서드의 인자를 보면 명확한 차이점이 있다. (Supplier의 Lazy Evaluation) (T other) vs (Supplier\u0026lt;? extends T\u0026gt; other)\n/** * Return the value if present, otherwise return {@code other}. * * @param other the value to be returned if there is no value present, may * be null * @return the value, if present, otherwise {@code other} */ public T orElse(T other) { return value != null ? value : other; } /** * Return the value if present, otherwise invoke {@code other} and return * the result of that invocation. * * @param other a {@code Supplier} whose result is returned if no value * is present * @return the value if present otherwise the result of {@code other.get()} * @throws NullPointerException if value is not present and {@code other} is * null */ public T orElseGet(Supplier\u0026lt;? extends T\u0026gt; other) { return value != null ? value : other.get(); } \u0026quot; orElse는 객체를 그대로 return 하는데 orElseGet은 Supplier 메소드를 받아서 return 한다. \u0026hellip; 결론적으로 두 개의 차이는 메소드를 파라미터로 넘길 때 실행시점에서 차이가 발생한다. orElse()는 Optional 객체가 null이 아닐 때에도 메소드가 실행되고, orElseGet은 실행되지 않는다. \u0026ldquo;\n예시 코드 # public class Main { public static void main(String[] args) { String check = \u0026#34;check\u0026#34;; // or null String str1 = Optional.ofNullable(check).orElse(func()); String str2 = Optional.ofNullable(check).orElseGet(Main::func); System.out.println(str1); System.out.println(str2); } public static String func() { System.out.println(\u0026#34;func() 실행합니다.\u0026#34;); return \u0026#34;func()\u0026#34;; } } // check 값이 non-null 일 때, func() 실행합니다. check check // check 값이 null 일 때, func() 실행합니다. func() 실행합니다. func() func() 참고 # orElse() vs orElseGet() 자바8 Optional 3부: Optional을 Optional답게 "},{"id":154,"href":"/docs/LANGUAGES/JAVA/JAVA-Reflection/","title":"[JAVA] Reflection","section":"JAVA","content":" Reflection # 로드된 클래스의 정보를 찾을 수 있게 지원합니다.\n구체적인 클래스(구현 클래스, 구현체)의 타입을 몰라도 그 클래스의 정보(변수, 타입, Method)에 접근할 수 있게 해주는 API입니다.\n//참조 클래스 구체적인 클래스 Object obj = new Car(); 동작 원리 # 동작원리는 다음과 같습니다.\nJVM이 실행되면, 클래스로더에 의해 사용자가 작성한 클래스가 Method area(Class area, Static area)에 저장됩니다. Reflection API 는 이 정보를 활용합니다. 예시 # 아래는 Reflection API 를 사용한 예제입니다.\n// Reflection API 예제 Object obj = new Car(); Class carClass = Car.class; Method move = carClass.getMethod(\u0026#34;move\u0026#34;); // Returns a Method object that reflects the specified public member method of the class or interface represented by this Class object. move.invoke(obj, null); // Reflection API 예제 Class carClass = Class.forName(\u0026#34;Car\u0026#34;); // Returns the Class object associated with the class or interface with the given string name. 특징 # Reflection 은 실제 운영에서 사용 시 남용하여 사용하는 것은 지양하는 것이 좋습니다. (* 사용 시 주의가 필요합니다.)\n프레임워크나 라이브러리에서 많이 사용된다고 합니다. (어떤 클래스에 사용될 지 예측할 수 없기에 동적으로 해결해주어야 한다.)\n아래와 같은 곳에서 사용되고 있다고 합니다.\nIntellij 자동완성 jackson 라이브러리 SprinFramework\u0026rsquo;s BeanFactory Spring Data Jpa (e.g. Entity의 @NoArgsContsructor) 단점\n사용자가 잘못 사용했다는 전제 하에 아래와 같은 단점이 있을 수 있습니다. Reflection 자체가 나쁜 것이 아니라는 것에 주의해야 합니다.\n성능 오버헤드가 발생할 수 있습니다. 이유 : 런타임에 동적으로 클래스를 분석하고 정보를 가져오기 때문에 추상화가 깨질 수 있습니다. 이유 : private 변수, 메서드에 접근할 수 있게 되기 때문에 참고 # docs.oracle.com : Class Class\u0026lt;T\u0026gt; "},{"id":155,"href":"/docs/LANGUAGES/JAVA/JAVA-Stack/","title":"[JAVA] Stack","section":"JAVA","content":"Thread-safe\nVector 클래스 상속 push, size =\u0026gt; Vector 클래스의 메서드 사용 synchronized 키워드 사용 method level push() : (Vector) synchronized pop() : synchronized peek() : synchronized empty() : (Vector) synchronized search() : synchronized public class Stack\u0026lt;E\u0026gt; extends Vector\u0026lt;E\u0026gt; { ... public E push(E item) { addElement(item); // (Vector) synchronized return item; } // synchronized public synchronized E pop() { E obj; int len = size(); obj = peek(); removeElementAt(len - 1); return obj; } // synchronized public synchronized E peek() { int len = size(); if (len == 0) throw new EmptyStackException(); return elementAt(len - 1); } public boolean empty() { return size() == 0; // (Vector) synchronized } // synchronized public synchronized int search(Object o) { int i = lastIndexOf(o); // (Vector) synchronized if (i \u0026gt;= 0) { return size() - i; } return -1; } } "},{"id":156,"href":"/docs/LANGUAGES/JAVA/JAVA-Static-method-Overriding-Hiding/","title":"[JAVA] Static Method Overriding (Hiding)","section":"JAVA","content":" Static method Overriding # JVM은 메서드를 호출할 때, 객체 메서드(instance method)의 경우 (런타임 시에) 해당 메서드를 구현하고 있는 실제 객체를 찾아 호출한다.\n하지만 스태틱 메서드(static method)에 대해서는 실제 객체를 찾는 작업을 하지 않는다. 따라서 Static method의 경우 컴파일 시점에 선언된 타입의 메서드를 호출한다.\n즉 Static method 에 대해서는 오버라이딩이 적용되지 않는다. 또, 이때에는 Overriding이 아닌 Hiding 이라고 부른다고 한다.\n예시 코드 # public class A{ public static void test() { System.out.println(\u0026#34;A test()\u0026#34;); } } class B extends A{ public static void test() { System.out.println(\u0026#34;B test()\u0026#34;); } } public class Test { public static void main(String[] args) { A a = new B(); System.out.println(a.test()); // 출력: A test() B b = new B(); System.out.println(b.test()); } } 참고 # https://blog.naver.com/gngh0101/221206214829 https://hashcode.co.kr/questions/358/왜-자바에서-static메소드의-오버라이딩을-허용하지-않는걸까요 "},{"id":157,"href":"/docs/LANGUAGES/JAVA/Java-String/","title":"[Java] String","section":"JAVA","content":" contains() # public boolean contains(CharSequence s) { return this.indexOf(s.toString()) \u0026gt;= 0; } public static int indexOf(byte[] value, int valueCount, byte[] str, int strCount, int fromIndex) { byte first = str[0]; int max = valueCount - strCount; for(int i = fromIndex; i \u0026lt;= max; ++i) { if (value[i] != first) { do { ++i; } while(i \u0026lt;= max \u0026amp;\u0026amp; value[i] != first); } if (i \u0026lt;= max) { int j = i + 1; int end = j + strCount - 1; for(int k = 1; j \u0026lt; end \u0026amp;\u0026amp; value[j] == str[k]; ++k) { ++j; } if (j == end) { return i; } } } return -1; } 시작 인덱스부터 for-loop 탐색 시작 첫 글자 같다면, 검사 시작 중간에 틀리면 다시 2번부터 시작 같다면 시작 인덱스 반환 "},{"id":158,"href":"/docs/LANGUAGES/JAVA/JAVA-Throwable-Error-Exception/","title":"[JAVA] Throwable (Error, Exception)","section":"JAVA","content":" Throwable # \u0026quot; The Throwable class is the superclass of all errors and exceptions in the Java language. Only objects that are instances of this class (or one of its subclasses) are thrown by the Java Virtual Machine or can be thrown by the Java throw statement. Similarly, only this class or one of its subclasses can be the argument type in a catch clause. For the purposes of compile-time checking of exceptions, Throwable and any subclass of Throwable that is not also a subclass of either RuntimeException or Error are regarded as checked exceptions. \u0026ldquo;\n오직 Throwable, Throwable 의 하위 클래스만 JVM, Java 에 의해 던져질 수 있음 (can be thrown)\n오직 Throwable, Throwable 의 하위 클래스만 catch 문법에 사용될 수 있음\nError, RuntimeException 을 제외한 Throwable 의 하위클래스는 CheckedException\nCheckedException : 컴파일 시점에 Exception 체킹 목적으로 사용됨\nclass 임에 주의 (참고 : why is java.lang.Throwable a class?)\npublic class Throwable implements Serializable { ... } Error # 시스템(서버) 레벨, HW 레벨의 오류\n수습할 수 없는 심각한 문제\nVirtualMachineError OutOfMemoryError InternalError StackOverflowError UnknownError Exception # CheckedException # 예외 처리 필수\n컴파일 시 체크\nIOException InterruptedException ClassNotFoundException NoSuchMethodException NoSuchFieldException RuntimeException (UncheckedException) # NullPointerException ArithmeticException IllegalArgumentException NumberFormatException "},{"id":159,"href":"/docs/LANGUAGES/JAVA/JAVA-Valve-Tomcat/","title":"[JAVA] Valve (Tomcat)","section":"JAVA","content":" https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true\u0026blogId=gallechess\u0026logNo=221047184041\n"},{"id":160,"href":"/docs/LANGUAGES/KOTLIN/KOTLIN-Companion-object-+-static/","title":"[KOTLIN] Companion Object (+ Static)","section":"KOTLIN","content":" Java에서 \u0026lsquo;static\u0026rsquo;은 다양한 이유로 사용할 수 있다. \u0026lsquo;메모리 관리\u0026rsquo;를 위해 \u0026lsquo;공유\u0026rsquo;를 위해 (클래스 선언 정보와 함께 메모리 영역에 올라간다.) companion object # 코틀린에서는 static 키워드가 없다.\n이를 대체하기 위해 companion object 를 많이 사용한다.\n(다른 말로 표현하면) (companion) object 를 통해 조금 더 (OOP와 적절한 방식으로)구현할 수 있다.\n예시 코드 # class MyClass { companion object { fun doSomething() { } } } public final class MyClass { // 결국에 object 로 만들어서 사용하는 것인데, 이는 OOP 의 방향성에 아주 적절하다. // 이 부분이 매우 중요하다!! public static final MyClass.Companion Companion = new MyClass.Companion(null); public static final class Companion { public final void doSomething() { } private Companion() { } public Companion() { this(); } } } (kotlin에서) static 이 없는 이유? # \u0026lsquo;Singleton\u0026rsquo; object 로 구현할 수 있음\n(java) static 은 object 가 아님 (OOP의 방향성과 맞지 않음) (kotlin) 위의 예시 코드와 같이 (싱글톤)객체로 구현 가능 (추가적으로) static 은 모던 프로그래밍 언어에 적절하지 않다고 한다. 가독성/생산성 측면 (Productive-Oriented)\n(java) static 은 장황/지저분한 코드를 생산한다. (kotlin) object 구문의 사용은 이 문제를 해결한다. 조금 더 생산성, 가독성 측면에서 우수하다고 말한다. 참고 # Kotlin - companion object로 static 메소드, 객체 정의하기 [kotlin] Companion Object (1) - 자바의 static 과 같은 것인가? Why does Kotlin remove \u0026ldquo;static\u0026rdquo; keyword? "},{"id":161,"href":"/docs/LANGUAGES/KOTLIN/KOTLIN-Naming-Convetion/","title":"[KOTLIN] Naming Convetion","section":"KOTLIN","content":" Source code organization # Source file names # UpperCamelCase\nSource file organization # Placing multiple declarations (classes, top-level functions or properties) in the same Kotlin source file is encouraged as long as these declarations are closely related to each other semantically, and the file size remains reasonable (not exceeding a few hundred lines). In particular, when defining extension functions for a class which are relevant for all clients of this class, put them in the same file with the class itself. When defining extension functions that make sense only for a specific client, put them next to the code of that client. Avoid creating files just to hold all extensions of some class.\n요약\n모든 클래스에서 사용되는 \u0026lsquo;확장 함수\u0026rsquo; : 해당 클래스 내에 선언 일부 클래스에서 사용되는 \u0026lsquo;확장 함수\u0026rsquo; : 클라이언트 클래스 쪽에 선언 모든 확장함수에 대해 파일을 생성하는 것은 피할 것 Class layout (order) # Property declarations (Initializer blocks) Secondary constructors Method declarations Companion Object Do not sort the method declarations alphabetically or by visibility, and do not separate regular methods from extension methods. Instead, put related stuff together, so that someone reading the class from top to bottom can follow the logic of what\u0026rsquo;s happening. Choose an order (either higher-level stuff first, or vice versa) and stick to it.\nPut nested classes next to the code that uses those classes. If the classes are intended to be used externally and aren\u0026rsquo;t referenced inside the class, put them in the end, after the companion object.\n요약\nProperty (초기화 블록) (Secondary) 생성자 Method Companion 객체 메서드 작성 시, \u0026lsquo;알파벳\u0026rsquo;, \u0026lsquo;접근제어자\u0026rsquo; 순으로 작성 X \u0026lsquo;관계가 있는\u0026rsquo; 메서드 순으로 작성 (자연스럽게 로직을 이해할 수 있게) 해당 클래스를 사용하는 코드 옆에 중첩 클래스 배치 (??) 클래스가 외부에서 사용되도록 의도되고 클래스 내부에서 참조되지 않는 경우 : Companion 객체 뒤에 작성 Interface implementation layout # When implementing an interface, keep the implementing members in the same order as members of the interface (if necessary, interspersed with additional private methods used for the implementation).\n요약\n인터페이스, 구현체의 작성 순서 : 동일 Overload layout # Always put overloads next to each other in a class.\n요약\n\u0026lsquo;오버로딩\u0026rsquo;은 붙여서 작성 Naming rules # Package \u0026amp; Class # Names of packages are always lowercase and do not use underscores (org.example.project). Using multi-word names is generally discouraged, but if you do need to use multiple words, you can either just concatenate them together or use camel case (org.example.myProject).\nNames of classes and objects start with an uppercase letter and use camel case.\n요약\n패키지 : lowercase 복수 단어 사용 시 : (1)붙여쓰거나, (2)lowerCamelCase 단, 최대한 복수 단어 사용을 피하자. 클래스(객체) : UpperCamelCase Function names # Names of functions, properties and local variables start with a lowercase letter and use camel case and no underscores.\nException: factory functions used to create instances of classes can have the same name as the abstract return type.\n요약\nFunction \u0026amp; Property \u0026amp; Local variable : lowerCamelCase 단, (객체를 생성하는)팩토리 메서드 : 그 클래스와 동일한 이름을 가질 수 있음 (??) interface Foo { /*...*/ } class FooImpl : Foo { /*...*/ } fun Foo(): Foo { return FooImpl() } Names for test methods # In tests (and only in tests), you can use method names with spaces enclosed in backticks. Note that such method names are currently not supported by the Android runtime. Underscores in method names are also allowed in test code.\n요약\n(` 으로 감싼) 공백 가능 underscore 허용 Property names # Names of constants (properties marked with const, or top-level or object val properties with no custom get function that hold deeply immutable data) should use uppercase underscore-separated (screaming snake case) names.\nconst val MAX_COUNT = 8 val USER_NAME_FIELD = \u0026#34;UserName\u0026#34; Names of top-level or object properties which hold objects with behavior or mutable data should use camel case names:\nval mutableCollection: MutableSet\u0026lt;String\u0026gt; = HashSet() Names of properties holding references to singleton objects can use the same naming style as object declarations.\nval PersonComparator: Comparator\u0026lt;Person\u0026gt; = /*...*/ For enum constants, it\u0026rsquo;s OK to use either uppercase underscore-separated names (screaming snake case) (enum class Color { RED, GREEN }) or upper camel case names, depending on the usage.\n요약\n상수(const + val, val) : UPPER_CASE (underscore-separated) Mutable 객체, 속성 : lowerCamelCase (??) Singleton 객체 : UperCamelCase (??) ENUM UPPER CASE(underscore-separated) UPPER CAMEL CASE Names for backing properties # If a class has two properties which are conceptually the same but one is part of a public API and another is an implementation detail, use an underscore as the prefix for the name of the private property.\nclass C { private val _elementList = mutableListOf\u0026lt;Element\u0026gt;() val elementList: List\u0026lt;Element\u0026gt; get() = _elementList } 요약\n(하나의 이름으로) public API, 속성 사용 : (private) 속성 이름 앞에 _(underscore) 사용 (prefix) 그 외 (Formatting, Documentation comments, Avoid redundant constructs, Idiomatic use of language features, \u0026hellip;)\n"},{"id":162,"href":"/docs/LANGUAGES/KOTLIN/KOTLIN-Nullable-types-and-non-null-types/","title":"[KOTLIN] Nullable Types and Non-Null Types","section":"KOTLIN","content":" 코틀린에서는 nullable, non-nullable 타입을 구분하여 사용한다. # non-nullable # var a: String = \u0026#34;abc\u0026#34; a = null // X : 불가능 (컴파일 오류 발생) 변수 a 에는 non-null 이 보장되기에 아래와 같은 문법 사용 가능하다.\nprintln(a.length) // O nullable # var a: String? = \u0026#34;abc\u0026#34; a = null // O : 가능 변수 a 에는 non-null 이 보장되지 않기에 아래와 같은 문법 사용 불가능하다.\nprintln(a.length) // X : 불가능 (컴파일 오류 발생) 아래(nullable) 예시의 경우, property 를 접근/사용하기 위한 3가지 방법이 있다. # 1. 명시적 null 체크 # println(if (a != null) a.length else 0) // 출력 : 0 [참고] if else 구문은 ?:(Elvis Operator) 로 대체할 수 있다.\n// println(if (a != null) a.length else 0) println(a?.length ?: 0) 2. Safe calls(?.) # // a 가 // null : null // non-null : a.length println(a?.length) // 출력 : null [참고] safe call 의 경우 아래와 같이 chain 형태로 유용하게 사용할 수 있다.\nperson?.department?.head?.name [참고] \u0026ldquo;safe call(non-null 보장) + 로직 수행\u0026rdquo; 을 위해, let 을 사용할 수 있다.\na?.let { println(\u0026#34;hi\u0026#34;) } [참고] safe call 의 경우, assignment 위치에서 사용하는 것도 가능하다.\nnull 이 포함되면 assignment 는 생략된다. 표현식(함수)의 경우, 실행되지 않음에 주의한다. person?.department?.head = managersPool.getManager() // person, department 중 하나가 null 인 경우 getManager() 은 실행되지 않는다. 3. Not-null assertion operator !! # non-null type 컨버팅 단, null 일 경우 NPE 발생 // a!! 는 String? 을 String 으로 컨버팅한다. // 단, a 가 null 인 경우 NPE 발생한다. println(a!!.length) [기타] Safe casts # Safe cast 통해 ClassCastException 대신 null 을 반환할 수 있다.\n타입 캐스팅 시 잘못된 타입일 경우 → ClassCastException 발생\nnull 인 경우, NPE 발생\n예시 : \u0026ldquo;null cannot be cast to non-null type kotlin.Int\u0026rdquo;\n// 잘못된 타입인 경우, null 반환 val aInt: Int? = a as? Int [기타] Collections of a nullable type # nullable 요소를 가진 컬렉션의 경우, null 과 관련된 처리를 할 수 있는 여러 함수가 있다.\nval nullableList: List\u0026lt;Int?\u0026gt; = listOf(1, 2, null, 4) val intList: List\u0026lt;Int\u0026gt; = nullableList.filterNotNull() 참고 # https://kotlinlang.org/docs/null-safety.html#safe-casts "},{"id":163,"href":"/docs/LANGUAGES/KOTLIN/KOTLIN-Scope-Functions/","title":"[KOTLIN] Scope Functions","section":"KOTLIN","content":"(객체의 컨텍스트 내에서) 임시 scope 를 생성하여 코드 블록(일련의 코드들)을 실행하기 위한 기능\n다음과 같이 5개의 범위 함수(scope function)가 존재한다. # 공식 문서 - scope-functions/function-selection\nFunction Object reference Return value Is extension function? (TIP) 선택 기준 let it Lambda result O 1. non-null 객체의 lambda 실행 시 2. local 범위의 변수로 표현식 사용 시 run this Lambda result O 1. 객체 configuration + result 계산(반환) run - Lambda result X called without the context object 1. 표현식 실행 (Running statements where an expression is required) with this Lambda result X takes the context object as an argument 1. 객체에 대한 그루핑(연관된 여러 개의 함수?) 함수 호출 (Grouping function calls on an object) apply this Context object O 1. 객체 configuration (Object configuration) also it Context object O 1. 추가적인 효과(코드)를 부여할 때 공통점 # \u0026lsquo;하나의 객체로 코드 블록(일련의 코드들)을 실행\u0026rsquo;한다는 것 (간결성, 가독성 향상) 차이점 # 범위 함수들이 각자 비슷하기 때문에 차이를 알아두는 것 중요\n블록 내에서 객체를 사용하는 방식 (The way to refer to the context object.) it : as a lambda argument this : as a lambda receiver 전체 표현식의 결과 (The return value.) 주의점 # 범위 함수(scope function) 의 사용 여부, 사용 기준은 각자의 회사/팀에서 결정하여 적절히 사용하면 된다. \u0026lsquo;남용\u0026rsquo; 피한다. \u0026lsquo;중첩 사용\u0026rsquo;은 피한다. (\u0026lsquo;체이닝\u0026rsquo; 시 주의한다.) 사용 예시를 살펴보자. # // 일반 코드 (without scope function) val person = Person(\u0026#34;name\u0026#34;, 20, \u0026#34;city\u0026#34;) println(person) person.incrementAge() // 20 -\u0026gt; 21 person.moveTo(\u0026#34;newCity\u0026#34;) // city -\u0026gt; newCity println(person) // 수정 코드 (with scope function) val person = Person(\u0026#34;name\u0026#34;, 20, \u0026#34;city).let { println(it) it.incrementAge() // 20 -\u0026gt; 21 it.moveTo(\u0026#34;newCity\u0026#34;) // city -\u0026gt; newCity println(it) } it vs this # 둘 다 동일한 기능을 제공한다. 특징(장단점)을 비교하여 사용하자. this # lambda receiver run, with, apply 와 함께 사용된다. this 키워드는 생략할 수 있다. 따라서, 객체 자신에 대해 특정 작업을 수행할 필요가 있을 때 사용하는 것이 권장된다. this 생략 시, 다른 외부 변수와 헷갈릴 수 있으니 사용에 주의하자. val adam = Person(\u0026#34;Adam\u0026#34;).apply { city = \u0026#34;London\u0026#34; age = 20 // \u0026#39;age = 20\u0026#39; 은 다음과 동일하다. // this.age = 20 // adam.age = 20 } println(adam) it # lambda argument (argument 의 이름이 지정되지 않으면 기본적으로 \u0026lsquo;it\u0026rsquo; 를 사용) let, also 와 함께 사용된다. However, when calling the object functions or properties you don\u0026rsquo;t have the object available implicitly like this. Hence, having the context object as it is better when the object is mostly used as an argument in function calls. it is also better if you use multiple variables in the code block. fun getRandomInt(): Int { return Random.nextInt(100).also { writeToLog(\u0026#34;getRandomInt() generated value $it\u0026#34;) } } val i = getRandomInt() println(i) Return Value # 아래를 기억하고, 사용/결정하자.\napply, also : return the context object let, run, with : return the lambda result Context object (apply, also) # 객체 자신을 반환한다 = 체이닝 가능 // 예시 : 체이닝 가능하다. val numberList = mutableListOf\u0026lt;Double\u0026gt;() numberList.also { println(\u0026#34;Populating the list\u0026#34;) } .apply { add(2.71) add(3.14) add(1.0) } .also { println(\u0026#34;Sorting the list\u0026#34;) } .sort() // 예시 : return (\u0026amp; assignment) 가능하다. fun getRandomInt(): Int { return Random.nextInt(100).also { writeToLog(\u0026#34;getRandomInt() generated value $it\u0026#34;) } } val i = getRandomInt() // Ex: 54 Lambda result # return value 를 사용하지 않을 수 있다. (무시 OK) // 에시 val numbers = mutableListOf(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;) val countEndsWithE = numbers.run { add(\u0026#34;four\u0026#34;) add(\u0026#34;five\u0026#34;) count { it.endsWith(\u0026#34;e\u0026#34;) } } println(\u0026#34;There are $countEndsWithE elements that end with e.\u0026#34;) // [출력] // There are 3 elements that end with e. // 예시 : ignore the return value val numbers = mutableListOf(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;) with(numbers) { val firstItem = first() val lastItem = last() println(\u0026#34;First item: $firstItem, last item: $lastItem\u0026#34;) } // [출력] // First item: one, last item: three Functions # let # 기능 사용 가능 여부 conext object O : it return value O : lambda result 1. (체이닝의 결과)연산 결과에 하나 이상의 함수를 호출하기 위해 사용될 수 있다. \u0026quot;let can be used to invoke one or more functions on results of call chains.\u0026quot;\n2. non-null 변수와 함께 코드 블록(몇몇의 코드들)을 호출하기 위해 사용될 수 있다. \u0026quot;let is often used for executing a code block only with non-null values\u0026quot;\n3. it 대신 (가독성을 위해)다른 변수명을 사용할 수 있다.\n/** 예시 : without let */ val numbers = mutableListOf(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;, \u0026#34;four\u0026#34;, \u0026#34;five\u0026#34;) val resultList = numbers.map { it.length }.filter { it \u0026gt; 3 } println(resultList) /** 예시 : with let */ val numbers = mutableListOf(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;, \u0026#34;four\u0026#34;, \u0026#34;five\u0026#34;) numbers.map { it.length }.filter { it \u0026gt; 3}.let { println(it) } /** 예시 : non-null 체크 */ val str: String? = \u0026#34;Hello\u0026#34; //processNonNullString(str) // → compilation error: str can be null val length = str?.let { println(\u0026#34;let() called on $it\u0026#34;) processNonNullString(it) // OK: \u0026#39;it\u0026#39; is not null inside \u0026#39;?.let { }\u0026#39; it.length } with # 기능 사용 가능 여부 conext object O : this return value O : lambda result 확장함수 X 1. return 없이 객체에 코드 블록(호출/처리들)을 수행하기 위해 사용하는 것을 권장한다. \u0026quot; We recommend with for calling functions on the context object without providing the lambda result. \u0026ldquo;\nval numbers = mutableListOf(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;) with(numbers) { println(\u0026#34;\u0026#39;with\u0026#39; is called with argument $this\u0026#34;) println(\u0026#34;It contains $size elements\u0026#34;) } run # 기능 사용 가능 여부 conext object O : this return value O : lambda result 1. 객체 초기화 / 결과 값(return value) 계산 시 사용하는 것을 권장한다.\n\u0026rdquo; run is useful when your lambda contains both the object initialization and the computation of the return value. \u0026ldquo;\nval service = MultiportService(\u0026#34;https://example.kotlinlang.org\u0026#34;, 80) val result = service.run { port = 8080 query(prepareRequest() + \u0026#34; to port $port\u0026#34;) } // the same code written with let() function: val letResult = service.let { it.port = 8080 it.query(it.prepareRequest() + \u0026#34; to port ${it.port}\u0026#34;) } 확장 함수 / non-확장 함수 관련된 내용에 대해서는 다시 확인해볼 것 https://kotlinlang.org/docs/scope-functions.html#run\napply # 기능 사용 가능 여부 conext object O : this return value O : context object 1. 결과 값(return value)을 반환하지 않고, 객체 속성에 대해 작업이 필요할 때 사용하는 것을 권장한다. \u0026rdquo; Use apply for code blocks that don\u0026rsquo;t return a value and mainly operate on the members of the receiver object. \u0026ldquo;\nval adam = Person(\u0026#34;Adam\u0026#34;).apply { age = 32 city = \u0026#34;London\u0026#34; } println(adam) // Person(name=Adam, age=32, city=London) also # 기능 사용 가능 여부 conext object O : it return value O : context object 1. 객체를 받아 (객체에 대한 작업이 아닌) 작업들을 수행할 때 사용하는 것 권장한다. \u0026rdquo; Use also for actions that need a reference to the object rather than its properties and functions, or when you don\u0026rsquo;t want to shadow the this reference from an outer scope. \u0026ldquo;\nval numbers = mutableListOf(\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, \u0026#34;three\u0026#34;) numbers.also { println(\u0026#34;The list ... $it\u0026#34;) }.add(\u0026#34;four\u0026#34;) // The list ... [one, two, three] println(numbers) // [one, two, three, four] takeIf, takeUnless # [요약] \u0026lsquo;객체 반환\u0026rsquo; or \u0026rsquo;null 반환\u0026rsquo; (← Predicate) 객체 참조 : it 변수 사용 범위 함수(scope function) 외 에, 표준 라이브러리 takeIf, takeUnless 가 있다. 1. 객체에 대한 값 확인/체크가 필요할 때 주로 사용된다.\n2. nullable 이기에, 이후 로직에서 safe call 등의 널 체크 필요하다.\n3. let 함수와 같이 사용하는 유스케이스가 많다.\n4. it (lambda argument) 값으로 객체 참조한다.\n반환 값 Predicate 객체 반환 takeIf : true takeUnless : false null 반환 takeIf : false takeUnless : true val number = Random.nextInt(100) val evenOrNull = number.takeIf { it % 2 == 0 } val oddOrNull = number.takeUnless { it % 2 == 0 } println(\u0026#34;even : $evenOrNull\u0026#34;) println(\u0026#34;odd : $oddOrNull\u0026#34;) // 예시 : safe call val str = \u0026#34;Hello\u0026#34; val caps = str.takeIf { it.isNotEmpty() }?.uppercase() //val caps = str.takeIf { it.isNotEmpty() }.uppercase() //compilation error println(caps) // 예시 : let 조합 fun displaySubstringPosition(input: String, sub: String) { input.indexOf(sub).takeIf { it \u0026gt;= 0 }?.let { println(input) println(it) } } displaySubstringPosition(\u0026#34;010000011\u0026#34;, \u0026#34;11\u0026#34;) displaySubstringPosition(\u0026#34;010000011\u0026#34;, \u0026#34;12\u0026#34;) // 예시 : 위 코드(let 조합)를 일반적으로 작성했을 경우 fun displaySubstringPosition(input: String, sub: String) { val index = input.indexOf(sub) if (index \u0026gt;= 0) { println(input) println(it) } } displaySubstringPosition(\u0026#34;010000011\u0026#34;, \u0026#34;11\u0026#34;) displaySubstringPosition(\u0026#34;010000011\u0026#34;, \u0026#34;12\u0026#34;) 참고 # https://kotlinlang.org/docs/scope-functions.html "},{"id":164,"href":"/docs/LANGUAGES/PHP/PHP-CodeIgniter-Library-%EB%A1%9C%EB%94%A9/","title":"[PHP] CodeIgniter Library 로딩","section":"PHP","content":" 이번 글은 CodeIgniter 2.x 기준으로 작성된 글이며, 커스터마이징 되어 있는 부분이 있기에 일반적인 상황과 조금은 다를 수 있습니다.\n개요 # (팀에서) PHP 프레임워크 CodeIgniter(2.x, 3.x)를 사용하고 있다.\nCodeIgniter는 MVC 패턴으로, 대부분이 그렇듯 controller 는 client 의 요청을 받고, view 는 화면 노출을 위해 사용되며 model 은 DB I/O 역할을 수행한다.\n여기에 추가로 Library 라는 개념(디렉터리 구조에 포함)이 있다. Library 는 말그대로 공통으로 사용될 기능들에 대한 클래스(library)를 만들어두고 사용하기 위해 존재한다.\n예를 들어 아래와 같이 사용한다.\n// github_library 라는 라이브러리가 있다고 가정한다. $this-\u0026gt;load-\u0026gt;library(\u0026#34;github_library\u0026#34;); $this-\u0026gt;github_library-\u0026gt;commit(); $this-\u0026gt;github_library-\u0026gt;pull(); ... 일반적으로 위와 같이 사용하는데, 이 library 에 아래와 같이 alias 를 적용시켜 사용할 수도 있다.\n// $this-\u0026gt;load-\u0026gt;library(library파일명(경로), library 생성자 데이터, Alias) $this-\u0026gt;load-\u0026gt;library(\u0026#34;github_library\u0026#34;, $constructParameter, \u0026#34;github\u0026#34;) $this-\u0026gt;github-\u0026gt;commit(); $this-\u0026gt;github-\u0026gt;pull(); 프로젝트마다 컨벤션(camelCase, snake_case)이 조금씩 다르다. 그래서 alias 를 걸어 사용할 수 있다.\n문제 # 그런데 우연히 아래와 같은 오류를 만났다.\nalias 와 함께 로드 alias 없이 로드 // A.class $this-\u0026gt;load-\u0026gt;library(\u0026#34;github_library\u0026#34;, $constructParameter, \u0026#34;github\u0026#34;); $this-\u0026gt;github-\u0026gt;pull(); ... // B.class $this-\u0026gt;load-\u0026gt;library(\u0026#34;github_library\u0026#34;); $this-\u0026gt;github_library-\u0026gt;pull(); // \u0026lt;-- 오류(Null) 발생 A class 에서 github_library에 alias 를 걸어 사용했고, 이후에 동작한 B class 에서는 alias 를 걸지 않은 상태였다. 그런데 B class 에서 load 한 github_library를 null 로 인식하고 오류를 발생시켰다.\n파일명을 잘못 작성한건지, 오타를 낸건지, 실수한 부분이 있는 줄 알고 한참을 확인했다. 그러다 혹시나해서 B class에서 $this-\u0026gt;github-\u0026gt;pull() 과 같이 작성하고 동작시켜봤는데, 잘 동작했다.(\u0026hellip;?)\nCodeIgniter 가 기본적으로 싱글톤 패턴으로 동작하기 때문이라고 보기엔 조금 애매했다. 아래와 같은 코드는 동작했기 때문이다.\nalias 없이 로드 alias 와 함께 로드 // A.class $this-\u0026gt;load-\u0026gt;library(\u0026#34;github_library\u0026#34;); $this-\u0026gt;github_library-\u0026gt;pull(); ... // B.class $this-\u0026gt;load-\u0026gt;library(\u0026#34;github_library\u0026#34;, $constructParameter, \u0026#34;github\u0026#34;); $this-\u0026gt;github-\u0026gt;pull(); // 정상 동작! Codeigniter 에서는 libary 를 어떻게 load 할까? # Codeigniter 에서는 최상단에 하나의 Global Instance 가 있다. (Spring 의 컨테이너 개념과 유사) 이 object에 library, model, 각종 class 들을 property로 주입(?)시켜 사용하는 개념이다. Global Instance 는 $this 변수로 접근할 수 있어서 위의 예시처럼 $this-\u0026gt;github 과 같이 사용할 수 있는 것이다.\n일단 CodeIgniter 의 global instance 를 출력해봤다. 내용이 정말 많았지만 그 중 github 은 (global instance의)property로 잡혀있는데 github_library 는 propery 로 잡혀있지 않은 것을 확인할 수 있었다.\nIndex Object ( ... [github] =\u0026gt; github_Library Object ( ... ) ... ) github_library property 가 없는 것을 확인하고 codeigniter 에서 library 를 어떻게 load 하는지 바로 확인했다.\ncore/Loader.php 쪽의 코드를 살펴보면, library() 메서드가 있는 것을 확인할 수 있다.\n... public function library($library, $params = NULL, $object_name = NULL) { if (empty($library)) { return $this; } elseif (is_array($library)) { foreach ($library as $key =\u0026gt; $value) { if (is_int($key)) { $this-\u0026gt;library($value, $params); } else { $this-\u0026gt;library($key, $params, $value); } } return $this; } if ($params !== NULL \u0026amp;\u0026amp; ! is_array($params)) { $params = NULL; } $this-\u0026gt;_ci_load_library($library, $params, $object_name); return $this; } library() 메서드에서 다시 _ci_load_library 메서드가 동작하는 것을 알 수 있다.\n_ci_load_library() 메서드를 살펴보자.\nprotected function _ci_load_library($class, $params = NULL, $object_name = NULL) { // Get the class name, and while we\u0026#39;re at it trim any slashes. // The directory path can be included as part of the class name, // but we don\u0026#39;t want a leading slash $class = str_replace(\u0026#39;.php\u0026#39;, \u0026#39;\u0026#39;, trim($class, \u0026#39;/\u0026#39;)); // Was the path included with the class name? // We look for a slash to determine this if (($last_slash = strrpos($class, \u0026#39;/\u0026#39;)) !== FALSE) { // Extract the path $subdir = substr($class, 0, ++$last_slash); // Get the filename from the path $class = substr($class, $last_slash); } else { $subdir = \u0026#39;\u0026#39;; } $class = ucfirst($class); ... } 위의 전체 코드는 GitHub 에서 확인할 수 있습니다.\n현재 회사에서는 (버전, 커스터마이징에 의해) 위의 내용과는 약간 다르다. 실제 소스는 아래의 형태와 같다.\nprotected function _ci_load_library($class, $params = NULL, $object_name = NULL) { // Get the class name, and while we\u0026#39;re at it trim any slashes. // The directory path can be included as part of the class name, // but we don\u0026#39;t want a leading slash $class = str_replace(\u0026#39;.php\u0026#39;, \u0026#39;\u0026#39;, trim($class, \u0026#39;/\u0026#39;)); // Was the path included with the class name? // We look for a slash to determine this $subdir = \u0026#39;\u0026#39;; if (($last_slash = strrpos($class, \u0026#39;/\u0026#39;)) !== FALSE) { // Extract the path $subdir = substr($class, 0, $last_slash + 1); // Get the filename from the path $class = substr($class, $last_slash + 1); } ... foreach ($this-\u0026gt;_ci_library_paths as $path) { $filepath = $path.\u0026#39;libraries/\u0026#39;.$subdir.$class.\u0026#39;.php\u0026#39;; if ( ! file_exists($filepath)) { continue; } // Safety: Was the class already loaded by a previous call? if (in_array($filepath, $this-\u0026gt;_ci_loaded_files)) { // Before we deem this to be a duplicate request, let\u0026#39;s see // if a custom object name is being supplied. If so, we\u0026#39;ll // return a new instance of the object if ( ! is_null($object_name)) { $CI =\u0026amp; get_instance(); if ( ! isset($CI-\u0026gt;$object_name)) { return $this-\u0026gt;_ci_init_library($class, \u0026#39;\u0026#39;, $params, $object_name); } } $is_duplicate = TRUE; log_message(\u0026#39;debug\u0026#39;, $class.\u0026#34; class already loaded. Second attempt ignored.\u0026#34;); return; } include_once($filepath); $this-\u0026gt;_ci_loaded_files[] = $filepath; return $this-\u0026gt;_ci_init_library($class, \u0026#39;\u0026#39;, $params, $object_name); } ... 위의 코드에서 핵심인 부분이 있다.\n$filepath = $path.\u0026#39;libraries/\u0026#39;.$subdir.$class.\u0026#39;.php\u0026#39;; ... if (in_array($filepath, $this-\u0026gt;_ci_loaded_files)) { // Before we deem this to be a duplicate request, let\u0026#39;s see // if a custom object name is being supplied. If so, we\u0026#39;ll // return a new instance of the object if ( ! is_null($object_name)) { $CI =\u0026amp; get_instance(); if ( ! isset($CI-\u0026gt;$object_name)) { return $this-\u0026gt;_ci_load_library($class, \u0026#39;\u0026#39;, $params, $object_name); } } $is_duplicate = TRUE; log_message(\u0026#39;debug\u0026#39;, $class.\u0026#34; class already loaded. Second attempt ignored.\u0026#34;); return; } library의 파일명(경로)을 기준으로 ($this-\u0026gt;_ci_loaded_files)이미 로드된 것인지 아닌지 판단한다.\n여기서 $object_name 이 바로 alias 인데, alias 값이 있으면 global instance 에 해당 alias로 propery가 설정되어 있는지 체크하고, 없다면 load 한다. ($this-\u0026gt;_ci_load_library($class, '', $params, $object_name))\n그런데 $object_name 이 없으면, object 의 property 를 검사하지 않고 중복된 선언이라며 log 를 남긴고 끝내버린다. (log_message('debug', $class.\u0026quot; class already loaded. Second attempt ignored.\u0026quot;);)\n그렇기 때문에, 아래와 같은 상황이 발생할 수 있다.\n// [CASE1] // (1) alias load // (2) alias 없이 load // 두 번째로 load 한 Lib_test 는 무시된다. $this-\u0026gt;load-\u0026gt;library(\u0026#34;Lib_test\u0026#34;, null, \u0026#34;test\u0026#34;); $this-\u0026gt;load-\u0026gt;library(\u0026#34;Lib_test\u0026#34;); print_r($this-\u0026gt;lib_test-\u0026gt;getHi()); // 에러!! // LOG DEBUG - 2021-07-19 21:41:21 --\u0026gt; ... DEBUG - 2021-07-19 21:41:21 --\u0026gt; Lib_test class already loaded. Second attempt ignored. DEBUG - 2021-07-19 21:41:21 --\u0026gt; ... // [CASE2] // (1) alias 없이 load // (2) alias load // 두 개의 library 모두 global instance 의 property 로 설정된다. $this-\u0026gt;load-\u0026gt;library(\u0026#34;Lib_test\u0026#34;); $this-\u0026gt;load-\u0026gt;library(\u0026#34;Lib_test\u0026#34;, null, \u0026#34;test\u0026#34;); print_r($this-\u0026gt;lib_test-\u0026gt;getHi()); // 정상!! // LOG DEBUG - 2021-07-19 21:43:24 --\u0026gt; ... 해결 방법 # 1. core/Loader.php 코드 수정\n현재 버전에서는 위와 같은 문제는 해결된 것으로 보여진다. ( GitHub)\n2. 컨벤션 통일\nalias를 모두 사용하거나, alias를 모두 사용하지 않는다는 컨벤션을 적용할 수 있다면, 더 효과적으로 속성(property)을 관리할 수 있을 것이다.\n예를 들어, 위의 예시는 결국 동일한 클래스를 2번 로딩/주입하는 것이기 때문이다.\n다만, 레거시 프로젝트의 특성상 이전부터 컨벤션이 적용되어 오지 않았기 때문에 이를 모두 수정하는 작업은 쉽지 않다.\n"},{"id":165,"href":"/docs/LANGUAGES/PHP/PHP-CodeIgniter-xss_clean/","title":"[PHP] CodeIgniter Xss_clean","section":"PHP","content":" CodeIgniter xss_clean() 메서드 살펴보기\n개요 # 오픈소스에서 제공하는 xss_clean() 메서드를 사용하고 있는데, 오탐으로 인해 사용자가 입력한 데이터가 변경되어 문제가 발생했다.\n문제가 발생한 문자열은 아래와 같다.\n원본 데이터\n... HgrSLy0VBO71Kjbr3Co7h76WU0QB1rVT61QGGT5/M/9pPf/muYF3eSdTkxDOZkXZT8vFUwbZiUyX BGVvMC1epaCn329BFB4G3B+gJPa5k2OjlfogcT0jYWA0sUe1O/7bmW6sEfMwoTqh/VbGQLc/Eawz mB8+Oxgvkhri175eT62jHhCKyseBKZU4JvyOLNzyMh4g3UU6TkuzKdLdc2Lmk4uEDT5qOs2Kkqnf KuJyrG3L5oNFuRw= -----END NEW CERTIFICATE REQUEST----- 변경된 데이터\n... HgrSLy0VBO71Kjbr3Co7h76WU0QB1rVT61QGGT5/M/9pPf/muYF3eSdTkxDOZkXZT8vFUwbZiUyX BGVvMC1epaCn329BFB4G3B+gJPa5k2OjlfogcT0jYWA0sUe1O/7bmW6sEfMwoTqh/VbGQLc/Eawz mB8+Oxgvkhri175eT62jHhCKyseBKZU4JvyOLNzyMh4g3UU6TkuzKdLdc2Lmk4uEDT5qOs2Kkqnf KuJyrG3L5 NEW CERTIFICATE REQUEST----- xss_clean() 살펴보기 # xss_clean 메서드가 어떻게 구현되어 있는지 살펴보기 위해 상속하고 있는 클래스를 따라가본다.\nA Class ---\u0026gt; MYRest_Controller ---\u0026gt; REST_Controller ---\u0026gt; CI_Controller\nclass A extends MYRest_Controller { ... public function method1() { try { $data = $this-\u0026gt;post(\u0026#39;data\u0026#39;, true, true); ... class MYRest_Controller { ... public function post($key = NULL, $xss_clean = TRUE, $required = FALSE, $type = FALSE){ $rs = parent::post($key, $xss_clean); ... } } class REST_Controller { ... public function post($key = NULL, $xss_clean = TRUE) { if ($key === NULL) { return $this-\u0026gt;_post_args; } return array_key_exists($key, $this-\u0026gt;_post_args) ? $this-\u0026gt;_xss_clean($this-\u0026gt;_post_args[$key], $xss_clean) : FALSE; } ... } class REST_Controller { ... protected function _xss_clean($val, $process) { if (CI_VERSION \u0026lt; 2) { return $process ? $this-\u0026gt;input-\u0026gt;xss_clean($val) : $val; } return $process ? $this-\u0026gt;security-\u0026gt;xss_clean($val) : $val; // \u0026lt;-- 여기 } ... } 끝가지 올라가보면, security 클래스(라이브러리)의 xss_clean 메서드가 실행되는 것을 알 수 있다.\nclass Security { ... public function xss_clean($str, $is_image = FALSE) { ... // Remove evil attributes such as style, onclick and xmlns $str = $this-\u0026gt;_remove_evil_attributes($str, $is_image); ... return $str; } ... } 실제로는 내용이 무척 긴 데, Z살펴봐야할 부분은 _remove_evil_attributes() 부분이다.\n$str = $this-\u0026gt;_remove_evil_attributes($str, $is_image); class Security { ... protected function _remove_evil_attributes($str, $is_image) { // All javascript event handlers (e.g. onload, onclick, onmouseover), style, and xmlns $evil_attributes = array(\u0026#39;on\\w*\u0026#39;, \u0026#39;style\u0026#39;, \u0026#39;xmlns\u0026#39;, \u0026#39;formaction\u0026#39;); ... do { $count = 0; $attribs = array(); // find occurrences of illegal attribute strings with quotes (042 and 047 are octal quotes) preg_match_all(\u0026#39;/(\u0026#39;.implode(\u0026#39;|\u0026#39;, $evil_attributes).\u0026#39;)\\s*=\\s*(\\042|\\047)([^\\\\2]*?)(\\\\2)/is\u0026#39;, $str, $matches, PREG_SET_ORDER); foreach ($matches as $attr) { $attribs[] = preg_quote($attr[0], \u0026#39;/\u0026#39;); } // find occurrences of illegal attribute strings without quotes preg_match_all(\u0026#39;/(\u0026#39;.implode(\u0026#39;|\u0026#39;, $evil_attributes).\u0026#39;)\\s*=\\s*([^\\s\u0026gt;]*)/is\u0026#39;, $str, $matches, PREG_SET_ORDER); foreach ($matches as $attr) { print_r($attr[0]); $attribs[] = preg_quote($attr[0], \u0026#39;/\u0026#39;); } // replace illegal attribute strings that are inside an html tag if (count($attribs) \u0026gt; 0) { $str = preg_replace(\u0026#39;/(\u0026lt;?)(\\/?[^\u0026gt;\u0026lt;]+?)([^A-Za-z\u0026lt;\u0026gt;\\-])(.*?)(\u0026#39;.implode(\u0026#39;|\u0026#39;, $attribs).\u0026#39;)(.*?)([\\s\u0026gt;\u0026lt;]?)([\u0026gt;\u0026lt;]*)/i\u0026#39;, \u0026#39;$1$2 $4$6$7$8\u0026#39;, $str, -1, $count); } } while ($count); return $str; } ... } 여기서도 핵심 부분은 아래 부분이다.\npreg_match_all(\u0026#39;/(\u0026#39;.implode(\u0026#39;|\u0026#39;, $evil_attributes).\u0026#39;)\\s*=\\s*([^\\s\u0026gt;]*)/is\u0026#39;, $str, $matches, PREG_SET_ORDER); 위의 코드를 조금 간단하게 살펴보면 아래와 같다.\npreg_match((on\\w*)\\s*=\\s*([^\\s\u0026gt;]*), $str); 더 간략하게 하면 아래와 같고, 이 부분에 걸린 것을 알 수 있다.\n`(on\\w*)\\s*=\\s*([^\\s\u0026gt;]*)` = `(on\\w*)=\\s*([^\\s]*)` = `(on\\w*)=\\s.*` "},{"id":166,"href":"/docs/LANGUAGES/PHP/PHP-Function-Return-Type/","title":"[PHP] Function Return Type","section":"PHP","content":"PHP7부터 function 에 return type 을 명시할 수 있다.\nfunction isTrue(): bool { return true; } \u0026lsquo;function 내부의 return 값\u0026rsquo; 과 \u0026lsquo;명시된 type\u0026rsquo; 이 다를 경우 # (암묵적으로) function 내부의 return 값의 타입을 변환한다.\nfunction isTrue(): bool { return 1; } var_dump(isTrue()); // 출력: bool(true) declare(strict_types=1); 선언을 통해 위와 같은 암묵적인 변환을 막을 수도 있다. 즉, 엄격하게 타입을 체크할 수 있다.\n위 선언을 해주면, IDE에서는 곧바로 빨간줄이 생긴다.\n참고 # https://wiki.php.net/rfc/return_types https://stackoverflow.com/a/38970809 "},{"id":167,"href":"/docs/LANGUAGES/PHP/PHP-PHP-%EA%B8%B0%EB%B3%B8/","title":"[PHP] PHP 기본","section":"PHP","content":" PHP 기본 # PHP(Hypertext Preprocessor)는 server-side html-embedded 스크립트 언어(\u0026ldquo;서버에서 실행되며 HTML 을 포함하는 스크립트 언어\u0026rdquo;)이다.\nhtml 내용을 php 확장자로 저장하여도 아무런 지장이 없다. 1개의 프로세스를 생성한 후, 그 안에서 여러 개의 쓰레드를 생성하여 응답/처리하는 방식이다.\nPHP 를 이해하기 위해서 알아야 할 가장 큰 것은, \u0026lsquo;PHP 는 1개가 아니다\u0026rsquo; 라는 것이다.\nPHP 는 스크립트(Script)다. # PHP 로 웹 서비스를 할 때, 웹서버는 단순히 중개 역할을 해준다. 예를 들어, PHP 파일에 대한 요청이 오면 이 요청을 PHP Interpreter 에게 넘겨주고, 응답을 받아 브라우저에게 최종적으로 응답하는 것이다.\n이러한 특징은 다른 언어(Java, Python, .Net)와의 차이점이기도 하다. 아래의 그림과 같이 Java, Python, .Net의 경우에는 Application Server (이하 WAS)안에서 동작한다. 즉 WAS 가 필요하다. (PHP는 필요없다.)\nPHP는 수정하게되면 바로 웹 상에서 확인할 수 있다. 반면에 Java와 같은 언어는 WAS 를 재시작해야한다.\nPHP는 웹 모듈이다. # 즉, 웹서버와 같이 동작해야 사용할 수 있다. (혼자서 동작하지 않는다.)\nPHP 의 처리 순서 # client 가 http://domain.com/index.php 를 입력한다. 웹서버는 해당 파일을 찾은 후 확장자를 검사/비교한다. (예를 들어, html|htm 이면 해당 파일을 그대로 브라우저로 보내준다.) Php 엔진(Php interpreter)이 처리해야 할 파일(php|php3|inc 등의 확장자)이라면, (웹서버에 장착되어 있는)php 엔진(php interpreter)에 보낸다. php 엔진은 php 소스를 해석하여 html 코드로 만들고 웹서버로 응답한다. 웹서버는 (응답받은) html 파일을 브라우저로 보내준다. // 예시 1. 브라우저에서 URL 요청 2. URL translation (URL -\u0026gt; IP -\u0026gt; 서버 찾음) 3. Header parsing, ... (Access-Control, Check MIME, Calls Handler) 4. PHP Script 실행 (tokenizing/lexing -\u0026gt; parsing -\u0026gt; compile -\u0026gt; optimize -\u0026gt; cache -\u0026gt; execute(zend engine)) Reference\nPHP 개요 (웹 시스템, CGI, WAS 원리) How does a PHP application work? How does PHP works and what is its architecture? How php interperter works "},{"id":168,"href":"/docs/LINUX/LINUX-epoll/","title":"[LINUX] Epoll","section":"LINUX","content":" http://blueheartscabin.blogspot.com/2013/08/c-epoll.html\nselect, poll, epoll # 관심 있는 fd (= 대상 fd)들을 등록해두고 이들 중 이벤트가 발생하는 것을 감지하기 위해 사용하는 함수다.\n다만, 이벤트를 감지하는 동작 방식에 차이가 있다.\nselect : 어떤 fd에 발생한 이벤트인지 찾기 위해 등록된 fd 리스트를 선형 탐색한다.\nepoll : 이벤트가 발생한 fd들을 반환해준다.\n이해한 내용이 맞는 지 다른 글도 확인\nepoll 프로그래밍 흐름 # 소켓 생성, 설정 socket(), bind(), setsockopt() epoll 에 등록 (epoll_ctl) listen() epoll_wait() epoll_wait 를 통해 이벤트 발생을 감지/accept : accpet() :thinking: accpet 로 부터 넘어온 fd와 통신 준비 fcntl() epoll 에 새로운 fd 등록 : epoll_ctl epoll_ctl # epoll이 관찰할 fd, 이벤트를 등록하기 위한 인터페이스라고 한다.\n\u0026quot; epoll_ctl은 epoll이 관심을 가져주길 바라는 fd와 그 fd에서 발생하는 관심있는 사건의 종류를 등록하는 인터페이스 \u0026ldquo;\n#include \u0026lt;sys/epoll.h\u0026gt; int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); epoll_wait # #include \u0026lt;sys/epoll.h\u0026gt; int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); epoll 의 핵심 인터페이스.\nepoll_wait 은 등록한 fd에 이벤트가 발생하는 것을 확인한다.\n(epoll_event).events[] : epoll의 이벤트 감지 결과는 select, poll 과 달리 (epoll_event).events[] 의 배열로 전달한다. maxevents : 최대 처리할 event 수를 지정할 수 있다. timeout : 해당 시간만큼 기다린다. \u0026rdquo; 간단한 채팅서버의 경우를 살펴보자. 서버가 어떠한 일을 해야하는 시점은 이용자 누군가가 데이터를 보내왔을 때인데, 아무도 아무말도 하지 않는다면 서버는 굳이 프로세싱을 할 이유가 없다. 이럴때 timeout을 (-1)로 지정해두고 이용자들의 입력이 없는 동안 운영체제에 프로세싱 타임을 넘기도록 한다.\n온라인게임(특히 MMORPG)의 경우에는, 이용자의 입력이 전혀 없는 도중이라고 하더라도, 몬스터에 관련된 처리, 적절한 저장, 다른 서버와의 통신들을 해야 하므로 적절한 timeout (필자의 경우에는 1/100 sec, 즉 10ms를 선호한다)을 지정해 주도록 한다.\n뭔가의 프로세싱을 주로 하면서 잠깐잠깐 통신이벤트를 처리하고자 하는 경우, 즉 프로세스의 CPU 점유를 높게해서 무언가를 하고 싶은 경우에는, timeout 0을 설정하여 CPU를 독점하도록 설계할 수도 있다.\n별도 thread를 구성하여 이 thread 가 입출력을 전담하도록 프로그램을 작성하고자 하는 경우에는, 당연히 timeout을 (-1)로 설정하여 남는 시간을 다른 thread, 혹은 운영체제에 돌려 주도록 한다. \u0026ldquo;\n#define MAX_EVENTS 100 struct epoll_event events[MAX_EVENTS]; for(;;) { // 이벤트가 발생한 fd의 개수가 반환된다. int nfds = epoll_wait(fd_epoll, events, MAX_EVENTS, 10); if(nfds \u0026lt; 0) { // ERROR ... exit(-1); } if(nfds == 0) { // IDLE (아무 이벤트도 발생하지 않음) continue; } // 이벤트가 발생함 for(int n=0; n\u0026lt;nfds; n++) { // 이벤트 처리 OnEvent(\u0026amp;events[n]); } } "},{"id":169,"href":"/docs/LINUX/LINUX-rsync/","title":"[LINUX] Rsync","section":"LINUX","content":" rsnyc # 서버 간 파일, 디렉토리 정보를 동기화한다.\n서로 다른 컴퓨터에 있는 정보(파일, 디렉토리)를 동기화한다.\n비교해서 수정된 부분만 업데이트한다.\n"},{"id":170,"href":"/docs/LINUX/LINUX-%EC%86%8C%EC%BC%93-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/","title":"[LINUX] 소켓 프로그래밍","section":"LINUX","content":" http://biscuit.cafe24.com/moniwiki/wiki.php/socket%C7%C1%B7%CE%B1%D7%B7%A1%B9%D6%B1%E2%BA%BB\nsocket() bind() listen() read() / write() 1. socket() # socket() 함수는 통신을 위한 하나의 포인트(= endpoint)를 만든다. 통신을 위한 매개체(= fd)를 만든다.\n\u0026quot; socket() 함수는, 통신을 위한 끝점 한개를 만든다 (무슨 소리냐! :@). 워낙 여러가지 통신에 사용할 수 있는 함수이지만, 이 글에서는 TCP/IP 통신을 위한 부분에 국한해서, 뭔가 통신을 하기위한 매개체(이것을 fd, file descriptor 라고 한다)를 한개 생성하는데 쓴다. \u0026ldquo;\n#include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; int socket(int domain, int type, int protocol); int fd; if ((fd = socket(PF_INET, SOCK_STREAM, 0)) \u0026lt; 0) { fprintf(stderr, \u0026#34;socket() error\\n\u0026#34;); exit(-1); } \u0026rdquo; socket() 함수의 파라미터 domain과 type은 TCP/IP의 IP와 TCP를 의미한다. 참고로 UDP통신을 위해서는 type에 SOCK_DGRAM 을 쓴다. 프로그래밍에서 Stream이라는 단어는 연속적으로 주르륵 붙어있는 자료구조를 가리키는데, 통신을 하다보면 항상 먼저보낸 데이터가 먼저 도착하지는 않는데, 그럼에도 불구하고 데이터의 순서를 TCP라는 통신규약이 바로잡아주기 때문에 Stream이다. 물론 UDP는 그런것이 보장되지 않는다. \u0026ldquo;\nsocket() 함수는 리턴 값으로 fd 값을 반환한다.\n\u0026rdquo; socket()함수는 단지 정수값 한개를 돌려주는데 (보통은 4이다. 왜냐면 stdin, stdout, stderr 가 각각 1개씩 차지하고 있어서 4번째 fd 가 된다) 앞으로의 모든 조작은 이 정수값을 통해서 하게 된다 (다른 함수를 호출할때마다 이 값을 넘겨줘야 한다). \u0026ldquo;\n2. bind() # #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; int bind(int sockfd, struct sockaddr *my_addr, socklen_t addrlen); bind() 함수는 앞서 만든 fd에 소켓의 설정을 연결시켜준다.\n\u0026rdquo; bind()함수는 Socket과 Name을 연결시켜(binding) 주는 함수이다(역시 무슨 소리냐! :@). socket의 성격을 설명하는 sockaddr라는 구조체의 값들을 앞서 만든 fd 값에 연결시켜준다. \u0026ldquo;\nint port_listen = 8000; struct sockaddr_in server_addr; ... bzero((char *)\u0026amp;server_addr, sizeof(server_addr)); server_addr.sin_family = PF_INET; server_addr.sin_addr.s_addr = INADDR_ANY; server_addr.sin_port = htons(port_listen); if((bind(fd, (struct sockaddr *)\u0026amp;server_addr, sizeof(server_addr))) \u0026lt; 0 ){ fprintf(stderr, \u0026#34;bind() error\\n\u0026#34;); exit(-1); } sockaddr_in 을 보면 알 수 있듯이, 소켓에 대한 속성 정보(= 설정)을 위한 구조체다.\n위 예제는 INADDR_ANY(= 어디에서나 접속 가능한)와 8000번 포트를 설정해주고 있다.\n\u0026rdquo; sockaddr_in 이라는 구조체가 등장하는데, bind에서 연결할 소켓속성을 담을 구조체이다. 예제에서는 \u0026lsquo;어디에서나 접속가능한\u0026rsquo;(INADDR_ANY) 8000 번 포트를 listen 하도록 설정하고 있다. bind() 에서 에러가 나는 경우는 첫째 이미 다른프로그램이 이 포트를 이용하는 경우, 둘째 당신의 권한이 부족한 경우이다. 슈퍼유저(root)만이 1024번 아래 포트를 쓸 수 있다. \u0026ldquo;\n3. listen() # 소켓에 대한 생성,설정 이후 클라이언트의 요청을 받기 위한 명령어다.\n\u0026rdquo; listen 함수는, 이제 클라이언트들을 위해 귀를 기울여라!하고 최종명령을 내리는 것이다. 여태까지를 정리하면, (1) socket을 생성 (2) sockaddr_in 구조체를 만들어 대충 채우고 (3) bind() 로 1과2 두개를 묶고, (4) listen 하는 순서이다. 이렇게 해서 서버는 연결을 받아들일 준비가 된다. 실제로 클라이언트가 연결을 하면 서버는 accept 함수로 연결을 받아들이고, 적당한 때에 해당 소켓에서 데이터를 읽고 또 적당한 때에 쓰면 되는 것. \u0026ldquo;\n\u0026rdquo; 바로 이 적당한 때를 구현하는 방법이 사실 소켓 프로그래밍의 핵심이다!! \u0026ldquo;\n\u0026lt;br.\n4. read() / write() # #include \u0026lt;unistd.h\u0026gt; ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); 소켓의 데이터를 읽거나, 소켓에 데이터를 쓸 때 사용한다. (= 파일에 데이터를 읽고, 쓰는 것과 동일하다.)\n\u0026rdquo; read(), write()는 사실 소켓과는 별로 상관이 없지만, unix의 모든 장치는 FILE이다라는 철학에 의해 소켓에 데이터를 쓰거나 읽을때 사용한다. 파일에 쓰거나 읽는거와 다르지 않다. 다만, 소켓연결이 끊기거나 에러가 발생했을 경우 부수적인 처리들이 필요하다. \u0026ldquo;\n소켓은 별 게 아니고, 파일이다. :star:\n#define MAX_BUF 1024 int nread; char buf[MAX_BUF]; nread = read(fd, buf, MAX_BUF); if(nread \u0026lt;= 0) { if(nread \u0026lt; 0){ // some error handling routine } close(fd); } fd가 가리키는 곳으로부터 MAX_BUF 만큼 데이터를 읽는다. read()의 리턴 값이 0인 경우 EOF 를 의미하고, -1인 경우 에러를 의미한다. (0, -1일 때 소켓 종료 처리에 신경써야 한다.)\nwrite()도 read()와 유사하다.\n\u0026rdquo; write()의 경우는 좀더 신경써야 할 일이 많다. 그 중 가장크게 신경을 써야 하는 것은 WOULDBLOCK이다. 운영체제 내부적으로 통신을 위한 버퍼를 가지고 있는데, 이 버퍼보다 큰 데이터를 보내려고 하거나 이미 가득 차 있는데 무언가를 더 보내려고 하는 경우에 WOULDBLOCK이 발생하게 된다. \u0026hellip; 이런일은 일시적인 통신지체 (흔히 \u0026lsquo;랙\u0026rsquo;) 상황에서 일반적으로 발생하는데 그냥 연결을 끊어버릴 수도 없고, 버퍼가 비워질때까지 무작정 기다릴 수도 없는 노릇. 그래서 Send Buffering 기법을 쓴다. 보내야 할 데이터가 발생하면 바로 전송하지 않고 어플리케이션 버퍼에 넣어두며, 적당한 시점에서 실제 전송을 시도하도록 하는 방법이다. \u0026ldquo;\n"},{"id":171,"href":"/docs/NETWORK/NETWORK-LDAP/","title":"[NETWORK] LDAP","section":"NETWORK","content":" 우선 개념만 정리, 다시 학습 필요 !!\nLDAP(Lightwieght Directory Access Protocol) # 디렉토리 서비스를 제공하기 위한 프로토콜\n네트워크상에서 조직(Organization), 개인(Private), 파일(File), 디바이스(Device) 등을 \u0026lsquo;찾아볼 수 있게 해주는\u0026rsquo; 소프트웨어 프로토콜\nLDAP 은 DAP 의 스펙을 최대한 유지 + 경량화 → 네트워크 부담을 줄이고 활용성을 높임\n데이터 형식에 있어서, 대부분 단순한 문자열을 사용 → \u0026lsquo;구현 단순화\u0026rsquo;, \u0026lsquo;성능 향상\u0026rsquo;시켰다고 한다.\nLDAP 등장하기 전, 디렉토리 서비스 표준이었던 X.500 DAP(Directory Access Protocol)이 존재했었다. 하지만 이 프로토콜은 무겁고, 제약이 많았다고 한다. 때문에 잘 활용되지 않았다고 한다.\nDAP 의 경우, OSI 7 Layer 에서 운영된다고 한다. 반면에, LDAP 은 TCP/IP 위에서 운영된다고 한다.\n흐름 예시\n사용자/Application 에서 LDAP 을 통해 LDAP 서버에 요청 TCP/IP LDAP 서버에서 요청 처리 후 응답 TCP/IP 사용자/Application ---------\u0026gt; LDAP Server ---------\u0026gt; DB RDB vs LDAP\n* LDAP 서버도 결국에는 데이터를 저장하는 데이터베이스 유형 중 하나\n서버 설명 RDB - 저장된 여러 데이터를 종합적으로/복합적으로 조회 검색 가능 (LDAP 에 비해) 조회 성능 ↓ (LDAP 에 비해) 쓰기 작업 안정성 ↑ 목적 : 복합(읽기, 쓰기) 용도로 사용 LDAP - 저장된 데이터를 신속하고 빠르게 조회/검색 가능 (RDB 에 비해) 조회 성능 ↑ - (RDB 에 비해) 쓰기 작업 안정성 ↓ 목적 : 조회/검색 용도로 사용 LDAP 구조(모델) # Information 모델 # 데이터 종류, 디렉토리에 저장되는 기본 단위에 대한 정의 기본 요소 : Entry, Attribute, Value 용어 설명 Entry 디렉토리에서 정보를 표현하는 기본 단위 - Entry 는 다수의 attribute 로 구성 - Entry 는 DN(Distinguish Name)으로 구분 - Tree 구조 형성 (DIT, Directory Information Tree) Attribute (Entry 안의) 값을 구성하는 단위 - Type, Value 로 구성 - Type 은 Attribute 가 포함하는 정보의 종류를 명시 (단순하게 Key, Value 의 Key 라고 보면 될 것 같다.) - dn(distinguished name), o(organization), cn(common name), c(country), rdn(relative dn), ou(organization unit), sn(surname), \u0026hellip; Value (Attribute 의) 값 Value 는 Syntax, Matching Rule 을 표현할 수 있다.(?) (앞서 언급한바와 같이)\nLDAP 디렉토리 구조는 Entry 데이터들을 트리 구조로 형성, 관리 (DIT, Directory Information Tree)\n용어 설명 예시 Root Entry(Suffix) DIT 중 가장 상위에 있는 Entry ObjectClass Entry 생성 시 Object Class 지정 → Object Class 내의 Attribute 사용 즉, (Entry 내에서) 꼭 필요하거나, 가질 수 있는 Attribute 타입에 대한 정의 Entry 내의 클래스(?)라고 볼 수 있을 것 같다. ObjectClass : cn, sn 정의 (Attribute) Entry 생성 시 Person(ObjectClass) 지정 → Entry 에 cn, sn 값 설정 가능 Schema ObjectClass, Attribute 를 정의하는 파일/규칙 ObjectClass에 어떤 Attribute 가 들어갈지, Attribute 값에 대한 제약, 조건 등과 관련된 규칙들을 정의 Naming 모델 # (LDAP 디렉토리 구조에서) 각 Entity 를 어떻게 식별/참조하고 구성할 것인지에 대한 정의 용어 설명 DN RND 값들을 이어 붙여 생성된 고유한 문자 (Distinguished Name) - \u0026ldquo;CN=leehyunjae, OU=People\u0026rdquo; RDN 각 Entry 의 Attribute (DN 값 중 가장 좌측의 컴포넌트) - \u0026ldquo;OU=People\u0026rdquo; 에서 OU - \u0026ldquo;CN=leehyunjae\u0026rdquo; 에서 CN Functional 모델 # LDAP 디렉토리에서 작업하는 명령어를 다룸 데이터에 접근하는 명령어에 대한 정의 명령어에 따라 3가지 기능(그룹)으로 구분 그룹 명령어 설명 질문 (Interrogation) Search Entry 검색 질문 (Interrogation) Comapre Entry 비교 갱신 (Update) Add Entry 추가 갱신 (Update) Modify Entry 수정 갱신 (Update) Delete Entry 삭제 인증/제어 (Authentication/Control) Bind 디렉토리 서버 연결 시, 사용자 인증 인증/제어 (Authentication/Control) Unbind 디렉토리 서버와 연결 해제 인증/제어 (Authentication/Control) Abandon 이전의 요청한 명령 취소 Security 모델 # 디렉토리에 접근하는 사용자 \u0026lsquo;인증\u0026rsquo;, \u0026lsquo;인가\u0026rsquo;를 통해 서비스를 보호하는 방식 (TCP 프로토콜로 연결이 이뤄지기 위해) 서버 ←→ 클라이언트 간의 인증 과정 필요 \u0026lsquo;인증\u0026rsquo;된 경우만 디렉토리의 정보 제공 SSL/TLS 적용 가능 v3 버전 : 기존 보안 방식 + 외부 인증 기능 제공할 수 있는 SASL(Simple Authentication and Security Layer) 방식 제공 SASL 학습 필요\nLDAP 서버 (종류) # 종류 설명 OpenLDAP LDAP 디렉토리 구축/관리할 수 있는 CLI 기반의 서버 LDAP 출시 이후 최초의 오픈소스 (현재까지 꾸준히 활용되고 있음) LDAP 기능만 제공 (확장성 ↑) Apache Directory Server 자바로 작성된 LDAP 서버 이클립스와 같은 자바 기반의 응용 프로그램에서 쉽게 임베드할 수 있음 LDAP + 다른 기능 포함 (DNS, Kerberos, \u0026hellip;) Active Directory LDAP + 다양한 형태의 디렉토리 구조 / 여러 프로토콜 제공 기존 LDAP 확장하여 다양한 기능 제공 GUI 제공 *윈도우 환경에서만 서비스 가능 LDAP 클라이언트/API (종류) # * Java 기반 클라이언트\n종류 설명 JNDI JDK2 부터 제공된 내장 라이브러리 네이밍, 디렉토리 관련 기능 제공하는 라이브러리 * LDAP 이 가진 모든 기능 (Controls), Extension 등)을 제공한다고 한다. Spring LDAP Spring 프레임워크 기반의 LDAP 라이브러리 (JNDI 와 비교해) 간결하고, 쉽게 활용 가능 + 유연한 예외 처리 제공 UnboundID LDAP Ping Identity 사에서 제공 다른 LDAP 라이브러리보다 빠르고, 쉽다(고 강조하고 있다고 한다.)\n데이터 포맷, 암호화 등을 비롯한 다양한 API 들과 LDAP 기반의 In-Memory 테스트 환경 제공 참고 # https://ldap.or.kr/ldap-%EC%9D%B4%EB%9E%80/ https://www.samsungsds.com/kr/insights/LDAP.html "},{"id":172,"href":"/docs/NETWORK/NETWORK-Network_NAT/","title":"[NETWORK] Network_NAT","section":"NETWORK","content":"NAT(Network Address Translation)는 IP, PORT 정보를 변경하는 기술이다. 패킷(IP, Port)에 변화가 생기기에 패킷에 대한 체크섬도 재계산되어야 한다고 한다.\nNAT 를 이용하면 내부의 여러 사설 IP가 외부로 나갈 때 하나의 공인 IP 주소를 통해 나갈 수 있다.\n\u0026lsquo;NAT를 사용하여 얻을 수 있는 이점\u0026rsquo; == \u0026lsquo;사설 네트워크(사설 IP)를 사용하여 얻을 수 있는 이점\u0026rsquo;\n1. IP 주소 절약\n\u0026lsquo;사설 IP 사용\u0026rsquo;의 이점인 것 같다. NAT를 통해 사설 IP, 공인 IP 를 활용할 수 있는데, 사설 IP 를 활용할 수 있다는 것은 그만큼 IP 주소를 절약할 수 있다는 것이다.\n2. 보안\n이것도 \u0026lsquo;사설 IP 사용\u0026rsquo;을 통한 이점인 것 같다. 사설 IP 정보에 대해 외부에 노출되지 않는다.\n"},{"id":173,"href":"/docs/NETWORK/NETWORK-Network_Tunneling/","title":"[NETWORK] Network_Tunneling","section":"NETWORK","content":"\u0026lsquo;터널링\u0026rsquo;이란, 연결해야 할 두 지점간에 통로를 생성하는 것이다. 이 터널은 터널링을 지원하는 프로토콜을 사용하여 구현되며, 사설망과 같은 보안 기능을 제공하게 된다. 경유지(두 지점 사이의 홉)들을 통하지 않고 두 지점을 바로 연결시킨 것이다.\n참고 # VPN이란? 정의/터널링/터널링 프로토콜 등 "},{"id":174,"href":"/docs/NETWORK/NETWORK-OSI-7-Layer/","title":"[NETWORK] OSI 7 Layer","section":"NETWORK","content":" OSI 7 Layer 이해하기\nOSI 7 Layer # (전송 시) 7계층 -\u0026gt; 1계층 순서로 헤더를 붙인다. (캡슐화)\n(수신 시) 1계층 -\u0026gt; 7계층 순서로 헤더를 떼어낸다. (디캡슐화)\nApplication Layer (7 Layer)\n응용프로그램과 관련된 계층이다. 사용자/애플리케이션이 네트워크에 접근할 수 있도록 한다. 사용자를 위한 인터페이스를 지원한다. (사용자가 직접적으로 접촉하는 유일한 계층이다.) HTTP, FTP, SMTP, DNS 등이 있다. 데이터 Format : Data + HTTP Header Presentation Layer (6 Layer)\n데이터를 어떻게 표현할지 결정한다. (전송할, 전송된) 데이터의 인코딩, 디코딩, 암호화 등이 이뤄진다. (다음 계층이 이해할 수 있도록) 전송 시 : Application Layer 로부터 온 데이터(전송할 데이터)를 변환/압축한다. 수신 시 : Application Layer 로 보낼 데이터(수신한 데이터)를 변환/압축한다. Session Layer (5 Layer)\n양쪽의 연결을 관리/지속시킨다. 세션을 만들고, 유지하고, 종료한다. (복구 기능도 있다고 한다.) 세션 계층에서 TCP/IP 세션을 만들고 없앤다. Transport Layer (4 Layer)\n송/수신자의 (논리적)연결을 담당한다. 신뢰성 있는 연결을 유지할 수 있도록 한다. 연결을 생성하고, 데이터를 얼마나 보내고 받았는지, 제대로 데이터를 받았는지 확인한다. PORT 를 사용한다. TCP, UDP 가 대표적이다. 데이터 단위 : Segment 데이터 Format : Data + HTTP Header + TCP Header Network Layer (3 Layer)\nIP(Internet Protocol)이 활용되는 부분이다. 즉 (Routing)경로/목적지를 찾을 수 있도록 한다. 장비 : 라우터, L3 스위치가 있다. 데이터 단위 : Packet 데이터 Format : Data + HTTP Header + TCP Header + IP Header DataLink Layer (2 Layer)\n같은 네트워크 내의 단말들에 대해 신뢰성 있는 전송을 보장한다. \u0026lsquo;MAC Address\u0026rsquo; 를 활용하여 Endpoint, Switching 장비에 데이터를 전달한다. 오류를 찾아내고, 재전송할 수 있다. (오류 검출) 장비 : Bridge, Switch 가 있다. 데이터 단위 : Frame 데이터 Format : Data + HTTP Header + TCP Header + IP Header + Ethernet Frame Header 이다. Physical Layer (1 Layer)\n물리적으로 데이터가 전송되는 구간이다. 데이터가 전기적인 신호로 변한다. 데이터의 전달만 한다. 알고리즘, 오류제어 등의 기능이 없다. 장비 : Cable, Repeater, Hub 수신자는 아래의 과정을 거친다고 한다.\nEthernet Frame Header 를 보고 목적지 MAC Address 가 자신이 맞는지 확인한다. IP Header 를 확인하여 목적지 IP 가 자신이 맞는지 확인한다. TCP Header 를 확인하여 신뢰성 있는 연결이 필요한지 판단한다. (필요하다면 3-way Handshake 실시하여 연결을 맺는다.) HTTP Header 를 확인하여 어떤 HTTP(Application) 요청인지 확인한다. (현재는 HTTP 로 가정) Data 를 확인한다. 즉 위의 Data Format 을 거꾸로 풀어가면서 확인하는 것\n참고 # OSI 7 Layer 쉽게 이해하기 네트워크 OSI 7 계층 기본 개념, 각 계층 설명 "},{"id":175,"href":"/docs/NETWORK/NETWORK-%EB%A1%9C%EB%93%9C%EB%B0%B8%EB%9F%B0%EC%84%9C/","title":"[NETWORK] 로드밸런서","section":"NETWORK","content":"먼저 \u0026lsquo;L4/L7 로드밸런싱 쉽게 이해하기\u0026rsquo; 블로그의 글을 읽었다.\nL4/L7 로드밸런싱에 대해서 놓치기 쉬운 것(오해하기 쉬운 것)은 다음과 같다고 한다.\n상위 계층의 장비는 하위 계층의 기능을 포함한다. 다만 효율성 있게 사용하기 위해 사용하지 않을 뿐이다.\n로드밸런서 # 로드밸런서의 종류는 L2(MAC addr), L3(IP), L4(Port), L7(Application) 로드밸런서가 있다고 한다. 이들 중 L4, L7 로드밸런서가 많이 사용된다고 한다. (* L4부터 Port 를 다룰 수 있는데, 이 말은 즉슨 한 대의 서버에 여러 포트로 여러 서비스를 운영할 수 있다는 것을 의미한다.) 예전에는 L4 위주의 장비를 많이 사용했다고 한다면, 요새는 MSA 의 추세로 L7 장비도 많이 사용되고 있다고 한다.\n\u0026quot; 로드밸런서의 종류를 나누는 기준은 OSI 7계층을 기준으로 어떻게 부하를 분산하는지에 따라 종류가 나뉩니다. \u0026quot;\n로드밸런서는 3가지의 주요 기능을 통해 로드밸런싱을 진행할 수 있다고 한다. (* 이 부분은 조금 더 알아봐야할 것 같다.)\n1. Network Addresss Translation (NAT)\nIP 를 변환한다.\n2. Tunneling\n(인터넷 상에서) 통로를 만들어 통신할 수 있게 해주는 개념이라고 한다.\n데이터를 캡슐화하여 연결된 상호 간에만(연결되어진 노드만) 캡슐화된 패킷(데이터)을 해제하여 볼 수 있게한다.\n3. Dynamic Source Routing protocol(DSR)\n(요청에 대한) 응답을 할 때 로드밸런서가 아닌 클라이언트 IP로 응답한다. 즉 응답을 할 때 로드밸런서를 거치지 않고 곧바로 요청을 보낸 client 로 응답한다.\nL2 로드밸런서 # MAC Address 를 기준으로 요청을 분산한다.\nLayer 가 낮은만큼 구조가 간단하기에 가격이 저렴하고 성능이 좋다.\nBroadcast 패킷에 의해 성능 저하가 발생할 수 있다.\nL3 로드밸런서 # IP(+ Mac Address) 를 기준으로 요청을 분산한다.\nL4 로드밸런서 # IP, Port를 기준으로 요청을 분산한다.\n주로 RoundRobin 알고리즘이 사용된다고 한다.\nL7 로드밸런서 # L7 로드밸런서는 IP, Port + Application(Layer 7) 레벨의 내용(URI, Payload, HTTP Header, Cookie) 등의 내용을 기준으로 요청을 분산한다. 즉 데이터를 보고 판단할 수 있다. (그래서 \u0026lsquo;콘텐츠 기반 스위칭\u0026rsquo;이라고 불리우기도 한단다.)\n데이터를 보고 판단하는 것과 같이, 더 디테일하게 판단할 수 있다는 것은 그만큼 자원의 소모가 크다는 것을 의미한다고 한다.\nL4 로드밸런서가 단지 부하를 분산시키는 것을 목적으로 한다면, L7 로드밸런서는 조금 더 디테일하게 요청을 분산할 수 있다. (예를 들어, A 기능은 \u0026lsquo;a\u0026rsquo; 쪽으로, B 기능은 \u0026lsquo;b\u0026rsquo; 쪽으로 등)\n참고 # L4/L7 로드밸런싱 쉽게 이해하기 L4/L7 로드밸런서 차이 "},{"id":176,"href":"/docs/NUXT/NUXT-Nuxt-%EB%9D%BC%EC%9D%B4%ED%94%84%EC%82%AC%EC%9D%B4%ED%81%B4/","title":"[NUXT] Nuxt 라이프사이클","section":"NUXT","content":" Nuxt LifeCycle # Nuxt ServerInit (lifecycle hook 호출) Route Middleware validate() asyncData() Vue lifecycle "},{"id":177,"href":"/docs/NUXT/NUXT-Static-site-vs-SSR/","title":"[NUXT] Static-Site vs SSR","section":"NUXT","content":" Static-Site vs SSR (in Nuxt) # Static-Site # 빌드 시에 완벽한 HMTL 페이지를 생성한다.\n이 페이지들은 웹서버를 통해 전달된다.\n페이지의 내용을 변경하기 위해서는 재빌드 되어야한다.\n속도, 배포, 보안 측면에서 장점이 있다.\n즉 빌드 시에 페이지를 완성시키고, 클라이언트의 요청이 들어오면 완성된 페이지를 전달하기만 하면 된다.\nSSR # SSR 은 웹페이지를 브라우저에서 렌더링하지 않고 서버에서 렌더링하여 전달하는 것이다.\n콘텐츠 변경(최신 유지) 등의 장점이 있다.\n즉 클라이언트의 요청이 들어오면, 서버 측에서 렌더링을 진행하고 전달한다.\nReference\nhttps://www.smashingmagazine.com/2020/07/differences-static-generated-sites-server-side-rendered-apps/ "},{"id":178,"href":"/docs/NUXT/NUXT-Vue-%EB%9D%BC%EC%9D%B4%ED%94%84%EC%82%AC%EC%9D%B4%ED%81%B4/","title":"[NUXT] Vue 라이프사이클","section":"NUXT","content":" Vue Life-cycle # new Vue() Init (Event, Lifecycle) : 이벤트 \u0026amp; 라이프사이클 초기화 beforeCreate Init (injections \u0026amp; reactivity) : 반응성 주입 created \u0026hellip; (el, template 속성 확인 등) beforeMount mounted beforeUpdate updated beforeDestroy destroyed beforeCreate() # 가장 먼저 실행되는 훅이다.\nVue 인스턴스가 생성된 직후에 실행된다.\n데이터(data), 이벤트(methods) 속성이 정의되어 있지 않다.\n화면(template) 요소에 접근할 수 없다.\ncreated() # 데이터(data)와 이벤트(methods)가 초기화되어, 접근할 수 있다.\n화면(template) 요소에 접근할 수 없다.\nbeforeMount() # render() 함수가 실행되기 직전의 단계이다. 즉 화면에 렌더링 되기 전에 실행된다.\n컴포넌트에 접근할 수 있다.\n$el 속성을 사용할 수 없다.\nmounted() # 렌더링되고 난 직후 호출된다.\n$el 속성을 사용할 수 있다.\n대게 제일 많이 사용되는 훅이다.\nbeforeUpdate() # 데이터 변경을 감지하고, re-render 전에 호출된다.\nupdated() # re-render 후에 호출된다.\nbeforeDestroy() # 인스턴스가 삭제되기 전에 호출된다.\ndestroyed() # Vue 인스턴스가 모두 삭제된 후 실행된다.\nVue 인스턴스에 정의된 모든 속성, 이벤트 등이 사라진다.\n생성 단계 (Create) # beforeCreate(), create() 단계가 포함된다. 이벤트, 생명주기 메소드가 초기화된다. 초기화 단계 (Mount) # Vue 문법을 적용, 화면에 값들을 렌더링한다. 갱신 단계 (Update) # 데이터의 변화를 감지하면 화면을 다시 렌더링(re-render)한다. Virtual DOM 을 활용하여 렌더링한다. 소멸 단계 (Destroy) # 이벤트 등을 해제하고, Vue 인스턴스를 메모리에서 해제한다. 참고 # https://hyeooona825.tistory.com/40 "},{"id":179,"href":"/docs/OS/01.-OS-Introduction/","title":"01. OS Introduction","section":"OS","content":" OS Introduction # OS 란?\n프로그램이 동작하는 것을 쉽게 해준다. 시스템을 효율적으로, 정확하게 운영한다. \u0026lsquo;자원관리자\u0026rsquo; 이다. 물리 자원 : CPU, Dram(Memory), Disk, keyboard(KBD), Network, \u0026hellip; 가상 자원 : Process, Thread, Virtual Memory, Page, File, Directory, Driver, Protocol, \u0026hellip; * OSTEP(OS Three Easy Picese) : Virtualization, Concurrency, Persistence\n* OS 의 기본 목표 : Abstraction, Performance, Protection, Reliability, \u0026hellip;\n컴퓨터 시스템의 계층\nuser1 user2 user3 ... userN -------------------------------------- | System Program \u0026amp; Application Program | | OS | -------------------------------------- -------------------------------------- | HW | -------------------------------------- 프로그램을 수행하면 아래와 같은 것들이 진행된다.\nloading memory management file management scheduling context switch i/o processing 키워드 내용 Memory Address + Content(instruction + data) Register CPU 내부에 있는 data holding elements Interept HW 가 kernel 에 event 의 발생을 알리는 것 Trap SW 가 kernel 에 event 의 발생을 알리는 것 Scheduling 다음에 수행할 프로세스를 어떻게 선택할 지 결정하는 것\n자원을 누구에게 줄지 정하는 것 IPC Inter Process Comunication\nProcess 간 통신하는 것 Signal Process 에게 event 를 알리는 것(단위(?)) Mode Kernel mode\nUser mode\nex. system call 을 사용하기 위해 mode switch 가 발생한다. System call OS 가 제공하는 API(인터페이스) * 명령어 수행 시 : fetch -\u0026gt; execute (fetch : memory -\u0026gt; IR)\nCPU 가상화 (CPU Virtualization)\n각각의 Process 는 자기만의 CPU 를 갖는 것 처럼 동작한다.\nCPU 의 수가 적어도 가상화를 통해 많은 수의 Process 를 실행할 수 있게 한다.\nMemory 가상화 (CPU Virtualization)\n각각의 Process 는 자기만의 Memory 를 갖는 것 처럼 동작한다.\nProcess 사이에서 memory 의 독립성을 보장한다.\n병행성 (Concurrency)\n여러 Process 가 동시에 실행되는 것 처럼 보이는 것 (혹은 그렇게 느낄 수 있도록 해주는 것)\n병행성(Concurrency) vs 병렬성(Parallelism)https://nesoy.github.io/articles/2018-09/OS-Concurrency-Parallelism\n영속성 (Persistence)\n자원(Data)을 영구히 보존하는 것 (file)\n* File System 의 오류 핸들링 : journaling, cow(copy-on-write)\n* File System 의 성능 향상법 : cache, delayed write\n"},{"id":180,"href":"/docs/OS/02.-Processes/","title":"02. Processes","section":"OS","content":" Processes # * Program : Disk 상의 file\n* Process : Program 실행 상태\nProcess 를 운영하기 위해 필요한 것\nCPU : registers (IR, PC, SP, \u0026hellip;) Memory : Address Space (stack, heap, data, text) I/O information : Opened files/devices Multiple Processes 운영 방식\nTime sharing 기법 사용\ncontext switch 발생 Program 실행 시 OS 의 역할\nLoad (적재) Disk -\u0026gt; Memory Eagerly vs Lazily Dynamic Allocation (동적 할당) stack heap initialize parameters (argc, argv) Initialization (초기화) file descriptors(0, 1, 2) I/O Jump to main (main 함수 실행) Process 의 Lify-Cycle (상태)\nnew(생성) terminated(종료) \u0026lt;------\u0026gt; \u0026lt;------\u0026gt; ready(준비) \u0026lt;------------------\u0026gt; running(동작/운영) \u0026lt;------\u0026gt; \u0026lt;------\u0026gt; waiting(대기) PCB (Process Control Block, Task Structure)\nProcess 를 관리하기 위한 자료구조\nProcess 생성 만들어진다.\n------------- |Process State | ------------- |Process Number| ------------- | PC | ------------- | Registers | ------------- | ... | ------------- fork()\nCreate a new process : 새로운 프로세스를 생성한다. (Parent - Child 관계)\nReturn two values : 2개의 값을 반환한다. (Parent, Child)\nNon-determinism: 어떤 것이 먼저 실행될지 모른다.\nwait()\n자식 프로세스가 종료될 때 까지 기다린다. (Synchronization)\nexec()\nmemory image 를 새 것으로 바꾼다.\nexec() 밑의 코드는 실행되지 않는다.\nModular approach of unix(especially for shell): fork -\u0026gt; exec (on child)\n그 외\ngetpid(), kill(), signal(), \u0026hellip;\n"},{"id":181,"href":"/docs/OS/03.-Scheduling/","title":"03. Scheduling","section":"OS","content":" Scheduling # 스케줄링 이란, 시스템의 자원을 어떤 프로세스에게 할당할 것인지 선택하는 것이다.\n누가(어떤 프로세스) 자원(CPU)을 사용할지 선택하는 것이다.\n선점형 스케줄링, 비선점형 스케줄링이 있다.\n* Workload : 일의 양\nScheduling Metric\n완료 시간 (Turnaround time)\nTurnaround time = Completion time - Arrival time Batching System 에 좋은 metric 이다. 응답 시간 (Response time)\nResponse time = First run time - Arrival time I/O 에 좋은 metric 이다. (사용자는 빠른 응답시간이 중요하다.) 공평성 (Fairness)\n처리율 (Throughput)\n임계시간 (Deadline)\n* 설계 목적에 따라 우선시 되는 기준(metric)이 달라진다.\n* 모든 것을 만족시킬 수는 없다.\n비선점형 스케줄링 # 어떤 프로세스가 시스템의 자원을 사용하여 작업을 진행하게 되면, 종료될 때까지 자원을 뺏을 수 없다. 기다려야 한다.\nFCFS (FIFO)\n선입 선출의 스케줄링 기법이다.\nSJF (Shortest Job First)\n실행시간(처리시간)이 짧은 것부터 자원을 점유한다.\nHRN (Hightest Response-ratio Next)\nSJF의 Starvation (기아, 굶주림) 을 해결하기 위한 기법이다.\n우선순위 = 실행시간 + 대기시간 / 실행시간 의 계산을 통해 우선순위를 정한다.\n선점형 스케줄링 # 어떤 프로세스가 시스템의 자원을 사용하여 작업을 진행하는 도중, 해당 작업을 중지하고 시스템의 자원을 다른 프로세스에게 넘겨줄 수 있는 스케줄링이다.\nRound Robin (RR)\nFCFS 기법 + 선점형의 기법이다.\nTime slice 를 설정하여 해당 time 동안만 실행되고 자원을 넘긴다.\nTime slice 가 짧다면, 응답률은 좋지만 높은 context switch overhead 가 발생한다.\nTime slice 가 길다면, 응답률은 안좋지만 낮은 context switch overhead 가 발생한다.\nSRT (Shortest Remaining Time, STCF, Shortest Time to Completion First)\nSJF + 선점형의 기법이다.\n남은시간(완료 되기까지의 시간)이 짧은 것을 우선적으로 선택한다.\nMLQ\nQueue 에 자원을 점유할 프로세스들을 대기시킨다.\n여러 개의 Queue 를 갖는다. Queue 마다 우선순위가 있다.\n우선순위가 높은 Queue 에 대기하는 프로세스가 자원을 점유한다.\n선점형 기법이기 때문에, 우선순위가 높은 프로세스가 대기 상태로 들어오면 바로 자원을 점유할 수 있다. (사용중이던 애는 자원을 빼앗긴다.)\n* MLQ 를 이용했을 때의 특징은 I/O 와 같이 처리 시간이 빨라야 하는 것은 우선순위가 높은 Queue에 대기시키고, 비교적 처리 시간이 느슨해도 되는 프로세스는 우선순위가 낮은 Queue 에 대기시킬 수 있다는 것이다.\nMFQ\nMLQ + Time Slice, 큐 간의 이동 등의 기법이 추가되었다.\nMLQ 와 동일하게 Queue 에 우선순위가 있다. 그러나 Queue 마다 Time slice 가 있으며, 해당 Time slice 동안 종료되지 않는 프로세스는 다음 Queue(우선순위가 낮은)로 이동된다.\nQueue 에서 일정한 대기시간이 지나면 우선순위가 높은 Queue 로 이동될 수 있다.\n이슈\nHow many queues? How big should the time slice be per queue? How often do the periodic boost? \u0026hellip; * 보통 우선순위가 낮은 큐일수록 time quantum(time slice) 가 길다.\n* 하지만 Starvation 을 완전히 방지할 수는 없다. -\u0026gt; Periodic Boosting\n* Periodic Boosting : (주기적으로) 모든 작업을 Top Queue 로 올린다.\n(+)\nProportional Share Scheduler (Fair Share Scheduler) # 위에서 소개한 스케줄링 기법들은 Turnaround time, Response time 들의 최적화를 위한 스케줄링 기법이다.\n그러나 이 스케줄링은 각각의 프로세스에게 CPU 의 사용량(사용 시간)을 균등하게 배분하는 것에 목적이 있다.\nLottery Scheduling\n복권에 당첨된(즉, 랜덤에서 당첨된) 프로세스가 자원을 사용한다.\n이때 Ticket 개념(the share of a resource)이 사용된다. 더 많은 ticket 을 가질수록 복권에 당첨될 확률이 높아진다.\nTicket machanisms\nTicket currency : Allow users to allocate tickets Ticket transfer : A job can hand off its tickets to another job (client/server 환경에서 유용하다.) Ticket inflation : Temporarily raise or lower the # of tickets 특징\n구현이 간단하다. (random, counter, ticket, \u0026hellip;) Non-deterministic 어떤 프로세스에게 티켓을 많이/적게 할당해야할지 고민해야한다. 프로세스별로 티켓이 할당되더라도, 랜덤(Non-deterministc)한 성격이기에, 보장할 수 없다. Stride Scheduling\nA deterministic fair share scheduler\n* Stride : inverse in proportion to the # of tickets (= ticket / N)\n각각의 프로세스는 Stride, Pass value 값을 갖고 있는다.\nPass value 가 가장 작은 프로세스를 선택한다.\n프로세스가 실행될 때 마다, pass value 에 stride 를 더해준다.\n다만, 중간에 새로운 Process(pass value : 0) 가 들어온다면, 해당 프로세스가 일정시간 동안 자원을 계속해서 차지할 수 있다.\nMultiprocessor Scheduling # Parallel program\nScheduler that can handle multiple CPUs\nCPU Cache(L1, L2, LLC)\nCache hit\nDelayed write\nTemporal locality (시간 지역성) : 한 데이터가 사용이 되면, 그 데이터는 곧 다시 사용될 가능성이 높다.\nSpatial locality (공간 지역성) : 한 데이터가 사용이 되면, 그 데이터 주변에 있는 것들도 사용될 가능성이 높다.\nCache 는 Multiprocessor 에서 굉장히 복잡하게 동작한다.\n아래와 같은 상황에서 incoherence 문제가 발생한다.\nCPU1 에서 A 라는 데이터를 읽었고, 수정했다 (A -\u0026gt; A\u0026#39;) (이때 A\u0026#39; 값을 바로 write 하지 않고, Delayed write 한다고 가정한다.) 이때 CPU2 에서 A 라는 데이터를 읽었다. (A\u0026#39; 를 읽지 못한다.) Bus Snooping : A mechanism for supporting coherence\nMonitoring cache, invalidate or update if data is modified Issue on Multiprocessor\nSynchronization : locking 과 같은 기법 필요\nCache affinity\n\u0026hellip;\nScheduling for Multiprocessor\nSQMS (Single Queue Multiprocessor Scheduling)\n한 큐를 여러 CPU 가 사용\n장점 : 간단\n단점 : Cache affinity(캐시 선호도) 낮음, Scalability(확장성) 낮음\nMQMS (Multi Queue Multiprocessor Scheduling)\nSQMS 의 반대 ( + 자원 경쟁 하락 )\nReference\nhttps://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-6.-CPU-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81 Fair Share scheduling, https://icksw.tistory.com/125 "},{"id":182,"href":"/docs/OS/04.-Memory-Management/","title":"04. Memory Management","section":"OS","content":" Memory Management # Memory Virtualization Keywords\nVirtual address (Private) Address space HW help Address Space 개념의 변천사\nEarly System -\u0026gt; Multiprogramming \u0026amp; Time sharing -\u0026gt; Virtual memory(Address space)\nEalry System\nSingle programming system\n물리 메모리를 직접적으로 사용한다.\n물리 메모리보다 큰 메모리가 필요하다면, Overlay 기법을 사용한다.\n* Overlay : 현재 꼭 필요한 Part 만 메모리에 올리는 것 (Part 번갈아가면서 실행)\nMultiprogramming \u0026amp; Time sharing\n컴퓨터 HW 가 좋아지면서, 한번에 여러 개의 프로그램을 올릴 수 있게 되었다 (?)\nMultiprogramming : Multiple processes are ready to run\nTime sharing : Switch CPU among ready processes\n이슈\nProtection Free space (It isn\u0026rsquo;t easy to find free space) Virtual memory (Address space)\n위의 이슈(protection, free space) 를 해결한다.\n* Address space : code(text), data, heap, stack\n각각의 프로세스는 자신들의 고유한 Address space(Virtual memory) 를 갖는다.\n이 Virtual memory 는 결국 물리 메모리에 올려져 실행될 것이다.\n목표\nTransparency (투명성) : 프로그래머가 메모리의 사이즈, 사용가능한 공간에 대해 알 필요가 없다. Eficiency (효율성, 성능) : 시간/공간적 효율성을 보장한다 Protection, Isolation (보호, 독립성) : 프로세스(혹은 그것의 메모리)를 보호한다. code(text), data 영역 : 할당받는 사이즈가 고정적이다.\nstack, heap 영역 : 할당받는 사이즈가 동적이다. (stack : 컴파일러에 의해, heap : 개발자에 의해)\n메모리 사용을 잘못 했을 때, 주로 Segmantation fault 가 발생한다.\nAddress Translation\n가상 메모리주소와 물리 메모리주소를 변환(매핑)시켜줄 수 있어야한다.\n가상 메모리의 시작은 0 부터 시작하고, 물리 메모리의 100 위치에 올려졌다고 가정한다. 가상 메모리의 10 의 주소를 읽을 때, 물리 메모리의 110 위치를 읽을 수 있어야 한다. Hardware support\nMMU (Memory Management Unit)\nAddress translation 을 돕는 CPU 의 한 part 이다.\nBase/Limit registers, Segmentation related registers, Paging related registers, TLB + Circuitry Memory Management # Base / Limit Registers Segmentation Paiging Base \u0026amp; Limit registers\nOther mechanisms : Segmentation, Paging\nBase ~ Base + Limit 구간을 사용한다. (Base 보다 작거나, Base + Limit 보다 큰 곳을 사용하면 Segmant fault 발생)\nBase register : 32KB PC : 128 물리 메모리 주소 : 32768 + 128 = 32896 Segmentation\nBase \u0026amp; Limit Register 메커니즘의 경우는 필요한 메모리가 통으로(연속해서) free 해야 물리 메모리에 올릴 수 있다. 이 문제를 해결하기 위한 메커니즘 중 하나이다.\nBase \u0026amp; Limit register 기법을 base 로 한다.\n프로세스를 논리적으로 나누고 이 각각의 영역을 \u0026lsquo;segmant\u0026rsquo; 라고 한다. (예: code, data, stack, heap 영역으로 나눈다. 혹은 이것을 더 세분화 한다.)\n이 세그먼트들은 분리(독립)하여 물리 메모리에 올린다. (이때 각각의 segment 는 각각의 base \u0026amp; limit register 를 갖는다.)\n* Segment table 을 사용해 address translation 을 진행한다.\n물리 메모리의 주소 : Segment number + offset\nSharing : 특정 segment 영역을 공유할 수 있다.\nProtection : 세그먼트 별로 proteciton 정책을 정할 수 있다. (granularity)\nSegment-Size\nCoarse-grained (크게 작업) : 관리 쉬워진다.\nFine-grained (작게 작업) : 효율성 향상, 관리를 위해 segment table 사용한다.\nAllocation\nBest-fit Worst-fit First-fit Buddy algorithm 문제점\n외부 단편화 : segment 의 사이즈는 가변적인데, 이것은 외부 단편화를 특히 더 야기시킨다. Paging # Page table 사용 (Page number, offset : page size * page number + offset)\n32bit 환경에서 page 의 크기 : 4KB (보통) Memory 에 저장 (CPU register 에 저장하기엔 사이즈가 크다.) Fixed size 사용 (관리 용이해진다 -\u0026gt; HW 적으로도 support 원활해진다.)\n여기까지는 paging 의 속도는 굉장히 느리다.\nPTE 주소를 찾아야한다. (memory) PTE에서 fetch 할 때에도 memory 에 접근한다. Bits 를 체크한다. (PTE Bits) 물리 메모리에 올릴 때, 또 memory 에서 읽는다. * TLB(Translation Lookaside Buffer) 기법 -\u0026gt; Faster translation\nCache of recent used PTE (Better name would be an address-translation cache) * 가능한 cache 를 사용하자!! References\nVirtual Memory, https://velog.io/@woo0_hooo/OS-CH3-3-Virtual-Memory Segmentation, https://wansook0316.github.io/cs/os/2020/04/06/운영체제-정리-15-세그멘테이션.html "},{"id":183,"href":"/docs/OS/07.-Concurrency-Thread-and-Lock/","title":"07. (Concurrency) Thread and Lock","section":"OS","content":" Concurrency : Thread and Lock # * 병행성 : 동시에 처리되는 것 처럼 보이게 하는 것\n* 병렬성 : 동시에 처리되는 것\nKeywords of concurrency\nShared data Race condition Coarse-grained locking \u0026hellip; Fron now on \u0026hellip;\nMulti-threaded Program : multiple control flows in a program Concurrency : shared data -\u0026gt; race condition What is a Thread ?\nComputing resources for a program\nThread는 프로세스 내에서 실행되는 흐름의 단위를 말한다.\nAddress space 에서 code(text), data, heap 영역을 공유한다.\nfast creation better sharing worse isolation Benefit of thread\nFast creation Parallelism Multithread : devide \u0026amp; conquer (MapReduce model) Can overlap processing with waiting Ex. Webserver : request thread, processing thread, response thread, \u0026hellip; Data sharing Issue of multithread\nUncontrolled scheduling\nAtomicity : do all or none Critical section : race condition problem Mutual exclusion : allow only one thread to access the critical section Issue of concurrency\nMutual exclusion Synchronization Evaluation of locking(unlocking)\nCorrection : Does it work correctly? Coarse-grained lock : lock 범위 크게 (단순, 낮은 효율) Fine-grained lock : lock 범위 작게 (복잡, 높은 효율) How to build the locking(unlocking)\nDisable interrupt single cpu 에서는 문제가 없다. multi cpu 에서 문제가 있다. 남용/오용의 가능성이 있다. SW Dekker\u0026rsquo;s algorithm, Peterson\u0026rsquo;s algorithm, \u0026hellip; 잘 사용되지 않는다. (이해하기 어렵고, 비효율적이다. 가끔 부정확하다.) HW (HW atomic operation) Test-and-Set instruction Compare-and-Swap Load-Linked and Store-Conditional Fetch-and-Add \u0026hellip; Lock Mechanisms\nSpin Lock sleep lock 에 비해 비효율적이다. Sleep Lock context switch overhead 발생한다. * context switch 의 비용이 spin lock 보다 비효율적이라면, spin lock 을 사용한다. (짧게 기다릴 때 : spin lock, 오래 기다릴 때 : sleep lock)\n"},{"id":184,"href":"/docs/OS/08.-Concurrency-Semaphore-and-Deadlock/","title":"08. (Concurrency) Semaphore and Deadlock","section":"OS","content":" Concurrency: Semaphore and Deadlock # Producer/Consumber problem (Bounded buffer problem) # 한번에 여러 producer, consumer 가 버퍼에 접근하는 것을 막아야한다.\nSemaphore # For both a lock and a condition variable\n"},{"id":185,"href":"/docs/OS/10.-File-System-Basic/","title":"10. File System Basic","section":"OS","content":" File System Basic # Persistence\n메모리(휘발성) 상의 문제는 컴퓨터를 reboot 하면 해결된다.\n디스크(비휘발성) 상의 문제는 컴퓨터를 reboot 해도 해결되지 않는다.\nComputer system\u0026rsquo;s 4 key abstractions\nProcess Virtual Memory Lock File What is a file?\n(영구히 저장되는) Bytes 들의 선형 집합(배열)이다.\n각각의 file 은 절대경로, 상대경로를 갖는다.\nInode (OS, Low-level 단의 이름) 을 갖는다.\nDevice, Pipe, Socket, some processes 는 file 로서 취급된다.\n(OS 가 관리하는 모든 장치는 file 로서 접근 가능하다.)\nDRAM 에 write 하는 것은, Disk 에 write 하는 것 보다 대략 10000배 빠르다.\n* Delayed write : Write later all dirty data into disk(memory)\nContents in a FS\nUserdata : data written by users Metadata : data written by fs for managing files (in inode) "},{"id":186,"href":"/docs/OS/99.-RAID/","title":"99. RAID","section":"OS","content":" Redundant Array Inexpensive(Independent) Disk # (초창기에는) \u0026ldquo;저렴한 디스크를 사용해서 구성한다는 느낌으로\u0026rdquo; \u0026lsquo;Inexepnsive\u0026rsquo; 키워드를 사용했다고 한다.\n\u0026ldquo;독립적인 저장 공간 구성한다는 느낌으로(즉, 안정성, 가용성)\u0026rdquo;,\u0026lsquo;Independent\u0026rsquo; 키워드를 사용한다고 한다.\n개요 # RAID 특징\n고가용성 (안정성) 향상 디스크 I/O 성능 향상 디스크 확장성 향상 RAID 구성은 \u0026lsquo;HW 방식\u0026rsquo;과 \u0026lsquo;SW 방식\u0026rsquo;이 있다.\n1. HW 방식 # HW 방식은 메인보드에 \u0026lsquo;RAID 컨트롤러 카드\u0026rsquo; 라는 것을 장착하여 구현한다고 한다.\n운영체제 부팅 진입 전, RAID 구성을 확인한다고 한다.\n\u0026lsquo;RAID 컨트롤러 카드\u0026rsquo; : RAID 를 컨트롤하기 위한 장치\n2. 펌웨어 방식 # 간소화된 HW 방식이라고 볼 수 있다.\nRAID 칩을 메인보드에 탑재(펌웨어)한 방식이라고 한다.\n3. SW 방식 # SW를 통해 RAID 를 구성하는 방식이다.\n스트라이핑(striping) : 데이터를 분할하여(번갈아가며) 저장하는 방식 = \u0026lsquo;I/O 작업\u0026rsquo;을 디스크 수 만큼 분할하여 처리하기 때문에 성능이 향상된다고 한다.\n미러링(mirroring) : replication 과 같이 데이터를 복제하여 저장한다는 의미\n방식 설명 특징 RAID 0 스트라이핑 구성 * 성능을 최우선으로 할 때 사용한다고 한다. 성능 : ★★★★★ RAID 1 미러링(replication 과 같이) 방식으로 데이터 저장 - 가용성(안전성) : ★★★★★ - 비용 : ★ (비용 n 배)\n- 읽기 성능 : ↑ - 쓰기 성능 : ↓ (악간) RAID 2 (bit 단위)스트라이핑 구성 패리티 비트(오류 검사, 수정) 기능 추가\n즉, \u0026lsquo;실제 사용하는 디스크\u0026rsquo;, \u0026lsquo;오류 핸들링을 위해 사용하는 디스크\u0026rsquo;로 분리\n* RAID 3, RAID 4에 비해 이점이 없어, 현재는 사용되지 않는 추세라고 한다. RAID 3 (byte 단위)스트라이핑 구성 디스크 1개 : 패리티 비트 용도 사용 * 너무 작은 단위(byte)로 스트라이핑하기에 현재는 사용되지 않는 추세라고 한다. RAID 4 (block 단위) RAID 3과 동일한 방식(스트라이핑 + 디스크 1개 : 패리티)\n(패리티 용도의)디스크가 장애 시 \u0026lsquo;에러 핸들링 불가\u0026rsquo; * block 단위로 저장할 경우, 파일의 사이즈가 작다면 하나의 블록(디스크)에서 데이터를 가져올 수 있기에, (비교적)성능 향상을 기대할 수 있다.\n* RAID 4 역시 RAID 5 로 많이 대체되었다고 한다. RAID 5 (block 단위) RAID 4와 동일한 방식 단, 패리티 디스크를 특정한 디스크로 지정하지 않고, 매 번 다른 디스크에 패리티 정보를 저장한다는 차이\n= (패리티 용도의) 디스크가 특정되지 않았기에, RAID 4의 \u0026lsquo;패리티 디스크\u0026rsquo; 장애 시의 문제를 (비교적)해결\n= (어떤 디스크라도)하나의 디스크 장애 시, 복구 가능 - 성능 : (단일 디스크 사용 방식 대비) 전체 디스크 수 - 1\n- 용량 : (단일 디스크 사용 방식 대비) 전체 디스크 수 - 1 RAID 6 RAID 5 + 2차 (패리티 용도 디스크) 추가\n(일반적인 경우) 2개의 디스크에 장애가 나도 핸들링 가능 (= 설계 목적) 중첩 RAID\n- RAID01\n- RAID10\n- RAID50\n- \u0026hellip; \u0026quot; RAID의 주 사용 목적은 크게 무정지 구현(안정성)과 고성능 구현으로 구분된다.\n무정지 구현을 극도로 추구하면 RAID 1, 고성능 구현을 극도로 추구하면 RAID 0이 되며 RAID 5, 6은 둘 사이에서 적당히 타협한 형태 RAID 10이나 RAID 01과 같이 두 가지 방식을 혼용하는 경우도 있다. \u0026ldquo;\n출처: https://zetastring.tistory.com/121\n참고 # https://www.stevenjlee.net/2020/03/01/이해하기-raid-구현-방식과-종류에-대하여/ https://zetastring.tistory.com/121 "},{"id":187,"href":"/docs/OS/99.-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81/","title":"99. 스케줄링","section":"OS","content":" 스케줄링 # 스케줄링이란, 시스템의 자원을 어떤 프로세스에게 할당할 것인지 선택하는 것이다.\n선점형 스케줄링, 비선점형 스케줄링이 있다.\n선점형 스케줄링 # 어떤 프로세스가 시스템의 자원을 사용하여 작업을 진행하는 도중, 해당 작업을 중지하고 시스템의 자원을 다른 프로세스에게 넘겨줄 수 있는 스케줄링이다.\nRound Robin (RR)\nFCFS 기법 + 선점형의 기법이다.\nSRT (Shortest Remaining Time)\nSJF + 선점형의 기법이다.\nMLQ\nQueue 에 자원을 점유할 프로세스들을 대기시킨다.\n여러 개의 Queue 를 갖는다. Queue 마다 우선순위가 있다.\n우선순위가 높은 Queue 에 대기하는 프로세스가 자원을 점유한다.\n선점형 기법이기 때문에, 우선순위가 높은 프로세스가 대기 상태로 들어오면 바로 자원을 점유할 수 있다. (사용중이던 애는 자원을 빼앗긴다.)\n* MLQ 를 이용했을 때의 특징은 I/O 와 같이 처리 시간이 빨라야 하는 것은 우선순위가 높은 Queue에 대기시키고, 비교적 처리 시간이 느슨해도 되는 프로세스는 우선순위가 낮은 Queue 에 대기시킬 수 있다는 것이다.\nMFQ\nMLQ + Time Slice, 큐 간의 이동 등의 기법이 추가되었다.\nMLQ 와 동일하게 Queue 에 우선순위가 있다. 그러나 Queue 마다 Time slice 가 있으며, 해당 Time slice 동안 종료되지 않는 프로세스는 다음 Queue(우선순위가 낮은)로 이동된다.\nQueue 에서 일정한 대기시간이 지나면 우선순위가 높은 Queue 로 이동될 수 있다.\n비선점형 스케줄링 # 어떤 프로세스가 시스템의 자원을 사용하여 작업을 진행하게 되면, 종료될 때까지 자원을 뺏을 수 없다. 기다려야 한다.\nFCFS (FIFO)\n선입 선출의 스케줄링 기법이다.\nSJF (Shortest Job First)\n실행시간(처리시간)이 짧은 것부터 자원을 점유한다.\nHRN (Hightest Response-ratio Next)\nSJF의 Starvation (기아, 굶주림) 을 해결하기 위한 기법이다.\n우선순위 = 실행시간 + 대기시간 / 실행시간 의 계산을 통해 우선순위를 정한다.\nReference\nhttps://velog.io/@codemcd/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9COS-6.-CPU-%EC%8A%A4%EC%BC%80%EC%A4%84%EB%A7%81 "},{"id":188,"href":"/docs/REDIS/REDIS-Data-Structures/","title":"[REDIS] Data Structures","section":"REDIS","content":" Lists # Redis Lists are implemented with linked lists because for a database system it is crucial to be able to add elements to a very long list in a very fast way.\nO(1) # LPUSH, RPUSH LPOP, RPOP LLEN O(n) # LINDEX, LRANGE LSET Use Case # Feed system can be a good use case.\nEvery time a user posts a new photo, we add its ID into a list with LPUSH. When users visit the home page, we use LRANGE 0 9 in order to get the latest 10 posted items.\nSets # Sets stores collections of unique, unsorted string elements.\nAdd, remove, and check for the existence of members is very cheap.\nIf you have a collection of items and it is very important to check for the existence(SISMEMBER) or size of the collection(SCARD) in a very fast way.\nAnother cool thing about sets is support for peeking(SRANDMEMBER) or popping random elements(SPOP).\nO(1) # TYPE COMMAND CREATE SADD DELETE SPOP RETRIEVE SISMEMBER OTHERS SCARD O(N) # TYPE COMMAND DELETE SREM RETRIEVE SDIFF OTHERS SUNION LIST SMEMBERS O(N*M) # TYPE COMMAND OTHERS SINTER Use Case # Sets are good for expressing relations between objects.\nFor example, we can use sets in order to implement many-to-many relationships between posts and tags.\n출처: https://medium.com/analytics-vidhya/the-most-important-redis-data-structures-you-must-understand-2e95b5cf2bce\n1. To get all the posts tagged in by MYSQL\nsmembers tag:Mysql:posts 2. To get all the posts tagged by multiple tags like MYSQL, Java, Redis.\nsinter tag:Java:posts tag:MySQL:posts, tag:Redis:posts Hash # Redis Hashes can be used to represent objects.\nO(1) # TYPE COMMAND CREATE HSET RETRIEVE HGET OTHERS HLEN O(n) # TYPE COMMAND RETRIEVE HGETALL LIST HKEYS Use Case # We can use Hash map to model a user(whatever can be a model).\nHMSET user:139960061 login dr_josiah id 139960061 followers 176 OK HGETALL user:139960061 1) \u0026#34;login\u0026#34; 2) \u0026#34;dr_josiah\u0026#34; 3) \u0026#34;id\u0026#34; 4) \u0026#34;139960061\u0026#34; 5) \u0026#34;followers\u0026#34; 6) \u0026#34;176\u0026#34; HINCRBY user:139960061 followers 1 \u0026#34;177\u0026#34; Sorted Sets # Every member of a Sorted Set is associated with a score, that is used in order to take the sorted set ordered, from the smallest to the greatest score.\n\u0026hellip; Accessing the middle of a sorted set is also very fast, so you can use Sorted Sets as a smart list of non repeating elements where you can quickly access everything you need: elements in order, fast existence test, fast access to elements in the middle!\nO(1) # TYPE COMMAND OTHERS ZCARD O(log(n)) # TYPE COMMAND CREATE ZADD DELETE ZREM, ZPOPMAX RETRIEVE ZRANGE, ZRANK Use Case # Many Q\u0026amp;A platforms like StackOverflow and Quara use Redis Sorted Sets to rank the highest voted answers for each proposed question to ensure the best content is listed at the top of the page.\n"},{"id":189,"href":"/docs/REDIS/REDIS-Redis-Pipelining/","title":"[REDIS] Redis Pipelining","section":"REDIS","content":" Redis Pipelining # \u0026quot; How to optimize round-trip times by batching Redis commands \u0026ldquo;\n여러 명령(command)을 한번에 요청/응답하는 것\nDB 에서는 Bulk 연산자를 지원하지만, 레디스에서는 Bulk 연산자를 지원하지 않는다. 대신 pipelin api 를 지원한다.\n(흔히 나오는 예시) (아래)HTTP pipelining 과 비슷한 개념이다.\n문제1. RTT (Round-Trip Time) # Redis는 고성능의 저장소이지만, TCP 기반 위에서 동작한다.\n즉 요청/응답을 위해 (TCP 기반의)네트워크 I/O가 발생할 것이다. Redis 의 성능이 아무리 좋아도, RTT가 길다면 클라이언트 입장에서 (시간 당)처리량이 줄어들 수 밖에 없다.\n문제2. Socket I/O # RTT 뿐만 아니라, (파이프라이닝 없이)여러 커맨드를 요청했을 때 발생하는 socket I/O 비용도 크다. 한번에 요청하면 이 비용을 절약할 수 있다.\n\u0026rdquo; This involves calling the read() and write() syscall, that means going from user land to kernel land. The context switch is a huge speed penalty. When pipelining is used, many commands are usually read with a single read() system call, and multiple replies are delivered with a single write() system call. \u0026ldquo;\nSpring Data Redis :: Pipelining # (Spring Data Redis의) RedisTemplate 은 파이프라이닝 기능을 지원하는 (몇 개의)메서드를 제공한다.\nexecute / executePipelined execute\n파이프라이닝을 사용하되, 결과(result)를 신경쓰지 않는다면 execute 메서드에 pipeline 인자에 true 값만 주면 된다.\npublic class RedisTemplate\u0026lt;K, V\u0026gt; extends RedisAccessor implements RedisOperations\u0026lt;K, V\u0026gt;, BeanClassLoaderAware { ... public \u0026lt;T\u0026gt; T execute(RedisCallback\u0026lt;T\u0026gt; action, boolean exposeConnection, boolean pipeline) { ... } ... } executePipelined\npublic class RedisTemplate\u0026lt;K, V\u0026gt; extends RedisAccessor implements RedisOperations\u0026lt;K, V\u0026gt;, BeanClassLoaderAware { ... public List\u0026lt;Object\u0026gt; executePipelined(SessionCallback\u0026lt;?\u0026gt; session, @Nullable RedisSerializer\u0026lt;?\u0026gt; resultSerializer) { Assert.isTrue(initialized, \u0026#34;template not initialized; call afterPropertiesSet() before using it\u0026#34;); Assert.notNull(session, \u0026#34;Callback object must not be null\u0026#34;); RedisConnectionFactory factory = getRequiredConnectionFactory(); // bind connection RedisConnectionUtils.bindConnection(factory, enableTransactionSupport); try { return execute((RedisCallback\u0026lt;List\u0026lt;Object\u0026gt;\u0026gt;) connection -\u0026gt; { connection.openPipeline(); // (1) : Open pipeline boolean pipelinedClosed = false; try { Object result = executeSession(session); if (result != null) { throw new InvalidDataAccessApiUsageException( \u0026#34;Callback cannot return a non-null value as it gets overwritten by the pipeline\u0026#34;); } List\u0026lt;Object\u0026gt; closePipeline = connection.closePipeline(); // (3) : Close pipeline pipelinedClosed = true; return deserializeMixedResults(closePipeline, resultSerializer, hashKeySerializer, hashValueSerializer); // (2) : Deserilize (mixed)results } finally { if (!pipelinedClosed) { connection.closePipeline(); // (3) : Close pipeline } } }); } finally { RedisConnectionUtils.unbindConnection(factory); } } ... public List\u0026lt;Object\u0026gt; executePipelined(RedisCallback\u0026lt;?\u0026gt; action, @Nullable RedisSerializer\u0026lt;?\u0026gt; resultSerializer) { ... } ... } pipeline 을 열고, 닫는것을 제외하고는 거의 execute 와 유사하다.\n예시\nList\u0026lt;Object\u0026gt; results = stringRedisTemplate.executePipelined( new RedisCallback\u0026lt;Object\u0026gt;() { public Object doInRedis(RedisConnection connection) throws DataAccessException { StringRedisConnection stringRedisConn = (StringRedisConnection)connection; for(int i=0; i\u0026lt; batchSize; i++) { stringRedisConn.rPop(\u0026#34;myqueue\u0026#34;); } return null; } }); 위 예시는 하나의 요청(커넥션)에서 bulk rPop 연산을 처리하는 예시이다.\nresults 에는 pop 된 아이템들이 결과물로 나온다.\nRedisConnection.openPipeline() # public interface RedisConnection extends RedisCommands, AutoCloseable { ... /** * Activates the pipeline mode for this connection. When pipelined, all commands return null (the reply is read at the * end through {@link #closePipeline()}. Calling this method when the connection is already pipelined has no effect. * Pipelining is used for issuing commands without requesting the response right away but rather at the end of the * batch. While somewhat similar to MULTI, pipelining does not guarantee atomicity - it only tries to improve * performance when issuing a lot of commands (such as in batching scenarios). * \u0026lt;p\u0026gt; * Note: * \u0026lt;/p\u0026gt; * Consider doing some performance testing before using this feature since in many cases the performance benefits are * minimal yet the impact on usage are not. * * @see #multi() */ void openPipeline(); ... } public class LettuceConnection extends AbstractRedisConnection { ... @Override public void openPipeline() { if (!isPipelined) { isPipelined = true; ppline = new ArrayList\u0026lt;\u0026gt;(); flushState = this.pipeliningFlushPolicy.newPipeline(); flushState.onOpen(this.getOrCreateDedicatedConnection()); } } ... } 특징을 살펴보면,\n(해당 커넥션에) 파이프라인 모드를 활성화한다. 이미 파이프라인이 오픈된 상태에서는 아무 효과가 없다. 파이프라인 동안에는, 모든 명령어는 null 을 반환한다. (null 반환하지 않을 경우 Exception 터지는 로직이 있기도 함) MULTI 와 비슷할 수 있지만, pipelining 은 atomicity 를 보장하지는 않는다. 파이프라이닝은 다수의 명령어에 대한 성능 향상이 목적이다. RedisConnection.closePipeline() # public interface RedisConnection extends RedisCommands, AutoCloseable { ... /** * Executes the commands in the pipeline and returns their result. If the connection is not pipelined, an empty * collection is returned. * * @throws RedisPipelineException if the pipeline contains any incorrect/invalid statements * @return the result of the executed commands. */ List\u0026lt;Object\u0026gt; closePipeline() throws RedisPipelineException; ... } public class LettuceConnection extends AbstractRedisConnection { ... @Override public List\u0026lt;Object\u0026gt; closePipeline() { if (!isPipelined) { return Collections.emptyList(); } flushState.onClose(this.getOrCreateDedicatedConnection()); flushState = null; isPipelined = false; List\u0026lt;io.lettuce.core.protocol.RedisCommand\u0026lt;?, ?, ?\u0026gt;\u0026gt; futures = new ArrayList\u0026lt;\u0026gt;(ppline.size()); for (LettuceResult\u0026lt;?, ?\u0026gt; result : ppline) { futures.add(result.getResultHolder()); } try { boolean done = LettuceFutures.awaitAll(timeout, TimeUnit.MILLISECONDS, futures.toArray(new RedisFuture[futures.size()])); List\u0026lt;Object\u0026gt; results = new ArrayList\u0026lt;\u0026gt;(futures.size()); Exception problem = null; if (done) { for (LettuceResult\u0026lt;?, ?\u0026gt; result : ppline) { if (result.getResultHolder().getOutput().hasError()) { Exception err = new InvalidDataAccessApiUsageException(result.getResultHolder().getOutput().getError()); // remember only the first error if (problem == null) { problem = err; } results.add(err); } else if (!result.isStatus()) { try { results.add(result.conversionRequired() ? result.convert(result.get()) : result.get()); } catch (DataAccessException e) { if (problem == null) { problem = e; } results.add(e); } } } } ppline.clear(); if (problem != null) { throw new RedisPipelineException(problem, results); } if (done) { return results; } throw new RedisPipelineException(new QueryTimeoutException(\u0026#34;Redis command timed out\u0026#34;)); } catch (Exception e) { throw new RedisPipelineException(e); } } ... } 특징을 살펴보면,\n파이프라인 안에서 실행한 명령어들에 대한 결과(results)가 반환된다. 파이프라이닝 상태가 아니었다면, 빈 컬렉션(empty collection)이 반환된다. 추가 # 1. command 의 순서가 변경되지 않는다.\nRedis pipelining 은 단순히 요청을 한번에 보내는 것일 뿐 요청(커맨드)의 순서에 영향을 주지 않는다. 공식 문서에서 이것과 관련된 내용은 못찾았다. 다만, 여기를 포함해 다른 글들을 참고할 수 있을 것 같다.\n출처 # Redis pipelining Spring Data Redis "},{"id":190,"href":"/docs/REDIS/REDIS-%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98/","title":"[REDIS] 트랜잭션","section":"REDIS","content":" \u0026quot; 여러 자료구조를 사용할 수 있는 Redis 의 특성상 트랜잭션을 잘 이용하면 더 유용하게, 다양한 상황에서 Redis 를 사용할 수 있을 것 입니다. \u0026ldquo; 출처 : https://sabarada.tistory.com/177\nRedis 에서는 MULTI, EXEC, DISCARD 와 WATCH 명령어를 사용할 수 있다.\n명령어 설명 MULTI 트랜잭션 시작 트랜잭션 시작 시, 이후 명령어(들)은 바로 실행되지 않고 queue 에 쌓임 EXEC queue 에 쌓인 명령어(들)을 일괄적으로 실행\n* RDBMS 의 commit DISCARD queue 에 쌓인 명령어(들)을 버림\n* RDBMS 의 rollback WATCH (Optimistic Lock 기반) Lock\n*WATCH 이후 UNWATCH 되기 전 1번의 EXEC 혹은 Transaction 이 아닌 다른 명령어만 허용 * EXEC 호출 시 내부적으로 UNWATCH 호출\n(= 두 번째 EXEC 호출 시에는 WATCH 없는 상태) 참고 사항 # 트랜잭션 과정 중 서버가 다운되었을 경우, 서버 재시작 시 감지되고 오류와 함께 재시작되지 않을 것이다. 트랜잭션 과정 중 해당 클라이언트의 커넥션이 끊겼을 경우, 명령어들은 실행되지 않는다. (DISCARD 처리 (?)) References # redis.io : Transactions [redis] 트랜잭션(Transaction) - 이론편 "},{"id":191,"href":"/docs/SPRING/SPRING-2.7.2-3.0.1-migration/","title":"[SPRING] 2.7.2 -\u003e 3.0.1 Migration","section":"SPRING","content":" 전제 조건 # Java 17 이상 SpringBoot 2.7.x 참고 문서 # wiki: Spring Boot 3.0 Migration Guide TIP # 다음 라이브러리가 도움을 준다.\nruntime(\u0026#34;org.springframework.boot:spring-boot-properties-migrator\u0026#34;) 의존성 설치 후 애플리케이션을 시작하면, 로그에 변경된 사항을 알려준다.\nCore Changes # Jakarta EE (패키지명 변경 : javax -\u0026gt; jakarta) # history 잠깐 보면, 2017년 오라클에서 이클립스 재단으로 자바 EE를 이관했다. (\u0026ldquo;썬 마이크로시스템즈를 인수한 오라클이 사실상 자바EE의 수익화에 실패하면서 기술 주도권을 포기한 것으로 판단됩니다.\u0026rdquo;) (오픈소스) 이클립스 재단으로 이관된 자바 EE의 공식 명칭이 자카르타 EE 이다. (\u0026ldquo;이클립스 재단으로 이관된 자바EE의 공식 명칭은 자카르타EE, 프로젝트 명은 EE4J(Eclipse Enterprise for Java)로 변경되었습니다.\u0026rdquo;)\n\u0026ldquo;오라클이 자바EE 프로젝트는 이관했지만 자바 상표권은 여전히 보유하고 있기 때문에 자바 네임스페이스 사용에 제약이 있었습니다. 이러한 이유로 자카르타EE에서는 자바 네임스페이스가 Jakarta로, API 패키지명은 javax.* 에서 Jakarta.* 로 변경되었습니다.\u0026rdquo;\n참고 : https://www.samsungsds.com/kr/insights/java_jakarta.html\n@ConstructingBinding No Longer Needed at the Type Level # @ConstructorBinding is no longer needed at the type level on @ConfigurationProperties classes and should be removed. When a class or record has multiple constructors, it may still be used on a constructor to indicate which one should be used for property binding.\n클래스 레벨에 사용하는 것은 안되고, 생성자 위에 사용하는 것이 가능해졌나보다.\n// before @Target({ ElementType.TYPE, ElementType.CONSTRUCTOR }) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface ConstructorBinding { } // after @Target({ ElementType.CONSTRUCTOR, ElementType.ANNOTATION_TYPE }) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface ConstructorBinding { } Auto-configuration Files # 2.7에서 auto-configuration 위해 META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports 이 도입되었다. (예시 - https://github.com/spring-projects/spring-boot/blob/main/spring-boot-project/spring-boot-autoconfigure/src/main/resources/META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports)\n기존에 spring.factories(org.springframework.boot.autoconfigure.EnableAutoConfiguration)와 호환 가능했지만, 이번 릴리즈 부터는 spring.factories 는 제거됐다.\nData Access Changes # (application.yml) spring.redis -\u0026gt; spring.data.redis 설정 변경 # https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-3.0-Migration-Guide#redis-properties\nSpring Batch Changes (5.0) # @EnableBatchProcessing is now discouraged # Previously, @EnableBatchProcessing could be used to enable Spring Boot’s auto-configuration of Spring Batch. It is no longer required and should be removed from applications that want to use Boot’s auto-configuration. A bean that is annotated with @EnableBatchProcessing or that extends Batch’s DefaultBatchConfiguration can now be defined to tell the auto-configuration to back off, allowing the application to take complete control of how Batch is configured.\n+ https://stackoverflow.com/a/74845329\nMultiple Batch Jobs # JobBuilderFactory and StepBuilderFactory bean exposure/configuration # jobBuilderFactory\n// before @Bean fun myJob(): Job = jobBuilderFactory .get(\u0026#34;myJob\u0026#34;) .start(myStep()) .build() // after @Bean fun myJob(): Job = JobBuilder(\u0026#34;myJob\u0026#34;, jobRepository) .start(myStep()) .build() JobBuilder, StepBuilder 는 원래 있었는데 생성자 하나가 더 생겼다. (기존 생성자는 Deprecated)\n@Deprecated(since = \u0026#34;5.0\u0026#34;) public JobBuilder(String name) { super(name); } public JobBuilder(String name, JobRepository jobRepository) { super(name); super.repository(jobRepository); } @Deprecated(since = \u0026#34;5.0\u0026#34;) public StepBuilder(String name) { super(name); } public StepBuilder(String name, JobRepository jobRepository) { super(name); super.repository(jobRepository); } stepBuilderFactory\n// before @Bean fun myStep(): Step = stepBuilderFactory .get(\u0026#34;myStep\u0026#34;) .tasklet { _: StepContribution, _: ChunkContext -\u0026gt; ... } .build() // after @Bean fun myStep(): Step = StepBuilder(\u0026#34;myStep\u0026#34;, jobRepository) .tasklet(myTasklet, transactionManager) Database schema updates # 스키마 변경이 있다. (스키마 마이그레이션 시) 해당 프레임워크 내에 쿼리를 제공하고 있으니 그걸 사용하면 된다.\nTransaction manager bean exposure/configuration # (몇 가지 이슈가 있어서) @EnableBatchProcessing 가 이제 txmanager 빈을 노출시키지 않음 -\u0026gt; 사용자가 수동으로 설정하게 되었다. (?) :thinking:\n// Sample with v4 @Configuration @EnableBatchProcessing public class MyStepConfig { @Autowired private StepBuilderFactory stepBuilderFactory; @Bean public Step myStep() { return this.stepBuilderFactory.get(\u0026#34;myStep\u0026#34;) .tasklet(..) // or .chunk() .build(); } } // Sample with v5 @Configuration @EnableBatchProcessing public class MyStepConfig { @Bean public Tasklet myTasklet() { return new MyTasklet(); } @Bean public Step myStep(JobRepository jobRepository, Tasklet myTasklet, PlatformTransactionManager transactionManager) { return new StepBuilder(\u0026#34;myStep\u0026#34;, jobRepository) .tasklet(myTasklet, transactionManager) // or .chunk(chunkSize, transactionManager) .build(); } } @Deprecated(since = \u0026#34;5.0\u0026#34;) public TaskletStepBuilder tasklet(Tasklet tasklet) { return new TaskletStepBuilder(this).tasklet(tasklet); } public TaskletStepBuilder tasklet(Tasklet tasklet, PlatformTransactionManager transactionManager) { return new TaskletStepBuilder(this).tasklet(tasklet, transactionManager); } (kotlin의 경우) 람다를 못쓴다. (\u0026hellip;?) :thinking:\nETC # org.hibernate.dialect.MySQL57Dialect -\u0026gt; org.hibernate.dialect.MySQLDialect # jakarta.persistence.sharedCache.mode 설정 # "},{"id":192,"href":"/docs/SPRING/SPRING-@SpringBootApplication/","title":"[SPRING] @SpringBootApplication","section":"SPRING","content":" @SpringBootApplication # /** * Indicates a configuration class that declares one or more @Bean methods * and also triggers auto-configuration and component scanning. * This is a convenience annotation that is equivalent to declaring @Configuration, @EnableAutoConfiguration and @ComponentScan. */ @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = { @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) }) public @interface SpringBootApplication { ... } 아래 기능을 하는 Configuration Class\n@Bean 메서드를 선언할 수 있음 auto-configuration, component scanning 을 발생시킴 Annotation 기능 @SpringBootConfiguration\n(@Configuration) @Bean 메서드들을 선언할 수 있음 (오직 한번만 선언 되어야함) @EnableAutoConfiguration AutoConfiguration 클래스(Configuration)들을 설정(로드) @ComponentScan ComponentScan의 base package @SpringBootConfiguration # /** * Indicates that a class provides Spring Boot application @Configuration. * Can be used as an alternative to the Spring\u0026#39;s standard @Configuration annotation * so that configuration can be found automatically (for example in tests). * * Application should only ever include one @SpringBootConfiguration * and most idiomatic Spring Boot applications will inherit it from @SpringBootApplication. */ @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Configuration public @interface SpringBootConfiguration { ... } 요약 # @Configuration 과 동일하다. 애플리케이션은 오직 하나의 @SpringBootConfiguration 을 포함해야 한다. @SpringBootTest 에서 자동으로 해당 어노테이션(클래스)를 찾는다. 주석 내용 중, ~~~ configuration can be found automatically (for example in tests) @EnableAutoConfiguration # /** * Enable auto-configuration of the Spring Application Context, * attempting to guess and configure beans that you are likely to need. * * Auto-configuration classes are usually applied based on your classpath and what beans you have defined. * * ... * * When using @SpringBootApplication, the auto-configuration of the context is automatically enabled and adding this annotation has therefore no additional effect. * * The package of the class that is annotated with @EnableAutoConfiguration, * usually via @SpringBootApplication, has specific significance and is often used as a \u0026#39;default\u0026#39;. * For example, it will be used when scanning for @Entity classes. * It is generally recommended that you place @EnableAutoConfiguration (if you\u0026#39;re not using @SpringBootApplication) in a root package * so that all sub-packages and classes can be searched. * * Auto-configuration classes are regular Spring @Configuration beans. * They are located using the SpringFactoriesLoader mechanism (keyed against this class). * Generally auto-configuration beans are @Conditional beans (most often using @ConditionalOnClass and @ConditionalOnMissingBean annotations). */ @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage @Import(AutoConfigurationImportSelector.class) public @interface EnableAutoConfiguration { String ENABLED_OVERRIDE_PROPERTY = \u0026#34;spring.boot.enableautoconfiguration\u0026#34;; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ Class\u0026lt;?\u0026gt;[] exclude() default {}; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ String[] excludeName() default {}; } 요약 # Spring Application Context 의 auto-configuration 을 활성화 AutoConfiguration classes ( + SpringFactoriesLoader, @Configuration beans ) 사용자 정의 Beans(classes) 해당 어노테이션이 달린 클래스 패키지 (= \u0026lsquo;default\u0026rsquo; 패키지) (하위 경로의) @Entity classes 스캔 해당 내용은 따로 자세히 작성(확인)\n@ComponentScan # /** * Configures component scanning directives for use with @Configuration classes. * * ... * * Either basePackageClasses or basePackages (or its alias value) may be specified to define specific packages to scan. * If specific packages are not defined, scanning will occur from the package of the class that declares this annotation. */ @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.TYPE) @Documented @Repeatable(ComponentScans.class) public @interface ComponentScan { ... } "},{"id":193,"href":"/docs/SPRING/SPRING-@ToString-Enable-toString-Object-View/","title":"[SPRING] @ToString (Enable ToString() Object View)","section":"SPRING","content":" Intellij 디버깅 시,\nBuild, Execution, Deployment \u0026gt; Debugger \u0026gt; Data Views \u0026gt; Java \u0026gt; Enable toString() Object View 설정이 활성화되어 있다는 가정\nLazy 연관관계를 가진 Entity 조회 시, Lazy 객체의 초기화(Fetch) 시점이 예상과 다를 수 있다.\n예시 # ... @ToString @Entity public class Poster { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = \u0026#34;user_id\u0026#34;) private User user; @ManyToOne(fetch = FetchType.LAZY) @JoinColumn(name = \u0026#34;poster_type_id\u0026#34;) private PosterType posterType; ... public void test() { List\u0026lt;Poster\u0026gt; allPosters = posterRepository.findAll(); Poster poster = allPosters.get(0); // \u0026lt;-- (1) 이때 쿼리 발생 System.out.println(poster.getPosterType()); // \u0026lt;-- (2) 이때 Lazy 객체가 사용되니까, 이때 쿼리가 발생하는 것 예상 } (1) 시점에 쿼리 발생\n... Hibernate: select user0_.user_id as user_id1_3_0_, user0_.email as email2_3_0_, user0_.is_activated as is_activ3_3_0_, user0_.is_authenticated as is_authe4_3_0_, user0_.name as name5_3_0_, user0_.oauth_type as oauth_ty6_3_0_, user0_.phone as phone7_3_0_, user0_.role as role8_3_0_ from user user0_ where user0_.user_id=? ... Hibernate: select postertype0_.poster_type_id as poster_t1_2_0_, postertype0_.height as height2_2_0_, postertype0_.type as type3_2_0_, postertype0_.width as width4_2_0_ from poster_type postertype0_ where postertype0_.poster_type_id=? 이유 # (Intellij 에서) 디버깅 시 Object 의 상태를 보여주기 위해 데이터를 조회 (* Lazy 초기화 조건과 마찬가지로, 실제 데이터가 필요하니까 데이터를 조회)\ntoString 있을 때\ntoString 없을 때\n아래 설정을 해제하거나 @ToString 을 제거하면 예상한것과 같이 동작하는 것을 볼 수 있다.\nResolve https://github.com/hjjae2/Anything/issues/15\n"},{"id":194,"href":"/docs/SPRING/SPRING-@Transactional/","title":"[SPRING] @Transactional","section":"SPRING","content":" PROPAGATION (전파) # 이름 설명 REQUIRED Default 설정 - 이미 시작된 트랜잭션이 없는 경우 : 트랜잭션 생성 - 이미 시작된 트랜잭션이 있는 경우 : 해당 트랜잭션에 참여 REQUIRES_NEW 항상 새로운(new), 독립된 트랜잭션 시작 - 이미 시작된 트랜잭션이 없는 경우 : 트랜잭션 생성 - 이미 시작된 트랜잭션이 있는 경우 : 새로운 트랜잭션 생성, 기존 트랜잭선은 보류(suspend) * 트랜잭션 보류(suspension)의 경우 모든 트랜잭션 매니저(Transaction manager)에서 기본적으로 동작하지 않음에 주의.\n(TransactionManager to be made available to it) SUPPORTS - 이미 시작된 트랜잭션이 없는 경우 : 트랜잭션 없이 진행 - 이미 시작된 트랜잭션이 있는 경우 : 해당 트랜잭션에 참여 MANDATORY 기존에 생성된 트랜잭션이 있도록 강제한다. - 이미 시작된 트랜잭션이 없는 경우 : Throw Exception - 이미 시작된 트랜잭션이 있는 경우 : 해당 트랜잭션에 참여 NOT_SUPPORTED 트랜잭션을 사용하지 않도록 한다. - 이미 시작된 트랜잭션이 없는 경우 : 트랜잭션 없이 진행 - 이미 시작된 트랜잭션이 있는 경우 : 기존 트랜잭션 보류(suspend) * 트랜잭션 보류(suspension)의 경우 모든 트랜잭션 매니저(Transaction manager)에서 기본적으로 동작하지 않음에 주의.\n(TransactionManager to be made available to it) NEVER 트랜잭션을 사용하지 않도록 강제한다. - 이미 시작된 트랜잭션이 없는 경우 : 트랜잭션 없이 진행 - 이미 시작된 트랜잭션이 있는 경우 : Throw Exception NESTED 중첩된 트랜잭션 (REQUIRES_NEW 의 독립적인 트랜잭션과 다름에 주의) - 이미 시작된 트랜잭션이 없는 경우 : 트랜잭션 생성 - 이미 시작된 트랜잭션이 있는 경우 : 중첩 트랜잭션 시작 - 기존 트랜잭션(이하 부모 트랜잭션)의 commit/rollback 은 중첩 트랜잭션(이하 자식 트랜잭션)에 영향 - 자식 트랜잭션의 commit/rollback 은 부모 트랜잭션에 영향 X e.g. 자식 트랜잭션에서 exception 에 의해 rollback 발생해도 부모 트랜잭션의 로직은 commit 될 수 있음 * 기본적으로 모든 트랜잭션 메니저(Transaction manager)에서 기본적으로 동작하지 않음에 주의.\n(일부 JTA provider, JDBC DatasourceTransactionManager 에서 동작) ISOLATION (격리) # 각 격리 수준의 설명은 DB 격리 수준의 내용과 동일하기에 생략\n이름 설명 DEFAULT Datasource 설정 따름 Use the default isolation level of the underlying datastore READ_UNCOMMITED READ_COMMITED REPEATABLE_READ SERIALIZABLE timeout # The timeout for this transaction (in seconds).\n기본 값 : 시스템의 트랜잭션 타임아웃 값\nDefaults to the default timeout of the underlying transaction system.\n\u0026lsquo;새롭게 시작된 트랜잭션\u0026rsquo;에만 적용할 수 있기 때문에, REQUIRED, REQUIRES_NEW와 함께 사용하도록 설계됨\nExclusively designed for use with Propagation.REQUIRED or Propagation.REQUIRES_NEW since it only applies to newly started transactions.\nreadOnly # -\nrollbackFor, rollbackForClassName / noRollbackFor, noRollbackForClassName # rollback, noRollback 대상 지정\n[참고] Transaction 롤백 대상에 관하여,\n\u0026quot; By default, a transaction will be rolling back on RuntimeException and Error but not on checked exceptions (business exceptions). See org.springframework.transaction.interceptor.DefaultTransactionAttribute.rollbackOn(Throwable) for a detailed explanation. \u0026quot;\nDefaultTransactionAttribute 내용을 살펴보면, 다음과 같다.\nRuntimeException, Error = unexpected outcome CheckedException = expected outcome\npublic class DefaultTransactionAttribute extends DefaultTransactionDefinition implements TransactionAttribute { ... /** * The default behavior is as with EJB: rollback on unchecked exception (RuntimeException), assuming an unexpected outcome outside of any business rules. * Additionally, we also attempt to rollback on Error which is clearly an unexpected outcome as well. * By contrast, a checked exception is considered a business exception and therefore a regular expected outcome of the transactional business method, i.e. a kind of alternative return value which still allows for regular completion of resource operations. */ @Override public boolean rollbackOn(Throwable ex) { return (ex instanceof RuntimeException || ex instanceof Error); } ... } 그 외 # https://techblog.woowahan.com/2606/ \u0026quot; 여기서 주목할 만한 사실은, 전파속성(propagation) 때문에 실제 트랜잭션이 재사용되더라도 트랜잭션 메서드의 반환시점마다 트랜잭션의 완료처리(completion)를 한다는 것입니다. 물론 커밋이나 롤백같은 최종완료처리는 최초 트랜잭션이 반환될 때 일어나겠지만요. \u0026quot;\n요약 : 트랜잭션 완료처리 시점(메서드 반환)에 (unchecked)Exception이 터지면 rollback 마킹\n"},{"id":195,"href":"/docs/SPRING/SPRING-@Version/","title":"[SPRING] @Version","section":"SPRING","content":" @Version # \u0026lsquo;낙관적 락\u0026rsquo; 구현 시 사용될 수 있음\npackage javax.persistence; ... /** * Specifies the version field or property of an entity class that serves as its optimistic lock value. * * The version is used to ensure integrity when performing the merge operation and for optimistic concurrency control. * * Only a single Version property or field should be used per class; applications that use more than one Version property or field will not be portable. * * ... * * The following types are supported for version properties: int, Integer, short, Short, long, Long, java.sql.Timestamp. */ @Target({METHOD, FIELD}) @Retention(RUNTIME) public @interface Version {} 1. 자바 표준 애노테이션\n패키지 : javax.persistence;\n2. 클래스 당 오직 하나의 @Version 필드, 컬럼\n3. 지원 타입\nInteger (int) Short (short) Long (long) Timestamp 4. 수정 시 (조회했을 때의)Version 값이 다르다면, 예외 발생\nCAS\nupdate mytable set ~~~ where ~~~ and version = ? select customerve0_.id as id1_1_0_, customerve0_.name as name2_1_0_, customerve0_.version as version3_1_0_ from customer_version customerve0_ where customerve0_.id=? -- 업데이트 전 : CustomerVersion(id=1, name=c1, version=0) update customer_version set name=?, version=? where id=? and version=? -- 업데이트 후 : CustomerVersion(id=1, name=name1, version=1) "},{"id":196,"href":"/docs/SPRING/SPRING-ApplicationEventPublisher/","title":"[SPRING] ApplicationEventPublisher","section":"SPRING","content":" 동작 순서 : ApplicationEventPublisher.publishEvent() # 간단 요약 # AbstractApplicationContext.publishEvent() 호출 ApplicationEvent 타입 확인 \u0026amp; Wrapping (PayloadApplicationEvent) Multicast to listeners ApplicationEventMulticaster.multicastEvent() 호출 (Default) SimpleApplicationEventMulticaster Listener loop 돌며 invoke() public void myMethod() { ... applicationEventPublisher.publishEvent(myObject); } AbstractApplicationContext # public abstract class AbstractApplicationContext extends DefaultResourceLoader implements ConfigurableApplicationContext { ... /** * Publish the given event to all listeners. * Note: Listeners get initialized after the MessageSource, * to be able to access it within listener implementations. * * Thus, MessageSource implementations cannot publish events. * * @param event the event to publish (may be an ApplicationEvent * or a payload object to be turned into a PayloadApplicationEvent) */ @Override public void publishEvent(Object event) { publishEvent(event, null); } /** * Publish the given event to all listeners. * * @param event the event to publish * (may be an ApplicationEvent or a payload object to be turned into a PayloadApplicationEvent) * @param eventType the resolved event type, if known * @since 4.2 */ protected void publishEvent(Object event, @Nullable ResolvableType eventType) { Assert.notNull(event, \u0026#34;Event must not be null\u0026#34;); // Decorate event as an ApplicationEvent if necessary ApplicationEvent applicationEvent; if (event instanceof ApplicationEvent) { applicationEvent = (ApplicationEvent) event; } else { applicationEvent = new PayloadApplicationEvent\u0026lt;\u0026gt;(this, event); if (eventType == null) { eventType = ((PayloadApplicationEvent\u0026lt;?\u0026gt;) applicationEvent).getResolvableType(); } } // Multicast right now if possible - or lazily once the multicaster is initialized if (this.earlyApplicationEvents != null) { this.earlyApplicationEvents.add(applicationEvent); } else { getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); // 참고 : ApplicationEventMulticaster, SimpleApplicationEventMulticaster } // Publish event via parent context as well... if (this.parent != null) { if (this.parent instanceof AbstractApplicationContext) { ((AbstractApplicationContext) this.parent).publishEvent(event, eventType); } else { this.parent.publishEvent(event); } } } } 1. Event(Object) 타입 변환 : ApplicationEvent, PayloadApplicationEvent\nPayloadApplicationEvent : Wrapper 클래스 2. 이벤트 멀티캐스팅 : ApplicationEventMulticaster.multicastEvent\n기본 : SimpleApplicationEventMulticaster.multicastEvent(); (ApplicationEventMulticaster) SimpleApplicationEventMulticaster # public class SimpleApplicationEventMulticaster extends AbstractApplicationEventMulticaster { ... @Override public void multicastEvent(final ApplicationEvent event, @Nullable ResolvableType eventType) { // ResolvableType =\u0026gt; PayloadApplicationEvent (Object 의 Wrapper 클래스) ResolvableType type = (eventType != null ? eventType : resolveDefaultEventType(event)); Executor executor = getTaskExecutor(); for (ApplicationListener\u0026lt;?\u0026gt; listener : getApplicationListeners(event, type)) { if (executor != null) { executor.execute(() -\u0026gt; invokeListener(listener, event)); } else { invokeListener(listener, event); } } } protected void invokeListener(ApplicationListener\u0026lt;?\u0026gt; listener, ApplicationEvent event) { ErrorHandler errorHandler = getErrorHandler(); if (errorHandler != null) { try { doInvokeListener(listener, event); } catch (Throwable err) { errorHandler.handleError(err); } } else { doInvokeListener(listener, event); } } private void doInvokeListener(ApplicationListener listener, ApplicationEvent event) { try { // ApplicationListenerMethodAdapter listener.onApplicationEvent(event); } catch (ClassCastException ex) { String msg = ex.getMessage(); if (msg == null || matchesClassCastMessage(msg, event.getClass()) || (event instanceof PayloadApplicationEvent \u0026amp;\u0026amp; matchesClassCastMessage(msg, ((PayloadApplicationEvent) event).getPayload().getClass()))) { // Possibly a lambda-defined listener which we could not resolve the generic event type for // -\u0026gt; let\u0026#39;s suppress the exception. Log loggerToUse = this.lazyLogger; if (loggerToUse == null) { loggerToUse = LogFactory.getLog(getClass()); this.lazyLogger = loggerToUse; } if (loggerToUse.isTraceEnabled()) { loggerToUse.trace(\u0026#34;Non-matching event type for listener: \u0026#34; + listener, ex); } } else { throw ex; } } } ... } 3. ApplicationListenerMethodAdapter onApplicationEvent(Event) 호출\n결국 ApplicationListner 의 onApplicationEvent 를 호출하는 것 ApplicationListenerMethodAdapter # public class ApplicationListenerMethodAdapter implements GenericApplicationListener { ... @Override public void onApplicationEvent(ApplicationEvent event) { processEvent(event); } public void processEvent(ApplicationEvent event) { Object[] args = resolveArguments(event); // --\u0026gt; Event Object (e.g. Member member) if (shouldHandle(event, args)) { Object result = doInvoke(args); // 이벤트 핸들러(메서드)의 결과 값에 따라 `handleResult` 가 실행된다. // 결과 값이 있으면, 또 publish (?) if (result != null) { handleResult(result); } else { logger.trace(\u0026#34;No result object given - no result to handle\u0026#34;); } } } private boolean shouldHandle(ApplicationEvent event, @Nullable Object[] args) { if (args == null) { return false; } String condition = getCondition(); if (StringUtils.hasText(condition)) { Assert.notNull(this.evaluator, \u0026#34;EventExpressionEvaluator must not be null\u0026#34;); return this.evaluator.condition( condition, event, this.targetMethod, this.methodKey, args, this.applicationContext); } return true; } @Nullable protected Object doInvoke(Object... args) { Object bean = getTargetBean(); // EventListener Bean (e.g. SessionMemberLoginEventHandler) // Detect package-protected NullBean instance through equals(null) check if (bean.equals(null)) { return null; } ReflectionUtils.makeAccessible(this.method); try { return this.method.invoke(bean, args); // ** 우리가 작성한 핸들러(메서드)가 실행된다. ** } catch (IllegalArgumentException ex) { assertTargetBean(this.method, bean, args); throw new IllegalStateException(getInvocationErrorMessage(bean, ex.getMessage(), args), ex); } catch (IllegalAccessException ex) { throw new IllegalStateException(getInvocationErrorMessage(bean, ex.getMessage(), args), ex); } catch (InvocationTargetException ex) { // Throw underlying exception Throwable targetException = ex.getTargetException(); if (targetException instanceof RuntimeException) { throw (RuntimeException) targetException; } else { String msg = getInvocationErrorMessage(bean, \u0026#34;Failed to invoke event listener method\u0026#34;, args); throw new UndeclaredThrowableException(targetException, msg); } } } ... } * 실제 메서드 호출 시 Reflection 사용!\n!! Listner 가 등록되기 전에 event publishing 되는 경우 # 일단 earlyApplicationEvents 저장한다. private Set\u0026lt;ApplicationEvent\u0026gt; earlyApplicationEvents; earlyApplicationEvents.add(Event); listener 가 등록될 때, 저장되어 있던 이벤트들을 multicast 하고 null 로 변경한다. // this.earlyApplicationEvents 가 null 인 경우 -\u0026gt; listener 가 등록되었다는 의미 if (this.earlyApplicationEvents != null) { this.earlyApplicationEvents.add(applicationEvent); } else { getApplicationEventMulticaster().multicastEvent(applicationEvent, eventType); } protected void registerListeners() { // Register statically specified listeners first. for (ApplicationListener\u0026lt;?\u0026gt; listener : getApplicationListeners()) { getApplicationEventMulticaster().addApplicationListener(listener); } // Do not initialize FactoryBeans here: We need to leave all regular beans // uninitialized to let post-processors apply to them! String[] listenerBeanNames = getBeanNamesForType(ApplicationListener.class, true, false); for (String listenerBeanName : listenerBeanNames) { getApplicationEventMulticaster().addApplicationListenerBean(listenerBeanName); } // Publish early application events now that we finally have a multicaster... // 1. this.earlyApplicationEvents null 처리 // 2. multicastEvent 호출 Set\u0026lt;ApplicationEvent\u0026gt; earlyEventsToProcess = this.earlyApplicationEvents; this.earlyApplicationEvents = null; if (!CollectionUtils.isEmpty(earlyEventsToProcess)) { for (ApplicationEvent earlyEvent : earlyEventsToProcess) { getApplicationEventMulticaster().multicastEvent(earlyEvent); } } } "},{"id":197,"href":"/docs/SPRING/SPRING-DispatcherServlet/","title":"[SPRING] DispatcherServlet","section":"SPRING","content":" Dispatcher Servlet # (웹 상에서) 클라이언트로부터 어떠한 요청이 들어오면 (Tomcat 과 같은) Servlet Container 가 요청을 받는다. 이때 제일 앞에서 서버로 들어오는 모든 요청을 처리하는(수신하는) \u0026lsquo;Front-Controller\u0026rsquo; 를 Dispatcher-Servlet 이라고 한다.\nMVC 아키텍쳐는 보통 이 Front-Controller 패턴과 함께 사용된다고 한다.\n공통적인 작업은 Dispatcher-Servlet 이 처리하고 세부적인 작업에 대해서는 적절한 Controller 에 작업을 위임한다.\n잠시 Servlet 개념으로 돌아가보면, 기존에는 모든 Servlet 에 대해 web.xml 에서 URL 매핑을 등록해주어야 했다. 그런데 Dispatcher-Servlet 이 등장하면서 해당 애플리케이션으로 들어오는 모든 요청을 핸들링 해주었다. web.xml의 역할을 축소시키고 편리함을 제공했다.\n즉, 1. 모든 요청을 한 곳(DispatcherServlet)에서 받아서 필요한 공통의 작업을 처리하고 2. 요청에 맞는 handler(Controller) 로 위임(dispatch), 3. 해당 handler의 실행 결과를 Http Response 형태로 만들어 반환하는 역할을 한다.\n\u0026quot; Spring이 없는 JAVA 런타임에는 Controller 가 존재하지 않는다. 따라서 우리는 서블릿 객체를 생성하고, 그것을 web.xml 에 모두 등록해줘야 했다. \u0026quot;\nController 의 등장\n@Controller 어노테이션을 사용할 수 있게 되었다.\nFront-Contrller 패턴 구조(2차 Controller 구조)\nBefore: 요청 -\u0026gt; web.xml (각각의 서블릿(Controller))\nweb.xml 에 각 Controller 를 모두 등록해줘야 한다.\nAfter: 요청 -\u0026gt; DispatcherServlet (1차) -\u0026gt; 일반 Controller (2차)\nDispatcherServlet이 모든 요청을 받고, 위임하는 역할을 함으로써 web.xml 에 모두 등록할 필요가 없어졌다. 공통/최우선 작업 처리\n공통적으로 진행되어야 할 작업들을 우선적으로 처리할 수 있다. (인코딩과 같은 것들이 있다.)\n실행 흐름\nClient -\u0026gt; DispatcherServlet\n클라이언트가 자원을 요청한다. DispatcherServlet -\u0026gt; HandlerMapping\n해당 요청을 처리할 Controller 가 있는지 검색한다. HandlerMapping -\u0026gt; (특정) Controller\nController 를 찾았으면, 처리를 요청한다. Controller -\u0026gt; DispatcherServlet\n요청을 처리하고, 결과를 출력할 View(이름) 를 리턴해준다. DispatcherServlet -\u0026gt; ViewResolver\n받은 View(이름)을 검색한다. ViewResolver -\u0026gt; (해당하는) View\n해당 View 를 찾았으면, 해당 View 에 Controller 가 처리한 데이터를 전달한다. (?)\n해당 View 를 매핑해준다(찾아준다). View -\u0026gt; DispatcherServlet\n최종적으로 페이지를 만들고 DispatcherServlet 에 전달한다. DispatcherServlet -\u0026gt; Client (or Web Server)\n결과물을 응답한다. 출처: https://bk-investing.tistory.com/57?category=903513\n위의 흐름은 효율적으로 보여지나, 실제로는 아래와 같은 문제점이 있었다고 한다.\nDispatcherServlet 는 모든 요청을 처리(수신)하다보니, 이미지/HTMl 파일 등의 정적 파일들에 대한 요청도 전부 Controller 로 넘긴다. (DispatcherServlet가 수신하지 않으면 자원을 내어줄 수 있는 상황에서) JSP 파일 안의 JS, CSS 파일들에 대한 요청도 가로채어 수신하기 때문에 자원을 내어주지 못하는 상황이 생긴다. (이것을 처리하는 Controlle 가 없기 때문일 것이다.) 해결책 1\n/apps 의 URL 로 접근하면 DispatcherServlet 가 처리한다. /resources 의 URL 로 접근하면 DispatcherServlet 가 처리하지 않는다. 이 방법은 괜찮지만 코드가 지저분해지는 단점이 있다.\n또, 모든 요청에 대해 /apps, /resources 와 같은 URL 을 붙여주어야 하는 단점이 있다.\n해결책 2\n모든 요청을 컨트롤러에 등록한다. 무식한 방법이라고 한다.\n위의 문제에 대한 Spring 이 해결책을 제공해준다.\n\u0026lt;map:resources /\u0026gt;\nDispatcherServlet 에서 요청에 대한 Controller 를 찾을 수 없는 경우에, 2차적으로 설정된 경로에 요청을 보내는 것이다.\n코드로 살펴보기 # 상속(구현) 관계\nDispatcherServlet -\u0026gt; FrameworkServlet -\u0026gt; (HttpServletBean) -\u0026gt; HttpServlet\n/** Central dispatcher for HTTP request handlers/controllers, e.g. for web UI controllers or HTTP-based remote service exporters. Dispatches to registered handlers for processing a web request, providing convenient mapping and exception handling facilities. */ public class DispatcherServlet extends FrameworkServlet { } /** Base servlet for Spring\u0026#39;s web framework. Provides integration with a Spring application context, in a JavaBean-based overall solution. */ public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware { } public abstract class HttpServletBean extends HttpServlet implements EnvironmentCapable, EnvironmentAware { } 1. ApplicationFilterChain filter 처리 후, servlet.service(request, response); 호출 # 몇몇 분기 내용은 배제\npublic final class ApplicationFilterChain implements FilterChain { ... private void internalDoFilter(ServletRequest request, ServletResponse response) throws IOException, ServletException { // Call the next filter if there is one (다음 Filter 가 있다면, 호출합니다.) if (pos \u0026lt; n) { ApplicationFilterConfig filterConfig = filters[pos++]; try { Filter filter = filterConfig.getFilter(); ... // (중략) filter.doFilter(request, response, this); } catch (IOException | ServletException | RuntimeException e) { ... } catch (Throwable e) { ... } return; } // We fell off the end of the chain -- call the servlet instance // (FilterChain 의 끝에 도착 -\u0026gt; Servlet 객체를 호출합니다.) try { ... // (중략) servlet.service(request, response); // \u0026lt;-- 여기 } catch (IOException | ServletException | RuntimeException e) { ... } catch (Throwable e) { ... } finally { ... } } } 2. HttpServlet(Servlet) service() 메서드 호출 # 타입 변환 : ServletRequest -\u0026gt; HttpServletRequest doPost(), doGet() 등의 메서드 호출 현재 테스트에서는 doPost() 호출\npublic abstract class HttpServlet extends GenericServlet { ... @Override public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException { HttpServletRequest request; HttpServletResponse response; try { request = (HttpServletRequest) req; response = (HttpServletResponse) res; } catch (ClassCastException e) { throw new ServletException(lStrings.getString(\u0026#34;http.non_http\u0026#34;)); } service(request, response); } ... protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String method = req.getMethod(); if (method.equals(METHOD_GET)) { ... // If-Modified-Since(Last-Modified) (캐시 분기) doGet(req, resp); // or resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); } else if (method.equals(METHOD_HEAD)) { long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); } else if (method.equals(METHOD_POST)) { doPost(req, resp); } else if (method.equals(METHOD_PUT)) { doPut(req, resp); } else if (method.equals(METHOD_DELETE)) { doDelete(req, resp); } else if (method.equals(METHOD_OPTIONS)) { doOptions(req,resp); } else if (method.equals(METHOD_TRACE)) { doTrace(req,resp); } else { String errMsg = lStrings.getString(\u0026#34;http.method_not_implemented\u0026#34;); ... resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); } } } 3. FrameworkServlet doPost() # FrameworkServlet : doPost() 호출 FrameworkServlet : processRequest(request, response) 호출 DispatcherServlet : doService() 호출 public abstract class FrameworkServlet extends HttpServletBean implements ApplicationContextAware { ... @Override protected final void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { processRequest(request, response); // \u0026lt;-- 여기 } // Process this request, publishing an event regardless of the outcome. // The actual event handling is performed by the abstract doService template method. protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { ... try { doService(request, response); // \u0026lt;-- 여기 } catch (ServletException | IOException ex) { ... } catch (Throwable ex) { ... } finally { resetContextHolders(request, previousLocaleContext, previousAttributes); if (requestAttributes != null) { requestAttributes.requestCompleted(); } logResult(request, response, failureCause, asyncManager); publishRequestHandledEvent(request, response, startTime, failureCause); } } } 4. DispatcherServlet doService() # DispatcherServlet : doService() 호출 DispatcherServlet : doDsipatch(request, response); 호출 public class DispatcherServlet extends FrameworkServlet { ... protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception { logRequest(request); // Keep a snapshot of the request attributes in case of an include, // to be able to restore the original attributes after the include. // (attributeSnapShow 저장) Map\u0026lt;String, Object\u0026gt; attributesSnapshot = null; while(...) { attributesSnapshot.put(attrName, request.getAttribute(attrName)); } // Make framework objects available to handlers and view objects. // (HttpServletRequest 에 WebApplicationContext, localeResolver 등 저장) request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext()); request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver); request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver); request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); ... try { doDispatch(request, response); } finally { ... } } ... } 5. DispatcherServlet doDispatch() # 중요!\n(1) HandlerExecutionChain 객체 획득 (getHandler()) (2) HandlerAdapter 객체 획득 (getHandlerAdapter()) (3) 인터셉터의 preHandle() 호출 (4) handlerAdapter.handle() 호출 (-\u0026gt; ModelAndView 객체 획득) (5) 인터셉터의 postHandle() 호출 public class DispatcherServlet extends FrameworkServlet { ... protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception { HttpServletRequest processedRequest = request; HandlerExecutionChain mappedHandler = null; boolean multipartRequestParsed = false; WebAsyncManager asyncManager = WebAsyncUtils.getAsyncManager(request); try { ModelAndView mv = null; Exception dispatchException = null; try { // Convert the request into a multipart request, and make multipart resolver available. // If no multipart resolver is set, simply use the existing request. // (checkMultiPart() 의 경우, multipart 요청이면 MultipartHttpServletRequest 객체를 반환합니다.) processedRequest = checkMultipart(request); multipartRequestParsed = (processedRequest != request); ... // (중략) // Determine handler for the current request. // (HandlerExecutionChain 객체를 얻습니다.) // ( = 우리가 작성한 Controller/Method 를 의미합니다.) mappedHandler = getHandler(processedRequest); if (mappedHandler == null) { noHandlerFound(processedRequest, response); return; } // Determine handler adapter for the current request. // (HandlerAdapter 객체를 얻습니다.) HandlerAdapter ha = getHandlerAdapter(mappedHandler.getHandler()); // Process last-modified header, if supported by the handler. String method = request.getMethod(); boolean isGet = \u0026#34;GET\u0026#34;.equals(method); if (isGet || \u0026#34;HEAD\u0026#34;.equals(method)) { long lastModified = ha.getLastModified(request, mappedHandler.getHandler()); if (new ServletWebRequest(request, response).checkNotModified(lastModified) \u0026amp;\u0026amp; isGet) { return; } } // Apply preHandle methods of registered interceptors. (in HandlerExecutionChain) // (등록된 인터셉터의 preHandle 을 실행합니다.) if (!mappedHandler.applyPreHandle(processedRequest, response)) { return; } // Actually invoke the handler. // (HandlerAdapter handel() 메서드를 호출합니다.) // (ModelAndView 를 반환받습니다.) mv = ha.handle(processedRequest, response, mappedHandler.getHandler()); // \u0026lt;-- 여기 if (asyncManager.isConcurrentHandlingStarted()) { return; } applyDefaultViewName(processedRequest, mv); // Apply postHandle methods of registered interceptors. // (등록된 인터셉터의 postHandle 을 실행합니다.) mappedHandler.applyPostHandle(processedRequest, response, mv); } catch (Exception ex) { dispatchException = ex; } catch (Throwable err) { // As of 4.3, we\u0026#39;re processing Errors thrown from handler methods as well, // making them available for @ExceptionHandler methods and other scenarios. dispatchException = new NestedServletException(\u0026#34;Handler dispatch failed\u0026#34;, err); } processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); } catch (Exception ex) { triggerAfterCompletion(processedRequest, response, mappedHandler, ex); } catch (Throwable err) { triggerAfterCompletion(processedRequest, response, mappedHandler, new NestedServletException(\u0026#34;Handler processing failed\u0026#34;, err)); } finally { if (asyncManager.isConcurrentHandlingStarted()) { // Instead of postHandle and afterCompletion if (mappedHandler != null) { mappedHandler.applyAfterConcurrentHandlingStarted(processedRequest, response); } } else { // Clean up any resources used by a multipart request. if (multipartRequestParsed) { cleanupMultipart(processedRequest); } } } } ... @Nullable protected HandlerExecutionChain getHandler(HttpServletRequest request) throws Exception { if (this.handlerMappings != null) { for (HandlerMapping mapping : this.handlerMappings) { HandlerExecutionChain handler = mapping.getHandler(request); if (handler != null) { return handler; } } } return null; } ... // Return the HandlerAdapter for this handler object. protected HandlerAdapter getHandlerAdapter(Object handler) throws ServletException { if (this.handlerAdapters != null) { for (HandlerAdapter adapter : this.handlerAdapters) { if (adapter.supports(handler)) { return adapter; } } } throw new ServletException(\u0026#34;No adapter for handler [\u0026#34; + handler + \u0026#34;]: The DispatcherServlet configuration needs to include a HandlerAdapter that supports this handler\u0026#34;); } } 6. HandlerAdapter.handle() 호출 # AbstractHandlerMethodAdapter : handle() RequestMappingHandlerAdapter : handlerInternal() invokeHandlerMethod() 호출 public abstract class AbstractHandlerMethodAdapter extends WebContentGenerator implements HandlerAdapter, Ordered { ... @Override @Nullable public final ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { // RequestMappingHandlerAdapter.handleInternal() 호출 return handleInternal(request, response, (HandlerMethod) handler); } ... } public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter { ... @Override protected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception { ModelAndView mav; checkRequest(request); // 세션 필수 여부, HTTP Method 체크 ... // (중략) // Execute invokeHandlerMethod in synchronized block if required. if (this.synchronizeOnSession) { HttpSession session = request.getSession(false); if (session != null) { Object mutex = WebUtils.getSessionMutex(session); synchronized (mutex) { mav = invokeHandlerMethod(request, response, handlerMethod); } } else { // No HttpSession available -\u0026gt; no mutex necessary mav = invokeHandlerMethod(request, response, handlerMethod); } } else { // No synchronization on session demanded at all... mav = invokeHandlerMethod(request, response, handlerMethod); } if (!response.containsHeader(HEADER_CACHE_CONTROL)) { if (getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) { applyCacheSeconds(response, this.cacheSecondsForSessionAttributeHandlers); } else { prepareResponse(response); } } return mav; } ... } 7. HandlerAdapter : invokeHandlerMethod() 호출 # invocableMethod.invokeAndHandle(webRequest, mavContainer); 호출 public class RequestMappingHandlerAdapter extends AbstractHandlerMethodAdapter { ... @Nullable protected ModelAndView invokeHandlerMethod(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception { ServletWebRequest webRequest = new ServletWebRequest(request, response); try { ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod); // \u0026lt;-- 여기 ... // (중략 : asyncManager, mavContainer 등의 설정) // Invoke the method and handle the return value // through one of the configured HandlerMethodReturnValueHandlers. invocableMethod.invokeAndHandle(webRequest, mavContainer); if (asyncManager.isConcurrentHandlingStarted()) { return null; } return getModelAndView(mavContainer, modelFactory, webRequest); } finally { webRequest.requestCompleted(); } } ... } 8. ServletInvocableHandlerMethod :: invokeForRequest() 호출 # (1) Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); (2) this.returnValueHandlers.handleReturnValue(returnValue, getReturnValueType(returnValue), mavContainer, webRequest);\npublic class ServletInvocableHandlerMethod extends InvocableHandlerMethod { ... // Invoke the method and handle the return value // through one of the configured HandlerMethodReturnValueHandlers. public void invokeAndHandle(ServletWebRequest webRequest, ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception { Object returnValue = invokeForRequest(webRequest, mavContainer, providedArgs); setResponseStatus(webRequest); if (returnValue == null) { if (isRequestNotModified(webRequest) || getResponseStatus() != null || mavContainer.isRequestHandled()) { disableContentCachingIfNecessary(webRequest); mavContainer.setRequestHandled(true); return; } } else if (StringUtils.hasText(getResponseStatusReason())) { mavContainer.setRequestHandled(true); return; } mavContainer.setRequestHandled(false); Assert.state(this.returnValueHandlers != null, \u0026#34;No return value handlers\u0026#34;); try { // returnValue 처리!! this.returnValueHandlers.handleReturnValue( returnValue, getReturnValueType(returnValue), mavContainer, webRequest); } catch (Exception ex) { if (logger.isTraceEnabled()) { logger.trace(formatErrorForReturnValue(returnValue), ex); } throw ex; } } ... } this.returnValueHandlers = HandlerMethodReturnValueHandlerComposite.class\npublic class HandlerMethodReturnValueHandlerComposite implements HandlerMethodReturnValueHandler { protected final Log logger = LogFactory.getLog(getClass()); private final List\u0026lt;HandlerMethodReturnValueHandler\u0026gt; returnValueHandlers = new ArrayList\u0026lt;\u0026gt;(); ... } public class RequestResponseBodyMethodProcessor extends AbstractMessageConverterMethodProcessor { ... @Override public boolean supportsReturnType(MethodParameter returnType) { return (AnnotatedElementUtils.hasAnnotation(returnType.getContainingClass(), ResponseBody.class) || returnType.hasMethodAnnotation(ResponseBody.class)); } ... @Override public void handleReturnValue(@Nullable Object returnValue, MethodParameter returnType, ModelAndViewContainer mavContainer, NativeWebRequest webRequest) throws IOException, HttpMediaTypeNotAcceptableException, HttpMessageNotWritableException { mavContainer.setRequestHandled(true); ServletServerHttpRequest inputMessage = createInputMessage(webRequest); ServletServerHttpResponse outputMessage = createOutputMessage(webRequest); // Try even with null return value. ResponseBodyAdvice could get involved. writeWithMessageConverters(returnValue, returnType, inputMessage, outputMessage); // \u0026lt;-- 여기서 HttpMessageConverter converters 가 사용되어 변환 처리 } ... 9. InvocableHandlerMethod :: invokeAndHandle() 호출 # (1) getMethodArgumentValues() : Object -\u0026gt; DTO 변환\nHandlerMethodArgumentResolver (2) doInvoke(args);\nresolvers = {HandlerMethodArgumentResolverComposite@16108} - argumentResolvers = {LinkedList@16583} size = 36 0 = {ProxyingHandlerMethodArgumentResolver@16599} 1 = {RequestParamMethodArgumentResolver@16600} 2 = {RequestParamMapMethodArgumentResolver@16601} 3 = {PathVariableMethodArgumentResolver@16602} 4 = {PathVariableMapMethodArgumentResolver@16603} 5 = {MatrixVariableMethodArgumentResolver@16604} 6 = {MatrixVariableMapMethodArgumentResolver@16605} 7 = {ServletModelAttributeMethodProcessor@16606} 8 = {RequestResponseBodyMethodProcessor@16589} 9 = {RequestPartMethodArgumentResolver@16607} ... public class InvocableHandlerMethod extends HandlerMethod { ... private HandlerMethodArgumentResolverComposite resolvers = new HandlerMethodArgumentResolverComposite(); // private final List\u0026lt;HandlerMethodArgumentResolver\u0026gt; argumentResolvers = new LinkedList\u0026lt;\u0026gt;(); // private final Map\u0026lt;MethodParameter, HandlerMethodArgumentResolver\u0026gt; argumentResolverCache = new ConcurrentHashMap\u0026lt;\u0026gt;(256); ... @Nullable public Object invokeForRequest(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception { // 여기서 Object -\u0026gt; DTO 로 변환 Object[] args = getMethodArgumentValues(request, mavContainer, providedArgs); if (logger.isTraceEnabled()) { logger.trace(\u0026#34;Arguments: \u0026#34; + Arrays.toString(args)); } return doInvoke(args); } // Get the method argument values for the current request, // checking the provided argument values and falling back to the configured argument resolvers. // The resulting array will be passed into doInvoke. protected Object[] getMethodArgumentValues(NativeWebRequest request, @Nullable ModelAndViewContainer mavContainer, Object... providedArgs) throws Exception { MethodParameter[] parameters = getMethodParameters(); if (ObjectUtils.isEmpty(parameters)) { return EMPTY_ARGS; } Object[] args = new Object[parameters.length]; for (int i = 0; i \u0026lt; parameters.length; i++) { MethodParameter parameter = parameters[i]; parameter.initParameterNameDiscovery(this.parameterNameDiscoverer); args[i] = findProvidedArgument(parameter, providedArgs); if (args[i] != null) { continue; } if (!this.resolvers.supportsParameter(parameter)) { throw new IllegalStateException(formatArgumentError(parameter, \u0026#34;No suitable resolver\u0026#34;)); } try { args[i] = this.resolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); } catch (Exception ex) { // Leave stack trace for later, exception may actually be resolved and handled... if (logger.isDebugEnabled()) { String exMsg = ex.getMessage(); if (exMsg != null \u0026amp;\u0026amp; !exMsg.contains(parameter.getExecutable().toGenericString())) { logger.debug(formatArgumentError(parameter, exMsg)); } } throw ex; } } return args; } ... @Nullable protected Object doInvoke(Object... args) throws Exception { // getBridgedMethod : 우리가 작성한 Controller/Method ReflectionUtils.makeAccessible(getBridgedMethod()); try { return getBridgedMethod().invoke(getBean(), args); } catch (IllegalArgumentException ex) { assertTargetBean(getBridgedMethod(), getBean(), args); String text = (ex.getMessage() != null ? ex.getMessage() : \u0026#34;Illegal argument\u0026#34;); throw new IllegalStateException(formatInvokeError(text, args), ex); } catch (InvocationTargetException ex) { // Unwrap for HandlerExceptionResolvers ... Throwable targetException = ex.getTargetException(); if (targetException instanceof RuntimeException) { throw (RuntimeException) targetException; } else if (targetException instanceof Error) { throw (Error) targetException; } else if (targetException instanceof Exception) { throw (Exception) targetException; } else { throw new IllegalStateException(formatInvokeError(\u0026#34;Invocation failure\u0026#34;, args), targetException); } } } } // getArgumentResolver() 통해, resolver 들의 supportsParameter 여부 판단 -\u0026gt; 한개 획득 // resolveArgument public class HandlerMethodArgumentResolverComposite implements HandlerMethodArgumentResolver { ... @Override @Nullable public Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception { HandlerMethodArgumentResolver resolver = getArgumentResolver(parameter); if (resolver == null) { throw new IllegalArgumentException(\u0026#34;Unsupported parameter type [\u0026#34; + parameter.getParameterType().getName() + \u0026#34;]. supportsParameter should be called first.\u0026#34;); } return resolver.resolveArgument(parameter, mavContainer, webRequest, binderFactory); } @Nullable private HandlerMethodArgumentResolver getArgumentResolver(MethodParameter parameter) { HandlerMethodArgumentResolver result = this.argumentResolverCache.get(parameter); if (result == null) { for (HandlerMethodArgumentResolver resolver : this.argumentResolvers) { if (resolver.supportsParameter(parameter)) { result = resolver; this.argumentResolverCache.put(parameter, result); break; } } } return result; } ... } e.g. RequestResponseBodyMethodProcessor\npublic class RequestResponseBodyMethodProcessor extends AbstractMessageConverterMethodProcessor { ... @Override public boolean supportsParameter(MethodParameter parameter) { return parameter.hasParameterAnnotation(RequestBody.class); } ... // HttpMessageConverter 들을 순회하며 변환 @Override public Object resolveArgument(MethodParameter parameter, @Nullable ModelAndViewContainer mavContainer, NativeWebRequest webRequest, @Nullable WebDataBinderFactory binderFactory) throws Exception { ... Object arg = readWithMessageConverters(webRequest, parameter, parameter.getNestedGenericParameterType()); ... return adaptArgumentIfNecessary(arg, parameter); } ... } 10. (Reflection) Method.invoke() # ReflectionUtils.makeAccessible(getBridgedMethod()); try { return getBridgedMethod().invoke(getBean(), args); } (1) reflect.Method.class :: invoke() (2) DelegatingMethodAccessorImpl :: invoke() (3) NativeMethodAccessorImpl :: invoke() 참고 # Reference\nhttps://medium.com/@fntldpf12/dispatcher-servlet%EC%9D%B4%EB%9E%80-624a2195d38f https://velog.io/@seculoper235/2.-DispatcherServlet-%EC%9D%B4%EB%9E%80 https://galid1.tistory.com/525 "},{"id":198,"href":"/docs/SPRING/SPRING-Embeded-TomcatTCP-ThreadRequest-Connection/","title":"[SPRING] Embeded Tomcat(TCP, Thread(Request), Connection)","section":"SPRING","content":" TCP 연결을 맺고 동시에 여러 요청(API 호출)을 했을 때 :arrow_right: 서로 다른 Thread 로 처리 # 내장 톰캣 설정 확인 # org.springframework.boot.autoconfigure.web.ServerProperties\npackage org.springframework.boot.autoconfigure.web; @ConfigurationProperties(prefix = \u0026#34;server\u0026#34;, ignoreUnknownFields = true) public class ServerProperties { ... /** * Tomcat properties. */ public static class Tomcat { /** * Maximum number of connections that the server accepts and processes at any * given time. Once the limit has been reached, the operating system may still * accept connections based on the \u0026#34;acceptCount\u0026#34; property. */ private int maxConnections = 8192; /** * Maximum queue length for incoming connection requests when all possible request * processing threads are in use. */ private int acceptCount = 100; /** * Maximum number of idle processors that will be retained in the cache and reused * with a subsequent request. When set to -1 the cache will be unlimited with a * theoretical maximum size equal to the maximum number of connections. */ private int processorCache = 200; ... } ... /** * Tomcat thread properties. */ public static class Threads { /** * Maximum amount of worker threads. */ private int max = 200; /** * Minimum amount of worker threads. */ private int minSpare = 10; ... } (위의 설정을 기준으로)\n우선, 10개의 thread 로 처리 요청이 왔는데 idle 상태의 thread 가 없다면, 새로운 Thread 생성 -\u0026gt; 이게 max(200)값 까지 가능 * 일단 minSpare 보다 더 생기면, 언제 없어지는지 확인 필요 // 예시 로그 1 [2022-03-06 18:47:30:6150] | [http-nio-8080-exec-1] | [DEBUG] o.a.coyote.http11.Http11NioProtocol - Created new processor [org.apache.coyote.http11.Http11Processor@3adee237] [2022-03-06 18:47:50:26136] | [http-nio-8080-exec-2] | [DEBUG] o.a.coyote.http11.Http11NioProtocol - Created new processor [org.apache.coyote.http11.Http11Processor@3da5aceb] [2022-03-06 18:48:52:88219] | [http-nio-8080-exec-2] | [DEBUG] o.a.coyote.http11.Http11NioProtocol - Processing socket [org.apache.tomcat.util.net.NioChannel@336254f7:java.nio.channels.SocketChannel[connected local=/0:0:0:0:0:0:0:1:8080 remote=/0:0:0:0:0:0:0:1:65371]] with status [ERROR] [2022-03-06 18:48:52:88219] | [http-nio-8080-exec-2] | [DEBUG] o.a.coyote.http11.Http11NioProtocol - Found processor [null] for socket [org.apache.tomcat.util.net.NioChannel@336254f7:java.nio.channels.SocketChannel[connected local=/0:0:0:0:0:0:0:1:8080 remote=/0:0:0:0:0:0:0:1:65371]] [2022-03-06 18:48:52:88219] | [http-nio-8080-exec-2] | [DEBUG] o.a.tomcat.util.threads.LimitLatch - Counting down[http-nio-8080-exec-2] latch=1 // 예시 로그 2 [2022-03-06 18:43:15:31335] | [http-nio-8080-exec-2] | [DEBUG] o.a.coyote.http11.Http11NioProtocol - Processing socket [org.apache.tomcat.util.net.NioChannel@693ffb87:java.nio.channels.SocketChannel[connected local=/0:0:0:0:0:0:0:1:8080 remote=/0:0:0:0:0:0:0:1:64227]] with status [OPEN_READ] [2022-03-06 18:43:15:31335] | [http-nio-8080-exec-2] | [DEBUG] o.a.coyote.http11.Http11NioProtocol - Found processor [null] for socket [org.apache.tomcat.util.net.NioChannel@693ffb87:java.nio.channels.SocketChannel[connected local=/0:0:0:0:0:0:0:1:8080 remote=/0:0:0:0:0:0:0:1:64227]] [2022-03-06 18:43:15:31335] | [http-nio-8080-exec-2] | [DEBUG] o.a.coyote.http11.Http11NioProtocol - Popped processor [null] from cache [2022-03-06 18:43:15:31335] | [http-nio-8080-exec-2] | [DEBUG] o.a.coyote.http11.Http11NioProtocol - Register [org.apache.coyote.http11.Http11Processor@67f808d0] as [Tomcat:type=RequestProcessor,worker=\u0026#34;http-nio-8080\u0026#34;,name=HttpRequest2] [2022-03-06 18:43:15:31335] | [http-nio-8080-exec-2] | [DEBUG] o.a.coyote.http11.Http11NioProtocol - Created new processor [org.apache.coyote.http11.Http11Processor@67f808d0] [2022-03-06 18:43:15:31336] | [http-nio-8080-exec-2] | [DEBUG] o.a.coyote.http11.Http11InputBuffer - Before fill(): parsingHeader: [true], parsingRequestLine: [true], parsingRequestLinePhase: [0], parsingRequestLineStart: [0], byteBuffer.position(): [0], byteBuffer.limit(): [0], end: [0] [2022-03-06 18:43:15:31336] | [http-nio-8080-exec-2] | [DEBUG] o.a.t.util.net.SocketWrapperBase - Socket: [org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper@63c790f7:org.apache.tomcat.util.net.NioChannel@693ffb87:java.nio.channels.SocketChannel[connected local=/0:0:0:0:0:0:0:1:8080 remote=/0:0:0:0:0:0:0:1:64227]], Read from buffer: [0] [2022-03-06 18:43:15:31336] | [http-nio-8080-exec-2] | [DEBUG] o.a.tomcat.util.net.NioEndpoint - Socket: [org.apache.tomcat.util.net.NioEndpoint$NioSocketWrapper@63c790f7:org.apache.tomcat.util.net.NioChannel@693ffb87:java.nio.channels.SocketChannel[connected local=/0:0:0:0:0:0:0:1:8080 remote=/0:0:0:0:0:0:0:1:64227]], Read direct from socket: [869] [2022-03-06 18:43:15:31336] | [http-nio-8080-exec-2] | [DEBUG] o.a.coyote.http11.Http11InputBuffer - Received [GET /test HTTP/1.1 설정 예시\nserver: tomcat: threads: max: 1 min-spare: 1 accept-count: 1 참고하기 # https://velog.io/@sihyung92/how-does-springboot-handle-multiple-requests "},{"id":199,"href":"/docs/SPRING/SPRING-Filter-vs-Interceptor-vs-AOP/","title":"[SPRING] Filter vs Interceptor vs AOP","section":"SPRING","content":" Filter # 요청 / 응답을 필터링한다.\nDispatcherServlet 이전에 실행 된다. 즉, 스프링 영역 외부에 존재하여, 스프링과 무관한 자원에 대해 동작한다.\ninit() : ServletContainer 에 Filter 가 등록되어 초기화될 때 실행 doFilter() : Filter가 적용된 servlet에 요청이 들어왔을 때 실행 (servlet에 전달하기 전에) destroy() : ServletContainer 가 종료될 때(Filter 가 삭제될 때)실행 일반적으로 Encoding 처리, XSS 방어 등을 처리하기 위해 사용될 수 있다.\nInterceptor # 요청/응답에 대해 전(pre)/후(post)로 가로챈다.\nDispatcherServlet 이 Controller 를 호출하기 전/후로 가로챈다.\nDispatcherServlet -\u0026gt; Handler Mapping -\u0026gt; Interceptor -\u0026gt; Controller(Handler) 스프링의 모든 Bean (객체)에 접근할 수 있다.\nInterceptor 는 여러 개를 사용할 수 있다.\nHTTP 헤더, HTTP 메소드, 세션 / 쿠키, 요청 URL 등을 가져올 수 있다.\npreHandler()\nController(Handler) 가 실행되기 전에 처리된다. postHandler()\nController(Handler) 가 실행된 후에 처리된다. afterCompletion()\nview 페이지가 렌더링 되고 난 후에 처리된다. 일반적으로 로그인 체크, 권한(JWT), 프로그램 실행시간 계산 등을 처리하기 위해 사용될 수 있다.\nSpringBoot 에서는 HandlerInterceptor 인터페이스를 구현하여 사용할 수 있다.\nAOP # OOP 시에, 종단면(관점)에서 중복되는 것들을 처리한다.\nFilter, Interceptor 와 달리 메소드 전/후에 자유롭게 설정이 가능하다.\nAOP \u0026lt;-\u0026gt; HandlerInterceptor 의 가장 큰 차이는 \u0026lsquo;파라미터의 차이\u0026rsquo; 이다.\nAdvice 의 경우 JoinPoint, ProceedingJoinPoint 등을 사용 HandlerInterceptor 는 Filter 와 유사하게 HttpServletRequest, HttpServletResponse 를 사용 일반적으로 로깅, 트랜잭션, 에러처리 등의 처리를 위해 사용될 수 있다.\nReference\nhttps://galid1.tistory.com/521?category=783055 https://bk-investing.tistory.com/61 "},{"id":200,"href":"/docs/SPRING/SPRING-IoC-%EC%99%80-DI/","title":"[SPRING] IoC 와 DI","section":"SPRING","content":" IoC (Inversion of Control) # 제어(관리)의 역전 프로그램에 대해서 개발자가 관리하는 것이 아닌, 제 3의 존재가 관리한다. IoC의 이점\n역할 / 책임을 분리한다. (의존성 주입 등 관리의 일부를 제 3의 존재가 한다. 즉 역할이 분리되는 것이다.) 유연하게 코드를 작성할 수 있다. (개발 코드에 집중할 수 있다. 편리하다.) 개발자가 관리한다는 것은 권한도 강해짐을 의미한다. 이를 제어할 수 있다. DI (Dependencies Injection) # IoC 이라는 큰 범주의 개념 중 구체적인 한 특징 (?) 제 3의 존재가 의존성을 주입/관리해준다. (이것 또한 제어의 역전이다.) Spring Framework 은 IoC 중에서도 DI 의 개념이 두드러진다. DI는 클래스타입이 고정되어 있지 않고 인터페이스 타입의 파라미터를 통해 다이나믹하게 구현 클래스를 결정해서 제공 받을수 있어야 한다. (즉, 동적으로, 다양하게 객체를 이용할 수 있어야 한다.) 토비의 스프링에서 말하는 DI 조건 3가지\n클래스 모델, 코드에는 런타임 시점의 의존 관계가 드러나지 않는다. 그러기 위해서는 인터페이스에만 의존하고 있어야 한다. (?) 런타임 시점의 의존 관계는 컨테이너나 팩토리 같은 제 3의 존재가 결정한다. 의존 관계는 사용할 객체에 대한 참조를 외부에서 주입해줌으로써 만들어진다. Reference\nhttps://biggwang.github.io/2019/08/31/Spring/IoC,%20DI%EB%9E%80%20%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C/ "},{"id":201,"href":"/docs/SPRING/SPRING-Logging/","title":"[SPRING] Logging","section":"SPRING","content":"\u0026lsquo;Log\u0026rsquo; 는 소프트웨어의 행위(이벤트)를 기록하여, 문제가 발생했을 때 문제를 빠르게 파악할 수 있게 합니다. 또는 소프트웨어 자체를 모니터링할 수 있게 합니다.\nJava 에서 log 관련 프레임워크는 아래와 같은 것들이 있습니다.\nSlf4j Log4j Logback Log4j2 Slf4j (Simple Logging Facade For Java) # logger 인터페이스, 추상체 역할을 합니다. 즉, 다른 logging 프레임워크 구현체들의 인터페이스, 추상체 역할을 합니다.\n예를 들어, Logback, Log4j2 의 Logger 클래스는 Slf4j Logger 인터페이스를 구현합니다.\npackage ch.qos.logback.classic; public final class Logger implements org.slf4j.Logger, ... { ... } Slf4j 인터페이스를 통해 쉽게 구현체(Logback, Log4j2, \u0026hellip;)를 변경할 수 있습니다.\nLog4j # 가장 오래된 로깅 프레임워크입니다. 2015년에 개발이 중단되었습니다.\nConsole / File 출력 등의 로깅이 가능합니다. xml, properties 를 통해 설정 가능합니다. Logback # log4j 보다 향상된 기능을 제공합니다. (필터링, 구성 파일 변경 후 자동 재적용 등)\nLog4j2 # Log4j, Logback, Log4j2 중 가장 최근에 나온 프레임워크입니다.\nLog4j, Logback 에 확장된 기능/성능을 제공합니다. (필터링, 구성 파일 변경 후 자동 재적용 등)\n특징\n비동기 로거(Async Logger) 지원 : (멀티 쓰레드일수록) 처리량 우수하고 대기시간이 짧다고 합니다. 람다식(Lazy Evaluation) 지원 HTTP, Kafka 등에 출력 가능 SpringBoot 에서 사용 시에는 기본으로 의존되는 starter-logging 모듈을 exclude 하고, log4j2 의존성 주입을 해야 사용할 수 있습니다.\n비동기 로거란?\n로그 발생(로깅 메서드 호출)과 로그 쓰기 작업을 분리합니다.\nThread A는 로그를 발생시키고 Queue, Buffer 등에 로그 정보를 삽입합니다. Thread B는 Queue, Buffer 에 쌓인 데이터를 꺼내어 쓰기 작업을 진행합니다. (Disk 쓰기라면 성능 차이가 더 심할 것 입니다.) * 주의할 점은 Queue, Buffer의 데이터가 유실될 가능성이 있습니다.\n쓰기 작업 전에 Application 이 종료된 경우 Buffer, Queue 에 용량이 꽉 차 데이터가 제거, 삽입할 수 없는 경우 Log Level # LEVEL 설명 TARCE DEBUG 보다 상세한 내용을 나타냅니다. DEBUG 개발 시 디버깅 용도로 사용합니다. INFO 정보 제공 용도로 사용합니다. WARN 이후 에러가 될 수 있는 내용들을 알려줍니다. ERROR 에러가 발생한 상태입니다. FATAL 심각한 에러가 발생한 상태입니다. Log Component # 요소 설명 Logger - 로그의 주체, 로깅을 위한 클래스입니다.\n- 출력할 메시지를 Appender에 전달합니다.\n- LogLevel, Appender 를 설정합니다.\n- 패키지, 애플리케이션 별로 설정할 수 있습니다. Appender - \u0026lsquo;어디\u0026rsquo;에 출력할 지 결정합니다. (Console, File 등) Layout - 어떤 형식(패턴)으로 출력할 지 결정합니다. "},{"id":202,"href":"/docs/SPRING/SPRING-Lombok-%EB%8F%99%EC%9E%91-%EC%9B%90%EB%A6%AC/","title":"[SPRING] Lombok 동작 원리","section":"SPRING","content":"컴파일 시점에 Annotation Processor 를 통해 소스코드의 AST(Abstract Syntax Tree)를 동적으로 조작/수정한다.\n컴파일 시점에 바이트 코드를 변환하여 추가적인 코드를 주입/생성한다.\nAnnotationProcessor # 컴파일 단계에서 정의/사용된 annotation 코드를 스캔/분석/처리하기 위해 사용되는 훅이다.\n컴파일 시점에 끼어들어 annotation 이 붙어있는 코드를 스캔/분석/처리하여 추가적인 소스 코드를 만들어낼 수 있다.\n참고 # Lombok의 동작원리 Lombok은 어떻게 동작하는 걸까? "},{"id":203,"href":"/docs/SPRING/SPRING-OSIV/","title":"[SPRING] OSIV","section":"SPRING","content":" Spring Framework 의 OSIV 에 대해 이해해보기\n스프링에서 기본적으로 영속(준영속)상태, 트랜잭션의 범위는 아래와 같다고 한다.\n그림에서와 같이 Intercepter, Controller, View 단에서는 준영속 상태이기 때문에 영속 상태의 이점을 누리지 못한다. 영속 상태의 이점이란, 변경 감지, 지연 로딩 등의 기능이다. 즉, 쉽게 보면 Controller 에서는 변경 감지나 지연 로딩의 기능을 사용할 수 없는 것이다.\npublic class OrderController { ... public String index(Long id) { Order order = orderService.getOrder(id); order.getShop(); // 지연로딩이라면 사용할 수 없다. (예외 발생) order.setName(\u0026#34;new\u0026#34;); // 변경감지를 사용할 수 없다. } } 위의 문제는 1. Eager 방식, 2. Fetch Join, 3. 강제 초기화, 4. FACADE 계층 도입 5. OSIV 등의 해결 방법이 있다고 한다. 이들 중 OSIV 를 활용한 방법을 살펴본다.\nOSIV # \u0026lsquo;Open Session In View\u0026rsquo;, 영속성 컨텍스트를 View 까지 오픈한다는 의미라고 한다. 영속성 컨텍스트를 열어둔다는 것(살려둔다는 것)은 엔티티가 영속 상태로 유지됨을 의미한다. 즉 위의 Intercepter, Controller, View 에서 영속 상태의 이점(변경 감지, 지연 로딩)을 활용할 수 있음을 의미한다.\nOSIV : 요청 당 트랜잭션 # 요청 당 트랜잭션의 방식은 말 그대로 요청 당 트랜잭션을 할당하는 것이다. 요청이 들어오면 Servlet Filter / Intercepter 에서 트랜잭션을 시작하여 요청이 끝날 때까지 트랜잭션이 유지되는 것이다.\n다만 이 방식은 프레젠테이션 계층(Controller, View)에서 자유롭게 엔티티를 수정할 수 있기에 위험한 방법이라고 볼 수 있다.\n최근에는 이 방식을 거의 사용하지 않는다고 한다.\nOSIV : Spring Framework # Spring Frmework 에서는 위의 방식을 보완한 OSIV 를 제공한다. 비즈니스 계층에서만 트랜잭션을 유지(쓰기 작업 유지)하는 것이다. 즉, 프레젠테이션 계층에서 지연 로딩과 같이 읽기 작업에 대해서는 열어두되, 변경 감지와 같은 쓰기 작업에 대해서는 제한을 거는 것이다.\n아래와 같은 방식으로 동작한다고 한다.\n요청이 들어오면 Servlet Filter / Intercepter 에서 영속성 컨텍스트를 생성한다. (요청 당 트랜잭션에서는 트랜잭션을 시작한다고 했다.) 비즈니스 계층에서 @Transactional 를 통해 트랜잭션이 시작되면 1번에서 생성해둔 영속성 컨텍스트를 찾아와 트랜잭션이 시작된다. 비즈니스 계층(@Transactional)이 끝나면 영속성 컨텍스트는 종료되지 않고 트랜잭션은 commit 된다. 프레젠테이션 계층에서는 영속성 컨텍스트가 유지된다. (이때 트랜잭션은 없다.) 요청이 끝날 때 영속성 컨텍스트를 종료한다. (마찬가지로 트랜잭션이 없다. flush를 호출하지 않는다.) 다만 아래와 같은 코드 형태에 대해서 주의해야 한다고 한다.\npublic class OrderController { ... public String index(Long id) { Order order = orderService.getOrder(id); order.getShop(); order.setName(\u0026#34;new\u0026#34;); orderService.updateLogic(); // updateLogic 은 Transactional 이 걸려있다고 가정한다. } } orderService.updateLogic() 이 실행되면서 트랜잭션이 다시 시작되고 끝(commit)나게 된다. 이때 order.setName(\u0026quot;new\u0026quot;) 의 코드에 대해서 변경 감지가 발동하여 쿼리가 나가게 된다.\n이러한 문제는 단순히 비즈니스 로직을 먼저 호출하는 방식으로 피하기도 한다고 한다.\n참고 # OSIV와 Spring Framework에서의 OSIV에 대해서\n"},{"id":204,"href":"/docs/SPRING/SPRING-Reactive-Kafka/","title":"[SPRING] Reactive Kafka","section":"SPRING","content":" Overview # 두 가지 핵심 인터페이스(패키지)\n카프카에 메시지 발행\nreactor.kafka.sender.*\nreactor.kafka.sender.KafkaSender 카프카의 메시지 컨슘\nreactor.kafka.receiver.*\nreactor.kafka.receiver.KafkaReceiver KafkaSender # KafkaSender 는 thread-safe 하다. 여러 스레드와 공유하여 처리할 수 있다.\n카프카로 메시지를 전송할 때 사용하는 KafkaProducer 하나와 연결된다.\nKafkaSender 는 sender 설정 옵션(reactor.kafka.sender.SenderOptions) 인스턴스로 만든다.\nKafkaSender 를 만든 후엔, SenderOptions 를 수정해도 KafkaSender 에 반영되지 않는다. 동시에 전송할 수 있는 최대 메시지 수(max inflight)와 같은 KafkaSender 전용 설정 옵션도 KafkaSender 인스턴스를 만들기 전에 미리 설정할 수 있다. KafkaSender 를 생성하기 전에, SenderOptions 인스턴스에 Key, Value 의 Serializer 를 설정해야 한다. Broker(list), Serializer 와 같은 프로퍼티(속성)는 KafkaProducer 로 전달된다. 이런 프로퍼티는 SenderOptions 인스턴스 생성 시점에 만들어도 되고, 인스턴스 생성 후에 setter 메서드 (SenderOptions#producerProperty)를 사용해도 된다. Map\u0026lt;String, Object\u0026gt; producerProps = new HashMap\u0026lt;\u0026gt;(); producerProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); producerProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, IntegerSerializer.class); producerProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); SenderOptions\u0026lt;Integer, String\u0026gt; senderOptions = SenderOptions.\u0026lt;Integer, String\u0026gt;create(producerProps) // 1 : KafkaProducer 에서 사용할 옵션 값들을 설정한다. .maxInFlight(1024); // 2 : KafkaSender 에서 사용할 옵션 값들을 설정한다. 필요한 옵션을 SenderOptions 에 정의했다면, 이 옵션으로 KafkaSender 인스턴스를 만들 수 있다.\nKafkaSender\u0026lt;Integer, String\u0026gt; sender = KafkaSender.create(senderOptions); 이제 KafkaSender 를 통해 카프카에 메시지를 보낼 수 있다.\n내부 KafkaProducer 인스턴스는 첫 번째 메시지를 보낼 준비가 되면 그때서야 생성된다. (lazy) 위 코드 시점에서는 KafkaSender 인스턴스는 생성되었지만, 카프카에 연결되지는 않았다. SenderRecord # 대략적으로 다음과 같은 느낌인 것 같다. ProducerRecord + SendResult + correlation 메타데이터\n레코드(ProducerRecord)와 전송 결과(SendResult)를 매칭하기 위한 별도의 correlation 메타데이터를 추가한 클래스이다.\nProducerRecord 는 카프카로 보낼 Key/Value 쌍과, (메시지를 전송할) 카프카 토픽명을 갖고 있다.\n파티션을 지정해도 되고, 지정하지 않으면 설정에 있는 파티셔너에 의해 알아서 선택된다. 타임스탬프를 지정해도 되고, 지정하지 않으면 프로듀서가 현재 타임스탬프를 할당한다. SenderRecord 의 \u0026lsquo;correlation 메타데이터\u0026rsquo;는 카프카로 전송되지 않지만, send 연산자가 완료/실패되었을 때 해당 레코드를 보내고 받은 결과가 SendResult에 담긴다.\n다른 파티션에 보낸 전송 결과가 중간에 끼어들 수도 있기 때문에, 이 correlation 메타데이터로 (해당 레코드와 매칭해서) 올바른 레코드(전송 결과)를 찾을 수 있다. 예시 # Flux\u0026lt;SenderRecord\u0026lt;Integer, String, Integer\u0026gt;\u0026gt; outboundFlux = Flux.range(1, 10) .map(i -\u0026gt; SenderRecord.create(topic, partition, timestamp, i, \u0026#34;Message_\u0026#34; + i, i)); sender.send(outboundFlux) .doOnError(e-\u0026gt; log.error(\u0026#34;Send failed\u0026#34;, e)) // 1 : 카프카 전송(send)에 실패한 경우 에러를 처리한다. .doOnNext(r -\u0026gt; System.out.printf(\u0026#34;Message #%d send response: %s\\n\u0026#34;, r.correlationMetadata(), r.recordMetadata())) // 2 : 카프카에서 결과를 받으면 처리한다. .subscribe(); // 3 : subscribe 를 통해 레코드(record)를 카프카로 전송하는 실제 플로우를 트리거한다. 카프카가 보낸 응답에는 record 를 전송한 파티션, 오프셋 정보들이 있다.\n레코드들을 여러 파티션에 전송했다면, 다른 파티션의 응답이 중간에 끼어들 수 있다.\nError Handling # public SenderOptions\u0026lt;K, V\u0026gt; stopOnError(boolean stopOnError); SenderOptions#stopOnError() 는 레코드 하나라도, 설정한 재시도 횟수만큼 카프카에 retry 한다.\n그럼에도 실패하면,\n전송 시퀀스를 즉시 실패시킬건지 모든 레코드를 처리할 때 까지 기다릴 건지를 지정한다. ProducerConfig#ACKS_CONFIG, ProducerConfig#RETRIES_CONFIG 와 함께 설정해 원하는 서비스 품질을 구현할 수 있다.\n\u0026lt;T\u0026gt; Flux\u0026lt;SenderResult\u0026lt;T\u0026gt;\u0026gt; send(Publisher\u0026lt;SenderRecord\u0026lt;K, V, T\u0026gt;\u0026gt; outboundRecords); stopOnError 가 false 이면, 각 레코드를 전송할 때마다 성공/에러 응답을 반환한다.\n에러 응답을 받았을 때 : 카프카가 전송에 실패한 이유를 SendResult#exception() 에서 조회할 수 있다. Flux는 outboundRecords에 발행한 모든 레코드를 전송해보고, 에러로 종료된다. outboundRecords 가 종료하지 않는 Flux라면 send 연산자는 사용자가 직접 SenderResult Flux를 취소할 때까지 계속해서 레코드를 전송한다. stopOnError 가 true 이면, 첫 번째로 전송에 실패(설정한 retry 도 실패)했을 때 응답을 반환한다. (SenderResult Flux는 에러 발생 즉시 종료된다.)\n여러 개가 전송 중이었을 때 : 일부 메시지는 카프카에 전달되었을 수도 있다. \u0026hellip;\nKafka Receiver # KafkaReceiver 는 카프카 토픽에 저장된 메시지를 컨슘한다.\nKafkaReceiver 인스턴스는 단일 KafkaConsumer 인스턴스와 연결된다. 내부 KafkaConsumer도 thread-safe 하지 않기 때문에, KafkaReceiver도 thread-safe 하지 않다. KafkaReceiver 는 reactor.kafka.receiver.ReceiverOptions 인스턴스로 만든다.\nKafkaReciever 인스턴스를 만든 후엔, ReceiverOptions 를 수정해도 KafkaReceiver 에 반영되지 않는다. Broker(list), Deserializer 와 같은 KafkaConsumer 관련 속성들은 KafkaConsumer에 전달된다. 이런 프로퍼티는 인스턴스 생성 전에 설정해도 되고, 생성 후에 setter 메서드(ReceiverOptions#consumerProperty)를 사용해도 된다. KafkaReceiver 전용 설정 옵션(ex: 토픽 설정)은 KafkaReceiver 인스턴스를 만들기 전에 추가되어야 한다. Map\u0026lt;String, Object\u0026gt; consumerProps = new HashMap\u0026lt;\u0026gt;(); consumerProps.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers); consumerProps.put(ConsumerConfig.GROUP_ID_CONFIG, \u0026#34;sample-group\u0026#34;); consumerProps.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, IntegerDeserializer.class); consumerProps.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); ReceiverOptions\u0026lt;Integer, String\u0026gt; receiverOptions = ReceiverOptions.\u0026lt;Integer, String\u0026gt;create(consumerProps) // 1 : KafkaConsumer 에 제공할 프로퍼티를 지정한다. .subscription(Collections.singleton(topic)); // 2 : 구독할 토픽을 설정한다. (KafkaReceiver 옵션) Flux\u0026lt;ReceiverRecord\u0026lt;Integer, String\u0026gt;\u0026gt; inboundFlux = KafkaReceiver.create(receiverOptions) .receive(); 내부 KafkaConsumer 인스턴스는 inbound-flux 를 구독하면 그때가서 생성된다. (lazy)\nReceiverRecord # 대략적으로 다음과 같은 느낌인 것 같다. ConsumerRecord + ReceiverOffset (\u0026lt;- 커밋 기능을 제공하는 객체)\n인바운드 메시지는 ReceiverRecord 로 표현한다.\n확인되지 않은 오프셋은 커밋하지 않으므로, 메시지를 처리하고 나면 반드시 오프셋을 처리했음을 알려야 한다. (acknowledge)\n커밋 인터벌(commit-interval), 커밋 배치 사이즈(commit-batch-size)를 설정했다면, 확인된(acknowledged) 오프셋을 주기적으로 커밋한다.\n커밋 연산을 더 세밀하게 제어해야 할 땐, ReceiverOffset#commit() 을 사용해 수동으로 오프셋을 커밋할 수도 있다.\ninboundFlux.subscribe(r -\u0026gt; { System.out.printf(\u0026#34;Received message: %s\\n\u0026#34;, r); // 1 : 인바운드 메시지를 처리한다. r.receiverOffset().acknowledge(); // 2 : offset을 커밋할 수 있게 레코드를 처리했음을 알린다. (acknowledge) }); 작성 중\n참고 # Reactive Kafka Sender \u0026amp; Kafka Receiver "},{"id":205,"href":"/docs/SPRING/SPRING-RedisKeyValueAdapter-update/","title":"[SPRING] RedisKeyValueAdapter (Update)","section":"SPRING","content":" update # element 가 컬렉션인 경우 # (컬렉션 요소들) 전체 삭제 후 다시 insert\n// 1 127.0.0.1:6379\u0026gt; hgetall test 1) \u0026#34;_class\u0026#34; 2) \u0026#34;~~~\u0026#34; 3) \u0026#34;ids.[0]\u0026#34; 4) \u0026#34;1\u0026#34; 3) \u0026#34;ids.[1]\u0026#34; 4) \u0026#34;2\u0026#34; // 2 127.0.0.1:6379\u0026gt; hgetall test 1) \u0026#34;_class\u0026#34; 2) \u0026#34;~~~\u0026#34; // 3 127.0.0.1:6379\u0026gt; hgetall test 1) \u0026#34;_class\u0026#34; 2) \u0026#34;~~~\u0026#34; 3) \u0026#34;ids.[0]\u0026#34; 4) \u0026#34;3\u0026#34; 그 외 # hmset, hset 커맨드로 overwrite\n참고 # public void update(PartialUpdate\u0026lt;?\u0026gt; update) { RedisPersistentEntity\u0026lt;?\u0026gt; entity = this.converter.getMappingContext() .getRequiredPersistentEntity(update.getTarget()); String keyspace = entity.getKeySpace(); Object id = update.getId(); byte[] redisKey = createKey(keyspace, converter.getConversionService().convert(id, String.class)); RedisData rdo = new RedisData(); this.converter.write(update, rdo); redisOps.execute((RedisCallback\u0026lt;Void\u0026gt;) connection -\u0026gt; { RedisUpdateObject redisUpdateObject = new RedisUpdateObject(redisKey, keyspace, id); for (PropertyUpdate pUpdate : update.getPropertyUpdates()) { String propertyPath = pUpdate.getPropertyPath(); if (UpdateCommand.DEL.equals(pUpdate.getCmd()) || pUpdate.getValue() instanceof Collection || pUpdate.getValue() instanceof Map || (pUpdate.getValue() != null \u0026amp;\u0026amp; pUpdate.getValue().getClass().isArray()) || (pUpdate.getValue() != null \u0026amp;\u0026amp; !converter.getConversionService().canConvert(pUpdate.getValue().getClass(), byte[].class))) { redisUpdateObject = fetchDeletePathsFromHashAndUpdateIndex(redisUpdateObject, propertyPath, connection); } } if (!redisUpdateObject.fieldsToRemove.isEmpty()) { connection.hDel(redisKey, redisUpdateObject.fieldsToRemove.toArray(new byte[redisUpdateObject.fieldsToRemove.size()][])); } for (Index index : redisUpdateObject.indexesToUpdate) { if (ObjectUtils.nullSafeEquals(DataType.ZSET, index.type)) { connection.zRem(index.key, toBytes(redisUpdateObject.targetId)); } else { connection.sRem(index.key, toBytes(redisUpdateObject.targetId)); } } if (!rdo.getBucket().isEmpty()) { if (rdo.getBucket().size() \u0026gt; 1 || (rdo.getBucket().size() == 1 \u0026amp;\u0026amp; !rdo.getBucket().asMap().containsKey(\u0026#34;_class\u0026#34;))) { connection.hMSet(redisKey, rdo.getBucket().rawMap()); } } ... "},{"id":206,"href":"/docs/SPRING/SPRING-Servlet/","title":"[SPRING] Servlet","section":"SPRING","content":" Servlet # 클라이언트의 요청을 처리하고, 결과를 반환하는 (Servlet 클래스의 구현 규칙을 지킨) Java 프로그램(클래스)이다.\n서블릿은 자바로 구현된 CGI라고 불린다.\n* 실제 주석 내용\n서블릿은 웹 서버 내에서 실행되는 작은 Java 프로그램이다. 일반적으로 서블릿은 HTTP 를 통해 웹 클라이언트의 요청을 받고, 응답한다.\n* CGI(Common GateWay Interface)란?\n외부 프로그램과 웹서버 사이에서 정보를 주고받는 방법/규약을 말한다.\nServlet (Interface) # 이 인터페이스는 서블릿을 초기화하고 요청을 서비스하고, 서블릿을 서버로부터 삭제하는 메소드를 정의하고 있다. 즉, 생명 주기 메소드들을 정의한다.\n/** A servlet is a small Java program that runs within a Web server. Servlets receive and respond to requests from Web clients, usually across HTTP, the HyperText Transfer Protocol. To implement this interface, you can write a generic servlet that extends javax.servlet.GenericServlet or an HTTP servlet that extends javax.servlet.http.HttpServlet. ... */ public interface Servlet { /** Called by the servlet container to indicate to a servlet that the servlet is being placed into service. */ init(ServletConfig): void /** Called by the servlet container to allow the servlet to respond to a request. This method is only called after the servlet\u0026#39;s init() method has completed successfully. Servlets typically run inside multithreaded servlet containers that can handle multiple requests concurrently. Developers must be aware to synchronize access to any shared resources such as files, network connections, and as well as the servlet\u0026#39;s class and instance variables. */ service(ServletRequest, ServletResponse): void /** Called by the servlet container to indicate to a servlet that the servlet is being taken out of service. This method is only called once all threads within the servlet\u0026#39;s service method have exited or after a timeout period has passed. After the servlet container calls this method, it will not call the service method again on this servlet. */ destroy(): void /** Returns information about the servlet, such as author, version, and copyright. */ getServletInfo(): String /** Returns a ServletConfig object, which contains initialization and startup parameters for this servlet. */ getServletConfig(): ServletConfig } (서블릿 컨테이너에 의해) 서블릿이 생성되고, init() 메서드 실행 (서블릿 컨테이너에 의해) service() 메서드 실행 (반드시 init() 메서드 성공 이후에 실행) (서블릿 컨테이너에 의해) destroy() 메서드 실행 (모든 threads 에서의 처리가 끝났거나, timeout 되었을 때 실행) ServletConfig (Interface) # 서블릿을 초기화하는 동안, 서블릿 Container -\u0026gt; 서블릿에게 정보를 전달하기 위해 사용하는 Servlet configuration object 이다.\n/** A servlet configuration object used by a servlet container to pass information to a servlet during initialization. */ public interface ServletConfig { getServletName(): String getServletContext(): ServletContext getInitParameter(String): String getInitParameterNames(): Enumeration\u0026lt;String\u0026gt; } GenericServlet (AbstractClass) # 프로토콜에 독립적인(상관없는) generic 한 서블릿 클래스이다. 즉, 특정 프로토콜을 위해 사용되는 서블릿 클래스가 아니고 한단계 추상적인 의미로 사용될 수 있는 generic 한 서블릿 클래스이다.\n/** Defines a generic, protocol-independent servlet. */ public abstract class GenericServlet implements Servlet, ServletConfig, java.io.Serializable { init(): void init(ServletConfig): void /** This method is declared abstract so subclasses, such as HttpServlet, must override it. */ service(ServletRequest, ServletResponse): void (abstract) destroy(): void ... } Servlet, ServletConfig 인터페이스를 구현했다. (Servlet 기능을 구현)\nGenericServlet 을 상속받아 구현한 서블릿들은 사용되는 프로토콜에 따라 service()를 오버라이딩해서 구현한다.\nHttpServlet (AbstractClass) # GenericServlet 을 상속받아 HTTP 프로토콜을 사용하는 서블릿 기능을 수행한다.\n위의 GenericServlet 클래스는 말 그대로 generic 한 클래스이다. 웹 (프로토콜) 전용으로 사용하기 위한 Servlet 이 바로 HttpServlet 클래스이다. (웹 서비스를 제공하는 서블릿을 만들 때 사용한다.)\n클라이언트의 요청 시, service() 가 호출되고 클라이언트의 요청 방식에 따라 doGet(), doPost(), doPut() 등의 메소드가 호출된다.\n/** Provides an abstract class to be subclassed to create an HTTP servlet suitable for a Web site. A subclass of HttpServlet must override at least one method, usually one of these: - doGet, if the servlet supports HTTP GET requests - doPost, for HTTP POST requests - doPut, for HTTP PUT requests - doDelete, for HTTP DELETE requests - init and destroy, to manage resources that are held for the life of the servlet - getServletInfo, which the servlet uses to provide information about itself There\u0026#39;s almost no reason to override the service method. service handles standard HTTP requests by dispatching them to the handler methods for each HTTP request type (the doMethod methods listed above). */ public abstract class HttpServlet extends GenericServlet { ... doGet(HttpServletRequest, HttpServletResponse): void doPost(HttpServletRequest, HttpServletResponse): void doPut(HttpServletRequest, HttpServletResponse): void doDelete(HttpServletRequest, HttpServletResponse): void doHead(HttpServletRequest, HttpServletResponse): void doOptions(HttpServletRequest, HttpServletResponse): void doTrace(HttpServletRequest, HttpServletResponse): void /** Dispatches client requests to the protected service method. There\u0026#39;s no need to override this method. 1. 형변환 : Servlet -\u0026gt; HttpServlet - ServletRequest -\u0026gt; HttpServletRequest - ServletResponse -\u0026gt; HttpServletResponse 2. service(HttpServletRequest, HttpServletResponse) 호출 */ service(ServletRequest, ServletResponse): void /** Receives standard HTTP requests from the public service method and dispatches them to the doMethod methods defined in this class. This method is an HTTP-specific version of the javax.servlet.Servlet.service method. There\u0026#39;s no need to override this method. 1. HTTP 요청(GET, POST, ...)에 따라 doMethod() 호출 */ service(HttpServletRequest, HttpServletResponse): void (protected) } 주석에도 나와있듯이, service() 메소드는 오버라이딩할 이유가 거의 없다. 표준 HTTP 요청에 대해서, HTTP 요청을 각각의 핸들러 메소드(doMethod()) 로 보내는 메소드이기 때문이다.\nReference\nhttps://mangkyu.tistory.com/14 "},{"id":207,"href":"/docs/SPRING/SPRING-ServletContext-ApplicationContext/","title":"[SPRING] ServletContext, ApplicationContext","section":"SPRING","content":" ServletContextListener # ServletContext 의 변화(라이프사이클)를 감지한다.\n웹 애플리케이션의 \u0026lsquo;시작\u0026rsquo;, \u0026lsquo;종료\u0026rsquo; 시에 아래 메서드가 호출된다. contextInitialized() : 웹 애플리케이션이 시작될 때 호출 servlet, filter 의 초기화보다 먼저 실행 contextDestroyed() : 웹 애플리케이션이 종료될 때 호출 servlet, filter 는 해당 메서드 호출 전에 이미 종료된 상태 /** * Implementations of this interface receive notifications about changes to the * servlet context of the web application they are part of. To receive * notification events, the implementation class must be configured in the * deployment descriptor for the web application. * * @see ServletContextEvent * @since v 2.3 */ public interface ServletContextListener extends EventListener { /** ** Notification that the web application initialization process is starting. * All ServletContextListeners are notified of context initialization before * any filter or servlet in the web application is initialized. * The default implementation is a NO-OP. * @param sce Information about the ServletContext that was initialized */ public default void contextInitialized(ServletContextEvent sce) { } /** ** Notification that the servlet context is about to be shut down. All * servlets and filters have been destroyed before any * ServletContextListeners are notified of context destruction. * The default implementation is a NO-OP. * @param sce Information about the ServletContext that was destroyed */ public default void contextDestroyed(ServletContextEvent sce) { } } ContextLoader # (Root)ApplicationContext 를 위해 실질적인 초기화 작업을 수행한다.\nServletContext 에 WebApplicationContext 를 설정 WebApplicationContext 에 ServletContext 를 설정 servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); wac.setServletContext(sc); ContextLoaderListner 에 의해 호출된다. contextInitialized() contextDestroyed() /** * Performs the actual initialization work for the root application context. * Called by {@link ContextLoaderListener}. * * \u0026lt;p\u0026gt;Looks for a \u0026#34;contextClass\u0026#34; parameter at the * web.xml context-param level to specify the context class type, falling * back to XmlWebApplicationContext if not found. * With the default ContextLoader implementation, any context class * specified needs to implement the ConfigurableWebApplicationContext interface. */ public class ContextLoader { ... public WebApplicationContext initWebApplicationContext(ServletContext servletContext) { long startTime = System.currentTimeMillis(); try { // Store context in local instance variable, to guarantee that // it is available on ServletContext shutdown. if (this.context == null) { this.context = createWebApplicationContext(servletContext); } if (this.context instanceof ConfigurableWebApplicationContext) { ConfigurableWebApplicationContext cwac = (ConfigurableWebApplicationContext) this.context; if (!cwac.isActive()) { // The context has not yet been refreshed -\u0026gt; provide services such as // setting the parent context, setting the application context id, etc if (cwac.getParent() == null) { // The context instance was injected without an explicit parent -\u0026gt; // determine parent for root web application context, if any. ApplicationContext parent = loadParentContext(servletContext); cwac.setParent(parent); } configureAndRefreshWebApplicationContext(cwac, servletContext); } } servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context); ... return this.context; } catch (RuntimeException | Error ex) { ... } } } ContextLoaderListener # Spring 의 (Root)WebApplicationContext 의 \u0026lsquo;시작\u0026rsquo;, \u0026lsquo;종료\u0026rsquo; 를 위한 리스너.\n(ContextLoader 를 통해)\nServletContext 에 WebApplicationContext 를 설정 WebApplicationContext 에 ServletContext 를 설정 /** * Bootstrap listener to start up and shut down Spring\u0026#39;s root WebApplicationContext. * As of Spring 3.1, ContextLoaderListener supports injecting the root web application context * via the ContextLoaderListener(WebApplicationContext) constructor, allowing for programmatic configuration in Servlet 3.0+ environments. * See org.springframework.web.WebApplicationInitializer for usage examples. */ public class ContextLoaderListener extends ContextLoader implements ServletContextListener { public ContextLoaderListener() { } public ContextLoaderListener(WebApplicationContext context) { super(context); } @Override public void contextInitialized(ServletContextEvent event) { // initWebApplicationContext 는 ContextLoader 메서드이다. // ServletContext 에 WebApplicationContext 를 설정한다. initWebApplicationContext(event.getServletContext()); } @Override public void contextDestroyed(ServletContextEvent event) { // closeWebApplicationContext 는 ContextLoader 메서드이다. closeWebApplicationContext(event.getServletContext()); ContextCleanupListener.cleanupAttributes(event.getServletContext()); } } ServletContext 가 초기화 되는 시점에, ContextLoaderListner(ContextLoader) 가 ServletContext 에 WebApplicationContext 를 설정합니다.\nApplicationContext # /** * Central interface to provide configuration for an application. * This is read-only while the application is running, but may be reloaded if the implementation supports this. */ public interface ApplicationContext extends EnvironmentCapable, ListableBeanFactory, HierarchicalBeanFactory, MessageSource, ApplicationEventPublisher, ResourcePatternResolver { ... } 참고\n인터페이스 설명 ListableBeanFactory 애플리케이션의 컴포넌트들에 접근하기 위한 Bean Factory Method ResourceLoader File resources 를 로드히기 위한 인터페이스 ApplicationEventPublish Event publishing 을 위한 인터페이스 MessageSource 국제화(Internationalization)를 지원하기 위한 인터페이스 WebApplicationContext # This interface adds a getServletContext() method to the generic ApplicationContext interface\n/** * Interface to provide configuration for a web application. * This interface adds a getServletContext() method to the generic ApplicationContext interface, * and defines a well-known application attribute name that the root context must be bound to in the bootstrap process. * * Like generic application contexts, web application contexts are hierarchical. * There is a single root context per application, * while each servlet in the application (including a dispatcher servlet in the MVC framework) has its own child context. * * In addition to standard application context lifecycle capabilities, * WebApplicationContext implementations need to detect ServletContextAware beans * and invoke the setServletContext method accordingly. * */ public interface WebApplicationContext extends ApplicationContext { ... @Nullable ServletContext getServletContext(); } DispatcherServlet # 스프링에서 정의한 Front Controller Servlet.\n모든 요청을 받아, 각각의 handler 로 요청을 위임한다. Handler 의 결과를 Http Response 형태로 만들어 반환한다. RootWebApplicationContext 는 infrastructure beans(repository, service 등) 를 포함한다.\nRootWebApplicationContext 는 모든 Servlet 에 공유된다. 해당 Bean 들은 ServletWebApplicationContext 에 상속되거나 재정의될 수 있다. ServletWebApplicationContext 는 controller, viewResolver, handlerMapping 등의 bean을 관리한다.\nServletWebApplicationContext 는 해당 DispatcherServlet 내에서만 사용할 수 있다. 다만, 요새는 위와 같이 RootWebApplicationContext, ServletWebApplicationContext 와 같이 구분짓지 않고 하나의 IoC Container 에서 관리한다고도 한다.\n"},{"id":208,"href":"/docs/SPRING/SPRING-Session-1/","title":"[SPRING] Session (1)","section":"SPRING","content":"서블릿 컨테이너(e.g. 톰캣) 자체적으로 세션 관리\nSession # 주요 인터페이스/클래스\nHttpSession StandardSession /** * Provides a way to identify a user across more than one page request or visit to a Web site and to store information about that user. * The session persists for a specified time period, across more than one connection or page request from the user. * A session usually corresponds to one user, who may visit a site many times. * * ... * Session information is scoped only to the current web application ( ServletContext), so information stored in one context will not be directly visible in another. */ public interface HttpSession { ... } /** * Standard implementation of the Session interface. * ... */ public class StandardSession implements HttpSession, Session, Serializable { ... /** * The session identifier of this Session. */ protected String id = null; /** * The collection of user data attributes associated with this Session. */ protected ConcurrentMap\u0026lt;String, Object\u0026gt; attributes = new ConcurrentHashMap\u0026lt;\u0026gt;(); /** * The Manager with which this Session is associated. */ protected transient Manager manager = null; ... } Session(StandardSession) 사용자 데이터 관리 : ConcurrentMap\u0026lt;String, Object\u0026gt; attributes 서블릿 컨테이너 입장에서 관리 : Map\u0026lt;SessionId(JSESSIONID), HttpSession\u0026gt; 일듯 ManagerBase protected Map\u0026lt;String, Session\u0026gt; sessions = new ConcurrentHashMap\u0026lt;\u0026gt;(); 이거 인듯 Manager # (위의 StandardSession 중) Manager manager\nManager ManagerBase /** * A Manager manages the pool of Sessions that are associated with a particular Context. * * Different Manager implementations may support * value-added features such as the persistent storage of session data, * as well as migrating sessions for distributable web applications. * * In order for a Manager implementation to successfully operate with a Context implementation * that implements reloading, it must obey the following constraints: * * 1. Must implement Lifecycle so that the Context can indicate that a restart is required. * 2. Must allow a call to stop() to be followed by a call to start() on the same Manager instance. * * @author Craig R. McClanahan */ public interface Manager { /** * Get the Context with which this Manager is associated. * 얘가 ServletContext. */ public Context getContext(); // A Context is a Container that represents a servlet context, and therefore an individual web application, in the Catalina servlet engine. ... /** * Minimal implementation of the Manager interface that supports no session persistence or distributable capabilities. * This class may be subclassed to create more sophisticated Manager implementations. */ public abstract class ManagerBase extends LifecycleMBeanBase implements Manager { ... /** * The name of the algorithm to use to create instances of java.security.SecureRandom which are used to generate session IDs * Session ID 생성하기 위해 알고리즘 사용함. * PRNG : pseudo-random number generator */ protected String secureRandomAlgorithm = \u0026#34;SHA1PRNG\u0026#34;; protected SessionIdGenerator sessionIdGenerator = null; // 얘가 secureRandomAlgorithm 사용함 ... /** * The set of currently active Sessions for this Manager, keyed by session identifier. */ protected Map\u0026lt;String, Session\u0026gt; sessions = new ConcurrentHashMap\u0026lt;\u0026gt;(); // 중요 ... /** * Generate and return a new session identifier. */ protected String generateSessionId() { String result = null; do { if (result != null) { // Not thread-safe but if one of multiple increments is lost // that is not a big deal since the fact that there was any // duplicate is a much bigger issue. duplicates++; } result = sessionIdGenerator.generateSessionId(); } while (sessions.containsKey(result)); return result; } ... } Session ID 생성 시 secure 알고리즘 사용\n랜덤하게 생성하기 위해서 인줄 알았는데, 아래와 같은 내용이 있다./ \u0026quot; 하지만, 암호학적으로 안전한 난수생성기를 쓰지 않는 경우, 사용자나 공격자들이 무식하게 경우의 수를 전부 미리 계산하고 그 결과를 이용해서 Bruteforce 하게 세션값을 위조해버리거나 조작해버리는 경우도 생길 수 있습니다. \u0026quot; 출처 : https://semtax.tistory.com/92\n예를 들어 1, 2, 3, 4, \u0026hellip; 와 같이 세션이 추측 가능하다면, 세션 ID 맘대로 사용 가능해지게 될 듯 세션ID 생성 시 do-while 문 통해서 중복되지 않게 만듬 (Map.contains() 체크)\n\u0026lsquo;JSESSION\u0026rsquo; 이라는 것은 어디서 가져오는지 ? # public class SessionConfig { private static final String DEFAULT_SESSION_COOKIE_NAME = \u0026#34;JSESSIONID\u0026#34;; private static final String DEFAULT_SESSION_PARAMETER_NAME = \u0026#34;jsessionid\u0026#34;; ... public static String getSessionUriParamName(Context context) { String result = getConfiguredSessionCookieName(context); if (result == null) { result = DEFAULT_SESSION_PARAMETER_NAME; } return result; } ... 확인해볼것 # ApplicationSessionCookieConfig TomcatServletWebServerFactory public class TomcatServletWebServerFactory extends AbstractServletWebServerFactory implements ConfigurableTomcatWebServerFactory, ResourceLoaderAware { ... private void configureCookieProcessor(Context context) { SameSite sessionSameSite = getSession().getCookie().getSameSite(); List\u0026lt;CookieSameSiteSupplier\u0026gt; suppliers = new ArrayList\u0026lt;\u0026gt;(); if (sessionSameSite != null) { suppliers.add(CookieSameSiteSupplier.of(sessionSameSite) .whenHasName(() -\u0026gt; SessionConfig.getSessionCookieName(context))); } if (!CollectionUtils.isEmpty(getCookieSameSiteSuppliers())) { suppliers.addAll(getCookieSameSiteSuppliers()); } if (!suppliers.isEmpty()) { context.setCookieProcessor(new SuppliedSameSiteCookieProcessor(suppliers)); } } public class ApplicationSessionCookieConfig implements SessionCookieConfig { ... public static Cookie createSessionCookie(Context context, String sessionId, boolean secure) { SessionCookieConfig scc = context.getServletContext().getSessionCookieConfig(); // NOTE: The priority order for session cookie configuration is: // 1. Context level configuration // 2. Values from SessionCookieConfig // 3. Defaults Cookie cookie = new Cookie( SessionConfig.getSessionCookieName(context), sessionId); // Just apply the defaults. cookie.setMaxAge(scc.getMaxAge()); cookie.setComment(scc.getComment()); if (context.getSessionCookieDomain() == null) { // Avoid possible NPE if (scc.getDomain() != null) { cookie.setDomain(scc.getDomain()); } } else { cookie.setDomain(context.getSessionCookieDomain()); } // Always set secure if the request is secure if (scc.isSecure() || secure) { cookie.setSecure(true); } // Always set httpOnly if the context is configured for that if (scc.isHttpOnly() || context.getUseHttpOnly()) { cookie.setHttpOnly(true); } cookie.setPath(SessionConfig.getSessionCookiePath(context)); return cookie; } ... } https://semtax.tistory.com/92\n"},{"id":209,"href":"/docs/SPRING/SPRING-Spring-Batch-1/","title":"[SPRING] Spring Batch (1)","section":"SPRING","content":" 개요 # \u0026quot; A Job has one to many steps, each of which has exactly one ItemReader, one ItemProcessor, and one ItemWriter \u0026ldquo;\n하나의 Job 은 여러 Step 을 갖는다.\n하나의 Step 은 각각 1개의 ItemReader, ItemProcessor, ItemWriter 를 갖는다.\nJob # \u0026rdquo; A Job is an entity that encapsulates an entire batch process. \u0026ldquo;\n하나의 잡은 Batch Process 를 표현하는 수단으로 볼 수 있음\nJob은 작업이 무엇이고, 어떻게 하는지 에 대해 정의\nJob 은 다음과 같은 정보를 포함\nJob 이름 Step 순서 (Step 에 대한 정의) (Definition and ordering of Step instances.) 재시작할 수 있는지에 대한 여부 (Whether or not the job is restartable.) JobInstance # \u0026rdquo; A JobInstance refers to the concept of a logical job run. \u0026ldquo;\nJob 의 논리적인 실행 개념(인스턴스)\n(+ 중복되지 않은 JobParameter) JobInstance 실행 가능\nJOB INSTANCE 정보\n+---------------+-------+--------------------------+--------------------------------+ |JOB_INSTANCE_ID|VERSION|JOB_NAME |JOB_KEY | +---------------+-------+--------------------------+--------------------------------+ |54 |0 |2022-02-26T18:50:40.703155|58e1898e417c22a4728898e6a35e76f0| |55 |0 |2022-02-26T18:51:29.449640|58e1898e417c22a4728898e6a35e76f0| +---------------+-------+--------------------------+--------------------------------+ JobParameters # \u0026rdquo; How is one JobInstance distinguished from another?\nThe answer is: JobParameters.\nA JobParameters object holds a set of parameters used to start a batch job.\nThey can be used for identification or even as reference data during the run \u0026ldquo;\nJOB EXECUTION PARAMETER 정보\nJob 실행 시 넘긴 파라미터 정보가 기록된다.\n(JOB_EXECUTION_ID) JOB_EXECUTION 을 바라본다.\n+----------------+-------+--------+----------+-------------------+--------+----------+-----------+ |JOB_EXECUTION_ID|TYPE_CD|KEY_NAME|STRING_VAL|DATE_VAL |LONG_VAL|DOUBLE_VAL|IDENTIFYING| +----------------+-------+--------+----------+-------------------+--------+----------+-----------+ |42 |STRING |version |1.3 |1970-01-01 09:00:00|0 |0 |Y | |43 |STRING |version |1.3 |1970-01-01 09:00:00|0 |0 |Y | +----------------+-------+--------+----------+-------------------+--------+----------+-----------+ JobExecution # \u0026rdquo; A JobExecution refers to the technical concept of a single attempt to run a Job. \u0026ldquo;\nJob(JobInstance)의 단일 시도\n\u0026rdquo; An execution may end in failure or success, but the JobInstance corresponding to a given execution is not considered to be complete unless the execution completes successfully. \u0026ldquo;\nJobExecution 은 성공/실패 로 끝날 수 있음\n하지만 JobInstance 는 JobExecution 이 완벽하게 성공하지 않으면 완료되지 않음\n실행(시도) 중 실제 발생한 것에 대해 기록한다.\nJOB INSTANCE 실행 기록\nJOB INSTANCE ID 생성 시간 시작 시간 종료 시간 상태 EXIT 상태 EXIT 메시지 \u0026hellip; 에러 로그는 상세히 기록된다. stackTrace 가 그대로 기록되는 것 같다. e.g.) org.springframework.dao.DataIntegrityViolationException: could not execute batch; SQL [update set ~~~ where ???] nested exception is org.hibernate.exception.DataException: could not execute batch \u0026hellip; e.g.) All steps already completed or no steps configured for this job. (NOOP 상태 일 때)\n+----------------+-------+---------------+-------------------+-------------------+-------------------+---------+---------+------------+-------------------+--------------------------+ |JOB_EXECUTION_ID|VERSION|JOB_INSTANCE_ID|CREATE_TIME |START_TIME |END_TIME |STATUS |EXIT_CODE|EXIT_MESSAGE|LAST_UPDATED |JOB_CONFIGURATION_LOCATION| +----------------+-------+---------------+-------------------+-------------------+-------------------+---------+---------+------------+-------------------+--------------------------+ |6 |2 |3 |2022-02-21 16:42:35|2022-02-21 16:42:35|2022-02-21 16:42:35|FAILED |FAILED | 에러로그 |2022-02-21 16:42:35|NULL | |7 |2 |3 |2022-02-21 16:42:56|2022-02-21 16:42:56|2022-02-21 16:42:56|COMPLETED|NOOP | NOOP 로그 |2022-02-21 16:42:56|NULL | |8 |2 |3 |2022-02-21 17:44:42|2022-02-21 17:44:42|2022-02-21 17:44:42|COMPLETED|NOOP | NOOP 로그 |2022-02-21 17:44:42|NULL | |.. |. |.. |2022-02-26 18:50:42|2022-02-26 18:50:43|2022-02-26 18:50:45|COMPLETED|COMPLETED| |2022-02-26 18:50:45|NULL | |71 |2 |54 |2022-02-26 18:50:42|2022-02-26 18:50:43|2022-02-26 18:50:45|COMPLETED|COMPLETED| |2022-02-26 18:50:45|NULL | |72 |2 |55 |2022-02-26 18:51:31|2022-02-26 18:51:31|2022-02-26 18:51:33|COMPLETED|COMPLETED| |2022-02-26 18:51:33|NULL | +----------------+-------+---------------+-------------------+-------------------+-------------------+---------+---------+------------+-------------------+--------------------------+ JOB EXECUTION CONTEXT 정보\n(JOB_EXECUTION_ID) JOB_EXECUTION 을 바라본다.\n+----------------+------------------------------+------------------+ |JOB_EXECUTION_ID|SHORT_CONTEXT |SERIALIZED_CONTEXT| +----------------+------------------------------+------------------+ |67 |{\u0026#34;@class\u0026#34;:\u0026#34;java.util.HashMap\u0026#34;}|NULL | |68 |{\u0026#34;@class\u0026#34;:\u0026#34;java.util.HashMap\u0026#34;}|NULL | |69 |{\u0026#34;@class\u0026#34;:\u0026#34;java.util.HashMap\u0026#34;}|NULL | +----------------+------------------------------+------------------+ Step # Job의 \u0026lsquo;단계\u0026rsquo;를 의미 Job은 한 개 이상의 Step 으로 구성 StepExecution # \u0026lsquo;Step\u0026rsquo; 의 \u0026lsquo;단일 시도\u0026rsquo;를 의미 Step 이 동작할 때마다, StepExecution 생성되는 개념 JobExecution, Step, Commit Count, Read Count, Filter Count, Write Count, ExecutionContext 등 포함 \u0026rdquo; ExecutionContext, which contains any data a developer needs to have persisted across batch runs, such as statistics or state information needed to restart. \u0026ldquo;\nSTEP 실행 기록\nJOB EXECUTION ID 이름 생성 시간 시작 시간 종료 시간 상태 COMMIT COUNT FILTER COUNT WRITE COUNT ROLLBACK COUNT \u0026hellip; EXIT 상태 EXIT 메시지 \u0026hellip; 에러 로그는 상세히 기록된다. stackTrace 가 그대로 기록되는 것 같다. e.g.) org.springframework.dao.DataIntegrityViolationException: could not execute batch; SQL [update set ~~~ where ???] nested exception is org.hibernate.exception.DataException: could not execute batch \u0026hellip; e.g.) All steps already completed or no steps configured for this job. (NOOP 상태 일 때)\n+-----------------+-------+---------+----------------+-------------------+-------------------+---------+------------+----------+------------+-----------+---------------+----------------+------------------+--------------+---------+------------+-------------------+ |STEP_EXECUTION_ID|VERSION|STEP_NAME|JOB_EXECUTION_ID|START_TIME |END_TIME |STATUS |COMMIT_COUNT|READ_COUNT|FILTER_COUNT|WRITE_COUNT|READ_SKIP_COUNT|WRITE_SKIP_COUNT|PROCESS_SKIP_COUNT|ROLLBACK_COUNT|EXIT_CODE|EXIT_MESSAGE|LAST_UPDATED | +-----------------+-------+---------+----------------+-------------------+-------------------+---------+------------+----------+------------+-----------+---------------+----------------+------------------+--------------+---------+------------+-------------------+ |5 |2 |step1 |13 |2022-02-21 18:19:31|2022-02-21 18:19:31|COMPLETED|0 |0 |0 |0 |0 |0 |0 |1 |FAILED | 에러로그 |2022-02-21 18:19:31| |6 |3 |step1 |14 |2022-02-21 18:20:20|2022-02-21 18:20:21|COMPLETED|1 |0 |0 |0 |0 |0 |0 |0 |COMPLETED| |2022-02-21 18:20:21| |7 |3 |step2 |14 |2022-02-21 18:20:21|2022-02-21 18:20:21|COMPLETED|1 |0 |0 |0 |0 |0 |0 |0 |COMPLETED| |2022-02-21 18:20:21| +-----------------+-------+---------+----------------+-------------------+-------------------+---------+------------+----------+------------+-----------+---------------+----------------+------------------+--------------+---------+------------+-------------------+ ... +-----------------+-------+---------+----------------+-------------------+-------------------+---------+------------+----------+------------+-----------+---------------+----------------+------------------+--------------+---------+------------+-------------------+ |STEP_EXECUTION_ID|VERSION|STEP_NAME|JOB_EXECUTION_ID|START_TIME |END_TIME |STATUS |COMMIT_COUNT|READ_COUNT|FILTER_COUNT|WRITE_COUNT|READ_SKIP_COUNT|WRITE_SKIP_COUNT|PROCESS_SKIP_COUNT|ROLLBACK_COUNT|EXIT_CODE|EXIT_MESSAGE|LAST_UPDATED | +-----------------+-------+---------+----------------+-------------------+-------------------+---------+------------+----------+------------+-----------+---------------+----------------+------------------+--------------+---------+------------+-------------------+ |60 |3 |step1 |66 |2022-02-26 18:19:52|2022-02-26 18:19:53|COMPLETED|1 |7 |0 |7 |0 |0 |0 |0 |COMPLETED| |2022-02-26 18:19:53| |61 |3 |step1 |67 |2022-02-26 18:36:26|2022-02-26 18:36:27|COMPLETED|1 |7 |0 |7 |0 |0 |0 |0 |COMPLETED| |2022-02-26 18:36:27| +-----------------+-------+---------+----------------+-------------------+-------------------+---------+------------+----------+------------+-----------+---------------+----------------+------------------+--------------+---------+------------+-------------------+ ExecutionContext # \u0026quot; An ExecutionContext represents a collection of key/value pairs that are persisted and controlled by the framework in order to allow developers a place to store persistent state that is scoped to a StepExecution object or a JobExecution object. \u0026quot;\nJOB EXECUTION CONTEXT 정보\n+-----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+ |STEP_EXECUTION_ID|SHORT_CONTEXT |SERIALIZED_CONTEXT| +-----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+ |65 |{\u0026#34;@class\u0026#34;:\u0026#34;java.util.HashMap\u0026#34;,\u0026#34;batch.taskletType\u0026#34;:\u0026#34;org.springframework.batch.core.step.item.ChunkOrientedTasklet\u0026#34;,\u0026#34;batch.stepType\u0026#34;:\u0026#34;org.springframework.batch.core.step.tasklet.TaskletStep\u0026#34;,\u0026#34;AbstractPagingItemReader.read.count\u0026#34;:8}|NULL | |66 |{\u0026#34;@class\u0026#34;:\u0026#34;java.util.HashMap\u0026#34;,\u0026#34;batch.taskletType\u0026#34;:\u0026#34;org.springframework.batch.core.step.item.ChunkOrientedTasklet\u0026#34;,\u0026#34;batch.stepType\u0026#34;:\u0026#34;org.springframework.batch.core.step.tasklet.TaskletStep\u0026#34;,\u0026#34;AbstractPagingItemReader.read.count\u0026#34;:8}|NULL | +-----------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------------+ References # https://docs.spring.io/spring-batch/docs/current/reference/html/domain.html#domainLanguageOfBatch\n"},{"id":210,"href":"/docs/SPRING/SPRING-Spring-Batch-2/","title":"[SPRING] Spring Batch (2)","section":"SPRING","content":" 애플리케이션 실행 순서 # SpringApplication ---\u0026gt; JobLauncherApplicationRunner (ApplicationRunner) ---\u0026gt; JobLauncherApplicationRunner # SpringApplication 에 의해 run() 메서드가 호출되고, execute() 메서드를 실행한다.\nprotected void execute(Job job, JobParameters jobParameters) throws JobExecutionAlreadyRunningException, JobRestartException, JobInstanceAlreadyCompleteException, JobParametersInvalidException, JobParametersNotFoundException { JobParameters parameters = getNextJobParameters(job, jobParameters); // (1) JobExecution execution = this.jobLauncher.run(job, parameters); // (2) if (this.publisher != null) { this.publisher.publishEvent(new JobExecutionEvent(execution)); // (3) } } (1) jobParameter 를 가져온다. (2) jobLauncher.run() 을 통해 job 을 실행한다. jobLauncher.run()은 JobExecution 을 반환한다. (3) JobExecutionEvent 발행한다. SimpleJobLauncher (JobLauncher) # // Run the provided job with the given JobParameters. // The JobParameters will be used to determine if this is an execution of an existing job instance, or if a new one should be created. // JobParameter 는 새 잡 인스턴스를 생성할 지, 기존 잡 인스턴스를 실행할 지 판단하기 위해 사용된다. public JobExecution run(final Job job, final JobParameters jobParameters) throws JobExecutionAlreadyRunningException, JobRestartException, JobInstanceAlreadyCompleteException, JobParametersInvalidException { ... // LastJobExecution 을 가져온다. // LastJobExecution 은 JobInstance 기준으로 마지막에 생성된 JobExecution 을 의미한다. JobExecution lastExecution = jobRepository.getLastJobExecution(job.getName(), jobParameters); // 이전 jobExecution 이 있다면 재시작 가능한 상태인지 확인합니다. if (lastExecution != null) { if (!job.isRestartable()) { throw new JobRestartException(\u0026#34;JobInstance already exists and is not restartable\u0026#34;); } for (StepExecution execution : lastExecution.getStepExecutions()) { BatchStatus status = execution.getStatus(); if (status.isRunning() || status == BatchStatus.STOPPING) { throw new JobExecutionAlreadyRunningException(...); } else if (status == BatchStatus.UNKNOWN) { throw new JobRestartException(...); } } } // JobParameter 유효성 검증합니다. job.getJobParametersValidator().validate(jobParameters); // 기존 JobInstance, JobExecution 이 있는 경우 : (LastJobExecution의) ExecutionContext 사용합니다. // 기존 JobInstance, JobExecution 이 없는 경우 : 새 JobInstnace, ExecutionContext 를 생성합니다. // [참고] JobExecution 은 항상 새롭게 생성된다. (JobInstnace, ExecutionContext 내용이 달라지는 것이다.) jobExecution = jobRepository.createJobExecution(job.getName(), jobParameters); try { taskExecutor.execute(new Runnable() { @Override public void run() { try { ... job.execute(jobExecution); ... } catch (Throwable t) { ... } } }); } catch (TaskRejectedException e) { // 에러가 발생한 경우, JobExecution 의 상태를 업데이트 합니다. // 에러가 발생하지 않은 경우, 위 job.execute() 호출 내에서 업데이트 됩니다. jobExecution.upgradeStatus(BatchStatus.FAILED); if (jobExecution.getExitStatus().equals(ExitStatus.UNKNOWN)) { jobExecution.setExitStatus(ExitStatus.FAILED.addExitDescription(e)); } jobRepository.update(jobExecution); } return jobExecution; } (1) 이미 존재하고 있는 JobInstance, JobExecution 내용을 확인하고 검증합니다. (JobParameter 유호성 검증도 포함합니다.) (2) JobExecution 을 생성합니다. (ExecutionContext 는 새 것이거나, 기존 내용이 됩니다.) (3) Job 을 실행합니다. (AbstractJob -\u0026gt; SimpleJob)\nJob (AbstractJob, SimpleJob) # \u0026hellip;\n"},{"id":211,"href":"/docs/SPRING/SPRING-Spring-Cloud-Gateway-1/","title":"[SPRING] Spring Cloud Gateway - 1","section":"SPRING","content":" Spring Cloud Gateway (SCG) # 용어 # Route\nSCG의 \u0026lsquo;기본 설정 그룹\u0026rsquo; 정도로 볼 수 있을 것 같음 ID, Dest URI, 일련의 Preciates, 일련의 Filters 등이 정의\n예를 들어, 하나의 route는 predicate 가 true 일 때 매치\nPredicate\nJava8 의 Predicate Input-Type : ServerWebExchange HTTP request(header, parameter 등)로부터 해당 route를 매치시킬 것인지 아닌지 등을 판단하기 위해 사용된다. Filter\n(SpringFramework GatewayFilter) (before or after sending the downstream request)request, response 를 조작할 수 있음 동작 원리 # 어떻게 동작하는지에 대한 그림은 여기를 참고하자.\n위의 그림을 간단하게 하면 아래와 같다.\n1. Client -\u0026gt; 2. Gateway Handler Mapping -\u0026gt; 3. Gateway Web Handler -\u0026gt; 4. Filter(s)/Proxy Filter -\u0026gt; 5. 각각의 Proxied Service\nGatewayHandlerMapping\ndetermines that a reuqest mathces a route, and then it is sent to the GatewayWebHandler GatewayWebHandler\nruns the request through a filter chain that is specific to the request. Filter(s)/ProxyFilter\nAll \u0026ldquo;pre\u0026rdquo; filter logic is executed Then the proxy request is made Then the \u0026ldquo;post\u0026rdquo; filter logic is run. Two ways of Configuring (Route Predicate Factories / Gateway Filter Factories) # Shortcuts Fully expanded arguments * 실제 구성 예시 코드는 여기를 참조하자.\nRoute Preddicate Factories (\u0026lt;-\u0026gt; Gateway Filter Factories) # * 이미 내장된(정의된) Route Predicate Factories 와 구체적인 예시는 여기에서 확인해보자.\nWe can combine multiple route predicate factories with logical and statements.\n내장된(정의된) Route Predicate Factories 에 대해서 대략적으로 살펴보면 아래와 같은 것들이 있다.\nBeefore : 특정 시간 이전인지 체크 After : 특정 시간 이후인지 체크 Betwwen : 특정 시간 사이인지 체크 Cookie : Cookie의 name,value(with regexp) 체크 Header : Header name, value(with regexp) 체크 Host : Host 체크 (host header) Method : HTTP Method(GET, POST, \u0026hellip;) 체크 Path : (API) Path 체크 Query : (API) Query 체크 (name, value) RemoteAddr : (request\u0026rsquo;s) IP 주소(Ipv4, IPv6) 체크 (CIDR-notation) Weight Route : 각 그룹별 weight 를 체크/맞춰준다. GatewayFilter Factories (\u0026lt;-\u0026gt; Route Predicate Factories) # * 이미 내장된(정의된) GatewayFilter Factories 와 구체적인 예시는 여기에서 확인해보자.\nThis allows \u0026rsquo;the modification\u0026rsquo; of the incoming HTTP request/outgoing HTTP response in some manner.\nThis is scoped to a particular \u0026lsquo;route\u0026rsquo;.\n내장된(정의된) Route Predicate Factories 에 대해서 대략적으로 살펴보면 아래와 같은 것들이 있다.\nAddRequestHeader : Header 에 name, value 추가 (to the downstream request\u0026rsquo;s header) AddRequestParameter : Parameter 에 name, value 추가 (to the request\u0026rsquo;s query string) AddResponseHader : Header 에 name, value 추가 (to the downstream response\u0026rsquo;s header) DedupeResponseHeader : name, strategy 값을 받고, Header name 의 값에서 strategy 전략을 통해 중복된 값을 제거 CircuitBreaker : Uses Spring Cloud CircuitBreaker APIs to wrap Gateway routes in a circuit breaker FallbackHeaders : When Spring Cloud CircuitBreaker\u0026rsquo;s execution exception happened, forward to a fallbackUri MapRequestHeader : fromHeader, toHeader 받고, 새로운 헤더를 추가(fromHeader -\u0026gt; toHeader) PrefixPath : (API) path 에 prefix 추가 PreserveHostHeader : This filter sets a request attribute that the routing filter inspects to determine if the original host header should be sent, rather than the host header determined by the HTTP client RequestRateLimiter : ReateLimiter 사용 -\u0026gt; 요청 수 제한 (HTTP 429 - Too Many Requests) (with KeyResolver) RedirectTo : status, uri 받고, redirect RemoveRequestHeader : name 받고, Header 의 name 제거 RemoveResponseHeader : name 받고, Header 의 name 제거 RemoveRequestParameter : name 받고, (API) query parameter 제거 RewritePath : (request)Path 에 대해 rewrite (자주 사용) RewriteLocationResponseHeader : Modifies the value of the Location (of response header) (usually to get rid of backend-specific details) RewriteResponseHeader : Header 정보 수정 (마스킹, 값 조작 등) SaveSession : before forwarding the call downstream, forces a WebSession::save operation SecureHeaders : response header 에 여러 정보를 추가 SetPath : (API) Path 조작 (vs RewritePath ?) SetRequestHeader : Request Header 에 name, value set (vs AddRequestHeader 와의 차이는 set, add?) SetResponseHeader : Response Header 에 name, value set SetStatus : HTTP response status 설정 StripPrefix : To strip from the request path(?) Retry : 규칙에 따라 retry (자주 사용) RequestSize : reuqest size 로 제한 여부 SetRequestHost : header host 를 replace ModifyRequestBody : request body 를 수정 ModifyResponseBody : response body 를 수정 Default : To add, apply a filter to all routes, we can use default-filters Global Filters # It has the same signature as GatewayFilter.\nIt is special filter that are conditionally applied to all routes. (vs Default filter (?))\n\u0026hellip;\n"},{"id":212,"href":"/docs/SPRING/SPRING-Spring-Cloud-Gateway-2/","title":"[SPRING] Spring Cloud Gateway - 2","section":"SPRING","content":" [웨비나] API Gateway를 활용한 API 개발과 비즈니스 로직 실행 # Gateway 고려사항 # 수많은 API 요청을 처리할 수 있는 안정적인 인프라 Scale Out 가능 여부 트래픽 제어 (Rate Limit, \u0026hellip;) Gateway 를 위한 트래픽 제어 Internel Service 를 위한 트래픽 제어 모니터링 사용 현황 (호출량) 응답 시간 오류 현황 다양한 성능 정보 인증 (+ 인가) API Key 를 이용한 제어 IP ACL 를 이용한 제어 유연한 API 관리 리소스, 메서드 관리 Client ---\u0026gt; Mock API ---\u0026gt; G/W ---\u0026gt; Internel 네이버 Gateway 의 경우 아래 Endpoint 에 대한 호출이 가능하다.\n(Serverless) Cloud Function Server LB 인증 # IAM 사용자를 생성, (Access Key, Secret Key)관리한다. 사용자별로 Access Key, Secret Key 를 통해 통신한다. Authorizer 별도 인증, 인가 시스템이 있을 때 사용할 수 있는 방법이다. Cloud Function 구조로 동작한다. 원한다면 인증 없이 Open 할 수 있다. Request / Response # 필요한 정보는 다음과 같을 것이다.\nURL Method Headers timestamp api key access key hmac signature \u0026hellip; Body 서울 - Spring Cloud Gateway - Spencer Gibb # "},{"id":213,"href":"/docs/SPRING/SPRING-Spring-Cloud-Gateway-3/","title":"[SPRING] Spring Cloud Gateway - 3","section":"SPRING","content":" spring-cloud-starter-gateway # Dependency # spring-cloud-starter spring-boot-starter-webflux netty \u0026hellip; spring-cloud-starter-loadbalancer (optional) spring-cloud-gateway-server 실질적으로 이 모듈에 Gateway와 관련된 클래스(코드)가 있다고 보면 될 것 같다. spring-cloud-gateway-server # Dependency # 기본적인 Dependency 가 모두 들어있다. (다만, optional 활성 여부를 꼭 확인할 것)\nspring-boot-starter spring-boot-starter-validation io.projectreactor.addons:reactor-extra spring-boot-starter-oauth2-client (optional) spring-boot-starter-actuator (optional) \u0026hellip; Flow # https://dlsrb6342.github.io/2019/05/14/spring-cloud-gateway-%EA%B5%AC%EC%A1%B0/ 여기의 글도 보기 좋다.\nHttpServerOperations (reactor-netty-http) ---\u0026gt; HttpWebHandlerAdapter(spring-web) ---\u0026gt; (WebHandler.handle(), DispatcherHandler.handle()) RoutePredicateHandlerMapping(spring-cloud-gateway-server) ---\u0026gt; FilteringWebHandler.handle() DispatcherHandler # public class DispatcherHandler implements WebHandler, PreFlightRequestHandler, ApplicationContextAware { @Nullable private List\u0026lt;HandlerMapping\u0026gt; handlerMappings; @Nullable private List\u0026lt;HandlerAdapter\u0026gt; handlerAdapters; @Nullable private List\u0026lt;HandlerResultHandler\u0026gt; resultHandlers; ... HandlerMapping 은 기본적으로 아래 7가지를 가지고 있다.\n이것들은 순서(Order)를 갖고 있다. 낮은 값(INT) 앞에 배치하고, 높은 값일수록 뒤에 배치한다.\nAdditionalHealthEndpointPathsWebFluxHandlerMapping WebFluxEndpointHandlerMapping ControllerEndpointHandlerMapping RouterFunctionMapping RequestMappingHandlerMapping RoutePredicateHandlerMapping SimpleUrlHandlerMapping HandlerAdapter 는 기본적으로 아래 4가지를 가지고 있다.\nWebSocketHandlerAdapter RequestMappingHandlerAdapter HandlerFunctionAdapter SimpleHandlerAdapter HandlerResultHandler 는 기본적으로 아래 4가지를 가지고 있다.\nResponseEntityResultHandler ServerResponseResultHandler ResponseBodyResultHandler ViewResolutionResultHandler RoutePredicateHandlerMapping (AbstractHandlerMapping, HandlerMapping) # DispatcherHandler (WebHandler)\npublic class DispatcherHandler implements WebHandler, PreFlightRequestHandler, ApplicationContextAware { ... @Override public Mono\u0026lt;Void\u0026gt; handle(ServerWebExchange exchange) { if (this.handlerMappings == null) { return createNotFoundError(); } if (CorsUtils.isPreFlightRequest(exchange.getRequest())) { return handlePreFlight(exchange); } return Flux.fromIterable(this.handlerMappings) .concatMap(mapping -\u0026gt; mapping.getHandler(exchange)) // 여기 : AbstractHandlerMapping.getHandler() 로 이어진다. .next() .switchIfEmpty(createNotFoundError()) .flatMap(handler -\u0026gt; invokeHandler(exchange, handler)) .flatMap(result -\u0026gt; handleResult(exchange, result)); } ... } AbstractHandlerMapping\npublic abstract class AbstractHandlerMapping extends ApplicationObjectSupport implements HandlerMapping, Ordered, BeanNameAware { @Override public Mono\u0026lt;Object\u0026gt; getHandler(ServerWebExchange exchange) { return getHandlerInternal(exchange).map(handler -\u0026gt; { // 여기 : RoutePredicateHandlerMapping.getHandlerInternal() 로 이어진다. if (logger.isDebugEnabled()) { logger.debug(exchange.getLogPrefix() + \u0026#34;Mapped to \u0026#34; + handler); } ServerHttpRequest request = exchange.getRequest(); if (hasCorsConfigurationSource(handler) || CorsUtils.isPreFlightRequest(request)) { CorsConfiguration config = (this.corsConfigurationSource != null ? this.corsConfigurationSource.getCorsConfiguration(exchange) : null); CorsConfiguration handlerConfig = getCorsConfiguration(handler, exchange); config = (config != null ? config.combine(handlerConfig) : handlerConfig); if (config != null) { config.validateAllowCredentials(); } if (!this.corsProcessor.process(config, exchange) || CorsUtils.isPreFlightRequest(request)) { return NO_OP_HANDLER; } } return handler; }); } } RoutePredicateHandlerMapping # public class RoutePredicateHandlerMapping extends AbstractHandlerMapping { private final FilteringWebHandler webHandler; private final RouteLocator routeLocator; ... @Override protected Mono\u0026lt;?\u0026gt; getHandlerInternal(ServerWebExchange exchange) { // don\u0026#39;t handle requests on management port if set and different than server port if (this.managementPortType == DIFFERENT \u0026amp;\u0026amp; this.managementPort != null \u0026amp;\u0026amp; exchange.getRequest().getURI().getPort() == this.managementPort) { return Mono.empty(); } exchange.getAttributes().put(GATEWAY_HANDLER_MAPPER_ATTR, getSimpleName()); return lookupRoute(exchange) // .log(\u0026#34;route-predicate-handler-mapping\u0026#34;, Level.FINER) //name this .flatMap((Function\u0026lt;Route, Mono\u0026lt;?\u0026gt;\u0026gt;) r -\u0026gt; { exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Mapping [\u0026#34; + getExchangeDesc(exchange) + \u0026#34;] to \u0026#34; + r); } exchange.getAttributes().put(GATEWAY_ROUTE_ATTR, r); return Mono.just(webHandler); // ← 여기 : FilteringWebHandler 를 반환한다. }).switchIfEmpty(Mono.empty().then(Mono.fromRunnable(() -\u0026gt; { exchange.getAttributes().remove(GATEWAY_PREDICATE_ROUTE_ATTR); if (logger.isTraceEnabled()) { logger.trace(\u0026#34;No RouteDefinition found for [\u0026#34; + getExchangeDesc(exchange) + \u0026#34;]\u0026#34;); } }))); } ... protected Mono\u0026lt;Route\u0026gt; lookupRoute(ServerWebExchange exchange) { return this.routeLocator.getRoutes() // individually filter routes so that filterWhen error delaying is not a // problem .concatMap(route -\u0026gt; Mono.just(route).filterWhen(r -\u0026gt; { // add the current route we are testing exchange.getAttributes().put(GATEWAY_PREDICATE_ROUTE_ATTR, r.getId()); return r.getPredicate().apply(exchange); }) // instead of immediately stopping main flux due to error, log and // swallow it .doOnError(e -\u0026gt; logger.error(\u0026#34;Error applying predicate for route: \u0026#34; + route.getId(), e)) .onErrorResume(e -\u0026gt; Mono.empty())) // .defaultIfEmpty() put a static Route not found // or .switchIfEmpty() // .switchIfEmpty(Mono.\u0026lt;Route\u0026gt;empty().log(\u0026#34;noroute\u0026#34;)) .next() // TODO: error handling .map(route -\u0026gt; { if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Route matched: \u0026#34; + route.getId()); } validateRoute(route, exchange); return route; }); /* * TODO: trace logging if (logger.isTraceEnabled()) { * logger.trace(\u0026#34;RouteDefinition did not match: \u0026#34; + routeDefinition.getId()); } */ } 2022-07-17 20:01:37.968 DEBUG 91322 --- [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : Route matched: 4162e05b-be86-4b3b-a2c7-bfcc4d2c89b4 2022-07-17 20:01:37.968 DEBUG 91322 --- [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : Mapping [Exchange: GET http://localhost:8080/api/samples] to Route{id=\u0026#39;4162e05b-be86-4b3b-a2c7-bfcc4d2c89b4\u0026#39;, uri=http://localhost:8081, order=0, predicate=PredicateSpec$$Lambda$529/0x0000000800510c40, gatewayFilters=[[ModifyResponseBody New content type = [null], In class = Object, Out class = ResponseFormatFilter.Response]], metadata={}} 2022-07-17 20:01:37.968 DEBUG 91322 --- [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : [d9c36f28-2] Mapped to org.springframework.cloud.gateway.handler.FilteringWebHandler@2937f9e0 FilteringWebHandler # public class FilteringWebHandler implements WebHandler { protected static final Log logger = LogFactory.getLog(FilteringWebHandler.class); private final List\u0026lt;GatewayFilter\u0026gt; globalFilters; ... @Override public Mono\u0026lt;Void\u0026gt; handle(ServerWebExchange exchange) { Route route = exchange.getRequiredAttribute(GATEWAY_ROUTE_ATTR); List\u0026lt;GatewayFilter\u0026gt; gatewayFilters = route.getFilters(); List\u0026lt;GatewayFilter\u0026gt; combined = new ArrayList\u0026lt;\u0026gt;(this.globalFilters); combined.addAll(gatewayFilters); // TODO: needed or cached? AnnotationAwareOrderComparator.sort(combined); if (logger.isDebugEnabled()) { logger.debug(\u0026#34;Sorted gatewayFilterFactories: \u0026#34; + combined); } return new DefaultGatewayFilterChain(combined).filter(exchange); // 여기 : Filter Chain 에 넘긴다. } ... } DefaultGatewayFilterChain\npublic class FilteringWebHandler implements WebHandler { ... private static class DefaultGatewayFilterChain implements GatewayFilterChain { private final int index; private final List\u0026lt;GatewayFilter\u0026gt; filters; ... @Override public Mono\u0026lt;Void\u0026gt; filter(ServerWebExchange exchange) { return Mono.defer(() -\u0026gt; { if (this.index \u0026lt; filters.size()) { GatewayFilter filter = filters.get(this.index); DefaultGatewayFilterChain chain = new DefaultGatewayFilterChain(this, this.index + 1); return filter.filter(exchange, chain); // 여기 : 우리가 등록한 filter(혹은 기본적으로 등록된 filter) 들이 동작한다. } else { return Mono.empty(); // complete } }); } } 아래 로그는 FilteringWebHandler 로그이다.\n등록된 Filter 들을 확인할 수 있다.\n2022-07-17 20:01:37.968 DEBUG 91322 --- [ctor-http-nio-2] o.s.c.g.handler.FilteringWebHandler : Sorted gatewayFilterFactories: [[GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.RemoveCachedBodyFilter@5707f613}, order = -2147483648], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.AdaptCachedBodyGlobalFilter@526e8108}, order = -2147482648], [ModifyResponseBody New content type = [null], In class = Object, Out class = ResponseFormatFilter.Response], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyWriteResponseFilter@11787b64}, order = -1], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.ForwardPathFilter@319642db}, order = 0], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.GatewayMetricsFilter@35bfa1bb}, order = 0], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.RouteToRequestUrlFilter@77b3752b}, order = 10000], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.config.GatewayNoLoadBalancerClientAutoConfiguration$NoLoadBalancerClientFilter@6b321262}, order = 10150], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.WebsocketRoutingFilter@59498d94}, order = 2147483646], GatewayFilterAdapter{delegate=com.baemin.openapi.filter.global.SampleCustomGlobalGatewayFilter@713a35c5}, [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyRoutingFilter@62aeddc8}, order = 2147483647], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.ForwardRoutingFilter@6367a688}, order = 2147483647]] 아래는 하나의 Request에 대한 전체 로그이다.\n... [ctor-http-nio-2] reactor.netty.http.server.HttpServer : [d9c36f28-2, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:53838] Handler is being applied: org.springframework.http.server.reactive.ReactorHttpHandlerAdapter@687105a6 ... [ctor-http-nio-2] o.s.w.s.adapter.HttpWebHandlerAdapter : [d9c36f28-2] HTTP GET \u0026#34;/api/samples\u0026#34; ... [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : Route matched: 4162e05b-be86-4b3b-a2c7-bfcc4d2c89b4 ... [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : Mapping [Exchange: GET http://localhost:8080/api/samples] to Route{id=\u0026#39;4162e05b-be86-4b3b-a2c7-bfcc4d2c89b4\u0026#39;, uri=http://localhost:8081, order=0, predicate=PredicateSpec$$Lambda$529/0x0000000800510c40, gatewayFilters=[[ModifyResponseBody New content type = [null], In class = Object, Out class = ResponseFormatFilter.Response]], metadata={}} ... [ctor-http-nio-2] o.s.c.g.h.RoutePredicateHandlerMapping : [d9c36f28-2] Mapped to org.springframework.cloud.gateway.handler.FilteringWebHandler@2937f9e0 ... [ctor-http-nio-2] o.s.c.g.handler.FilteringWebHandler : Sorted gatewayFilterFactories: [[GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.RemoveCachedBodyFilter@5707f613}, order = -2147483648], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.AdaptCachedBodyGlobalFilter@526e8108}, order = -2147482648], [ModifyResponseBody New content type = [null], In class = Object, Out class = ResponseFormatFilter.Response], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyWriteResponseFilter@11787b64}, order = -1], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.ForwardPathFilter@319642db}, order = 0], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.GatewayMetricsFilter@35bfa1bb}, order = 0], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.RouteToRequestUrlFilter@77b3752b}, order = 10000], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.config.GatewayNoLoadBalancerClientAutoConfiguration$NoLoadBalancerClientFilter@6b321262}, order = 10150], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.WebsocketRoutingFilter@59498d94}, order = 2147483646], GatewayFilterAdapter{delegate=com.baemin.openapi.filter.global.SampleCustomGlobalGatewayFilter@713a35c5}, [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.NettyRoutingFilter@62aeddc8}, order = 2147483647], [GatewayFilterAdapter{delegate=org.springframework.cloud.gateway.filter.ForwardRoutingFilter@6367a688}, order = 2147483647]] ... [ctor-http-nio-2] r.n.resources.PooledConnectionProvider : [d27fde7a, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] Channel acquired, now: 1 active connections, 0 inactive connections and 0 pending acquire requests. ... [ctor-http-nio-2] r.netty.http.client.HttpClientConnect : [d27fde7a-2, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] Handler is being applied: {uri=http://localhost:8081/api/samples, method=GET} ... [ctor-http-nio-2] r.n.r.DefaultPooledConnectionProvider : [d27fde7a-2, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/api/samples, connection=PooledConnection{channel=[id: 0xd27fde7a, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081]}}, [request_prepared]) ... [ctor-http-nio-2] reactor.netty.channel.FluxReceive : [d9c36f28-2, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:53838] FluxReceive{pending=0, cancelled=false, inboundDone=false, inboundError=null}: subscribing inbound receiver ... [ctor-http-nio-2] r.n.r.DefaultPooledConnectionProvider : [d27fde7a-2, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/api/samples, connection=PooledConnection{channel=[id: 0xd27fde7a, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081]}}, [request_sent]) ... [ctor-http-nio-2] r.n.http.client.HttpClientOperations : [d27fde7a-2, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] Received response (auto-read:false) : [Content-Type=application/json, Transfer-Encoding=chunked, Date=Sun, 17 Jul 2022 11:01:37 GMT] ... [ctor-http-nio-2] r.n.r.DefaultPooledConnectionProvider : [d27fde7a-2, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/api/samples, connection=PooledConnection{channel=[id: 0xd27fde7a, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081]}}, [response_received]) ... [ctor-http-nio-2] reactor.netty.channel.FluxReceive : [d27fde7a-2, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] FluxReceive{pending=0, cancelled=false, inboundDone=false, inboundError=null}: subscribing inbound receiver ... [ctor-http-nio-2] r.n.http.client.HttpClientOperations : [d27fde7a-2, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] Received last HTTP packet ... [ctor-http-nio-2] o.s.http.codec.json.Jackson2JsonDecoder : Decoded [{timestamp=0, errorCode=, statusCode=200, statusMessage=OK, data=[{name=, age=12}, {name=길동 (truncated)...] ... [ctor-http-nio-2] o.s.http.codec.json.Jackson2JsonEncoder : Encoding [Response(data={timestamp=0, errorCode=, statusCode=200, statusMessage=OK, data=[{name=현재, age= (truncated)...] ... [ctor-http-nio-2] r.n.http.server.HttpServerOperations : [d9c36f28-2, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:53838] Decreasing pending responses, now 0 ... [ctor-http-nio-2] r.n.http.server.HttpServerOperations : [d9c36f28-2, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:53838] Last HTTP packet was sent, terminating the channel ... [ctor-http-nio-2] o.s.w.s.adapter.HttpWebHandlerAdapter : [d9c36f28-2] Completed 200 OK ... [ctor-http-nio-2] r.n.http.server.HttpServerOperations : [d9c36f28-2, L:/0:0:0:0:0:0:0:1:8080 - R:/0:0:0:0:0:0:0:1:53838] Last HTTP response frame ... [ctor-http-nio-2] r.n.r.DefaultPooledConnectionProvider : [d27fde7a, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/api/samples, connection=PooledConnection{channel=[id: 0xd27fde7a, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081]}}, [response_completed]) ... [ctor-http-nio-2] r.n.r.DefaultPooledConnectionProvider : [d27fde7a, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] onStateChange(GET{uri=/api/samples, connection=PooledConnection{channel=[id: 0xd27fde7a, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081]}}, [disconnecting]) ... [ctor-http-nio-2] r.n.r.DefaultPooledConnectionProvider : [d27fde7a, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] Releasing channel ... [ctor-http-nio-2] r.n.resources.PooledConnectionProvider : [d27fde7a, L:/127.0.0.1:53841 - R:localhost/127.0.0.1:8081] Channel cleaned, now: 0 active connections, 1 inactive connections and 0 pending acquire requests. ... [ctor-http-nio-2] r.n.r.DefaultPooledConnectionProvider : [d27fde7a, L:/127.0.0.1:53841 ! R:localhost/127.0.0.1:8081] onStateChange(PooledConnection{channel=[id: 0xd27fde7a, L:/127.0.0.1:53841 ! R:localhost/127.0.0.1:8081]}, [disconnecting]) 참고 (L, R, -, !) # L : Local Address R : Remote Address - : active (active and so connected) ! : not active AbstractChannel 에서 확인할 수 있다.\npublic abstract class AbstractChannel extends DefaultAttributeMap implements Channel { ... @Override public String toString() { boolean active = isActive(); if (strValActive == active \u0026amp;\u0026amp; strVal != null) { return strVal; } SocketAddress remoteAddr = remoteAddress(); SocketAddress localAddr = localAddress(); if (remoteAddr != null) { StringBuilder buf = new StringBuilder(96) .append(\u0026#34;[id: 0x\u0026#34;) .append(id.asShortText()) .append(\u0026#34;, L:\u0026#34;) .append(localAddr) .append(active? \u0026#34; - \u0026#34; : \u0026#34; ! \u0026#34;) .append(\u0026#34;R:\u0026#34;) .append(remoteAddr) .append(\u0026#39;]\u0026#39;); strVal = buf.toString(); } else if (localAddr != null) { StringBuilder buf = new StringBuilder(64) .append(\u0026#34;[id: 0x\u0026#34;) .append(id.asShortText()) .append(\u0026#34;, L:\u0026#34;) .append(localAddr) .append(\u0026#39;]\u0026#39;); strVal = buf.toString(); } else { StringBuilder buf = new StringBuilder(16) .append(\u0026#34;[id: 0x\u0026#34;) .append(id.asShortText()) .append(\u0026#39;]\u0026#39;); strVal = buf.toString(); } strValActive = active; return strVal; } ... } "},{"id":214,"href":"/docs/SPRING/SPRING-Spring-Cloud-Gateway-4-Error-Handling/","title":"[SPRING] Spring Cloud Gateway - 4 (Error Handling)","section":"SPRING","content":"Gateway 에서 에러 발생 시, 핸들링할 수 있는 WebExceptionHandler를 구현합니다.\n구현 내용 # ErrorWebExceptionHandler 인터페이스 구현 → GlobalErrorWebExceptionHandler ErrorAttributes 인터페이스 구현 → GlobalErrorAttributes 흐름 # ExceptionHandlingWebHandler 가 FilteringWebHandler 에 Request 처리를 위임하는 방식 (참고 : WebHttpHandlerBuilder.build()) 연관 클래스 # 클래스 설명 / 역할 ExceptionHandlingWebHandler WebExceptionHandler List 포함 exceptionHandler 에러를 핸들링한다. WebExceptionHandler Contract for handling exceptions during web server exchange processing. GlobalErrorWebExceptionHandler 이 해당 WebHandler 에서 Exception 발생 시, WebExceptionHandler(GlobalErrorWebExceptionHandler) 가 처리 ErrorAttributes Provides access to error attributes which can be logged or presented to the user. 반환할, 로깅할 Error Attributes 를 제공하는 클래스 GlobalErrorAttributes 이 해당 예시 - ExceptionHandlingWebHandler.handle()\npublic Mono\u0026lt;Void\u0026gt; handle(ServerWebExchange exchange) { Mono\u0026lt;Void\u0026gt; completion; try { completion = super.handle(exchange); } catch (Throwable ex) { completion = Mono.error(ex); } for (WebExceptionHandler handler : this.exceptionHandlers) { completion = completion.onErrorResume(ex -\u0026gt; handler.handle(exchange, ex)); } return completion; } 예시 - 기본 구현체 (DefaultErrorAttributes) 는 아래 에러 컨텐츠를 반환\n{ \u0026#34;timestamp\u0026#34;: \u0026#34;2022-08-10T08:11:13.608+00:00\u0026#34;, \u0026#34;path\u0026#34;: \u0026#34;/api2/2xx\u0026#34;, \u0026#34;status\u0026#34;: 404, \u0026#34;error\u0026#34;: \u0026#34;Not Found\u0026#34;, \u0026#34;message\u0026#34;: null, \u0026#34;requestId\u0026#34;: \u0026#34;5c49ed8a-1\u0026#34; } 참고 # https://docs.spring.io/spring-framework/docs/5.1.6.RELEASE/spring-framework-reference/web-reactive.html#webflux-exception-handler https://docs.spring.io/spring-boot/docs/2.1.4.RELEASE/reference/htmlsingle/#boot-features-webflux-error-handling "},{"id":215,"href":"/docs/SPRING/SPRING-Spring-Cloud-Gateway-5-RouteLocator/","title":"[SPRING] Spring Cloud Gateway - 5 (RouteLocator)","section":"SPRING","content":" "},{"id":216,"href":"/docs/SPRING/SPRING-Spring-MVC-Error/","title":"[SPRING] Spring MVC - Error","section":"SPRING","content":" Spring MVC : Error # 핵심 클래스 / 인터페이스 # class (interface) 설명 ErrorMvcAutoConfiguration (MVC) Error Controller 관련 Auto-configuration 클래스 ErrorController Error Controller 인터페이스 하위 : AbstractErrorController, BasicErrorController BasicErrorController Error Controller 구현 클래스 Spring Web(MVC)에서 Default 로 사용되는 구현체 (with DefaultErrorViewResolver) ErrorProperties (위에서 사용되는) Error property 클래스 Path, WhiteLabel, \u0026hellip; ErrorMvcAutoConfiguration # // Load before the main WebMvcAutoConfiguration so that the error View is available @AutoConfiguration(before = WebMvcAutoConfiguration.class) @ConditionalOnWebApplication(type = Type.SERVLET) @ConditionalOnClass({ Servlet.class, DispatcherServlet.class }) @EnableConfigurationProperties({ ServerProperties.class, WebMvcProperties.class }) public class ErrorMvcAutoConfiguration { private final ServerProperties serverProperties; @Bean @ConditionalOnMissingBean(value = ErrorAttributes.class, search = SearchStrategy.CURRENT) public DefaultErrorAttributes errorAttributes() { return new DefaultErrorAttributes(); } @Bean @ConditionalOnMissingBean(value = ErrorController.class, search = SearchStrategy.CURRENT) public BasicErrorController basicErrorController(ErrorAttributes errorAttributes, ObjectProvider\u0026lt;ErrorViewResolver\u0026gt; errorViewResolvers) { return new BasicErrorController(errorAttributes, this.serverProperties.getError(), errorViewResolvers.orderedStream().collect(Collectors.toList())); } ... static class ErrorPageCustomizer implements ErrorPageRegistrar, Ordered { private final ServerProperties properties; private final DispatcherServletPath dispatcherServletPath; ... @Override public void registerErrorPages(ErrorPageRegistry errorPageRegistry) { ErrorPage errorPage = new ErrorPage( this.dispatcherServletPath.getRelativePath(this.properties.getError().getPath())); errorPageRegistry.addErrorPages(errorPage); // ErrorPageRegistry errorPageRegistry =\u0026gt; TomcatServletWebServerFactory (AbstractConfigurableWebServerFactory) } ... } ErrorPageCustomizer.registerErrorPages(...) /error 경로에 대한 ErrorPage 가 생성된다. 생성된 ErrorPage 는 errorPageRegistry 에 등록된다. TomcatServletWebServerFactory.configureContext(...) TomcatEmbeddedContext의 ErrorPageSupport에 org.apache.tomcat.util.descriptor.web.ErrorPage가 등록된다. 이후에 에러가 발생했을 때, ErrorReportValve \u0026gt; StandardHostValve.invoke(...) \u0026gt; StandardHostValve.status(...) \u0026gt; TomcatEmbeddedContext.findErrorPage(...) 순서로 ErrorPage 를 찾게 된다. (찾은 ErrorPage로 request를 forwarding) (ApplicationDispatcher, RequestDispatcher) rd.forward(request.getRequest(), response.getResponse()); (아래 코드 참고) public class TomcatServletWebServerFactory extends AbstractServletWebServerFactory implements ConfigurableTomcatWebServerFactory, ResourceLoaderAware { ... protected void configureContext(Context context, ServletContextInitializer[] initializers) { TomcatStarter starter = new TomcatStarter(initializers); if (context instanceof TomcatEmbeddedContext) { TomcatEmbeddedContext embeddedContext = (TomcatEmbeddedContext) context; embeddedContext.setStarter(starter); embeddedContext.setFailCtxIfServletStartFails(true); } context.addServletContainerInitializer(starter, NO_CLASSES); for (LifecycleListener lifecycleListener : this.contextLifecycleListeners) { context.addLifecycleListener(lifecycleListener); } for (Valve valve : this.contextValves) { context.getPipeline().addValve(valve); } for (ErrorPage errorPage : getErrorPages()) { org.apache.tomcat.util.descriptor.web.ErrorPage tomcatErrorPage = new org.apache.tomcat.util.descriptor.web.ErrorPage(); tomcatErrorPage.setLocation(errorPage.getPath()); tomcatErrorPage.setErrorCode(errorPage.getStatusCode()); tomcatErrorPage.setExceptionType(errorPage.getExceptionName()); context.addErrorPage(tomcatErrorPage); } ... /** * Valve that implements the default basic behavior for the * \u0026lt;code\u0026gt;StandardHost\u0026lt;/code\u0026gt; container implementation. * \u0026lt;p\u0026gt; * \u0026lt;b\u0026gt;USAGE CONSTRAINT\u0026lt;/b\u0026gt;: This implementation is likely to be useful only * when processing HTTP requests. * * @author Craig R. McClanahan * @author Remy Maucherat */ final class StandardHostValve extends ValveBase { ... /** * Select the appropriate child Context to process this request, * based on the specified request URI. If no matching Context can * be found, return an appropriate HTTP error. * * @param request Request to be processed * @param response Response to be produced * * @exception IOException if an input/output error occurred * @exception ServletException if a servlet error occurred */ @Override public final void invoke(Request request, Response response) throws IOException, ServletException { ... try { ... // Look for (and render if found) an application level error page if (response.isErrorReportRequired()) { // If an error has occurred that prevents further I/O, don\u0026#39;t waste time // producing an error report that will never be read AtomicBoolean result = new AtomicBoolean(false); response.getCoyoteResponse().action(ActionCode.IS_IO_ALLOWED, result); if (result.get()) { if (t != null) { throwable(request, response, t); } else { status(request, response); } } } ... } ... } private void status(Request request, Response response) { int statusCode = response.getStatus(); // Handle a custom error page for this status code Context context = request.getContext(); if (context == null) { return; } /* Only look for error pages when isError() is set. * isError() is set when response.sendError() is invoked. This * allows custom error pages without relying on default from * web.xml. */ if (!response.isError()) { return; } ErrorPage errorPage = context.findErrorPage(statusCode); if (errorPage == null) { // Look for a default error page errorPage = context.findErrorPage(0); // \u0026lt;-- 여기! } ... } ... } ErrorController # /** * Marker interface used to identify a {@link Controller @Controller} that should be used to render errors. */ public interface ErrorController { } BasicErrorController # /** * Basic global error @Controller, rendering ErrorAttributes. * More specific errors can be handled either using Spring MVC abstractions (e.g. @ExceptionHandler) or by adding servlet server error pages. */ @Controller @RequestMapping(\u0026#34;${server.error.path:${error.path:/error}}\u0026#34;) public class BasicErrorController extends AbstractErrorController { private final ErrorProperties errorProperties; ... @RequestMapping(produces = MediaType.TEXT_HTML_VALUE) public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) { HttpStatus status = getStatus(request); Map\u0026lt;String, Object\u0026gt; model = Collections .unmodifiableMap(getErrorAttributes(request, getErrorAttributeOptions(request, MediaType.TEXT_HTML))); response.setStatus(status.value()); ModelAndView modelAndView = resolveErrorView(request, response, status, model); return (modelAndView != null) ? modelAndView : new ModelAndView(\u0026#34;error\u0026#34;, model); } ... Spring 예외 처리 흐름 # 출처 : [Spring] Spring의 다양한 예외 처리 방법(ExceptionHandler, ControllerAdvice 등) 완벽하게 이해하기 - (1/2)\nWebMvcConfigurationSupport 클래스를 참고하면, 아래 순서로 register 되는 것을 알 수 있다. (addDefaultHandlerExceptionResolvers())\nExceptionHandlerExceptionResolver ResponseStatusExceptionResolver DefaultHandlerExceptionResolver /** * Registers a HandlerExceptionResolverComposite with this chain of exception resolvers: * * - ExceptionHandlerExceptionResolver for handling exceptions through org.springframework.web.bind.annotation.ExceptionHandler methods. * - ResponseStatusExceptionResolver for exceptions annotated with org.springframework.web.bind.annotation.ResponseStatus. * - DefaultHandlerExceptionResolver for resolving known Spring exception types */ public class WebMvcConfigurationSupport implements ApplicationContextAware, ServletContextAware { ... protected final void addDefaultHandlerExceptionResolvers(List\u0026lt;HandlerExceptionResolver\u0026gt; exceptionResolvers, ContentNegotiationManager mvcContentNegotiationManager) { ExceptionHandlerExceptionResolver exceptionHandlerResolver = createExceptionHandlerExceptionResolver(); exceptionHandlerResolver.setContentNegotiationManager(mvcContentNegotiationManager); exceptionHandlerResolver.setMessageConverters(getMessageConverters()); exceptionHandlerResolver.setCustomArgumentResolvers(getArgumentResolvers()); exceptionHandlerResolver.setCustomReturnValueHandlers(getReturnValueHandlers()); if (jackson2Present) { exceptionHandlerResolver.setResponseBodyAdvice( Collections.singletonList(new JsonViewResponseBodyAdvice())); } if (this.applicationContext != null) { exceptionHandlerResolver.setApplicationContext(this.applicationContext); } exceptionHandlerResolver.afterPropertiesSet(); exceptionResolvers.add(exceptionHandlerResolver); ResponseStatusExceptionResolver responseStatusResolver = new ResponseStatusExceptionResolver(); responseStatusResolver.setMessageSource(this.applicationContext); exceptionResolvers.add(responseStatusResolver); exceptionResolvers.add(new DefaultHandlerExceptionResolver()); } 이 클래스(주석 내용)는 중요하다. 별도로 살펴보자.\n"},{"id":217,"href":"/docs/SPRING/SPRING-Spring-Security-1/","title":"[SPRING] Spring Security (1)","section":"SPRING","content":" Overview # A Review Of Filters # DelegatingFilterProxy # package org.springframework.web.filter;\n서블릿 컨테이너(Servet Conatiner) \u0026lt;-\u0026gt; 스프링 애플리케이션컨텍스트(ApplicationContext) 사이를 연결시켜주는(bridge) 역할을 한다.\nWebApplicationContext 에서 위임할 Filter(Bean)을 찾고, 해당 Filter 의 doFilter() 메서드를 호출한다. \u0026lsquo;서블릿 컨테이너\u0026rsquo; 는 \u0026lsquo;스프링에 등록된 Bean\u0026rsquo; 들을 사용(인식)하지 않는다. 따라서, (서블릿 컨테이너 표준에 맞게 등록된) DelegatingFilterProxy가 스프링에 등록된 Bean(단, Fiter 구현체)에 위임한다. \u0026ldquo;(Servlet)Filter vs Bean Filter\u0026rdquo; 의 차이에 대해 이해할 것\npublic class DelegatingFilterProxy extends GenericFilterBean { ... // [NOTE] WebApplicationContext 를 가지고 있다. private WebApplicationContext webApplicationContext; ... @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException { // Lazily initialize the delegate if necessary. Filter delegateToUse = this.delegate; if (delegateToUse == null) { synchronized (this.delegateMonitor) { delegateToUse = this.delegate; if (delegateToUse == null) { WebApplicationContext wac = findWebApplicationContext(); if (wac == null) { throw new IllegalStateException(\u0026#34;No WebApplicationContext found: \u0026#34; + \u0026#34;no ContextLoaderListener or DispatcherServlet registered?\u0026#34;); } delegateToUse = initDelegate(wac); // [NOTE] WebApplicationContext 로 부터 위임할 Filter 를 가져온다(찾는다). } this.delegate = delegateToUse; } } // Let the delegate perform the actual doFilter operation. invokeDelegate(delegateToUse, request, response, filterChain); // [NOTE] work를 위임한다. } ... protected void invokeDelegate(Filter delegate, ServletRequest request, ServletResponse response, FilterChain filterChain) throws ServletException, IOException { delegate.doFilter(request, response, filterChain); } } FilterChainProxy # package org.springframework.security.web;\nSpring Security’s Servlet support is contained within FilterChainProxy\nFilterChainProxy is a special Filter provided by Spring Security that allows delegating to many Filter instances through SecurityFilterChain\nFilterChainProxy는 Spring Security를 지원하기 위해 사용된다.\nFilterChainProxy가 SecurityFilterChain의 다양한 Filter에 (work를)위임한다.\n출처 : https://docs.spring.io/spring-security/reference/servlet/architecture.html\nSecurityFilterChain # package org.springframework.security.web;\nSecurityFilterChain is used by FilterChainProxy to determine which Spring Security Filters should be invoked for this request.\n// FilterChainProxy.java private List\u0026lt;Filter\u0026gt; getFilters(HttpServletRequest request) { for (SecurityFilterChain chain : filterChains) { if (chain.matches(request)) { return chain.getFilters(); } } return null; } ... private void doFilterInternal(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException { FirewalledRequest fwRequest = firewall.getFirewalledRequest((HttpServletRequest) request); HttpServletResponse fwResponse = firewall.getFirewalledResponse((HttpServletResponse) response); List\u0026lt;Filter\u0026gt; filters = getFilters(fwRequest); if (filters == null || filters.size() == 0) { ... fwRequest.reset(); chain.doFilter(fwRequest, fwResponse); return; } VirtualFilterChain vfc = new VirtualFilterChain(fwRequest, chain, filters); vfc.doFilter(fwRequest, fwResponse); } (In SecurityFilterChain)Security Filter 들은 (DelegatingFilterProxy가 아닌)FilterChainProxy에 관리된다.\n이를 통해 얻는 이점은 다음과 같은 것들이 있다.\nSpring Security 관련 디버깅 시, FilterChainProxy를 starting point 로 사용할 수 있다. Spring Security 관련된 로직을 추가하고 싶다면, FilterChainProxy에 추가하면 된다. (무조건 실행되는, 핵심적인 부분이기 때문에) 추가적인 특징으로는 다음과 같은 것들이 있다.\nSecurityFilterChain 은 Security Filter 를 0~n 개 가질 수 있다. 또, 독립적인 여러 개의 SecurityFilterChain을 구성할 수 있다. Security Filters # Security Filter 의 종류는 대표적으로 다음과 같은 것들이 있다.\nUsernamePasswordAuthenticationFilter BasicAuthenticationFilter \u0026hellip; ExceptionTranslationFilter FilterSecurityInterceptor \u0026hellip; Handling Security Exceptions # ExceptionTranslationFilter는 AccessDeniedException / AuthenticationException 을 HTTP Response 로 변환한다.\ntry { filterChain.doFilter(request, response); } catch (AccessDeniedException | AuthenticationException ex) { if (!authenticated || ex instanceof AuthenticationException) { startAuthentication(); } else { accessDenied(); } } protected void sendStartAuthentication(HttpServletRequest request, HttpServletResponse response, FilterChain chain, AuthenticationException reason) throws ServletException, IOException { // SEC-112: Clear the SecurityContextHolder\u0026#39;s Authentication, as the // existing Authentication is no longer considered valid SecurityContextHolder.getContext().setAuthentication(null); requestCache.saveRequest(request, response); logger.debug(\u0026#34;Calling Authentication entry point.\u0026#34;); authenticationEntryPoint.commence(request, response, reason); } private void handleSpringSecurityException(HttpServletRequest request, HttpServletResponse response, FilterChain chain, RuntimeException exception) throws IOException, ServletException { if (exception instanceof AuthenticationException) { logger.debug(\u0026#34;Authentication exception occurred; redirecting to authentication entry point\u0026#34;, exception); sendStartAuthentication(request, response, chain, (AuthenticationException) exception); } else if (exception instanceof AccessDeniedException) { Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authenticationTrustResolver.isAnonymous(authentication) || authenticationTrustResolver.isRememberMe(authentication)) { logger.debug(\u0026#34;Access is denied (user is \u0026#34; + (authenticationTrustResolver.isAnonymous(authentication) ? \u0026#34;anonymous\u0026#34; : \u0026#34;not fully uthenticated\u0026#34;) + \u0026#34;); redirecting to authentication entry point\u0026#34;, exception); sendStartAuthentication( request, response, chain, new InsufficientAuthenticationException(messages.getMessage(\u0026#34;ExceptionTranslationFilter.insufficientAuthentication\u0026#34;, \u0026#34;Full authentication is required to access this resource\u0026#34;)) ); } else { logger.debug(\u0026#34;Access is denied (user is not anonymous); delegating to AccessDeniedHandler\u0026#34;, exception); accessDeniedHandler.handle(request, response, (AccessDeniedException) exception); } } } If the application does not throw an AccessDeniedException or an AuthenticationException, then ExceptionTranslationFilter does not do anything.\n위 코드를 보면, 아래와 같이 호출되는 것을 알 수 있다.\nAuthenticationException -\u0026gt; authenticationEntryPoint.commence() AccessDeniedException -\u0026gt; accessDeniedHandler.handle() 그렇기에 AuthenticationEntryPoint, AccessDeniedHandler 를 재정의(상속)하여 커스텀하게 핸들링할 수 있다.\n(error response, redirect to entry point 등)\n... http.exceptionHandling().accessDeniedHandler(new GPAccessDeniedHandler()); http.exceptionHandling().authenticationEntryPoint(new GPAuthenticationEntryPoint()); ... 참고 # https://docs.spring.io/spring-security/reference/servlet/architecture.html https://mangkyu.tistory.com/76 "},{"id":218,"href":"/docs/SPRING/SPRING-Spring-Security-2/","title":"[SPRING] Spring Security (2)","section":"SPRING","content":" Servlet Authentication Architecture # 클래스 설명 SecurityContextHolder Where Spring Security stores the details of who is authenticated SecurityContext It is contained in SecurityContextHolder\nIt contains the Authentication of the currently authenticated user AuthenticationManager \u0026lsquo;인증\u0026rsquo;을 처리하기 위한 인터페이스\nAuthentication authenticate(Authentication authentication) throws AuthenticationException; ProviderManager AuthenticationManager 구현 클래스 AuthenticationProvider (실질적인) \u0026lsquo;인증\u0026rsquo; 을 처리하는 인터페이스\ne.g. AbstractUserDetailsAuthenticationProvider : ID, Password 인증\n(ID, Password 인증은 추상메서드로 되어 있기에, 사용자가 구현) GrantedAuthority (인증 시) 부여된 권한 AbstractAuthenticationProcessingFilter A base Filter used for authentication\nSecurityContextHolder # (Default) ThreadLocal 기반으로 SecurityContext 를 가지고 있다.\nFilterChainProxy 가 Cleared SecurityContext 를 보장한다. SecurityContextHolder.clearContext() 전략\nMODE_GLOBAL MODE_INHERITABLETHREADLOCAL MODE_THREADLOCAL if (strategyName.equals(MODE_THREADLOCAL)) { strategy = new ThreadLocalSecurityContextHolderStrategy(); // private static final ThreadLocal\u0026lt;SecurityContext\u0026gt; contextHolder = new ThreadLocal\u0026lt;\u0026gt;(); } else if (strategyName.equals(MODE_INHERITABLETHREADLOCAL)) { strategy = new InheritableThreadLocalSecurityContextHolderStrategy(); // private static final ThreadLocal\u0026lt;SecurityContext\u0026gt; contextHolder = new InheritableThreadLocal\u0026lt;\u0026gt;(); } else if (strategyName.equals(MODE_GLOBAL)) { strategy = new GlobalSecurityContextHolderStrategy(); // private static SecurityContext contextHolder; } SecurityContext # Authentication 객체를 포함한다.\nAuthentication # 구성 요소\nprincipal : 인증 주체 ID credentials : 인증 증명을 위한 credentials (대부분) 인증 후에 credential 정보는 지울 수 있도록 한다. e.g. password authorities : 인증 주체 권한 GrantAuthority 상속한 클래스 e.g. roles, scopes 등 1. 인증하기 위한 객체로 사용될 때\nisAuthenticated() : false 2. 인증된 객체로 사용될 때\nisAuthenticated() : true SecurityContext 로 부터 획득 가능 AuthenticationManager # 인증 처리 위한 API (인터페이스)\nProviderManager # AuthenticationManager 의 구현체\nAuthenticationProvider(s) 에게 인증 위임한다.\npublic class ProviderManager implements AuthenticationManager, MessageSourceAware, InitializingBean { ... private List\u0026lt;AuthenticationProvider\u0026gt; providers = Collections.emptyList(); ... private AuthenticationManager parent; (인증을 처리할 수 있는)AuthenticationProvider 가 없는 경우, ProviderNotFoundException (AuthenticationException 의 하위 클래스) public class ProviderNotFoundException extends AuthenticationException { ... } AuthenticationProvider # 실질적인 인증(authentication)을 수행한다.\n참고 # https://docs.spring.io/spring-security/reference/servlet/authentication/architecture.html "},{"id":219,"href":"/docs/SPRING/SPRING-SpringBoot-JPA-Spring-Data-Jpa-Hibernate/","title":"[SPRING] SpringBoot JPA, Spring Data Jpa, Hibernate","section":"SPRING","content":" jpa vs hibernate vs spring data jpa 글을 읽고 이해한 내용 정리해보기\nJPA (Java Persisetence API) # JPA 는 인터페이스(명세)이다. 간단하게 \u0026ldquo;관계형 데이터베이스 사용을 위한 인터페이스\u0026rdquo; 이다.\nEntityManager 가 바로 JPA 인터페이스의 실물(구현체)이다.\nEntityManager 를 살펴보면 관계형 데이터베이스 사용을 위한 기능들이 정의되어 있음을 알 수 있다.\npublic interface EntityManager { /** * Make an instance managed and persistent. * ... */ public void persist(Object entity); /** * Merge the state of the given entity into the * current persistence context. * ... */ public \u0026lt;T\u0026gt; T merge(T entity); ... JPA 의 구현체 # JPA는 인터페이스라고 했다. 인터페이스이니까 분명 구현체가 존재할 것이다. 그 구현체는 어떤 클래스일까.\n그것이 바로 Hibernate 이다. 조금 더 구체적으로는 Hibernate 의 Session(SessionImpl) 클래스가 EntityManager 를 구현하고 있다.\n클래스의 이름이 Session 이어서 이게 맞나 싶었는데, 블로그 글에서 정확한 그림이 있었다.\n참고로 Hibernate 가 아닌 다른 구현체를 사용할 수도 있다. 블로그 글에서는 DataNucleus, EclipseLink 와 같은 구현체들이 있다고 한다.\n(Hibernate)Session(SessionImpl) ---\u0026gt; EntityManager (Hibernate)SessionFactory(SessionFactoryImpl) ---\u0026gt; EntityManagerFactory (Hibernate)Transaction(TransactionImpl) ---\u0026gt; EntityTransaction Spring Data JPA # Spring Data JPA는 JPA를 사용하기 쉽게 만들어 놓은 모듈이라고 한다. 즉, 한단계 더 추상화시켜 개발자가 사용하기 쉽게 만들어놓은 것이다. 우리가 JPA 를 직접적으로 사용했다면 아래와 같이 EntityManager 를 직접적으로 사용했을 것이다.\n@Autowired EntityManager em; ... public void test() { Entity entity = new Entity(...); em.persist(entity); ... } 그러나 대부분의 경우에 EntityManager 를 직접적으로 사용하지는 않았을 것이다. 대신 Repository 라는 것을 사용하고 있다.\n@Autowired EntityRepository repo; ... public void test() { Entity entity = new Entity(...); repo.save(entity); ... } \u0026quot; 사용자가 Repository 인터페이스에 정해진 규칙대로 메소드를 입력하면, Spring이 알아서 해당 메소드 이름에 적합한 쿼리를 날리는 구현체를 만들어서 Bean으로 등록해준다. \u0026quot;\n즉, 우리가 Repository 를 규칙에 맞게 작성하면 Spring은 이 Repository 인터페이스의 구현체를 만들어주고 Bean 으로 등록해준다는 것이다. 또 이 구현체에서는 JPA(EntityManager)를 사용할 것이다.\n[Application] ↕ [Spring Data JPA] JPA Hibernate(DataNucleus, EclipseLink, ...) JDBC ↕ [Database] "},{"id":220,"href":"/docs/SPRING/SPRING-SpringBoot-Multiple-DB-%EC%97%B0%EB%8F%99/","title":"[SPRING] SpringBoot Multiple DB 연동","section":"SPRING","content":" SpringBoot 에서 여러 개의 DB 연동해보기\n개요 # 회사에서 새로운 프로젝트를 SpringBoot 환경으로 진행하게 되었다. 기존의 대부분의 프로젝트는 PHP 진영의 CodeIgniter(이하 CI) 라는 프레임워크가 사용되어왔다. SpringBoot로 컨버팅하는 작업도 일부 포함되어 있었기에, 이것저것 알아봐야하는 것들이 많았다.\n그 중에 가장 처음 직면한 문제는 DB 연동 문제였다. 우리 팀은 기본적으로 Oracle DB를 베이스로 하는데, 몇몇 프로젝트에서는 Mysql 을 사용한 프로젝트도 있었다. 문제는 이번에 작업해야 할 프로젝트가 Oracle, Mysql DB를 둘 다 연동/사용해야 했다.\n여러 개의 DB 를 연결하기 위해 찾아본 내용을 정리해보고자 한다.\n설정 # 여러 개의 DB 연결 시, 참고해야 할 것은 다음과 같다.\n1. Java 코드(클래스)로 설정해준다.\n단일 DB 연동시에는 application.yml, application.properties 의 설정을 통해 자동으로 연결해왔다면, 여러 개의 DB 연동시에는 수동으로 설정해줘야하는 부분이 있다. 예를 들어, 아래와 같은 것들을 설정해주어야 한다.\nTarget package 설정, Entity 설정 DB(Datasource) 설정 Hibernate 설정 등 2. (어떤 DB를 적용할지는) Package 를 통해 구분한다.\n여러 개의 DB를 연동한다는 것은, Repository 마다 연결되어야 할 DB가 다름을 의미할 것이다. 이때 Repository 가 어떤 DB에 연동되어야 할지 결정해줘야 한다. 이것을 Package 경로를 통해 지정해준다. (1번에서 언급된 Target Package, Entity 설정)\napplication.yml 예시\n// 단일 DB 연동 시, 아래와 같은 형태로 쉽게 연결할 수 있다. spring: datasource: url: DB\u0026#39;s URL username: DB\u0026#39;s username password: DB\u0026#39;s password driver-class-name: com.mysql.cj.jdbc.Driver jpa: properties: hibernate: ~~~ database: mysql database-platform: org.hibernate.dialect.MySQL5InnoDBDialect // 여러 개의 DB 연동 시, Java 코드로 설정할 것이기에 spring.datasource 를 통한 설정/연결을 사용하지 않는다고 보면 된다. datasource: mysql: jdbc-url: ... username: ... password: ... database: mysql database-platform: org.hibernate.dialect.MySQL5InnoDBDialect driver-class-name: com.mysql.cj.jdbc.Driver ... oracle: jdbc-url: ... username: ... password: ... database: oracle database-platform: org.hibernate.dialect.Oracle10gDialect driver-class-name: oracle.jdbc.driver.OracleDriver ... Java Configuration 설정 # @RequiredArgsConstructor @EnableJpaRepositories( entityManagerFactoryRef = \u0026#34;firstEntityManager\u0026#34;, transactionManagerRef = \u0026#34;firstTransactionManager\u0026#34;, basePackages = {\u0026#34;com.demo.project.repository.first\u0026#34;} ) @ConfigurationProperties(prefix = \u0026#34;datasource.oracle\u0026#34;) @PropertySource({\u0026#34;classpath:application.yml\u0026#34;}) @Configuration public class FirstJpaConfiguration extends HikariConfig { private final Environment env; private String[] packagesToScan = {\u0026#34;com.demo.project.entity.first\u0026#34;}; ... @Bean public DataSource firstDataSource() { return new LazyConnectionDataSourceProxy(new HikariDataSource(this)); } @Bean public LocalContainerEntityManagerFactoryBean firstEntityManager() { LocalContainerEntityManagerFactoryBean entityManagerFactoryBean = new LocalContainerEntityManagerFactoryBean(); entityManagerFactoryBean.setDataSource(firstDataSource()); entityManagerFactoryBean.setPackagesToScan(packagesToScan); entityManagerFactoryBean.setJpaVendorAdapter(new HibernateJpaVendorAdapter()); entityManagerFactoryBean.setJpaPropertyMap(new HashMap\u0026lt;\u0026gt;() {{ put(\u0026#34;hibernate.dialect\u0026#34;, env.getProperty(dialect)); ... }}); return entityManagerFactoryBean; } @Bean public PlatformTransactionManager firstTransactionManager() { JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory(firstEntityManager().getObject()); return transactionManager; } } 위의 내용을 한줄한줄 살펴보면,\n... @Bean public DataSource firstDataSource() { return new LazyConnectionDataSourceProxy(new HikariDataSource(this)); } 첫 번째로는 연결할 DB(DataSource) Bean 을 생성/설정한다.\n... @Bean public LocalContainerEntityManagerFactoryBean firstEntityManager() { LocalContainerEntityManagerFactoryBean entityManagerFactoryBean = new LocalContainerEntityManagerFactoryBean(); entityManagerFactoryBean.setDataSource(firstDataSource()); entityManagerFactoryBean.setPackagesToScan(packagesToScan); entityManagerFactoryBean.setJpaVendorAdapter(new HibernateJpaVendorAdapter()); entityManagerFactoryBean.setJpaPropertyMap(new HashMap\u0026lt;\u0026gt;() {{ put(\u0026#34;hibernate.dialect\u0026#34;, env.getProperty(dialect)); ... }}); return entityManagerFactoryBean; } 두 번째로는 JPA 관련 설정(EntityManager)을 해준다. DB(DataSource), PacagesToScan, JpaVendor(Hibernate), 이 외 JPA 관련 설정 등을 설정해준다.\n... @Bean public PlatformTransactionManager firstTransactionManager() { JpaTransactionManager transactionManager = new JpaTransactionManager(); transactionManager.setEntityManagerFactory(firstEntityManager().getObject()); return transactionManager; } 세 번째로는 TransactionManager 를 설정해준다. TransactionManager 는 트랜잭션 관리를 위한 객체라고 보면된다.\n즉, 이 객체가 설정되어야 정상적으로 트랜잭션이 관리된다. (@Transactional 이라는 어노테이션을 많이 사용하는데, 이 어노테이션이 적용되어 있는 부분에 대해서 TransactionManager 가 관리해주고 있는 것이다.)\n원래 Spring의 기본 TransactionManager는 DataSourceTransactionManager(구현체)를 사용한다고 한다. 우리는 JPA를 사용할 것이기 때문에 JpaTransactionManager(구현체)를 사용한다.\n요약 # DB 별 DataSource Bean을 생성/설정한다. DB 별 JPA(EntityManager, LocalContainerEntityManagerFactoryBean)을 설정한다.\n이때 1번에서 생성한 DataSource Bean 을 주입해준다. DB 별 TransactionManager(PlatformTransactionManager)을 설정한다.\n이때 2번에서 생성한 EntityManager Bean 을 주입해준다. 해당 EntityManager의 트랜잭션을 관리하겠다는 의미이다. 참고 # JPA 다중 데이터소스 관리 What transaction manager to use? (JPA, Spring) "},{"id":221,"href":"/docs/SPRING/SPRING-SpringBoot-N+1/","title":"[SPRING] SpringBoot N+1","section":"SPRING","content":" N+1 문제 # (쿼리를 통해 데이터를 가져올때) (연관관계에 있는)데이터를 얻기 위해 추가적인 쿼리가 발생하는 문제\n예시 : 단건 조회 # @Getter @Builder @AllArgsConstructor @NoArgsConstructor(access = AccessLevel.PROTECTED) @Entity public class Orders { @GeneratedValue(strategy = GenerationType.IDENTITY) @Id private Long id; @Column private String name; @ManyToOne(fetch = FetchType.EAGER) @JoinColumn(name = \u0026#34;customer_id\u0026#34;) private Customer customer; @OneToMany(fetch = FetchType.EAGER, mappedBy = \u0026#34;orders\u0026#34;) private List\u0026lt;OrderItem\u0026gt; orderItems; } EAGER 방식\nleft join , inner join 으로 한번에 가져온다. * optional = false/true 에 따라 left, inner join 결정\nselect orders.id orders.customer_id orders.name customer.id customer.name order_item.order_id order_item.id order_item.id order_item.name order_item.order_id from orders left outer join customer on orders.customer_id = customer.id left outer join order_item on orders.id = order_item.order_id where orders.id = ? LAZY 방식\nselect orders.id, orders.customer_id, orders.name from orders where orders.id = ? 사용자 정의 메서드 단건 조회 # Optional\u0026lt;Orders\u0026gt; findByName(String name); EAGER 방식\nselect orders.id, orders.customer_id, orders.name from orders orders where orders.name = ? select customer.id, customer.name from customer where customer.id = ? select order_item.order_id order_item.id order_item.id order_item.name order_item.order_id from order_item where order_item.order_id = ? LAZY 방식\nselect orders.id, orders.customer_id, orders.name from orders orders where orders.name = ? -- (단, 해당 객체 필요/사용 시 발생) select customer.id, customer.name from customer where customer.id = ? -- (단, 해당 객체 필요/사용 시 발생) select order_item.order_id order_item.id order_item.id order_item.name order_item.order_id from order_item where order_item.order_id = ? 예시 : 리스트 조회 # EAGER 방식\n-- orders 전체 조회 쿼리 select orders.id, orders.customer_id, orders.name from orders -- customer 조회 쿼리 select customer.id, customer.name from customer customer where customer.id = ? -- order_item 조회 쿼리 select order_item.order_id order_item.id order_item.id order_item.name order_item.order_id from order_item where order_item.order_id = ? LAZY 방식\nselect orders.id, orders.customer_id, orders.name from orders -- (단, 해당 객체 필요/사용 시 발생) select customer.id, customer.name from customer customer where customer.id = ? -- (단, 해당 객체 필요/사용 시 발생) select order_item.order_id order_item.id order_item.id order_item.name order_item.order_id from order_item where order_item.order_id = ? 사용자 정의 메서드 리스트 조회 # List\u0026lt;Orders\u0026gt; findAllByName(String name); EAGER 방식\nselect orders.id, orders.customer_id, orders.name from orders where orders.name = ? select customer.id, customer.name from customer customer where customer.id = ? select order_item.order_id order_item.id order_item.id order_item.name order_item.order_id from order_item where order_item.order_id = ? LAZY 방식\nselect orders.id, orders.customer_id, orders.name from orders where orders.name = ? -- (단, 해당 객체 필요/사용 시 발생) select customer.id, customer.name from customer customer where customer.id = ? -- (단, 해당 객체 필요/사용 시 발생) select order_item.order_id order_item.id order_item.id order_item.name order_item.order_id from order_item where order_item.order_id = ? 이전 작성 글 # Person person * --- 1 Company compnay 첫 번째 예시 # Person 객체의 리스트를 조회하고 Person 객체의 엮인 Company 객체를 조회한다고 가정\n* Person 객체에 엮인 Company 는 모두 다르다고 가정\nclass Test { @Autowired TestEntityManager entityManager; @Autowired PersonRepository personRepository; @Autowired CompanyRepository companyRepository; @BeforeEach void setUp() { System.out.println(\u0026#34;------------------------ insert ------------------------\u0026#34;); Company company1 = Common.getCompany(\u0026#34;c1\u0026#34;); Company company2 = Common.getCompany(\u0026#34;c2\u0026#34;); Company company3 = Common.getCompany(\u0026#34;c3\u0026#34;); companyRepository.save(company1); companyRepository.save(company2); companyRepository.save(company3); personRepository.save(Common.getPerson(\u0026#34;p1\u0026#34;, company1)); personRepository.save(Common.getPerson(\u0026#34;p2\u0026#34;, company2)); personRepository.save(Common.getPerson(\u0026#34;p3\u0026#34;, company3)); entityManager.flush(); entityManager.clear(); } @Test void test() { System.out.println(\u0026#34;------------------------ test ------------------------\u0026#34;); List\u0026lt;Person\u0026gt; people = personRepository.findAll(); // FetchType 이 Eager 방식이라면 아래 로직은 생략한다고 가정한다. for (Person person : people) { System.out.println(person.getCompany().getName()); } } 그러면 아래와 같은 쿼리가 발생할 것이다.\n-- 예상 로그 select * from person; -- 1 번 select * from company where company_id = ? -- N 번 select * from company where company_id = ? select * from company where company_id = ? ... -- 실제 로그 ------------------------ insert ------------------------ Hibernate: insert into company (id, created_date, updated_date, address, email, person_id, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) Hibernate: insert into company (id, created_date, updated_date, address, email, person_id, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) Hibernate: insert into company (id, created_date, updated_date, address, email, person_id, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) Hibernate: insert into person (id, created_date, updated_date, address, company_id, email, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) Hibernate: insert into person (id, created_date, updated_date, address, company_id, email, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) Hibernate: insert into person (id, created_date, updated_date, address, company_id, email, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) ------------------------ test ------------------------ Hibernate: select person0_.id as id1_4_, person0_.created_date as created_2_4_, person0_.updated_date as updated_3_4_, person0_.address as address4_4_, person0_.company_id as company_9_4_, person0_.email as email5_4_, person0_.name as name6_4_, person0_.phone as phone7_4_, person0_.remark as remark8_4_ from person person0_ Hibernate: select company0_.id as id1_1_0_, company0_.created_date as created_2_1_0_, company0_.updated_date as updated_3_1_0_, company0_.address as address4_1_0_, company0_.email as email5_1_0_, company0_.person_id as person_i9_1_0_, company0_.name as name6_1_0_, company0_.phone as phone7_1_0_, company0_.remark as remark8_1_0_ from company company0_ where company0_.id=? Hibernate: select company0_.id as id1_1_0_, company0_.created_date as created_2_1_0_, company0_.updated_date as updated_3_1_0_, company0_.address as address4_1_0_, company0_.email as email5_1_0_, company0_.person_id as person_i9_1_0_, company0_.name as name6_1_0_, company0_.phone as phone7_1_0_, company0_.remark as remark8_1_0_ from company company0_ where company0_.id=? Hibernate: select company0_.id as id1_1_0_, company0_.created_date as created_2_1_0_, company0_.updated_date as updated_3_1_0_, company0_.address as address4_1_0_, company0_.email as email5_1_0_, company0_.person_id as person_i9_1_0_, company0_.name as name6_1_0_, company0_.phone as phone7_1_0_, company0_.remark as remark8_1_0_ from company company0_ where company0_.id=? 두 번째 예시 # Company 객체의 리스트를 조회하고 Company 객체에 엮인 Person List 를 조회한다고 해보자! @DataJpaTest class Test { @Autowired TestEntityManager entityManager; @Autowired PersonRepository personRepository; @Autowired CompanyRepository companyRepository; @BeforeEach void setUp() { Company company1 = Common.getCompany(\u0026#34;c1\u0026#34;); Company company2 = Common.getCompany(\u0026#34;c2\u0026#34;); Company company3 = Common.getCompany(\u0026#34;c3\u0026#34;); companyRepository.save(company1); companyRepository.save(company2); companyRepository.save(company3); personRepository.save(Common.getPerson(\u0026#34;p1\u0026#34;, company1)); personRepository.save(Common.getPerson(\u0026#34;p2\u0026#34;, company2)); personRepository.save(Common.getPerson(\u0026#34;p3\u0026#34;, company3)); entityManager.flush(); entityManager.clear(); } @Test void test() { System.out.println(\u0026#34;------------------------ test ------------------------\u0026#34;); List\u0026lt;Company\u0026gt; companies = companyRepository.findAll(); for (Company company : companies) { System.out.println(company.getPeople().size()); } } 그러면 아래와 같은 쿼리가 발생할 것이다.\n-- 예상 로그 select * from company; -- 1 번 select * from person where company_id = ? -- N 번 select * from person where company_id = ? select * from person where company_id = ? ... -- 실제 로그 ------------------------ insert ------------------------ Hibernate: insert into company (id, created_date, updated_date, address, email, person_id, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) Hibernate: insert into company (id, created_date, updated_date, address, email, person_id, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) Hibernate: insert into company (id, created_date, updated_date, address, email, person_id, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) Hibernate: insert into person (id, created_date, updated_date, address, company_id, email, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) Hibernate: insert into person (id, created_date, updated_date, address, company_id, email, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) Hibernate: insert into person (id, created_date, updated_date, address, company_id, email, name, phone, remark) values (null, ?, ?, ?, ?, ?, ?, ?, ?) ------------------------ test ------------------------ Hibernate: select company0_.id as id1_1_, company0_.created_date as created_2_1_, company0_.updated_date as updated_3_1_, company0_.address as address4_1_, company0_.email as email5_1_, company0_.person_id as person_i9_1_, company0_.name as name6_1_, company0_.phone as phone7_1_, company0_.remark as remark8_1_ from company company0_ Hibernate: select people0_.company_id as company_9_4_0_, people0_.id as id1_4_0_, people0_.id as id1_4_1_, people0_.created_date as created_2_4_1_, people0_.updated_date as updated_3_4_1_, people0_.address as address4_4_1_, people0_.company_id as company_9_4_1_, people0_.email as email5_4_1_, people0_.name as name6_4_1_, people0_.phone as phone7_4_1_, people0_.remark as remark8_4_1_ from person people0_ where people0_.company_id=? Hibernate: select people0_.company_id as company_9_4_0_, people0_.id as id1_4_0_, people0_.id as id1_4_1_, people0_.created_date as created_2_4_1_, people0_.updated_date as updated_3_4_1_, people0_.address as address4_4_1_, people0_.company_id as company_9_4_1_, people0_.email as email5_4_1_, people0_.name as name6_4_1_, people0_.phone as phone7_4_1_, people0_.remark as remark8_4_1_ from person people0_ where people0_.company_id=? Hibernate: select people0_.company_id as company_9_4_0_, people0_.id as id1_4_0_, people0_.id as id1_4_1_, people0_.created_date as created_2_4_1_, people0_.updated_date as updated_3_4_1_, people0_.address as address4_4_1_, people0_.company_id as company_9_4_1_, people0_.email as email5_4_1_, people0_.name as name6_4_1_, people0_.phone as phone7_4_1_, people0_.remark as remark8_4_1_ from person people0_ where people0_.company_id=? 즉, 프록시 객체로 되어있는, 연관관계가 있는 엔티티라면 언제든지 발생할 수 있는 것으로 이해했다.\n더불어 EAGER 방식이 권장되지 않는 이유도 분명히 알 수 있다.\nEAGER 방식의 경우: Person List 를 조회했을 뿐인데 연관된 모든 객체(엔티티, Company)를 조회하여 예측하지 못한 쿼리가 발생한다.\nLAZY 방식의 경우: 위의 로직에서 company.getPeople().isEmpty() 와 같은 실질적으로 객체(엔티티)가 사용되는 로직이 없다면 쿼리가 발생하지 않는 것이다.\nLazy vs Eager 예시 # Lazy 일 때\nList\u0026lt;Person\u0026gt; people = personRepository.findAll(); // select * from person; for (Person person : people) { System.out.println(person.getCompany().getName()); // select * from company where company_id = ? (N번) } Eager 일 때\nList\u0026lt;Person\u0026gt; people = personRepository.findAll(); // select * from person; // select * from company where company_id = ? (N번) 해결 방법 # 다른 글들에서 소개된 해결 방법은 FetchJoin, BatchSize, EntityGraph 설정 등의 방법이 소개되는 것 같다.\n+ 조금 이해/정리가 된 상태에서 https://incheol-jung.gitbook.io/docs/q-and-a/spring/n+1 여기의 글을 읽어보니 조금 더 확실히 이해가 되는 것 같다.\nhttps://jojoldu.tistory.com/165 https://velog.io/@woo00oo/N-1-문제 https://incheol-jung.gitbook.io/docs/q-and-a/spring/n+1 "},{"id":222,"href":"/docs/SPRING/SPRING-Webflux/","title":"[SPRING] Webflux","section":"SPRING","content":" 아래 글을 참고한다.\nhttps://godekdls.github.io/Reactive%20Spring/springwebflux/ https://godekdls.github.io/Reactive%20Spring/springwebflux2/ https://docs.spring.io/spring-framework/docs/current/reference/html/web-reactive.html "},{"id":223,"href":"/docs/SPRING/SPRING-WebServer-vs-WAS-vs-Servlet-Container/","title":"[SPRING] WebServer vs WAS vs Servlet Container","section":"SPRING","content":" WebServer vs WAS(Web Application Server) vs Servlet Container # WebServer (웹 서버) # 정적인 페이지(HTML, CSS)를 제공하는 서버이다.\n클라이언트의 요청 중 자체적으로 처리할 수 없는 요청은 WAS로 넘긴다.\n웹서버와 WAS, 즉 역할을 분리함으로써 요청에 대한 부담을 나눌 수 있다.\nApache, Nginx, IIS 등이 있다.\nWAS # 서버 사이드 언어(코드)를 통해 동적인 콘텐츠를 만드는 서버이다.\n웹 서버에서 처리할 수 없는 동적인 콘텐츠를 생성하고, 이것을 웹서버에 제공한다.\n보통 웹서버의 기능을 포함하고 있어서 웹 서버 없이도 웹 서비스를 운영할 수 있다.\nWAS 는 Servelet Container 개념을 포함한다.\nApache Tomcat, IBM WebSphere, Oracle WebLogic, Glassfish, JBoss 등이 있다.\n(WAS 내부의 Container들 중) Servlet Container의 실행 절차\n웹서버로부터 요청이 들어오면, WAS 내의 Servlet Container 가 요청을 받는다. Servlet Container 는 HttpServletRequest, HttpServletResponse 객체를 생성한다. 배포서술자(web.xml)를 참조하여 Servlet 을 호출한다. (Thread를 생성한다.) 호출된 Servlet은 service() 메소드를 호출하고, 요청에 맞게 doMethod() 메소드를 호출한다. 호출된 doMethod() 메소드는 동적으로 페이지를 생성하고 HttpServletResponse 객체에 응답을 실어서 Servlet Container 에 전달한다. (아마도 이때 우리가 작성한 코드(Controller, Service, \u0026hellip;)가 동작하여 동적 페이지가 생성될 것이다.) Container는 전달받은 Response 객체를 HTTPResponse 형태로 전환하여 웹서버에 전달한다. 생성되었던 Thread를 종료하고 HttpServletRequest, HttpServletResponse 객체를 소멸시킨다. (PHP의 경우는 WAS의 역할을 하지만 웹서버의 모듈 형태로 작동하므로 WAS라 불리는데 이견이 많다 \u0026hellip; ?)\nServlet Container # WAS 별로 다양한 종류의 컨테이너를 내장하고 있다. 이들 중 Servlet 에 관련된 기능을 하는 것(모아둔 것)을 Servlet Container 라고 한다. (이 외에도 Servlet Container, JSP Container, EJB Container 등의 다양한 컨테이너가 있다.)\n즉 서블릿을 관리해주는 컨테이너이다.\n주된 목적\n생명 주기 관리\nServlet을 초기화, 호출, 소멸시킨다. 통신 지원\n웹서버로부터 받은 요청을 분석하여 Servlet을 실행시킨다. 멀티쓰레딩 지원 (Multi-Threading)\n클라이언트의 요청에 따라 Servlet을 생성하고, 이미 생성된 Servlet에 대한 요청은 스레드를 생성해 실행한다. 보안 관리 JSP 지원 Apache Tomcat, 제티 등이 있다.\nReference\nhttps://pjh3749.tistory.com/267 "},{"id":224,"href":"/docs/WEB/WEB-Apache-vs-Nginx/","title":"[WEB] Apache vs Nginx","section":"WEB","content":" Apache # Apache 는 MPM(Multi Process Module) 방식으로 동작한다.\nMPM 은 다시 아래와 같은 방식이 있다.\nPrefork MPM Worker MPM Event MPM Prefork MPM # 각각의 요청을 각각의 프로세스(1 therad) 가 처리한다.\n프로세스 별로 처리하기 때문에 안정적이다. (= 메모리 영역을 공유하지 않는다, 메모리 공간이 독립적이다)\n자원의 사용량이 크다.\ndefault 개수만큼 apache 자식 프로세스를 생성해놓는다. 프로세스는 client 요청을 처리하고, 요청이 많을 경우 Process를 새로 생성하여 처리한다.\nWorker MPM # Prefork와 같이 Default로 Apache 자식 프로세스를 생성해놓는다. 요청이 많아지면 프로세스가 아닌 각 프로세스의 Thread를 생성해 처리하는 구조이다. (두 방식의 특징은 우리가 흔히 알고 있는 프로세스와 쓰레드 사용의 장/단점과 동일하다.)\n프로세스당 여러 개의 Therad가 존재한다.\n각각의 요청을 각각의 스레드가 처리한다. (최대 64개의 Therad 처리가 가능하다. (?))\n각각의 Therad 는 한번에 한 connection 을 담당한다.\n통신량이 많은 (대규모) 환경에 적합하다.\n자원의 사용량이 Prefork 방식에 비해 적다.\nRace Condition 이 발생할 수 있다.\nEvent MPM # Prefork, Worker 방식은 1개의 process(or therad)가 클라이언트와 연결된다. 연결이 끝나지 않는 한 process(or thread)가 소멸되지 않는다. (Keep Alive) 따라서, 대량 접속 환경에서 성능이 급격히 떨어졌다. 이러한 문제를 해결하기 위해 Apache 2.4부터는 Event MPM을 사용할 수 있게 되었다.\n(Prefork, Worker 방식의 단점을 보완하기 위해) Apache 2.4 버전에서 릴리즈 되었다.\nWorker 방식을 기반으로 한다.\n클라이언트로 데이터를 기다리도록 유지되는 단점을 보완하기 위해 각 프로세스에 대한 전용 리스너 스레드를 사용하여 Listening 소켓, Keep Alive 상태에있는 모든 소켓, 처리기 및 프로토콜 필터가 작업을 수행 한 소켓 및 나머지 유일한 소켓을 처리한다. (?)\nNginx # 시간이 지남에 따라, 동시 접속 / 대량의 트래픽이 발생했고 Apache 처리 방식(MPM)의 단점으로 인해 Nginx 가 탄생했다.\nNginx 의 처리 방식은 비동기 event-dirven 방식이다.\n한 개 또는 고정된 프로세스만을 생성한다. (= 프로세스가 한 개라면 context switching 으로 인한 오버헤드가 발생하지 않는다.) 이런 프로세스 내부에서 비동기방식을 통해 요청을 처리한다. (동시 접속 요청이 많아도 Process, Thread 생성 비용이 들지 않는다.)\nEvent-Driven 방식에선 작업을 하다 I/O, socket read/write 등 CPU가 관여하지 않는 작업이 시작되면 기다리지 않고 바로 다른 작업을 수행한다. 진행중인 I/O 등의 작업들이 끝나면 아! 내가 아까 했던 작업을 다시 진행하면 된다는 이벤트가 발생하고 그 작업을 처리하게 된다.\n이벤트를 받는 reactor, 실제 처리를 위한 worker, worker 로 전달하기 위한 handler 등으로 구성된다.\n다만, 긴 많은 I/O처리가 필요한 작업의 경우 시스템 큐에 요청이 쌓이게되어 성능이 저하 될 수 있다.\n복잡한 처리나 대용량 데이터처리가 필요한 서비스 등에서는 적합하지 않을수 있다.\nReference\nNginx \u0026amp; Apache 비교 Apache MPM 이란? Nginx와 Apache의 구동방식 비교 넌 뭐니 NGINX? Nginx 개념의 이해 NGINX와 Apache Nginx 개념의 이해 "},{"id":225,"href":"/docs/WEB/WEB-CSRF/","title":"[WEB] CSRF","section":"WEB","content":" CSRF # Cross Site Request Forgery\n웹 애플리케이션 취약점 중 하나이다.\n자신의 의지와는 무관하게 공격자가 의도한 행위(수정, 삭제, 등록 등)를 특정 웹사이트에 요청하게 하는 공격이다.\n피해자(희생자)의 권한을 도용하여 공격자가 웹사이트에 특정 요청을 하는 것이다.\n대상이 될 서비스(웹 애플리케이션)에 피해자가 로그인 한 상태이다. 이때, 정상적인 쿠키 등을 발급받는다. 피해자가 공격자의 피싱 사이트에 접속 방어 기법 # 일반적으로 CSRF 방어 기법은 조회성 메소드(GET) 에는 적용하지 않고, POST, PUT, PATCH, DELETE 메소드에 중점적으로 적용한다.\n1. Referrer 검증\n일반적으로 referrer 검증만으로 대부분의 CSRF 공격을 방어할 수 있다.\n예를 들어, 같은 도메인이 아닌 개인 이메일, 다른 도메인에서 들어오는 referrer 를 차단하는 것이다.\nXSS 취약점이 있다면, CSRF 공격에 취약해질 수 있다.\n2. CSRF Token 사용\nSecurity Token\n사용자의 세션에 임의의 토큰(난수 값)을 저장하고, 사용자는 요청 마다 해당 토큰을 포함시켜 전송한다. 서버에서는 요청을 받을 때마다 서버에 저장된 토큰 값과 요청에서 받은 토큰 값을 비교하여 검증할 수 있다.\n예를 들어, 서버에서 임의의 토큰(난수 값)을 생성하고 (View)form 쪽에 csrf 토큰을 세팅하여 페이지를 내려준다. 정상적인 페이지라면 해당 토큰 값이 존재하고 유효하기 때문에 성공, 피싱 페이지라면 해당 토큰 값이 존재하지도 않을 수 있고 유효하지 않기 때문에 실패할 것이다.\n참고 # https://itstory.tk/entry/CSRF-%EA%B3%B5%EA%B2%A9%EC%9D%B4%EB%9E%80-%EA%B7%B8%EB%A6%AC%EA%B3%A0-CSRF-%EB%B0%A9%EC%96%B4-%EB%B0%A9%EB%B2%95 https://sj602.github.io/2018/07/14/what-is-CSRF/ "},{"id":226,"href":"/docs/WEB/WEB-DOM/","title":"[WEB] DOM","section":"WEB","content":" DOM 이란?\nDOM(Document Object Model, 문서 객체 모델) 이란? # XML이나 HTML과 같은 문서에 접근(조작)하기 위한 인터페이스 문서 내의 모든 요소(예를 들어, 태그)를 정의하고 (그 요소들에)접근하는 방법을 제공 W3C의 표준 객체 모델 (위의 말을 조금 쉽게 풀어쓰면) 우리는 DOM 덕분에 아래와 같은 작업을 할 수 있다.\n(JS) 새로운 HTML 요소 추가/수정/삭제 (JS) 새로운 HTML Event 추가 (JS) CSS 변경 등 DOM은 아래와 같이 노드 트리 형태로 나타난다고 한다.\n출처: 위키백과: 문서 객체 모델\n단순히 텍스트로 작성된 HTML 소스(코드)를 Element로 변환하여 구조화된 형태로 만들고, 다양하게 사용될 수 있도록(예를 들어, 위에서 말한 API 인터페이스를 제공하는 것 등) 하는 것이다.\nDOM 의 종류 # DOM 의 종류는 아래와 같은 3 가지 모델이 있음\nCore DOM : 모든 문서(XML, HTML, \u0026hellip;) 타입을 위한 DOM 모델 HTML DOM : HTML 문서를 위한 DOM 모델 XML DOM : XML 문서를 위한 DOM 모델 주의할 것 # DOM과 문서(HTML, XML)는 다르다.\n(HTML, XML과 같은)문서에 의해 DOM이 생성되지만, 문서와 DOM이 100% 동일한 것은 아니다. 예를 들어, 아래와 같은 경우에서 DOM과 문서는 다를 수 있다.\n1.작성된 HTML 문서가 유효하지 않을 때\n\u0026lt;html\u0026gt; HI! \u0026lt;/html\u0026gt; 위의 코드는 HTML 필수 사항인 \u0026lt;head\u0026gt;, \u0026lt;body\u0026gt; 가 빠져있는데, DOM 에서는 교정된다.\nhtml | |- head |- body | |- HI! 2.자바스크립트에 의해 DOM이 추가/수정/삭제될 때\nJS에 의해 DOM에 동적으로 객체가 추가/수정/삭제될 수 있다. 이렇게 동적으로 변경된 DOM은 원본 문서(HTML)과 다르다.\n3.DOM != 브라우저에 보여지는 것\n최종적으로 브라우저에 보여지는 것은 DOM이 아니라 Render Tree라고 한다.\nRender Tree\nDOM + CSSOM으로 만들어진 것 최종적으로 화면에 보여지는 것만으로 구성되어 있는 것 예를 들면 아래와 같다.\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;HI!\u0026lt;/h1\u0026gt; \u0026lt;div style=\u0026#34;display:none;\u0026#34;\u0026gt;HI!\u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; // DOM html | |- head |- body | |- h1 | |- HI! |- div | |- HI! // Render Tree html | |- head |- body | |- h1 | |- HI! CRP(Critical Rendering Path) # (DOM에 대해 간략히 살펴보았으니) 웹페이지가 어떻게 빌드되는지에 대해서 살펴본다.\nCritical Rendering Path : 브라우저가 HTML 문서를 읽고, 스타일을 입히고 화면에 표시되기까지의 과정\nCRP 는 아래의 6개의 단계로 볼 수 있다고 한다.\nDOM Tree 생성 CSSOM Tree 생성 render blocking resource : Render Tree 는 CSS 전체를 파싱하기 전에는 생성될 수 없다. Running Javascript parser blocking resource : HTML 문서를 파싱하는 것이 JS에 의해 blocking(stop)될 수 있다. Render Tree 생성 최종적으로 페이지에 렌더링 되는 내용(tree)이다. Generating the Layout viewport의 size 를 결정한다. (-\u0026gt; viewport size에 종속적인 css context 제공한다.) default viewport width : 980px Layout computes the exact position and size of each object. 상대적인 사이즈(50%, 25%) 등은 pixel 값(절대값)으로 계산된다. Painting content -\u0026gt; 화면에 보여질 pixles 로 표현한다. DOM, Style(즉, Render Tree)에 따라 painting 의 시간이 결정된다. It takes in the final render tree and renders the pixels to the screen. Send Request - GET request sent for index.html Parse HTML and Send Request - Begin parsing of HTML and DOM construction. Send GET request for style.css and main.js Parse Stylesheet - CSSOM created for style.css Evaluate Script - Evaluate main.js Layout - Generate Layout based on meta viewport tag in HTML Paint - Paint pixels on document 출처: Understanding the Critical Rendering Path 위 과정을 간소화하면, 다음의 두 단계로 볼 수 있다.\n브라우저는 문서를 읽고/파싱한다. 어떤 내용을 페이지에 렌더링할 지 결정한다. DOM, CSSOM, Render Tree 를 생성한다. 브라우저는 렌더링 작업을 수행한다. 참고 # DOM의 개념 DOM은 정확히 무엇일까? Render-tree Construction, Layout, and Paint Understanding the Critical Rendering Path "},{"id":227,"href":"/docs/WEB/WEB-HTTP-Header/","title":"[WEB] HTTP Header","section":"WEB","content":" 커스텀 등록 헤더는 \u0026lsquo;X-\u0026rsquo; 라고 붙이곤 했었는데 RFC 6648(2012.06)에 의해 폐기\n분류 (by Context) # General Header\nrequest/response 공통(모두) 적용 body에 전송되는 데이터와는 관련이 없음 (예를 들면, Content-Type 등을 의미하는 건가?) Request Header\n클라이언트 정보 Response Header\n서버 정보 (이름, 버전 등) Entity Header\nEntity Body 정보 (Content-Length, MIME 타입 등) 프록시 처리 방법에 따라 분류할 수도 있다.\nEnd-to-end headers, Hop-by-hop headers\nGeneral Header # request / response 모두에서 사용되는 공통 헤더\n컨텐츠(body)에는 적용되지 않는 헤더 (컨텐츠와 관련이 없는 헤더)\n예시\nRequest URL: https://developer.mozilla.org/api/v1/whoami Request Method: GET Status Code: 200 Remote Address: 54.230.168.85:443 Referrer Policy: strict-origin-when-cross-origin Date Cache-Control Connection Request Header # HTTP 요청 시 사용되는 헤더\n예시\naccept: */* accept-encoding: gzip, deflate, br accept-language: ko,en-US;q=0.9,en;q=0.8 cookie: preferredlocale=ko referer: https://developer.mozilla.org/ko/docs/Glossary/Response_header sec-ch-ua: \u0026#34; Not A;Brand\u0026#34;;v=\u0026#34;99\u0026#34;, \u0026#34;Chromium\u0026#34;;v=\u0026#34;99\u0026#34;, \u0026#34;Google Chrome\u0026#34;;v=\u0026#34;99\u0026#34; sec-ch-ua-mobile: ?0 sec-ch-ua-platform: \u0026#34;macOS\u0026#34; sec-fetch-dest: empty sec-fetch-mode: cors sec-fetch-site: same-origin user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.84 Safari/537.36 엄격하게 본다면, (브라우저 확인 시) Request Header 에 포함된 헤더 모두가 Request Header 는 아님에 주의\n예를 들어, Content-Length 는 Entity Header 이다.\n\u0026ldquo;요청에 나타나는 모든 헤더가 요청 헤더인것은 아닙니다. 예를 들면, POST 요청에 나타나는 Content-Length는 실제로 요청 메시지 바디의 크기를 참조하는 entity header입니다. 하지만, 이러한 엔티티 헤더는 종종 컨텍스트와 같은 요청 헤더라 불립니다.\u0026rdquo;\nResponse Header # HTTP 응답 시 사용되는 헤더\n예시\ncache-control: max-age=0, no-cache, no-store, must-revalidate, private content-length: 35 content-type: application/json; charset=utf-8 date: Wed, 30 Mar 2022 13:42:04 GMT expires: Wed, 30 Mar 2022 13:42:04 GMT referrer-policy: same-origin server: gunicorn vary: Cookie via: 1.1 5062540db61fe5bfa0e8709e57809128.cloudfront.net (CloudFront) x-amz-cf-id: _OoJKUVILmX4SgHZ06Z3FJV5J8HcjgsgJtdsh0Yw26XjoLfxe74-Ng== x-amz-cf-pop: ICN51-C2 x-cache: Miss from cloudfront x-content-type-options: nosniff x-frame-options: DENY 엄격하게 본다면, (브라우저 확인 시) Response Header 에 포함된 헤더 모두가 Response Header 는 아님에 주의\n예를 들면 아래와 같은 것들은 Entity Header 이다.\nContent-Length Content-Encoding Content-Type \u0026ldquo;응답에 나타나는 모든 헤더가 응답 헤더인것은 아닙니다. 예를 들어, Content-Length 헤더는 응답 메시지 바디의 크기를 참조하는 entity header입니다. 그러나 이러한 엔티티 요청은 보통 컨텍스트에서 응답 헤더로 불립니다.\u0026rdquo;\nHTTP 종류 # https://developer.mozilla.org/ko/docs/Web/HTTP/Headers\n"},{"id":228,"href":"/docs/WEB/WEB-OAuth-2.0/","title":"[WEB] OAuth 2.0","section":"WEB","content":" Grant Type # 방식 사용자 인증 과정 개입 설명 authorization_code O * 인증 과정에서 Authorization Code 교환 후 access token 을 받고, 사용한다. implicit O * 인증 과정에서 Authorization Code 의 교환 없이, 즉시 access token 을 받고, 사용한다. client_credentials X * 인증 과정에서 client credential 정보(ex : client id, client secret)를 통해 access token 을 받고, 사용한다. password (Resource Owner Password Credentials, Password Credentials) X * 인증 과정에서 client credential 정보(ex : client id, client secret, id, password)를 통해 access token 을 받고, 사용한다. + client_credentials # Client(= 3rd party or resource owner)는 이미 토큰을 발행할 수 있는 주체이다.\n\u0026quot; 대부분의 토큰 발행 유형이 Resource Owner가 시발점이 되는데 반해서, 해당 방법은 명칭에서부터 알 수 있듯이 Client가 주권을 쥐고 있습니다. 여타 방법들에서의 허가(approve)에 대한 동의를 Client가 이미 도장 쾅쾅 찍은 상태라고 보시면 됩니다. 즉, 서비스(Client)는 이미 그 자체만으로도 토큰 발행을 요청할 수 있는 주체가 되어있고 토큰을 요청하기만하면 Authorization Server는 토큰을 발행해줍니다. \u0026ldquo;\n출처: https://blinders.tistory.com/65 [글쓰는 개발자:티스토리]\n"},{"id":229,"href":"/docs/WEB/WEB-Restful-API/","title":"[WEB] Restful API","section":"WEB","content":" REST(Representational State Transfer) # 정의 1. (자원을 정의한 후) 자원(혹은 자원의 이름, 표현)으로 구분하여 자원의 상태(정보)를 주고 받는 모든 것\n정의 2. Resource(자원, URI), Method(행위), Representation of Resource(자원의 형태/표현)를 사용하는 것\nREST 구성 요소 # 자원(Resource, URI)\n자원의 고유한 식별 값 (\u0026lsquo;모든 자원에는 고유한 ID가 존재한다\u0026rsquo;라는 전제) 행위(Method)\n(자원에 대해서) 하고자 하는 행위 e.g. (HTTP 프로토콜에서) GET, POST, PUT, DELETE 등 자원의 형태/표현(Representation of Resource)\nClient, Server가 주고 받는 자원의 형태/표현 e.g. json, xml, text 등 참고 # [Network] REST란? REST API란? RESTful이란? heejeong Kwon 21 Sep 2018 [Server] Restful API란? "},{"id":230,"href":"/docs/WEB/WEB-SSL-Handshake/","title":"[WEB] SSL Handshake","section":"WEB","content":" SSL Handshake 동작 원리 / 과정 # SSL Handshake의 목표\n신뢰할 수 있는 서버(연결)인지 확인합니다. 통신 시 사용할 암호화 알고리즘을 결정합니다. 자세한 설명/그림은 여기를 참고합니다.\n1. [Client 측] Client Hello\nClient -\u0026gt; Server 로 연결을 시도합니다. 이때, 아래의 내용을 포함합니다.\n사용할 수 있는 암호화 알고리즘 (즉, 어떤 암호화 알고리즘을 사용할 수 있는지) SSL Protocol version 등등 2. [Server 측] Server Hello / Certificate\nServer -\u0026gt; Client 로 응답합니다. 이때, 아래의 내용을 포함합니다.\nClient 가 보내준 암호화 알고리즘들 중 어떤 것을 사용할 것인지 SSL Protocol version SSL 인증서 내용 3. [Client 측] Server의 SSL 인증서 검증\nCA의 비밀키로 암호화된 서버의 SSL 인증서를, CA의 공개키로 복호화 시도합니다.\n복호화가 정상적으로 되었다면 검증이 완료된 것으로 봅니다.\n* CA의 공개키는 브라우저에 내장되어 있거나 인터넷상으로 다운로드 받아올 수 있다고 합니다.\n4. [Client 측] 대칭키 전달\nClient -\u0026gt; Server 로 대칭키를 전달합니다.\n대칭키를 전달할 때, Server의 공개키로 암호화하여 전달합니다.\n* Server의 공개키는 3번(Server의 SSL 인증서 검증/복호화)시점에서 얻은 것 입니다.\n5. [Server 측] SSL Handshake 종료\n서버의 비밀키를 통해 클라이언트가 전달한 대칭키를 획득합니다.\n이로써 SSL Handshake는 종료됩니다. (통신할 준비가 완료되었음을 의미합니다.)\n참고 # HTTPS 통신 원리 쉽게 이해하기 (Feat. SSL Handshake, SSL 인증서)\n"},{"id":231,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/@ComponentScan/","title":"@ComponentScan","section":"스프링 핵심 원리 (기본편)","content":" @Component 어노테이션이 달린 클래스들을 모두 찾아, 빈으로 등록 # @Component @Controlloer (@Component 갖고 있음) : Spring MVC 컨트롤러로 인식 @Service (@Component 갖고 있음) : 특별한 기능 X 비즈니스 로직 인식 용도 @Repository (@Component 갖고 있음) : 데이터(DB) 계층의 에러를 스프링의 (통일된)예외로 변환 여러 DB마다 에러가 다를 수 있다 -\u0026gt; 통일화 @Configuration (@Component 갖고 있음) : 스프링 설정 정보로 인식 * 어노테이션의 어노테이션을 인식 =\u0026gt; Java의 기능 X, Spring 의 기능 O\nbasePackage : default(클래스 파일의 위치) 설정 권장\n(아래와 같이)빈으로 등록할 때 의존관계가 있는 것들은 어떻게 해결?\n\u0026ndash;\u0026gt; 생성자 주입, 필드 주입, 세터 주입\n// 수정 전 @Configuration public class AppConfig { @Bean public MyService myService() { return new MyService(myRepository()); } @Bean public MyRepository myRepository() { return new MyRepository(); } } // 수정 후 @Component public class MyService { private final MyRepository myRepository; @Autowired MyService(MyRepository myRepository) { this.myRepository = myRepository; } } includeFilters, excludeFilters 를 엄청 사용하지는 않는 듯 단, excludeFilters 는 가끔 사용\nFilterType 옵션 # ANNOTATION : Default, 어노테이션 인식 ex) org.example.SomeAnnotation ASSIGNABLE_TYPE : 지정한 타입 , 자식 타입 인식 ex) org.example.SomeClass ASPECTJ : AspectJ 패턴 사용 ex) org.example..*Service+ REGEX : 정규표현식 사용 ex) org\\.example\\.Default.* CUSTOM : TypeFilter 인터페이스 구현/처리 ex) org.example.MyTypeFilter Bean 중복/충돌 # 자동 등록 : @Component by @ComponentScan\n수동 등록 : @Configuration (@Bean)\n자동 등록 vs 자동 등록\n-\u0026gt; 충돌 오류\n수동 등록 vs 자동 등록\n(SpringFramework) (오류 X) 수동 등록 우선순위\n* 단,(SpringBoot) 오류 O\n(등록하는 Bean이 너무 많기 때문에) 실무에서는 수동 등록 / 자동 등록의 경우가 꼬이는 경우가 대부분이다. -\u0026gt; 앱 실행 시 오류 발생하도록 정책 바꿈\nallow-bean-definition-overriding 옵션 설정 가능\n"},{"id":232,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/@Configuration%EA%B3%BC-%EB%B0%94%EC%9D%B4%ED%8A%B8%EC%BD%94%EB%93%9C-%EC%A1%B0%EC%9E%91%EC%9D%98-%EB%A7%88%EB%B2%95/","title":"@Configuration과 바이트코드 조작의 마법","section":"스프링 핵심 원리 (기본편)","content":" @Configuration, @Bean 을 통해 Bean 을 등록할 수 있다. # CGLIB 이 나의 클래스를 상속한 Proxy 클래스(객체)를 생성하고, 이 클래스(객체)를 Bean 으로 등록 # if(클래스(객체) 이미 존제?) { return 객체 반환 } else { obj = new 클래스(); obj -\u0026gt; bean 으로 저장; return obj } @Configuration 없이 @Bean 만 사용해도 Bean 으로 등록된다. # 단, 이때는 CGLIB 이 Proxy 객체로 만들어주지 않느다. = Proxy 객체를 생성 X = 싱글톤을 보장 X "},{"id":233,"href":"/docs/BOOKS/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%ED%81%B4%EB%A6%B0-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/01.-%EA%B3%84%EC%B8%B5%ED%98%95-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98%EC%9D%98-%EB%AC%B8%EC%A0%9C%EB%8A%94-%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C/","title":"01. 계층형 아키텍처의 문제는 무엇일까?","section":"만들면서 배우는 클린 아키텍처","content":" 01. 계층형 아키텍처의 문제는 무엇일까? # 사실 계층형 아키텍처는 \u0026lsquo;견고한 아키텍쳐\u0026rsquo;이다.\n(계층을 잘 이해하고 구성한다면) 웹 계층이나, 영속성 계층에 독립적으로 도메인 로직을 작성할 수 있다. (계층을 잘 이해하고 구성한다면) 도메인 로직에 영향을 주지 않고 웹 계층, 영속성 계층의 기술을 추가/변경할 수 있다. = 각각을 독립적인 계층으로 만들 수 있다. = 결합도를 낮출 수 있다. 잘 만들어진 \u0026lsquo;계층형 아키텍쳐\u0026rsquo;는 선택의 폭을 넓히고, 변화하는 요구사항과 외부 요인에 빠르게 적응할 수 있게 해준다.\n\u0026quot; 엉클 밥에 의하면 이것이 바로 아키텍처의 전부다. \u0026ldquo;\n다만, 책에서는 계층형 아키텍처는 아래와 같은 단점(특징)을 가지고 있다고 소개한다.\n나쁜 습관(= 계층을 제대로 유지하지 않고 깨버리거나, 무시하거나 등)들이 스며들기 쉬운 아키텍쳐이다. 시간이 지날수록 소프트웨어를 점점 더 변경하기 어렵게 만드는 수많은 허점들을 노출하는 아키텍쳐이다. 다만, 이러한 특징도 앞서 말한 것과 같이 계층형 아키텍처를 제대로 이해하지 못하고 구성했기 때문은 아닐까\u0026hellip;?? 혹은 제대로 이해했더라도 이를 쉽게 깰 수 있게하거나, 시간이 지날수록 어쩔 수 없는 문제점들이 있다고 말하는 것 같다.\n계층형 아키텍쳐는 \u0026lsquo;데이터베이스 주도 설계\u0026rsquo;를 유도한다. # \u0026rdquo; 정의에 따르면 전통적인 계층형 아키텍쳐의 토대는 \u0026lsquo;데이터베이스\u0026rsquo;이다. \u0026ldquo;\n계층형 아키텍쳐는 다음과 같이 의존 방향을 갖는다.\n웹 계층 → 도메인 계층 → 영속성 계층(DB) 따라서, 결국에는 영속성 계층(DB)에 의존하게 된다.\n우리가 만드는 대부분의 애플리케이션의 목적이 무엇인지 생각해보자.\n(우리는 대부분)\u0026lsquo;비즈니스를 관장하는 규칙/정책\u0026rsquo;을 반영한 모델을 만들어서, 사용자가 이 규칙/정책을 더욱 편리하게 활용할 수 있게 하는 것에 목적을 둔다. 이때, 우리는 상태(state)가 아니라 행동(behavior)을 중심으로 모델링한다. \u0026lsquo;상태(state)\u0026lsquo;가 중요한 요소이긴 하지만 행동(behavior)이 상태(state)를 바꾸는 주체이기 때문에 행동(behavior)이 비즈니스를 이끌어간다.\n그렇다면 우리는 왜 \u0026lsquo;도메인 로직\u0026rsquo;이 아닌 \u0026lsquo;데이터베이스\u0026rsquo;를 토대로 아키텍쳐를 만드는걸까?\n그동안 우리가, 내가 작업했던 방식을 돌이켜보면 데이터베이스를 먼저 설계하고 이를 토대로 도메인 로직을 구현했다.\n실제로 이것은 전통적인 계층형 아키텍쳐에서 합리적인 방법이다. (\u0026lsquo;의존성의 뱡향\u0026rsquo;에 따라 자연스럽게 구현한 것이기 때문이다.) ORM 프레임워크를 사용하기 때문이다. 하지만 이러한 순서(DB 설계가 먼저 진행되는 것)는 비즈니스 관점에서는 전혀 맞지 않다.\n비즈니스 관점에서는 도메인 로직(=비즈니스 로직 부분, 서비스 계층 등 으로 볼 수 있다.) 이 먼저 작성되어야 한다.\n일반적으로 내가 작성해왔던, 혹은 ORM에 의해 관리되는 엔티티들은 아래와 유사한 구조로 관리되어왔다.\n도메인 계층 서비스 | ---------- | | 영속성 계층 엔티티 ← 레포지토리 이 경우 아래와 같은 단점이 발생한다.\n1. 영속성 계층과 도메인 계층에 강한 결합이 생긴다.\n영속성 계층 변경 시 도메인 계층에 영향을 미친다. 2. 도메인 계층(서비스)에서 영속성 계층을 위한 작업(TX 관리, 즉시로딩/지연로딩, 플러시 등등)을 해줘야한다.\n지름길(= 나쁜길)을 선택하기 쉬워진다. # 계층형 아키텍쳐에서의 유일한 규칙은 \u0026lsquo;특정 계층에서는 같은 계층 or 아래 계층만 접근 가능하다\u0026rsquo;는 것이다.\n팀마다 다를 수 있지만 보통 위 규칙 외에 다른 규칙을 강제하지는 않는다.\n다만 여러가지 상황이 발생할 수 있다.\n1. \u0026lsquo;A\u0026rsquo; 컴포넌트를 개발 후에 어떤 계층에 넣을 것인지?\n이 경우, A 컴포넌트를 아무 곳에서나 쓸 수 있게 하기 위해서 밑에 계층(도메인, 영속성 계층)에 둘 수 있다. 이를 위한 명확한 규칙도 없다. (물론 감각적으로, 혹은 팀에서 정한 룰이 있을 것이다.) 2. 중간 계층을 건너뛸 수도 있다.\n이것들이 쌓이면 통일성, 유지보수가 힘들어질 것이다. \u0026rdquo; 계층형 아키텍쳐를 사용할 때 일반적으로 나타나는 변화의 형태이다. \u0026ldquo;\n3. 아래 계층(도메인, 영속성 계층)은 점점 더 비대해진다.\n(1번과 비슷한 의미로) 무심코 개발한 컴포넌트(헬퍼, 유틸리티성 등)를 아래 계층으로 내릴 가능성이 크다. 이러한 나쁜, 통일되지 않는 규칙들을 제거/관리하고 싶다면, 규칙을 코드/빌드 레벨단에서 강제해야 할 것이다.\n여기서 말한 코드/빌드 레벨이란, 아래와 같은 것들을 의미한다.\n빌드가 실패되게 한다. MR(PR)을 허용되지 않게 한다. 커밋(commit)이 허용되지 않게 한다. 테스트하기 어려워진다. # 책에서 말한 내용은 계층형 아키텍처를 잘 사용하지 못했을 때(예를 들어, \u0026ldquo;지름길(= 나쁜길)을 선택하기 쉬워진다.\u0026rdquo; 의 내용들이 기반일 때)에 특히나 나타날 수 있는 내용들인 것 같다.\n예를 들어, 중간 계층을 건너뛰는 코드가 있을 때 \u0026lsquo;컨트롤러 테스트에서 영속성 코드가 발생하고, 이것들을 테스트하기 어렵다\u0026rsquo;는 내용이다.\n이 비유법은 적절한건가? 다른 아키텍쳐였더라도 잘못 사용했더라면 이런 문제점은 똑같이 발생하지 않을까??\n(= 즉, 규칙을 잘 지킨다는 가정을 하면 다른 아키텍처들과 비슷하지 않을까??)\n유스케이스를 숨긴다. # 아래 내용은 다른 아키텍쳐에서도 발생하면 똑같이 어려움을 겪는 문제다. 다만 다른 아키텍쳐에서는 아래의 내용들을 나름(?) 강제하고 있나보다. 책에서는 계층형 아키텍처는 아래와 같은 것들을 이야기 할 때, \u0026ldquo;발생하기 쉽다\u0026rdquo; 고 이야기한다. 이 점을 인지하면서 읽으면 더욱 좋을 것 같다.\n계층형 아키텍쳐에서는 \u0026lsquo;도메인 로직\u0026rsquo;이 여러 계층(웹, 도메인, 영속성)에 흩어지기 쉽다.\n(이런 경우) 새로운 코드를 추가할 적당한 위치를 찾는 것은 이미 어려워진 상태다. (이런 경우) 이미 관리/유지보수가 어려워진 상태다. 계층형 아키텍쳐에서는 도메인(서비스)의 \u0026lsquo;너비\u0026rsquo;에 관한 규칙을 강제하지 않는다.\n1개의 서비스가 모든 로직(ex, CRUD)을 담당하는 넓은 서비스가 만들어지기 쉽다. 동시 작업이 어려워진다. # (이것도 잘 사용하지 못해서일 가능성이 크지만) 이 부분은 공감한다.\n\u0026rdquo; 지연되는 소프트웨어 프로젝트에 인력을 더하는 것은 개발을 늦출 뿐이다. \u0026ldquo;\n계층형 아키텍쳐에서는 동시 작업이 가능하게 하는 측면에서 그다지 도움이 되지 않는다.\n계층형 아키텍처에서는 \u0026lsquo;데이터베이스\u0026rsquo;를 먼저 작업하기 때문에 영속성 계층이 작업되기 전까지 웹, 도메인 계층을 작업하기 힘들다. 계층형 아키텍처에서는 \u0026lsquo;넓은\u0026rsquo; 서비스를 만들기 쉽게 하기 때문에, 결합도를 높여 같이 작업하기 힘들게 만든다. + 동시 작업에 대해서 예시를 들면, 아래와 같이 분배할 수 있을 것이다.\n한 명은 웹 계층, 한 명은 도메인 계층, 한 명은 영속성 계층 한 명은 A(웹, 도메인, 영속성), 한 명은 B(웹, 도메인, 영속성) 유지보수 가능한 소프트웨어를 만드는 데 어떻게 도움이 될까? # 올바르게 구축하고, 몇 가지 추가적인 규칙들을 적용하면 계층형 아키텍쳐는 유지보수하기 매우 쉬워지며 코드를 쉽게 변경하거나 추가할 수 있게 된다.\n그러나 계층형 아키텍쳐에서는 많은 것들이 잘못된 방향으로 흘러가도록 용인하고, 쉽게 허용한다.\n따라서, 철저하게 관리하지 않으면 시간이 지날수록 \u0026lsquo;잘\u0026rsquo; 관리되기 힘들다.\n\u0026rdquo; 특히, 이러한 규칙은 보통 마감일이 설정되었을 때 조금씩 느슨해지기 마련이다. \u0026ldquo;\n계층형 아키텍쳐로 만들든 다른 아키텍쳐 스타일로 만들든, 계층형 아키텍쳐의 함정을 인지하고 지름길을 택하지 않는다면, 유지보수하기에 더 쉬운 솔루션을 만드는 데 도움이 될 것이다.\n"},{"id":234,"href":"/docs/BOOKS/%EA%B0%80%EC%83%81-%EB%A9%B4%EC%A0%91-%EC%82%AC%EB%A1%80%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88/01_%EC%82%AC%EC%9A%A9%EC%9E%90-%EC%88%98%EC%97%90-%EB%94%B0%EB%A5%B8-%EA%B7%9C%EB%AA%A8-%ED%99%95%EC%9E%A5%EC%84%B1/","title":"01. 사용자 수에 따른 규모 확장성","section":"가상 면접 사례로 배우는 대규모 시스템 설계 기초","content":" 어떤 데이터베이스를 사용할 것인가? # 아래의 경우 NoSQL(비-관계형 데이터베이스)가 바람직한 선택이 될 수 있습니다.\n아주 낮은 응답 지연시간(latency) 요구 데이터 비정형 데이터 직렬화, 역직렬화를 할 수 있기만 하면 됨 아주 많은 양의 데이터를 저장 수직적 규모 확장 vs 수평적 규모 확장 # 수직적 규모 확장에는 다음과 같은 단점이 있습니다.\nSPOF, 서버 장애 시 모든 서비스 중단/장애 Scale-Up에 한계가 있음 CPU, Memory 를 무한으로 늘릴 수 없음 [다중화] (웹 계층)웹 서버의 다중화를 위해 선택할 수 있는 것? # (웹 계층)웹 서버의 다중화를 위해서는 무상태 아키텍쳐를 보장해주어야 한다. 세션과 같은 정보를 서버에서 갖고 있는 것이 아니라 외부 저장소(RDBMS, NoSQL)에서 저장/관리하면 된다.\n로드 밸런서\n웹서버가 클라이언트의 요청을 직접 처리하지 않는다. (로드 밸런서 이후) 서버 간에는 사설 IP를 통해 통신할 수 있다. 즉, 보안이 향상된다. 특정 서버 장애 시, 살아 있는 서버를 활용할 수 있어서 서비스가 중단되지 않는다. [다중화] (데이터 계층)DB의 다중화를 위해 선택할 수 있는 것? # 1. Replication\n2. 샤딩\n샤딩 사용 시 유의해야할 점 # 데이터의 재샤딩(resharding) : 샤드 키 계산 함수를 변경하여 데이터를 재배치해야 한다. 데이터가 너무 많아져서 하나의 샤드롷 더 이상 감당하기 어려울 때 샤드 간 데이터 분포가 균등하지 못하여, 한 샤드에 데이터가 빨리 찰 때(샤드 소진) Celebrity(유명인사) 문제 : 핫스팟 키들에에 대해 샤드 할당을 균등하게 해줘야한다. 특정 샤드에 질의가 집중되어 서버에 과부하가 걸릴 때 조인과 비정규화` : 샤딩 시 조인이 어려워진다. 적절한 비정규화를 통해 해결할 수 있다. 응답 시간을 개선하기 위해 선택할 수 있는 것? # 1. 캐싱\n책에서는 Application Logic \u0026lt;-\u0026gt; DB 사이에서 동작하는 것을 예시로 주었다.\n데이터를 캐싱하여 cache hit 시에는 캐싱된 데이터를, miss 시에는 DB 조회를 하도록 한다.\n2. CDN\n책에서는 Client 요청 \u0026lt;-\u0026gt; 로드밸런서 사이에서 동작하는 것을 예시로 주었다.\nClient는 CDN을 먼저 조회하여 찾고자 하는 정적 데이터가 있으면 CDN에서 데이터를 받을 수 있다. 찾고자 하는 데이터가 없으면 서버에서 데이터를 찾아오고, CDN에 저장하고 Client에 내어준다.\n캐시 사용 시 유의해야할 점 # 조회/참조가 빈번히 일어나는 데이터인가? 영속적으로 저장되어야 하는 데이터는 아닌가? 휘발성으로 날라가도 되는 데이터만 캐싱한다. 캐시의 만료시간은 어떻게 되어야 하는가? 만료시간이 짧으면, 캐싱의 이득이 없어진다. 만료시간이 길면, 데이터의 일관성이 깨질 수 있다. 캐시의 데이터와 DB의 데이터의 일관성을 어떻게 유지할 것인가? DB의 업데이트와 캐시의 업데이트가 단일 트랜잭션으로 처리되지 않으면 일관성이 꺠질 수 있다. 장애는 어떻게 대처활 것인가? 캐시 서버가 1대라면, SPOF이 될 수 있다. 여러 대로 캐시 서버를 분산시켜야한다. 캐시 메모리는 얼마나 크게 잡을 것인가? 메모리가 작으면, 캐시의 성능이 떨어진다. 메모리가 크면, 메모리를 많이 점유한다. 데이터 교체(방출) 정책은 어떻게 할 것인가? 흔히, LRU 가 쓰인다. 그 외 LFU, FIFO 등도 쓰이곤 한다.` CDN 사용 시 유의해야할 점 # 비용? 네트워크 비용이 발생하기에, 꼭 필요한 콘텐츠만 캐싱될 수 있도록 한다. 만료시간? 적절한 만료시간을 설정한다. 장애? CDN 서버가 죽었을 때 서비스의 영향이 없도록 한다. 예를 들어, CDN이 죽었을 경우 원본 서버로부터 데이터를 받아갈 수 있도록 되어야 한다. 콘텐츠 무효화? 캐싱을 제거할 수 있어야한다. 데이터를 버저닝하거나, CDN 사업자가 제공하는 API를 사용할 수 있을 것이다. `\n"},{"id":235,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-5-%EB%A0%88%EC%8B%9C%ED%94%BC/1%EC%9E%A5.%EC%8A%A4%ED%94%84%EB%A7%81-%EC%BD%94%EC%96%B4/","title":"01. 스프링 코어","section":"스프링 5 레시피","content":" 스프링 코어 # 아래 클래스는 스프링 IoC 컨테이너 (이하 IoC 컨테이너) 가 스캐닝한다.\n자바 구성 클래스 (Java Configuration Class)\n@Configuration @Bean 자바 컴포넌트 클래스 (Java Component Class)\n@Component @Controller @Service @Repository @Configuration public class SequenceGeneratorConfiguration { @Bean public SequenceGenerator sequenceGenerator() { SequenceGenerator seqGen = new SequenceGenerator(); ... return seqGen } } 스프링은 @Configuration 의 클래스를 스캐닝하면, 그 안에서 (Bean 인스턴스를 생성해 반환하는) @Bean 자바 메소드를 찾는다.\n기본적으로 Bean 의 이름은 메소드 명을 따라간다. Bean 의 이름을 따로 명시하려면 @Bean 의 name 값을 설정한다.\nIoC 컨테이너 # 위의 Annotation(@Configuration, @Bean, @Component, \u0026hellip;) 를 스캐닝하기 위해선, 우선 Ioc 컨테이너를 인스턴스화 해야 한다.\n즉, IoC 컨테이너를 먼저 생성해야 한다.\n스프링은 2 종류의 IoC 컨테이너(구현체, 인터페이스 등)를 제공한다.\nBean Factory Application Context (* Application Context 는 빈 팩토리를 확장하기에, 되도록 Application Context 를 사용하는 것을 권장한다.)\nApplication Context (인터페이스)의 구현체는 여러 개 있지만, 그 중 AnnotationConfigApplicationContext 를 권장한다.\n(IoC 인터페이스) (IoC 구현체) (자바 구성 클래스) ApplicationContext context = new AnnotationConfigApplicationContext(SequenceGeneratorConfiguration.class); IoC 컨테이너에서 POJO 인스턴스(이하 빈) 가져오기 # // context.getBean(\u0026#34;빈 이름\u0026#34;) 은 Object 형태를 return 한다. SequenceGenerator generator = (SequenceGenerator) context.getBean(\u0026#34;sequenceGenerator); // context.getBean(\u0026#34;빈 이름\u0026#34;, \u0026#34;타입\u0026#34;) 의 형태도 가능하다. SequenceGenerator generator = context.getBean(\u0026#34;sequenceGenerator, SequenceGenerator.class); ( * Bean 이 한 개라면 빈 이름을 생략할 수 있다. )\n@Component 로 Bean 생성하기 # public class Sequence { ... } public interface SequenceDao { ... } @Component(\u0026#34;sequenceDao\u0026#34;) \u0026lt;-- @Component 사용, Bean ID 는 sequenceDao public class SequenceDaoImpl implements SequenceDao { ... } @Component 에 이름을 설정하지 않으면 class 명의 camel-case 형태로 bean ID 가 설정된다.\n@Component 는 Spring 이 스캐닝할 수 있도록 POJO 에 붙이는 범용 Annotation 이다.\nSpring 에는 세 계층이 있다.\nPersistence Layer Service Layer Persentation Layer @Component : 범용 Annotation @Repository : Persistence(영속성) 계층을 위한 Annotation @Service : Service(서비스) 계층을 위한 Annotation @Controller : Presentation(표현) 계층을 위한 Annotation POJO 의 쓰임새(목적)이 명확하지 않을 땐 @Component 를 사용해도 된다. 그러나 되도록 (목적에 맞는) 구체적인 Annotation 을 사용하는 것을 권장한다.\n컨테이너 스캐닝 시, 필터(필터링) 적용 (필터로 IoC 컨테이너 초기화) # ( * 스캐닝 하는 객체가 많아 질 때, 모든 패키지를 스캐닝하면 불필요하게 속도가 느려질 수 있다. )\nSpring 이 지원하는 필터 표현식 은 4 종류이다.\nannotation assignable (assignable_type) regex aspectj @ComponentScan( includeFilters = { @ComponentScan.Filter( type = FilterType.REGEX, pattern = { \u0026#34;com.gg-pigs.*Dao\u0026#34;, \u0026lt;-- 해당 패키지 내의 Dao 로 끝나는 클래스 스캐닝 (@Component 등의 Annotation 이 없어도 스캐닝 된다.) \u0026#34;com.gg-pigs.*Service\u0026#34; \u0026lt;-- 해당 패키지 내의 Service 로 끝나는 클래스 스캐닝 } ) }, excludeFilters = { @ComponentScan.Filter( type = FilterType.ANNOTATION, classes = {org.springframework.stereotype.Controller.class} \u0026lt;-- @Controller 클래스 제외 ) } ) POJO 의 의존성 해결 # Setter 이용 @Autowired 이용 (+ @Primary, @Qualifier) @Primary : 타입이 같은 클래스(구현체)가 여럿일 때, 우선순위를 부여한다. @Qualifier : 타입이 같은 클래스(구현체)가 여럿일 때, 이름으로 무엇을 사용할지 결정할 수 있다. @Resource 이용 @Inject 이용 // Setter 사용 @Configuratin public class SequenceConfiguration { @Bean public DatePrefixGenerator datePrefixGenerator() { DatePrefixGenerator dpg = new DatePrefixGenerator(); dpg.setPattern(\u0026#34;yyyyMMdd\u0026#34;); return dpg; } @Bean public SequenceGenerator sequenceGenerator() { SequenceGenrator sequence = new SequenceGenrator(); ... sequence.setPrefixGenerator(datePrefixGenerator()); \u0026lt;-- 위의 datePrefixGenerator 메소드 (Bean 이름) return sequence; } } // Autowired 사용 @Service public class SequenceService { @Autowired private SequenceDao sequenceDao; public void setSequenceDao(SequenceDao sequenceDao) { \u0026lt;-- @Autowired 를 위해, 이 setter 가 필요한 것으로 알고 있음 this.sequenceDao = sequenceDao; } ... } // Autowired 사용 @Service public class SequenceService { @Autowired \u0026lt;-- 위와 동일한 예제, Setter 메소드에 적용했을 경우이다. public void setSequenceDao(SequenceDao sequenceDao) { \u0026lt;-- @Autowired 를 위해, 이 setter 가 필요한 것으로 알고 있음 this.sequenceDao = sequenceDao; } ... } // 생성자의 경우에도 가능하다. // Spring 4.3 이상의 버전부터는 생성자가 하나뿐인 클래스에서는 @Autowired 를 생략해도 된다. (기본으로 적용된다.) // Resource 사용 public calss SequeceGenerator { @Resource private PrefixGenerator prefixGenerator; } // Inject 사용 public class SequenceGenerator { @Inject pirvate PrefixGenerator prefixGenerator; } POJO Scope 지정 # singleton : IoC 컨테이너 당 Bean 인스턴스 1 개 생성 prototype : 요청할 때마다 Bean 인스턴스 새롭게 생성 request : HTTP 요청 당 1 개의 Bean 인스턴스 생성 (WebApplicationContext 만 해당) session : HTTP 세션 당 1 개의 Bean 인스턴스 생성 (WebApplicationContext 만 해당) globalSession : 전역 HTTP 세션 당 1개의 Bean 인스턴스 생성 (PortalApplicationContext 만 해당 (?)) 외부 리소스(text, xml, property, image) 사용 # @PropertySource : .properties 파일 로드 가능 Resource 인터테이스 (+ @Value) : 리소스 로드 가능 // discounts.properties specialcustomer.discount=0.1 endofyear.discount=0.2 ... @Configuration @PropertySource(\u0026#34;classpath:discounts.peroperties\u0026#34;) @ComponentScan(\u0026#34;~\u0026#34;) public class ShopConfiguration { @Value(\u0026#34;${endofyear.discount:0}\u0026#34;) private double specialEndofyearDiscountField; @Bean public static PropertySourcePlaceholderConfigurer propertySourcesPlaceholderConfigurer() { return new PropertySourcesPlaceholderConfigurer(); } @Bean public Product dvdrw() { ~~ } } // POJO class public class BannerLoader { private Resource banner; public void setBanner(Resource banner) { this.banner = banner; } @PostConstruct \u0026lt;-- Bean 생성 후 실행된다. public void showBanner() throws IOException { Files.lines(Paths.get(banner.getURI()), Charset.forName(\u0026#34;UTF-8)).forEachOrdered(System.out::println); } } // Configuration class @Configuration @PropertySource(\u0026#34;classpath:discounts.properties\u0026#34;) @ComponentScan(\u0026#34;~\u0026#34;) public class ShopConfiguration { @Value(\u0026#34;classpath:banner.txt\u0026#34;) \u0026lt;-- classpath 에 위치한 banner.txt 파일 private Resource banner; @Bean public static PropertySourcesPlaceholderConfigurer propertySourcesPlaceholderConfigurer() { ~~ } @Bean public BannerLoader bannerLoader() { BannerLoader bl = new BannerLoader(); bl.setBanner(banner); return bl; } } public class Main { public static void main(String[] args) throws Exception { ... Resource resource = new ClassPathResource(\u0026#34;discounts.properties\u0026#34;); \u0026lt;-- .properties 파일 읽어들인 후, Resource 객체로 캐스팅 Properties props = PropertiesLoaderUtils.loadProperties(resource); \u0026lt;-- Resource 객체를 Properteis 객체로 변환 System.out.println(props); \u0026lt;-- Properties 내용 출력 } } ClassPathResource : classpath 내부의 리소스 로딩 FileSystemResource : 외부 파일시스템의 리소스 로딩 URIResource : URL 상의 외부 리소스 로딩 Locale 별 다국어 지원 (with Properties) # MessageSource 인터페이스\nResource bundle 메세지를 처리하는 메서드가 몇 가지 정의되어 있다. 가장 많이 사용되는 구현체 : ResourceBundleMessageSource, 로케일 별로 분리된 Resource bundle message 를 해석 @Configuration public class ShopConfiguration { // Bean 이름(메소드명)은 반드시 \u0026#39;messageSource\u0026#39; 로 작성해야, ApplicationContext 가 알아서 감지한다. @Bean public ReloadableResourceBundleMessageSource messageSource() { ReloadableResourceBundleMessageSource messageSource = new ReloadableResourceBundleMessageSource(); messageSource.setBasenames(\u0026#34;classpath:messages\u0026#34;); messageSource.setCacheSeconds(1); return messageSource; } } \u0026lsquo;영어\u0026rsquo; 의 로케일을 사용할 때, (자동으로) 아래와 같은 순서를 탐색한다. (?)\nmessages_en_US.properties messages_en.properties messages.properties POJO 초기화/폐기 커스터마이징 (with Annotation) # 특정한 POJO 는 사용하기 전, 특정한 초기화 작업을 거친다. 예를 들어 File 열기, DB 연결, 메모리 할당 등의 선행 작업이 필요한 경우가 있을 수 있다. (대개 이런 경우 폐기 할 때에도 특정한 작업을 해주어야 한다.)\n@Bean 의 속성에 initMethod, destroyMethod 속성을 사용할 수 있다. (초기화, 폐기 콜백 메서드로 인지한다.) @PostConstruct, @PreDestroy 어노테이션을 사용할 수 있다. 이 외에 @Lazy, @DependsOn 의 어노테이션 등이 있다. // 1) @Bean 속성의 initMethod, destroyMethod 속성을 사용한다. public class Cashier { ... public void openFile() throws IOException { ... } ... public void closeFile() throws IOException { ... } } @Configuration public class ShopConfiguration { @Bean(initMethod = \u0026#34;openFile\u0026#34;, destroyMethod = \u0026#34;closeFile\u0026#34;) \u0026lt;-- 해당하는 POJO 클래스의 메소드이다. public Cashier cashier() { ... } } // 2) @PostConstruct, @PreDestroy 어노테이션을 사용한다. @Component \u0026lt;-- 1) 번 예제와의 차이점이다. 해당 클래스는 직접 @Component 를 붙인 클래스이다. public class Cashier { ... @PostConstruct public void openFile() throws IOException { ... } ... @PreDestroy public void closeFile() throws IOExcetpion { ... } } 기본적으로 스프링은 모든 POJO 를 eager 초기화한다. @Lazy 를 붙이면 lazy 초기화로 변경할 수 있다.\nlazy 초기화를 하면, 애플리케이션이 요구하거나 다른 POJO 가 참조하여 사용되기 전까지 초기화되지 않는다.\n@Component @Scope(\u0026#34;prototype\u0026#34;) @Lazy public class ShoppingCart { private List\u0026lt;Product\u0026gt; items = new ArrayList\u0026lt;\u0026gt;(); ... } @DependsOn 을 사용하여 초기화 순서를 지정할 수 있다. 예를 들어 어떤 POJO 가 다른 POJO 보다 먼저 초기화되도록 지정할 수 있다.\n@Configuration public class SequenceConfiguration { @Bean @DependsOn(\u0026#34;datePrefixGenerator\u0026#34;) public SequenceGenerator sequenceGenerator() { // datePrefixGenerator 를 DependsOn 한다고 해서 여기에 datePrefixGenerator 빈을 사용할 필요는 없다. SequenceGenerator s = new SequenceGenerator(); return s; } } 후처리기를 이용하여 POJO 검증/수정하기 # Bean post-processor(Bean 후처리기) 를 사용하여 초기화 콜백 메소드(initMethod, @PostConstruct) 전후에 원하는 로직을 추가할 수 있다.\nBean 후처리기의 주요한 특징은, IoC 컨테이너 내부의 모든 Bean 인스턴스를 대상으로 한다는 점이다.\n보통 Bean property 가 올바른지 검사하거나, 어떤 기준에 따라 Bean property 를 변경하거나, 전체 Bean 인스턴스를 상대로 어떤 작업을 수행하기 위한 목적으로 사용된다.\nBean 후처리기는 BeanPostProcessor 인터페이스를 구현한 객체이다. 스프링은 이 인터페이스를 구현한 Bean 을 발견하면 자신이 관리하는 모든 Bean 인스턴스에 postProcessBeforeInitialization(), postProcessAfterInitalization() 메소드를 적용한다.\n@Component public class AuditCheckBeanPostProcessor implements BeanPostProcessor { @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeanException { ... return bean; \u0026lt;-- 인자로 받은 원본 bean 을 무조건 반환해야 한다. } @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeanException { ... // 만약 특정한 Bean 만 처리하고 싶다면 아래와 같은 로직을 사용할 수 있을 것이다. if (bean instanceof 특정클래스) { ~~~ } return bean; \u0026lt;-- 인자로 받은 원본 bean 을 무조건 반환해야 한다. } } @Required 로 속성이 설정되었는지 검사할 수 있다.\n설정 여부만 검사할 수 있다. null인지, 다른 값인지는 검사하지 않는다.\n스프링의 Bean 후처리기 RequiredAnnotationBeanPostProcessor 가 @Required 를 붙인 값들이 설정되었는지 체크한다.\n값이 설정되어 있지 않다면, BeanInitializationException 예외를 던진다.\npublic class SequenceGenerator { private PrefixGenerator prefixGenerator; private String suffix; ... @Required public void setPrefixGenerator(PrefixGenerator prefixGenerator) { this.prefixGenerator = prefixGenerator; } @Required public void setSuffix(String suffix) { this.suffix = suffix; } } 팩토리(정적 메소드, 인스턴스 메소드, Spring FactoryBean)로 POJO 생성 # @Bean 메소드 내부에서 팩토리 메소드를 호출해서 POJO 를 생성할 수 있다.\nSpring 은 FactoryBean 인터페이스를 상속한 템플릿 클래스 AbstractFactoryBean 을 제공한다\n정적 팩토리 메소드로 POJO 생성\n일반 자바 구문을 활용한 케이스이다.\npublic class ProductCreator { // 정적 팩토리 메소드 public static Product createProduct(String productId) { if(\u0026#34;aaa\u0026#34;.equals(productId)) { return new Battery(\u0026#34;AAA\u0026#34;, 2.5); } else if(\u0026#34;bbb\u0026#34;.equals(productId)) { return new Disc(\u0026#34;CD-RW\u0026#34;, 1.5); } ... } throw new IllegalArgumentException(\u0026#34;Unknown product\u0026#34;); } @Configuration public class ShopConfiguration { @Bean public Product aaa() { return ProductCreator.createProduct(\u0026#34;aaa\u0026#34;); \u0026lt;-- 정적 팩토리 메소드 사용 } ... } 인스턴스 팩토리 메소드로 POJO 생성\npublic class ProductCreator { // Map 을 사용하여 팩토리 메소드를 구현할 수도 있다. // private Map\u0026lt;String, Product\u0026gt; products; public Product createProduct(String productId) { if(\u0026#34;aaa\u0026#34;.equals(productId)) { return new Battery(\u0026#34;AAA\u0026#34;, 2.5); } else if(\u0026#34;bbb\u0026#34;.equals(productId)) { return new Disc(\u0026#34;CD-RW\u0026#34;, 1.5); } ... } } @Configuration public class ShopConfiguration { @Bean public ProductCreator productCreatorFactory() { ProductCreator factory = new ProductCreator(); \u0026lt;-- 인스턴스 팩토리 메소드를 사용한다. ... return factory; } @Bean public Product aaa() { return productCreatorFactory().createProduct(\u0026#34;aaa\u0026#34;); \u0026lt;-- 위에서 정의된 Bean 을 사용한다. } ... } 스프링 팩토리 빈으로 POJO 생성하기\n(Custom)FactoryBean 은 AbstractFactoryBean 제네릭 클래스를 상속한다.\ncreateInstance() 메소드를 오버라이드 하여 Bean 인스턴스를 생성한다. getObject() 메소드를 오버라이드 하여 자동으로 주입될 수 있도록 한다. (?) 위에서 언급된 팩토리 메소드들과 유사하지만, Bean 생성 도중 IoC 컨테이너가 식별할 수 있는 스프링의 전용 Bean 이다. (?) public class DiscountFactoryBean extend AbstractFactoryBean\u0026lt;Product\u0026gt; { private Product product; private double discount; // setter ... @Override public Class\u0026lt;?\u0026gt; getObjectType() { return product.getClass(); } @Override protected Product createInstance() throws Exception { product.setPrice(product.getPrice() * (1 - discount)); return product; } } @Configuration public class ShopConfiguration { @Bean public Battery aaa() { Battery aaa = new Battery(~); return aaa; } ... @Bean public DiscountFactoryBean discountFactoryBeanAAA() { DiscountFactoryBean factory = new DiscountFactoryBean(); factory.setProduct(aaa()); \u0026lt;-- 위에서 정의된 Bean (aaa) factory.setDiscount(0.2); return factory; } ... } Spring environment, profile 마다 다른 POJO 로딩 # (예를 들어, 동일한 POJO 인스턴스를 개발/테스트/운영 환경별로 초기값을 달리하고 싶을 때)\n자바 Configuration Class 를 여러 개 생성하고, 각 클래스마다 Bean 을 정리한다. 의도를 잘 표현할 수 있게 Profile 을 명명한다. ApplicationContext 에서 해당하는 Profile 을 설정하여, 해당 POJO 들을 갖고온다. @Profile 활용\n@Configuration @Profile(\u0026#34;global\u0026#34;) public class ShopConfigurationGlobal { ... } @Configuration @Profile({\u0026#34;summer\u0026#34;, \u0026#34;winter\u0026#34;}) public class ShopConfigurationSumWin { ... } 자바 Configuration Class 에 속한 Bean 들은 해당 profile 에 편입된다.\nProfile 로드하기\nProfile을 Application에 로드하기 위해서 먼저 해당 profile 을 활성화(activation)한다. 프로파일 여러 개를 한 번에 로드하는 것도 가능하다. Java Runtime Flag, WAR 파일 초기화 매개변수를 지정해 로드할 수 있다. 기본 프로파일이 있어야 하며, 스프링은 활성화시킬 프로파일이 없다면 기본 프로파일을 찾아 적용시킨다. AnnotationConfigApplicationContext context = new AnnotationConfigApplicationContext(); context.getEnvironment().setActiveProfiles(\u0026#34;global\u0026#34;, \u0026#34;winter\u0026#34;); \u0026lt;-- 프로파일을 활성화한다. context.scan(~); countext.refresh(); -Dspring.profiles.active=global,winter \u0026lt;-- 프로파일을 활성화한다. POJO에서 IoC 컨테이너의 리소스 확인 # * 컴포넌트(POJO) -\u0026gt; IoC 컨테이너 에 의존관계를 맺는(직접 접근하는(?)) 설계는 바람직하지 않다. 그러나 때로는 Bean(POJO)에서 컨테이너의 리소스를 인지해야 할 수 있다.\nBean 이 IoC 컨테이너 리소스를 인지하려면 Aware 인터페이스를 구현해야 한다.\n자주 쓰이는 Aware 인터페이스 종류\nBeanNameAware : IoC 컨테이너에 구성한 인스턴스의 Bean 이름 BeanFactoryAware : 현재의 BeanFactory 를 호출하는 데 쓰인다. ApplicationContextAware : 현재의 ApplicationContext 를 호출하는 데 쓰인다. MessageSourceAware : MessageSource, 텍스트 메세지를 해석하는 데 쓰인다. ApplicationEventPublisherAware : ApplicationEvent(Publisher) 를 발행하는 데 쓰인다. ResourceLoaderAware : ResourceLoader 를 로드하는 데 쓰인다. EnvironmentAware : ApplicationContext 인터페이스에 엮인 Environment 인스턴스를 인지하기 위해 쓰인다. * ApplicationContext 는 MessageSource, ApplicationEventPublisher, ResourceLoader 를 상속한 인터페이스이다. 따라서 ApplicationContext 만 인지하면 이들(MessageSource, ApplicationEventPublisher, ResourceLoader)도 액세스할 수 있다. 그러나 요건을 충족하는, 최소한의 범위 내에서 Aware 인터페이스를 사용하는 것이 바람직하다.\n* 현재 Spring 최신 버전에서는 Aware 를 사용하지 않아도 된다. @Autowired 등을 통해 ApplicationContext 를 주입받을 수 있기 때문이다.\n* Aware 인터페이스를 구현한 클래스는 스프링과 엮이게 되므로 IoC 컨테이너 외부에서는 제대로 작동하지 않는다.\nAware 호출 과정(순서)\n생성자, 팩토리 메소드를 호출하여 Bean 인스턴스를 생성한다. Bean 의 속성들에 값을 주입한다. Aware 인터페이스에 정의한 setter 메소드를 호출한다. Bean 인스턴스들을 각 Bean 후처리기(postProcessBeforeInitialization()) 메소드로 넘겨 초기화 콜백 메소드를 호출한다. Bean 인스턴스들을 각 Bean 후처리기(postProcessAfterInitialization()) 메소드로 넘긴다. Bean 을 사용한다. 컨테이너가 종료되면 폐기 콜백 메소드를 호출한다. public class Cashier implements BeanNameAware { private String fileName; \u0026lt;-- Aware 인터페이스의 setter 메소드가 실행되면서 해당 속성 값이 채워진다. @Override public void setBeanName(String beanName) { this.fileName = beanName; } } @Configuration ... @Bean(~) public Cashier cashier() { final String path = System.getProperty(\u0026#34;java.io.tmpdir\u0026#34;) + \u0026#34;cashier\u0026#34;; Cashier cashier = new Cashier(); // cashier.setFileName(\u0026#34;filename\u0026#34;); \u0026lt;-- Aware setter 메소드를 통해 채워졌다. cashier.setPath(path); return cashier; } (* 제대로 이해한것인지 모르겠다.)\nAOP (with Annotation) # Aspect 를 정의하려면, 클래스에 @Aspect 를 붙이고 메소드별로 Advice 를 만든다.\nAdvice Annotation 은 다음의 종류가 있다.\n@Before @After @AfterReturning @AfterThrowing @Around IoC 컨테이너에서 Aspect Annotation 기능을 활성화하려면 Configuration Class 중 하나에 @EnableAspectJAutoProxy 를 붙인다.\n"},{"id":236,"href":"/docs/BOOKS/%EB%AA%A8%EB%93%A0-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-HTTP-%EC%9B%B9-%EA%B8%B0%EB%B3%B8-%EC%A7%80%EC%8B%9D/01_%EC%9D%B8%ED%84%B0%EB%84%B7%ED%86%B5%EC%8B%A0/","title":"01. 인터넷 통신","section":"모든 개발자를 위한 HTTP 웹 기본 지식","content":" 요약 # IP # 출발지 IP, 목적지 IP Packet 단위 사용 (Layer 3) 비연결성 패킷 받을 대상이 없는지 확인 X 패킷 받을 대상이 어떤 상태인지 알 수 X 비신뢰성 패킷을 잘 받았는지 확인 X 중간에 소실될 수 도 있음 패킷을 순서대로 잘 보냈는지 확인 X 늦게 보낸 게 더 빨리 도착할 수도 있음 프로그램 구분 X \u0026lsquo;비연결성, 비신뢰성, 프로그램 구분\u0026rsquo; 을 어떻게 해결 ?? =\u0026gt; TCP(UDP)\nTCP (혹은 UDP) # 참고 (TCP/IP Layer)\nApplication Layer : HTTP, FTP, \u0026hellip; (Applicaiton) Transport Layer : TCP, UDP (OS) Internet Layer : IP (OS) Network Interface Layer : LAN 장비/드라이버, \u0026hellip; (Ethernet) (HW) 출발지 PORT(응답 시 사용), 목적지 PORT(요청 시 사용) 연결성 (IP 의 비연결성 해결) 신뢰성 (IP 의 비신뢰성 해결) PORT (IP 의 프로그램 사용 미구분 해결) 흐름제어, 혼잡제어, 순서 등 * 현재 TCP 는 개선하기 힘들다. 이미 너무 많은 곳에서 사용하고 있기 때문. 최근 들어서는 UDP 를 활용하기 시작\n참고 1 - UDP # 비연결 비신뢰성 PORT (IP 의 프로그램 사용 미구분 해결) 체크섬 (간단한 오류 검증 정도만 사용) 즉, Application 단에서 추가적인 검증 과정이 필요할 것 참고 2 - DNS # IP 외우기 힘듬 IP 변경 가능성 "},{"id":237,"href":"/docs/BOOKS/%EB%AA%A8%EB%93%A0-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-HTTP-%EC%9B%B9-%EA%B8%B0%EB%B3%B8-%EC%A7%80%EC%8B%9D/02_URI/","title":"02. URI","section":"모든 개발자를 위한 HTTP 웹 기본 지식","content":" 요약 # URI : Uniform Resource Identifier # (통일화 된) 자원(리소스) 식별자 ..?\nURI 의 종류 # URL (Uniform Resource Locator) scheme, host, port, query parameter(string), fragment fragment 서버에 전송하는 정보 X html 내부 북마크 등에 사용 URN (Uniform Resource Name) URN 이 잘 안쓰이는 이유? 자원을 식별하기 위해서는 \u0026lsquo;고유\u0026rsquo;해야한다. \u0026lsquo;이름\u0026rsquo;으로 \u0026lsquo;고유성\u0026rsquo;을 갖기는 힘들지 않을까..? 이름을 고유한 번호 형태로 부여할 수도 있을텐데(e.g. ISBN) 이렇게 되면, 식별하기 어려울 것이다.\n반변 \u0026lsquo;Locator\u0026rsquo; 기반으로 하면 (애초에)IP(서버) 가 다 다르니까 \u0026lsquo;고유성\u0026rsquo;을 갖기 더 수월하지 않을까..?\n"},{"id":238,"href":"/docs/BOOKS/%EA%B0%80%EC%83%81-%EB%A9%B4%EC%A0%91-%EC%82%AC%EB%A1%80%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88/02_%EA%B0%9C%EB%9E%B5%EC%A0%81%EC%9D%B8-%EA%B7%9C%EB%AA%A8-%EC%B6%94%EC%A0%95/","title":"02. 개략적인 규모 추정","section":"가상 면접 사례로 배우는 대규모 시스템 설계 기초","content":" 2장 개략적인 규모 추정 # 구글의 시니어 펠로(senior fellow) 제프 딘(Jeff Dean)에 따르면, \u0026ldquo;개략적인 규모 추정\u0026quot;은 보편적으로 통용되는 성능 수치상에서 사고 실험을 행하여 추정치를 계산하는 행위로서, 어떤 설계가 요구사항에 부합할 것인지 보기 위한 것이다.\n개략적 규모 추정을 효과적으로 해내려면 규모 확장성을 표현하는 데 필요한 기본기에 능숙해야 한다.\n특히 2의 제곱수, latency(응답 지연), throughput(처리량, 처리율), 가용성과 관련된 수치들을 잘 이해하고 사용할 수 있어야 한다.\n2의 제곱수 # 2^n 근사치 단위 2^10 1,000 (1천) KB 2^20 1,000,000 (1백만) MB 2^30 1,000,000,000 (10억) GB 2^40 1,000,000,000,000 (1조) TB 2^50 1,000,000,000,000,000 (1,000조) PB Latency (모든 프로그래머가 알야아 하는 응답 지연 값) # 구글의 제프 딘은 2010년에 통상적인 (컴퓨터에서 구현된 연산들의) 응답 지연 값을 공개한 바 있다.\n이들 가운데 몇몇은 더 빠른 컴퓨터가 등장하면서 유효하지 않게 되었지만, 아래 표를 통해 대략적인 수치를 짐작할 수 있다.\n연산 시간 L1 캐시 0.5ns Branch mispredict (분기 예측 오류) 5ns L2 캐시 7ns Mutex lock/unlock 100ns Main Memory 참조 100ns Zippy 1KB 압축 10,000ns = 10μs 1 Gbps 네트워크에서 2KB 전송 20,000ns = 20μs Memory 순차적 1MB READ (메모리에서 순차적으로 1MB READ) 250,000ns = 250μs (같은) IDC 내에서의 네트워크 왕복 지연시간 500,000ns = 500μs Disk Seek 디스크 탐색 10,000,000ns = 10ms 네트워크에서 1BM 순차적으로 READ 10,000,000ns = 10ms DISK에서 1MB 순차적 READ 30,000,000ns = 30ms 1 패킷의 CA(캘리포니아)로부터 네덜란드까지의 왕복 지연시간 150,000,000ns = 150ms 위 표를 조금 정리해보면,\n연산 시간 L1 캐시 0.5ns L2 캐시 7ns L1 에 비해 10배 이상의 비용이 든다. Main Memory 참조 100ns L2 에 비해(CPU 참조에 비해) 최소 10배 이상의 비용이 든다. 메모리에서 순차적 1MB READ 250,000ns = 250μs (같은) IDC 내에서의 네트워크 왕복 지연시간 500,000ns = 500μs Disk Seek\n(디스크 탐색) 10,000,000ns = 10ms 네트워크에서 순차적 1MB READ 10,000,000ns = 10ms DISK에서 순차적 1MB READ 30,000,000ns = 30ms 1 패킷의 CA(캘리포니아)로부터 네덜란드까지의 왕복 지연시간 150,000,000ns = 150ms # (이 측정을 비교하는 것은 의미가 없겠지만) 대략적으로 어느정도 차이가 나는지 이해하자. CPU 참조 (0.5 ~ 10ns) ㄴ Main Memory 참조 (100ns ~ 250,000ns) (최소 10배 이상) ㄴ DISK 참조 \u0026amp; 네트워크 참조 (10ms ~ ) (최소 4배 이상) 한 구글 엔지니어가 위의 딘 박사가 나열한 것을 토대로 2020년 기준으로 수치화한 내용도 있다.\n연산 시간 L1 캐시 1ns Branch mispredict (분기 예측 오류) 3ns L2 캐시 4ns Mutex lock/unlock 17ns 일반 상용 네트워크에서 2KB 전송 44ns 이 기준으로 1MB 이면 22,000ns(22μs) 기술/성능이 좋아져서인지? 제프 딘이 발표한 내용(10ms)보다 적은 비용(22μs)이 든다고 표시했다. Main Memory 참조 100ns Zippy 1KB 압축 2,000ns = 2μs 기술/성능이 좋아져서인지? 제프 딘이 발표한 내용(102μs)보다 적은 비용(2μs)이 든다고 표시했다. Memory 순차적 1MB READ 3,000ns = 3μs 기술/성능이 좋아져서인지? 제프 딘이 발표한 내용(250μs)보다 적은 비용(3μs)이 든다고 표시했다. SSD(Disk)에서 임의 위치의 데이터 읽기 (Random Access) 16,000ns = 16μs SSD(Disk)에서 순차적 1MB READ 49,000ns = 49μs (같은) IDC 내에서의 네트워크 왕복 지연시간 500,000ns = 500μs 제프 딘이 발표한 내용과 동일하다. DISK에서 1MB 순차적 READ 825,000ns = 825μs 기술/성능이 좋아져서인지? 제프 딘이 발표한 내용(30ms)보다 적은 비용(825μs)이 든다고 표시했다. Disk Seek 디스크 탐색 2,000,000ns = 2ms 기술/성능이 좋아져서인지? 제프 딘이 발표한 내용(10ms)보다 적은 비용(2ms)이 든다고 표시했다. DISK에서 1MB 순차적 READ 30,000,000ns = 30ms 1 패킷의 CA(캘리포니아)로부터 네덜란드까지의 왕복 지연시간 150,000,000ns = 150ms 제프 딘이 발표한 내용과 동일하다. 요약하면,\n메모리는 빠르다. 디스크는 여전히 느리다. 디스크 탐색(Disk Seek)는 가능한 피하라. 디스크 탐색(Disk Seek)은 \u0026lsquo;같은 데이터 센터 내의 네트워크 왕복 지연시간\u0026rsquo;보다 느리며, \u0026lsquo;네트워크에서 순차적으로 1MB READ\u0026rsquo; 하는 것과 동일한 비용이 발생한다. 단순한 압축 알고리즘은 빠르다. 데이터를 인터넷으로 전송하기 전에 가능하면 압축하라. 단순한 압축 알고리즘은 빠르기에, 빠르게 압축하고 네트워크에 작은 용량으로 전달하는 것이 이득이다. 데이터 센터는 보통 여려 지역(region)에 분산되어 있다. 센터들 간에 데이터를 주고 받는데에는 시간이 걸린다. Availability (가용성) # 고가용성(high availability)은 시스템이 오랜 시간 동안 지속적으로, 중단 없이 운영될 수 있는 능력을 지칭하는 용어이다.\n고가용성을 표현하는 값은 퍼센트(percent)로 표현한다.\n100%는 시스템이 단 한 번도 중단되지 않는 것을 의미한다. 대부분의 서비스는 99%~100% 사이의 값을 갖는다. Service Level Agreement(SLA) 는 Service Provider(서비스 사업자)가 보편적으로 사용하는 용어로, 서비스 사업자와 고객 사이에 맺어진 합의를 의미한다.\n이 합의에는 서비스 사업자가 제공하는 서비스의 가용시간(uptime)이 공식적으로 기술되어 있다.\n아마존, 구글, MS 같은 사업자는 99% 이상의 SLA를 제공한다. 가용시간은 관습적으로 숫자 9를 사용해 표시한다. 9가 많으면 많을수록 좋다고 보면 된다.\n아래 표는 9의 개수와 시스템 장애시간(downtime) 사이의 관계를 나타낸 표이다.\n가용률 하루 당 장애시간 주 당 장애시간 월 당 장애시간 연간 장애시간 99% 14.40분 1.68시간 7.31시간 3.65일 99.9% 1.44분 10.08분 43.83분 8.77시간 99.99% 8.64초 1.01분 4.38분 52.60분 99.999% 864ms 6.05초 26.30초 5.26분 99.9999% 86.40ms 604.80ms 2.64초 31.56초 예제: QPS \u0026amp; 미디어 저장소 요구량 추정 # [가정]\nMonthly active user : 3million (300,000,000) 50% 사용자는 매일 사용한다. 각 사용자는 평균 2건의 게시물을 올린다. Media 를 포함하는 게시물은 10% 정도다. 데이터는 5년 보관한다. [추정]\n매일 1.5명의 사용자가 사용한다. 매일 3억건의 게시물이 생성된다. 이 중 3천만 건은 미디어를 포함한 게시물이다. 1. 시간 당 게시물 생성 수\n3억 / 24 = 1,250만건 건 (12,500,000)\n2. 초당 게시물 생성 수 (생성에 대한 QPS)\n12,500,000 / 60 / 60 = 3,472건\n= 약 3,500\n3. Peek QPS 추정치\n2번의 QPS * 2 = 7,000\n4. 저장소 요구량 추정\n각 게시물당 평균 데이터의 사이즈를 다음과 같이 가정한다.\n사용자 ID : 64 Byte 본문 내용 : 140 Byte 미디어 : 1MB 미디어 저장소 요구량 = 3억 * 10% * 1MB = 30TB/일\n5년간 미디어를 보관하기 위해 필요한 저장소 요구량 = 30TB * 365 * 5 = 약 55PB\n위와 같은 방식으로 QPS, 최대 QPS, 저장소 요구량, 캐시 요구량, 서버 수 등을 추정해보는 연습을 해볼 수 있다.\n"},{"id":239,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-5-%EB%A0%88%EC%8B%9C%ED%94%BC/2%EC%9E%A5.-%EC%8A%A4%ED%94%84%EB%A7%81-MVC/","title":"02. 스프링 MVC","section":"스프링 5 레시피","content":" 스프링 MVC # MVC 는 아주 일반적인 UI 디자인 패턴이다.\nModel, View, Controller 의 역할을 분리한다. (* UI 에서 비즈니스 로직을 분리시킬 수 있다.)\nModel : Data 에만 집중한다. View : Model(Data)를 보여주는 것에만 집중한다. (렌더링에 집중한다.) Controller : 요청을 받고, 비즈니스 로직을 수행을 위해 적절히 업무를 분배한다. Front Controller # Front Controller(프론트 컨트롤러)는 Spring MVC 의 중심 컴포넌트이다.\nSpring MVC 에서 \u0026lsquo;Dispatcher Servlet\u0026rsquo; 는 Front Controller 패턴을 구현한 것이다.\nSpring의 Controller 에는 @Controller, @RestController 를 사용한다.\nController 에 요청이 들어온다. Controller 내에서 핸들러 메서드(@RequestMapping 등이 붙은 메서드)를 찾아 위임한다. 핸들러 메서드에서 비즈니스 로직이 수행된다. 비즈니스 로직 수행 후, View 를 통해 렌더링할 데이터를 만든다. Spring MVC 애플리케이션 설정 # (현재 개발 중인 GG-PIGS Spring Boot 프로젝트 기준으로) 빌드 시 다음과 같은 Directory 구조가 만들어진다. build/classes/ : class 파일들 build/libs/ : (빌드 된)jar 파일 자바 EE 명세에는 다음과 같은 디렉토리 구조가 명시되어 있다.\nWEB-INF 루트에 web.xml(웹 배포 서술자) 위치하거나 1개 이상의 ServletContainerInitializer 구현 클래스 구성하거나 (웹 애플리케이션에 필요한) 각종 class, jar 파일들은 WEB-INF/classes/, WEB-INF/lib 등에 위치 web.xml(웹 배포 서술자) 는 자바 웹 애플리케이션의 필수 구성 파일이다.\n예를 들어 서블릿 정보, 매핑 정보를 기술한다. (* DispactherServlet 은 필요 시 여러 개를 정의할 수 있다.)\npublic class CourtServletContainerInitializer implements ServletContainerInitializer { ... @Override public void onStartup(Set\u0026lt;Class\u0026lt;?\u0026gt;\u0026gt; c, ServletContext ctx) throws ServletException { // AnnotationConfigApplicationContext \u0026lt;-\u0026gt; AnnotationConfigWebApplicationContext AnnotationConfigWebApplicationContext applicationContext = new AnnotationConfigWebApplicationContext(); \u0026lt;-- IoC 컨테이너 applicationContext.register(CourtConfiguration.class); \u0026lt;-- 구성 클래스 등록 DispatcherServlet dispatcherServlet = new DispatcherServlet(applicationContext) \u0026lt;-- DispatcherServlet 에 IoC 컨테이너 등록(?) ... } } Spring MVC Controller 예시 # @Controller @RequestMapping(\u0026#34;/reservationQuery\u0026#34;) public class ReservationQueryController { private final ReservationService reservationService; public ReservationQueryController(ReservationService reservationService) { this.reservationService = reservationService; } @GetMapping public void setupForm() {} \u0026lt;-- (View 이름을 의미하는) 반환 값이 없다는 것은 url 의 이름을 따라간다는 것을 의미한다. @PostMapping public String submitForm(@RequestParam(\u0026#34;courtName\u0026#34;) String courtName, Model model) { List\u0026lt;Reservation\u0026gt; reservations = java.util.Collections.emptyList(); if(courtName != null) { reservations = reservationService.query(courtName); \u0026lt;-- 비즈니스 로직 처리 } model.addAttribute(\u0026#34;reservations\u0026#34;, reservations); \u0026lt;-- Model 에 데이터 세팅 return \u0026#34;reservationQuery\u0026#34;; } } "},{"id":240,"href":"/docs/BOOKS/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%ED%81%B4%EB%A6%B0-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/02.-%EC%9D%98%EC%A1%B4%EC%84%B1-%EC%97%AD%EC%A0%84%ED%95%98%EA%B8%B0/","title":"02. 의존성 역전하기","section":"만들면서 배우는 클린 아키텍처","content":" 02. 의존성 역전하기 # 1장에서 계층형 아키텍쳐의 단점에 대해 살펴보았고, 이번 장에서는 \u0026lsquo;대안\u0026rsquo;(SRP, DIP) 에 대해 이야기한다.\n단일 책임 원칙 (SRP) # \u0026quot; 하나의 컴포넌트는 오로지 한 가지 일만 해야 하고, 그것을 올바르게 수행해야 한다. \u0026ldquo;\n(실제로) 위 문장(하나의 컴포넌트는 오로지 한 가지 일을 해야한다.)은 \u0026lsquo;단일 책임 원칙의 실제 의도\u0026rsquo;는 아니다.\n\u0026lsquo;오로지 한 가지 일만 하는 것\u0026rsquo;은 단일 책임이라는 말을 직관적으로 해석한 것이다.\n단일 책임 원칙의 실제 정의는 다음과 같다.\n\u0026rdquo; 컴포넌트를 변경하는 이유는 오직 하나뿐이어야 한다. \u0026ldquo;\n\u0026lsquo;오로지 한 가지 일만 하는 것\u0026rsquo; 보다는 \u0026lsquo;변경할 이유는 오직 하나\u0026rsquo; 로 해석해야 한다.\n컴포넌트를 변경할 이유가 오로지 하나라면, 자연스럽게 컴포넌트는 한 가지 일만 하게 된다.\n\u0026lsquo;변경할 이유\u0026rsquo;는 컴포터는 간의 의존성을 통해 너무도 쉽게 전파된다.\n\u0026lsquo;결합도\u0026rsquo;가 커진다는 것은 \u0026lsquo;변경의 전파\u0026rsquo;가 커진다는 것을 의미하는 것과 같지 않을까? 즉, \u0026lsquo;결합도 = 변경의 전파\u0026rsquo; 많은 코드는 SRP 를 위반하기 때문에, 시간이 지날수록 변경하기 더 어려워진다.\n의존성 역전 원칙 (DIP) # \u0026rdquo; 어떤 의존성이든 그 방향을 역전시킬 수 있다. \u0026ldquo;\n사실 양쪽 코드를 모두 제어하고 있을 때에만 의존성을 역전 시킬 수 있다. (= 예를 들어, 외부 라이브러리 처럼 우리가 컨트롤 할 수 없는 경우는 안됨을 의미한다.)\n이후 그림 / 설명은 생략한다. (p16 ~ p17)\n클린 아키텍처 # 여기서부터 다시 작성할 것!!\n육각형 아키텍처 (헥사고날 아키텍처) # 유지보수 가능한 소프트웨어를 만드는데 어떻게 도움이 될까? # "},{"id":241,"href":"/docs/BOOKS/%EB%AA%A8%EB%93%A0-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-HTTP-%EC%9B%B9-%EA%B8%B0%EB%B3%B8-%EC%A7%80%EC%8B%9D/03_HTTP/","title":"03. HTTP","section":"모든 개발자를 위한 HTTP 웹 기본 지식","content":" 요약 # HTTP (HyperText Transfer Protocol) # Client - Server 구조 클라이언트 - 서버의 분리는 역할/책임 분리의 의미에서도 중요한 것 비상태성 (Stateless) 서버 확장(Scale Out) OK (클라이언트의 요청에 대해서) 항상 다른 서버가 처리 OK 클라이언트쪽에서 조금 불편 (서버 측에서 정보를 기억하는게 아니니까) 상태가 필요한 경우 : 대표 예시 -\u0026gt; 로그인 특정 서버에 구애받지 않게 독립적인(외부) 상태 저장소 사용 비연결성 연결을 유지할 경우, 수많은 클라이언트와 연결해야 하는 부담 서버 자원을 효율적으로 사용하기 위함 단순 * HyperText 란?\n\u0026quot; 하이퍼텍스트(Hypertext, 문화어: 초본문, 하이퍼본문)는 참조(하이퍼링크)를 통해 독자가 한 문서에서 다른 문서로 즉시 접근할 수 있는 텍스트이다. \u0026quot; (출처 : https://ko.wikipedia.org/wiki/하이퍼텍스트)\nHTML TEXT \u0026hellip; HTTP 역사 # HTTP/0.9\n1991년 GET 만 지원 HTTP 헤더 X HTTP/1.0\n메서드(GET, HEAD, POST), 헤더 추가 -\u0026gt; 실제로 사용되기 시작 요청마다 TCP 연결/종료 Persistent Connection(Keep-Alive) 위해서 \u0026lsquo;Connection 헤더\u0026rsquo;에 사용 HTTP/1.1\nTCP\nPersistent Connection(Keep-Alive) : Default HTTP Pipelining : 이전 요청에 대한 응답을 기다리지 않고, 새로운 요청을 보낼 수 있음 HTTP 1.0 요청1 - 응답1 요청2 - 응답2 요청3 - 응답3 HTTP 1.1 요청1, 요청2, 요청3 응답1, 응답2, 응답3 Header : Host 정보 추가 VirtualHost 사용 가능하게 됨 캐시 헤더 ?? 캐시 제어 메커니즘 콘텐츠 협상 ?? PUT, DELETE, TRACE, OPTION HTTP/2\nTCP\n2015년 성능 개선 HTTP/3\n진행중 UDP 사용 (성능 개선) HTTP 메시지 구조 # start-line (시작 라인) header (헤더) empty line (공백 라인, 필수) message body (바디) HTTP 요청 메시지 예시\nGET /search HTTP/1.1 : method path(absolute-path[?query]) http-version HOST: www.naver.com HTTP 응답 메시지 예시\nHTTP/1.1 200 OK Content-Type: ~ =\u0026gt; field-name: field-value Content-Length: ~ \u0026lt;html\u0026gt; ~~~ \u0026lt;/html\u0026gt; HTTP 헤더 HTTP 전송에 필요한 모든 부가정보\nHTTP 바디 실제 전송할 데이터 (HTML, 이미지, 영상, JSON 등의 byte로 표현할 수 있는 모든 것 = 거의 모든것이지 않을까)\n"},{"id":242,"href":"/docs/BOOKS/%EA%B0%80%EC%83%81-%EB%A9%B4%EC%A0%91-%EC%82%AC%EB%A1%80%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88/06_Key-Value-Store-%EC%84%A4%EA%B3%84/","title":"03. Key-Value Store 설계","section":"가상 면접 사례로 배우는 대규모 시스템 설계 기초","content":" Key-Value Store # 대표적인 예시 : amazon dynamodb, memcached, redis, \u0026hellip;\nKey 는 유일해야 한다.\nKey 는 짧을수록 성능 상 유리하다. Value 는 Key를 통해서만 접근할 수 있다. Value 는 다양한 자료구조(문자열, 리스트, 객체)일 수 있다.\n완벽한 설계란 없다. READ(일기), WRITE(쓰기), MEMORY USAGE(메모리 사용량) 사이에 균형(balance)을 찾고 데이터의 일관성, 가용성 사이에서 타협적 결정을 내려야 한다.\n단일 서버 Key-Value Store # 한 대의 서버만 사용하는 Key-Value Store를 설계하는 것은 쉽다. 가장 직관적으로 (인메모리)해시 테이블에 저장하면 된다. 다만, 메모리가 부족해질 수 있은이 다음 요소를 고려해볼만 할 것이다.\n데이터 압축 (compression) 자주 사용되는 데이터만 메모리에 저장, 나머지는 디스크에 저장 그러나 단일 서버의 특성 상 금방 한계가 찾아온다.\n분산 Key-Value Store 를 고려하자.\n분산 Key-Value Store # 분산 Key-Value 저장소는 \u0026lsquo;분산 해시 테이블\u0026rsquo;이라고도 불린다.\n분산 Key-Value 저장소는 Key-Value 쌍을 여러 서버에 분산시키는 것이다.\n분산 시스템을 설계할 때는 CAP(Consistency, Availability, Partition tolerance theorem)를 이해해야한다.\nCAP 정리 # CAP 정리는 (C, A, P)세 가지 요구사항을 동시에 만족하는 분산 시스템을 설계하는 것은 불가능하다는 정리다. (이들 중 두 가지를 충족하려면 나머지 하나는 반드시 희생되어야 한다.)\n요구사항 설명 C (consistency, 일관성) 분산 시스템을 사용하는 모든 클라이언트는 어떤 노드에 접속하더라도 언제나 같은(일관성 있는)데이터를 사용/볼 수 있어야 한다. A (Availability, 가용성) 일부 노드에 장애가 발생하더라도 항상 정상 처리(응답)될 수 있어야 한다. P (Partition tolerance, 파티션 허용/내성) 네트워크에 파티션이 생기더라도 시스템은 계속 동작하여야 한다. * 파티션은 두 노드 사이에 통신 장애가 발생했음을 의미한다. Key-Value 저장소는 어떤 두 가지를 만족시키느냐에 따라 다음과 같이 분류할 수 있다.\n시스템 설명 CP 시스템 일관성, 파티션 허용을 지원하는 Key-Value 저장소. 가용성을 희생한다. CA 시스템 일관성, 가용성을 지원하는 Key-Value 저장소. 파티션 허용을 희생한다. 통상 네트워크 장애는 피할 수 없는 일로 여겨지므로, 분산 시스템은 반드시 파티션 문제를 감내할 수 있도록 설계되어야 한다.\n그러므로 실세계에 CA 시스템은 존재하지 않는다. AP 시스템 가용성, 파티션 허용을 지원하는 Key-Value 저장소. 일관성을 희생한다. 분산 시스템에서의 CAP 예시 # 서로 연결되어 있는, 복제되고 있는 n1, n2, n3 노드가 있다.\nn1 | | | n2 ----------------- n3 이때, n3 노드에서 장애가 발생했다. n1-n3, n2-n3 사이에 파티션이 발생했다.\n(= n3의 최신 데이터가 n1과 n2에 제대로 반영되지 않았다고 가정하자.)\n이 상황에서 우리의 분산 시스템은 일관성, 가용성 중 하나를 선택해야 한다.\n일관성 선택 (= CP 시스템)\n일관성을 선택했다면, n1, n2 의 쓰기/읽기 연산을 중지해야 한다. 이유는 n3의 최신 데이터가 n1, n2에 반영되지 않았을테니까. 최신 데이터로 업데이트 될 때까지 클라이언트에게 데이터를 제공할 수 없다. (즉, 가용성이 깨진다.)\n흔한 예시로, 은행권 시스템은 일관성을 우선적으로 지킨다.\n가용성 선택 (= AP 시스템)\n최신 데이터가 아닌, 오래된 데이터를 제공하더라도 n1, n2 노드에서는 연산을 허용한다.\n파티션 문제가 해결된 뒤 n1-n3, n2-n3 사이의 동기화가 이뤄질 것이다.\nKey-Value Store 시스템 컴포넌트 # Key-Value Store 에 사용되는 핵심 컴포넌트들을 살펴보자.\n데이터 파티션 Replication (데이터 다중화) Consistency (데이터 일관성) Inconsistency resolution (일관성 불일치 해소) 장애 처리 시스템 아키텍처 다이어그램 쓰기 경로 (write path) 읽기 경로 (read path) 시스템 컴포넌트 : 데이터 파티션 # 위에서 잠깐 언급했지만, 대규모 애플리케이션의 경우 전체 데이터를 한 대의 서버에서 처리하는 것은 한계가 있다. 해결책은 데이터들을 작은 파티션들로 분할하여 여러 대의 서버에 저장하는 것이다. (= 분산 시스템)\n데이터를 파티션 단위로 나눌 때, 다음 두 가지를 중요하게 따져봐야 한다.\n데이터를 여러 서버에 고르게 분산할 수 있는가? 노드가 추가되거나 삭제될 때 데이터의 이동(리밸런싱)을 최소화할 수 있는가? (계속)\n"},{"id":243,"href":"/docs/BOOKS/Real-Mysql-8.0/03_%EC%82%AC%EC%9A%A9%EC%9E%90-%EB%B0%8F-%EA%B6%8C%ED%95%9C/","title":"03. 사용자 및 권한","section":"Real Mysql 8.0","content":"MySQL 사용자 계정 = 사용자 ID, 호스트(사용자 IP) 구성\nMySQL 8.0 부터는 Role(역할) 개념이 도입되었다. Role 을 부여함으로써, 미리 준비된 권한들을 부여할 수 있다.\n3.1 사용자 식별 # 사용자 계정\n사용자 ID 호스트(사용자 IP, 도메인) 아래와 같이 동일한 두 계정이 있다면, 로그인 시 좁은 범위의 계정이 선택된다.\n`test`@`127.0.0.1` (pw : 123) `test`@`%` (pw : abc) (로컬호스트 환경에서) test 계정으로 로그인 시, test@127.0.01 계정으로 로그인을 시도 한다.\n3.2 사용자 계정 관리 # Mysql 8.0 부터는 SYSTEM_USER 권한을 가지고 있느냐에 따라, \u0026lsquo;시스템 계정(System Account)\u0026rsquo;, \u0026lsquo;일반 계정(Regular Account)\u0026rsquo; 로 구분된다.\n시스템 계정 : DB 서버 관리자 시스템 계정 / 일반 계정 관리 O DB 서버 관리 등의 중요 작업 수행 O 계정 관리 세션 / 쿼리 종료 등 일반 계정 : DB 일반 사용자 (개발자 등) Mysql 5.7 까지는 GRANT 명령어를 통해 \u0026lsquo;계정 생성\u0026rsquo; + \u0026lsquo;권한 부여\u0026rsquo;가 한번에 가능했다.\nMysql 8.0 부터는 계정 생성(CREATE USER), 권한 부여(GRANT) 명령어를 구분하여 실행한다.\nCREATE USER `user`@`%` IDENTIFIED WITH `mysql_native_password` BY `password` # 인증 방식 (및 비밀번호 설정) REQUIRE NONE # (서버 접속 시) 암호화된 SSL/TLS 채널 사용 여부 결정 PASSWORD EXPIRE INTERVAL 30 DAY # 비밀번호 만료 기간 설정 ACCOUNT UNLOCK # 계정 잠금 / 해제 설정 PASSWORD HISTORY DEFAULT # 비밀번호 이력 설정 PASSWORD REUSE INTERVAL DEFAULT # 비밀번호 재사용 이력 설정 PASSWORD REQUIRE CURRENT DEFAULT; # 비밀번호 변경 시 현재 비밀번호 입력 여부 설정 인증 방식에 대해서는 여러 종류가 있다고 하니, 상세한 내용은 별도로 확인해볼 것.\n3.3 비밀번호 관리 # validate_password\n다음과 같은 관리를 할 수 있다.\n비밀번호 유효기간 설정 (이력 관리를 통한) 재사용 금지 기능 금칙어 설정 기능 validate_password 컴포넌트 설치/적용 (Mysql 5.7 : validate_password 플러그인) LOW : 비밀번호 길이만 검증 MEDIUM : LOW + 숫자, 대소문자, 특수문자 조합 검증 STRONG : MEDIUM + 금칙어 포함 여부 검증 Dual Password\n하나의 계정에 2개의 비밀번호(Primary, Secondary) 사용 가능\n* 보통 실무에서 사용 중인 비밀번호는 못바꾸는 경우가 많다. (바꾸려면 잠깐 서비스를 중단해야 한다.) 이런 경우 dual password 를 사용할 수 있다.\n3.4 권한 (Privilege) # * Mysql 5.7 까지, \u0026lsquo;글로벌 권한\u0026rsquo;, \u0026lsquo;객체 권한\u0026rsquo;으로 구분했다. (\u0026lsquo;정적 권한\u0026rsquo; 이라고도 한다.) * Mysql 8.0 에서는, \u0026lsquo;동적 권한\u0026rsquo; 이 추가되었다. 정적 권한 : Mysql 소스코드에 (고정적으로)명시되어 있는 권한 동적 권한 : (Mysql 서버가 시작되면서) 동적으로 생성하는 권한 예시 : 컴포넌트, 플러그인이 설치되었을 때 등록되는 권한 글로벌 권한 : 글로벌에 적용하는 권한 (DB, 테이블에 적용하는 것 X) 객체 권한 : DB, Table 에 적용하는 권한 * 객체 권한을 (테이블의) 컬럼에 적용할 수 있다. 다만, 컬럼 단위의 권한이 하나라도 설정되면 나머지 모든 테이블의 모든 컬럼에 대해서도 권한 체크를 진행한다. 따라서 전체적인 성능에 영향을 미칠 수 있다.\n3.5 역할 (Role) # * Mysql 8.0 부터 생긴 개념이다.\n내부적으로 \u0026lsquo;계정\u0026rsquo;과 동일하다.\n# \u0026#39;역할\u0026#39; 생성 CREATE ROLE role_emp_read, role_emp_write; # \u0026#39;역할\u0026#39;에 권한 부여 GRANT SELECT ON employees.* TO role_emp_read; GRANT INSERT, UPDATE, DELETE ON employees.* TO role_emp_write; # \u0026#39;계정\u0026#39; 생성 CREATE USER `reader`@`127.0.0.1` IDENTIFIED BY \u0026#39;qwerty\u0026#39;; CREATE USER `writer`@`127.0.0.1` IDENTIFIED BY \u0026#39;qwerty\u0026#39;; # \u0026#39;계정\u0026#39;에 \u0026#39;역할\u0026#39; 부여 GRANT role_emp_reader TO `reader`@`127.0.0.1`; GRANT role_emp_writer TO `writer`@`127.0.0.1`; # \u0026#39;역할(권한)\u0026#39; 활성화 SET ROLE \u0026#39;role_emp_read\u0026#39;; SET ROLE \u0026#39;role_emp_writer\u0026#39;; 아래의 쿼리 시 \u0026lsquo;계정\u0026rsquo;, \u0026lsquo;역할\u0026rsquo; 모두 보여진다.\nselect user, host, account_locked from mysql.user; * \u0026lsquo;계정\u0026rsquo;, \u0026lsquo;역할\u0026rsquo;을 어떻게 구별하나?\n구별할 필요가 없다. 하나의 계정의 권한을 다른 계정의 권한에 병합하는 개념이다. 기본적으로 \u0026lsquo;역할\u0026rsquo;에는 account_locked (Y) 값을 통해 직접 로그인하지 못하도록 한다. 실제로 \u0026lsquo;역할\u0026rsquo;은 \u0026lsquo;계정\u0026rsquo;처럼 사용될 수도 있다. 그럼에도 역할과 계정을 나눈 이유는 책임을 분리하여 보안을 강화하고자 하는 용도라고 한다.\n"},{"id":244,"href":"/docs/BOOKS/Real-Mysql-8.0/04_%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/","title":"04. 아키텍처","section":"Real Mysql 8.0","content":"Mysql 서버 = Mysql 엔진 + Storage 엔진\nHandler API(핸들러 API)를 구현하여, (추가적인) Storage 엔진을 개발/적용할 수 있다. 4.1 MySQL 엔진 아키텍처 # Mysql 서버는 다른 DBMS 에 비해 구조가 독특하다고 볼 수 있다.\n아래와 같이 구조를 나눠볼 수 있다. Mysql 엔진 Storage 엔진 - 커넥션 핸들러 - SQL 파서 - SQL 옵티마이저\n- 캐시 \u0026amp; 버퍼\n- \u0026hellip; - InnoDB\n- MyISAM\n- \u0026hellip; 커넥션 핸들러 SQL 파서 , SQL 옵티마이저 , 캐시 \u0026amp; 버퍼 스토리지 엔진 (InnoDB, MyISAM, ...) DISK (Data File, Log File, ...) * 단, \u0026lsquo;Mysql 엔진\u0026rsquo; 이라는 용어는 공식적인 용어는 아닌 것 같기도하다. * \u0026lsquo;Storage 엔진\u0026rsquo; 은 공식적인 용어인 것 같다.\nMysql 엔진\nDBMS 두뇌역할 (쿼리 분석, 최적화 등)\ngroup by, order by 등의 복잡한 처리는 Mysql 엔진(쿼리 실행기)에서 처리 *\u0026lsquo;데이터 쓰기/읽기 작업\u0026rsquo;은 (반드시) \u0026lsquo;핸들러 API\u0026rsquo; 통해 스토리지 엔진에 작업 요청\n스토리지 엔진\n실제로 디스크로부터 데이터를 읽어오는 역할\n* 각 스토리지 엔진은 성능 향상을 위해 키 캐시(MyISAM), 버퍼 풀(InnoDB) 와 같은 기능을 내장\nMysql 스레딩 구조\n프로세스 기반 X 스레드 기반 O 포그라운드 스레드 백그라운드 스레드 Mysql 커뮤니티 에디션 : 전통적인 Thread 모델 = Thread Pool 모델 사용 X Mysql 엔터프라이즈 에디션 (혹은 Percona Mysql 서버) : Thread Pool 모델 사용 가능\n포그라운드 Thread\n(Thread Pool을 사용하지 않았다는 가정하에) 최소 Mysql 서버에 접속된 클라이언트 수만큼 존재 각 클라이언트의 요청(쿼리) 처리 커넥션 종료 시 (해당 커넥션을 담당하던) Thread는 Thread Cache 되돌아가거나 혹은 소멸 데이터를 Buffer 혹은 Cache 로부터 가져온다. Buffer 혹은 Cache에 없는 경우 디스크, 인덱스로부터 데이터 가져온다. MyISAM : 포그라운드 Thread 가 처리 InnoDB : 백그라운드 Thread 에 위임 백그라운드 Thread\nMyISAM 의 경우 해당하지 않는다.\n아래의 작업들이 백그라운드 Thread 처리\nInsert Buffer Merge(병합) 스레드 Log 를 Disk 로 기록하는 스레드 (로그 스레드) InnoDB Buffer Pool 의 데이터를 disk 에 기록 (쓰기 스레드) 데이터를 버퍼(buffer)로 읽어오는 스레드 Lock, DeadLock 모니터링 스레드 이 중 \u0026lsquo;로그 스레드\u0026rsquo;, \u0026lsquo;쓰기 스레드\u0026rsquo; 가 가장 중요하다고 한다.\n사용자의 요청을 처리하는 중 \u0026lsquo;데이터 쓰기 작업\u0026rsquo; 은 지연될 수 있다. 대부분의 DBMS 에서는 쓰기 지연 기능(버퍼링)이 포함되어 있다. (대부분의 경우 응답이 더 빠르다.) MyISAM 의 경우 포그라운드 스레드(사용자 스레드)가 \u0026lsquo;쓰기 작업\u0026rsquo;까지 처리한다. (따라서, 쓰기 지연 기능 X, 바로바로 처리한다.) 사용자의 요청을 처리하는 중 \u0026lsquo;데이터 읽기 작업\u0026rsquo; 은 지연될 수 없다.\n메모리 할당 및 사용 구조\n각 운영체제의 메모리 할당 방식은 매우 복잡하다. 요청된 메모리 공간을 100% 할당해줄 수도 있고, 요청된 공간을 예약만 해두고 실제 필요할 때마다 할당해주는 경우도 있다. Mysql 서버가 실제로 사용하는 정확한 메모리의 양을 측정하는 것도 쉽지 않다고 한다. (따라서 단순하게 시스템 변수로 설정해둔만큼 메모리를 할당받는다고 생각해도 된다고 함)\nMysql 메모리 공간 = 글로벌 메모리 영역(Global Memory Area) + 로컬 메모리 영역(Local/Session Memory Area)\n글로벌 메모리 영역 모든 쓰레드(클라이언트)가 공유 즉, 오직 하나의 메모리 공간만 할당 단, (필요에 따라) 2개 이상의 메모리 공간을 할당 받을 수 있음 메모리 영역의 설정값에 따라 (최악의 경우) 서버가 죽을 수 있음 Mysql 서버 시작 시 운영체제로부터 할당 InnoDB 버퍼 풀 / MyISAM 키 캐시 bin_log 버퍼 redo_log 버퍼 table cache \u0026hellip; 로컬 메모리 영역\n클라이언트 접속(연결) 시 할당 클라이언트 쓰레드가 쿼리를 처리하기 위해 사용하는 메모리 영역 (클라이언트 쓰레드 별로) 독립적인 영역 \u0026lsquo;클라이언트의 메모리 영역의 설정값\u0026rsquo;은 \u0026lsquo;글로벌 메모리 영역의 설정값\u0026rsquo;보다 비교적 덜 주의해서 설정해도 됨 각 쿼리의 용도별로 공간이 할당 필요 시에만 공간이 할당되는 개념 필요하지 않은 경우 공간이 할당되지 않을 수 있음 커넥션 후 계속 할당되어 있는 영역이 있음 (커넥션 버퍼, 결과 버퍼) 커넥션 후 쿼리 실행 순간에만 할당되고 곧바로 해제되는 영역이 있음 (조인 버퍼, 소트 버퍼) 조인 버퍼 (join buffer) 정렬 버퍼 (sort buffer) 리드 버퍼 (read buffer) 네트워크 버퍼 (network buffer) \u0026hellip; 플러그인 모델\nMysql 독특한 구조(기능) 중 대표적인 기능 : \u0026lsquo;플러그인 모델\u0026rsquo;\n단순히 스토리지 엔진 뿐만 아니라, 다양한 기능을 플러그인 모델을 통해 지원한다.\n플러그인의 종류\n스토리지 엔진 ARCHIVE BLACKHOLE MyISAM FEDERATED InnoDB MEMORY CSV PERFORMANCE_SCHEMA \u0026hellip; 인증 파서 (전문 검색 파서 등) 커넥션 제어 \u0026hellip; 컴포넌트\nMysql 8.0 부터는 아래의 \u0026lsquo;플러그인 단점\u0026rsquo;을 보완하기 위해 \u0026lsquo;컴포넌트\u0026rsquo;로 대체/지원한다.\n플러그인 단점 Mysql 서버와 통신 OK, 플러그인끼리는 통신할 수 없음 Mysql 서버의 변수, 함수를 직접 호출 (캠슐화 X) 상호 의존 관계 설정할 수 없음 =\u0026gt; 초기화 어려움 (* 누가 먼저 실행이 되어야 하는지 일일히 확인해줘야 하는 의미인 것 같다.) 쿼리 실행 구조\nSQL 요청 -\u0026gt; MySQL 엔진 - 쿼리 파서 - 전처리기 - 옵티마이저 (쿼리 변환, 쿼리 최적화, 실행 계획 수립) - 쿼리 실행기 -\u0026gt; 스토리지 엔진 - InnoDB - MyISAM - ... 쿼리 파서\n요청온 쿼리의 기본적인 문법을 확인한다.\n쿼리 문장을 토큰화 트리 형태의 구조로 생성 전처리기\n쿼리 파서에서 만들어진 파서 트리를 기반으로 쿼리 문장에 구조적인 문제가 있는지 확인한다.\n실제로 해당 테이블, 컬럼이 존재하는지? 접근 권한이 있는지? 옵티마이저\n* DBMS 의 두뇌라고 한다. 아주 중요하다.\n가장 저렴한 비용으로, 최적화된 쿼리로 실행할 수 있도록 한다.\n실행 엔진\n실행 엔진은 \u0026lsquo;핸들러 API\u0026rsquo;를 통해 (옵티마이저에 의해)최적화된 쿼리를 처리한다.\n쿼리 캐시\nMysql 8.0 부터 해당 기능을 제거했다.\n아래와 같은 이유이다.\nKey : SQL 쿼리 Value : SQL 실행 결과 (Memory) 해당 쿼리에 연관된 테이블의 데이터가 변경되면, 관련된 캐시들은 모두 삭제해야 했다. * (따라서) 오히려 성능(동시성) 저하, 버그가 많았다고 한다.\n스레드 풀\n\u0026lsquo;Percona Server (Thread Pool 플러그인)\u0026rsquo; 알아볼 것\nThread Pool 의 스레드 수를 무작정 많이 늘리는 것은 좋지 않다. 스케줄링 대상 많아짐 불필요한 컨텍스트 스위칭 비용 커짐 메타데이터(데이터 딕셔너리) 관리\n메타데이터(데이터 딕셔너리) : 테이블 구조 정보, 스토어드 프로그램 등의 정보\nMysql 5.7 : File 관리 Mysql 8.0 : InnoDb : (InnoDB 스토리지 엔진의)DB,Table로 관리 (mysql db) (트랜잭션 OK) 그 외 : File 관리 File 관리 시 문제점 : 중간에 오류 시 \u0026lsquo;일관성\u0026rsquo; 보장할 수 없다. (= DB가 깨졌다. 테이블이 깨졌다.)\n* mysql DB 에 테이블 조회 시 실제로는 존재하되, 보이지 않음(select 불가) (사용자가 수정하지 못하게 하기 위함) 대신 information_schema DB의 TABLES, COLUMNS 와 같은 view 를 통해 조회 가능\n4.2 InnoDB 스토리지 엔진 아키테처 # Mysql 스토리지 엔진 중 거의 유일하게 \u0026lsquo;레코드 기반 잠금\u0026rsquo; 을 제공한다.\n높은 동시성 처리 (높은 성능) 높은 안정성 프라이머리 키에 의한 클러스터링 # PK = 클러스터링 인덱스\nPK 를 이용한 스캔은 빠르게 처리된다. 실행 계획 시, PK 를 이용한 인덱스는 선택될 확률이 높다. (비중이 크게 설정된다.) (기본적으로) InnoDB의 모든 테이블은 PK 를 기준으로 클러스터링되어 저장된다.\n(= PK 순서대로 디스크에 저장된다는 의미이다.)\n모든 세컨더리 인덱스는 \u0026lsquo;레코드의 주소\u0026rsquo; 대신 \u0026lsquo;PK 값\u0026rsquo;을 주소로 사용한다.\n(= 세컨더리 인덱스 =\u0026gt; PK =\u0026gt; 물리 주소)\n\u0026quot; MyISAM 의 경우 클러스터링 키(인덱스)를 지원하지 않는다. 따라서, PK 와 세컨더리 인덱스는 차이가 없다.(PK 인덱스는 유니크 제약을 갖는 세컨더리 인덱스일 뿐이다.) 또, PK 와 세컨더리 인덱스 모두 물리 주소를 갖고 있다. \u0026ldquo;\n외래 키 지원 # \u0026rdquo; MyISAM 스토리지 엔진은 지원하지 않는다. \u0026ldquo;\n\u0026lsquo;운영 상의 불편함\u0026rsquo;, \u0026lsquo;데드락을 유발하는 원인\u0026rsquo;이 되기도 해서 실제로 외래키를 생성하지 않는 경우도 종종 있다고 한다.\n데드락을 유발하는 원인\n참조하는 테이블, 참초 테이블 모두 해당 컬럼에 대한 \u0026lsquo;인덱스 생성\u0026rsquo;이 필요 변경 시, 관련된 테이블에 데이터가 있는지 체크 (= 잠금, 처리가 여러 테이블로 전파) foreign_key_checks 시스템 변수\non : default off : (CASCADE 포함) 외래키 처리(확인) X 외래 키 확인(일관성)을 위한 부가적인 처리가 필요 없어지기 때문에 빠르게 동작할 것이다. GLOBAL, SESSION 모두에 적용 가능한 변수이다. 주의한다.\nMVCC (Multi Version Concurrency Control) # MVCC의 핵심 목표 : 잠금을 사용하지 않고 일관된 읽기 제공\n일반적으로 레코드 기반 잠금을 지원하는 DBMS 에서 제공하는 기능이다.\nInnoDB 는 언두 로그를 이용해 MVCC 를 구현한다.\n값이 업데이트 되었을 때 아래와 같이 동작한다.\n버퍼풀 / 데이터 파일(디스크)는 값을 변경 언두 로그에는 이전 값을 저장(기록) 동작 설명 커밋 시 언두 로그 삭제(다른 트랜잭션에 의해 해당 언두로그가 더 이상 사용되지 않을 때) (언두 로그의 내용 바로 삭제되는 것 아님) 롤백 시 1. 언두 로그 적용 2. 언두 로그 삭제 버퍼 풀의 값이 데이터 파일(디스크)에 적용되는 정확한 시점은 알 수 없다. 다만 (통상적으로) 버퍼 풀의 값은 데이터 파일(디스크)의 값과 동일하다고 보아도 무방하다.\n고립 레벨 동작 READ UNCOMMITED 버퍼풀의 데이터를 읽는다. READ COMMITED\nREPEATABLE READ\nSREALIZABLE 언두로그의 데이터를 읽는다. \u0026rdquo; 트랜잭션이 길어지면, 언두로그에 데이터가 많이 쌓이게 되고 그만큼의 시간동안 관리해주어야 한다. 따라서 성능 저하(문제 발생)로 이루어질 수 있다. \u0026ldquo;\n* 트랜잭션은 가능한 빨리 커밋/롤백을 완료하는 것이 좋다.\n잠금 없는 읽관된 읽기 (Non-Locking Consistent Read) # MVCC 기술을 통해 잠금 없이 \u0026lsquo;일관된 읽기\u0026rsquo;(읽기 작업)를 지원한다.\n다른 Tx가 진행중인 상황에서, 또 다른 Tx가 값을 읽을 때 전혀 방해받지 않는 것이다. \u0026rdquo; 단, \u0026lsquo;SERIALIZABLE\u0026rsquo; 레벨은 잠금을 건다. (= 공유 잠금일 듯) \u0026ldquo;\n자동 데드락 감지 # (데드락을 모니터링하기 위해) 잠금 대기 목록을 그래프 형태로 관리한다.\n이것을 주기적으로 확인하는 **\u0026lsquo;데드락 감지 스레드\u0026rsquo;**가 존재한다.\n데드락이 감지되면 그 중 하나의 트랜잭션을 강제 종료한다.\n\u0026lsquo;언두 로그 양\u0026rsquo;을 기준으로 종료할 트랜잭션을 선택한다.\n= 처리 대상이 적다는 의미 = Mysql 서버 부하가 적다는 의미 \u0026rdquo; 참고로 InnoDB 스토리지 엔진은 (상위 레이어인) Mysql 엔진에서 관리되는 테이블 잠금은 볼 수가 없어서 데드락 감지가 북활실할 수도 있는데, innodb_table_locks 시스템 변수를 활성화하면 테이블 잠금까지 감지할 수 있다. 특별한 이유가 없다면 innodb_table_locoks 시스템 변수를 활성화하자. \u0026ldquo;\n일반적인 경우, 데드락 감지 스레드가 데드락을 확인하는 작업은 크게 부담되지 않는다.\n다만, 동시 처리량이 매우 많거나, 잠금의 수가 많아지는 경우 데드락 감지 스레드가 느려진다.\n시스템 변수 설명 innodb_deadlock_detect 데드락 감지 스레드 동작 활성화/비활성화 innodb_lock_wait_timeout 데드락 상황에서 일정 시간 지난 경우 자동으로 실패 처리 (second 단위) \u0026rdquo; 데드락 감지 스레드가 부담되어 innodb_deadlock_detect를 off 로 설정했다면, innodb_lock_wait_timeout을 기본값인 50초보다 훨씬 낮은 값으로 변경할 것을 권장한다. \u0026ldquo;\n\u0026rdquo; 데드락 감지 스레드는 잠금 목록을 검사할 때 잠금 상태가 변경하지 않도록 잠금 목록이 저장된 리스트(잠금 테이블)에 새로운 잠금을 걸고 처리를 한다. 이 상황에서 데드락 감지 스레드가 느려지면 전체적인 처리(일반 쿼리 등) 작업에 영향을 미치게 된다. \u0026ldquo;\n자동화된 장애 복구 # Mysql 서버는 시작될 때, \u0026lsquo;완료되지 못한 트랜잭션\u0026rsquo;, \u0026lsquo;Partial write(디스크에 일부만 기록된 데이터 페이지)\u0026rsquo; 등에 대한 복구 작업이 자동으로 진행된다. 복구 작업이 실패하면 서버는 시작되지 않고 종료된다.\n또, 커밋되지 않은 데이터를 롤백하거나, 종료된 시점의 데이터 상태를 만들어낸다..?\n\u0026rdquo; InnoDB 스토리지 엔진은 매우 견고해서 데이터 파일이 손상되거나 Mysql 서버가 시작되지 못하는 경우는 거의 발생하지 않는다. 하지만 Mysql 서버와 무관하게, 디스크와 같은 서버 HW 이슈로 인해 Innodb 스토리지 엔진이 자동으로 복구를 못 하는 경우도 발생할 수 있다. \u0026ldquo;\n(서버 시작 시의)복구 작업이 실패할 경우, innodb_force_recovery 값을 설정해 Mysql 서버를 강제로 시작시킬 수 있다. (이후 dump 등의 작업을 통해 새로운 mysql 서버 구축, 데이터 import 하는 것을 권장)\nlevel 설명 \u0026amp; 시도할 수 있는 케이스 1 (SRV_FORCE_IGNORE_CORRUPT) InnoDB 테이블스페이스, 데이터 파일(디스크), 인덱스 페이지가 손상되었을 때\nDatabase page corruption on disk or a failed 와 같은 메시지가 출력될 때 2 (SRV_FORCE_NO_BACKGROUND) 메인 스레드가 언두 로그의 데이터를 삭제하는 과정에서 장애가 발생했을 때 메인 스레드를 시작하지 않고 mysql 서버를 시작 3 (SRV_FORCE_NO_TRX_UNDO) 커밋되지 않은 트랜잭션의 작업을 롤백하지 않고 그대로 놔둠\n즉, 커밋되지 않고 종료된 트랜잭션은 그 상태 그대로 남아 있게 함 4 (SRV_FORCE_NO_IBUF_MERGE) 인서트 버퍼를 사용할 수 없을 때(손상되었을 때)\n인서트 버퍼의 내용을 무시 후 mysql 서버를 시작\n* 인덱스와 관련된 부분이므로 테이블 덤프 시 데이터의 손실 없이 복구 가능하다. 5 (SRV_FORCE_NO_UNDO_LOG_SCAN) 언두 로그 사용할 수 없을 때(손상되었을 때)\n언두 로그 무시하고 mysql 서버 시작\n* 언두로그를 사용하지 않았기 때문에 -\u0026gt; 정상적으로 롤백되어야 할 것들이 안되었을 것 -\u0026gt; 데이터 파일에 잘못된 데이터가 남아있는 것으로 볼 수 있음 6 (SRV_FORCE_LOG_REDO) 리두 로그 사용할 수 없을 때(손상되었을 때)\n리두 로그 무시하고 mysql 서버 시작\n* 즉, 마지막 체크포인트 시점의 데이터만 남아있는 것으로 볼 수 있음 값이 높을 수록 심각하고, 데이터 복구 가능성 낮음\n* 인서트 버퍼 : insert, update, delete 등의 데이터 변경으로 인한 인덱스 변경 작업 시 인서트 버퍼에 저장하고 나중에 처리할 수 있다. (즉시 처리할 수도 있다.) 인서트 버퍼에 기록된 내용은 언제 디스크에 병합(merege) 될 지 알 수 없다.\n* Mysql 서버 장애, 종료 시점에 진행 중인 트랜잭션은 mysql이 그 커넥션을 강제로 끊어버리고 별도의 정리 작업 없이 종료한다. mysql 재시작 시 언두 로그, 리두 로그를 이용해 종료(장애) 시점의 상태를 재현한다.\n위와 같은 방식으로 데이터를 복구하거나, 백업이 있을 경우 마지막 풀 백업 시점 + binlog 통해 데이터를 복구할 수 있다.\n작성 중\u0026hellip; # "},{"id":245,"href":"/docs/BOOKS/%EC%8B%A4%EB%AC%B4%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%B1%EB%8A%A5-%EC%B5%9C%EC%A0%81%ED%99%94/1-01.-%EC%84%B1%EB%8A%A5%EC%9D%B4%EB%9E%80/","title":"1-01. 성능이란?","section":"실무로 배우는 시스템 성능 최적화","content":" 01. 성능이란 # 시스템 성능은 \u0026lsquo;시간당 처리량\u0026rsquo;이며, 영향을 미치는 요소는 \u0026lsquo;응답시간\u0026rsquo;, \u0026lsquo;동시에 처리할 수 있는 프로세스 수\u0026rsquo;이다.\n응답시간은 사용자의 특성, 환경에 따라 요구하는 수준이 다르다. 동일한 응답시간에 대해 고객마다 만족도도 다르다.\n이는 모든 시스템과 사용자에게 일률적으로 적용할 수 있는 응답시간의 기준은 없다는 것을 의미한다.\n1.1 동시 사용자 # 성능 분석이나 테스트 시 공식적으로 적용되는 동시 사용자라는 의미는 대상 서버에 접속하고 있는 사용자로 정의한다.\n동시 사용자는 다음과 같이 두 유형의 합으로 표현할 수 있다.\n동시 사용자 수 = 요청 사용자 수 + 비요청 사용자 수\n1.2 처리량 (throughput) # \u0026lsquo;처리량\u0026rsquo;은 서버가 일정 시간 내에 처리한 트랜잭션의 양이다.\n단, 이때 서버 입장에서 바라보는 트랜잭션과 클라이언트 입장에서 바라보는 트랜잭션은 다르다.\n고객이 A 화면을 조회했을 때 서버에서 n개의 쿼리, m개의 자원(css, 이미지, html) 등이 처리/응답됐다고 가정하자.\n이때 고객(클라이언트)입장에서는 1개의 트랜잭션이 처리된 것이고, 서버 입장에서는 n+m개의 트랜잭션이 처리된 것이다.\n성능에서 중요한 것은 서버 입장에서의 트랜잭션이 아니고 클라이언트 입장에서의 트랜잭션이다.\n따라서, 처리량의 평가 단위로서 사용되는 TPS(Transaction Per Second)의 \u0026ldquo;T\u0026quot;는 고객의 업무 처리 건수가 되어야 하겠다.\n시스템을 설계하고 분석하는 엔지니어 입장에서는 서버 측의 트랜잭션도 중요할 수 있다. 이때 TPS 이외의 처리량 평가 단위로 PPS, HPS 등이 있다.\nPPS (Page Per Second)\n웹 성능을 분석할 때 화면 단위(Page)를 트랜잭션 평가 단위로 사용하기도 한다. \u0026ldquo;사용자 등록 화면 -\u0026gt; 사용자 입력 확인 화면 -\u0026gt; 주소 검색 초기 화면 -\u0026gt; 주소 검색 결과 화면 -\u0026gt; 사용자 등록 성공 화면\u0026rdquo; 의 단계로 사용자 등록 흐름이 구성돼 있다면 PPS 관점에서의 처리량은 화면 기준으로 5가 된다.\n단, 사용자 입장의 TPS 관점에서는 1이 되겠다.\nHTS(Hit Per Second)\n웹 서버에서 이미지, 스크립트 파일, css 등은 별개 요청으로 응답되는데, 각각이 1개의 Hit 가 된다.\nHTP 를 측정 단위로 삼는다면 TPS, PPS 에 비해 세분화된 것으로 볼 수 있다.\n1.3 응답시간 (latency) # 응답시간은 요청한 후부터 응답을 받을 때까지 소요된 시간이다. 측정하는 위치에 따라 여러 유형으로 나뉜다.\np8 ~ p12 참고\n1.4 자원 (resource) # 자원은 포괄적인 용어다.\n서버의 HW(CPU, 메모리, 디스크), 네트워크 자원, WAS 자원(스레드 풀, 힙 메모리, DB 커넥션 풀), DB 자원(최대 프로세스 수, 오픈 가능한 커서 수, 공유 캐시 메모리 크기) 등 물리적인 자원부터 소프트웨어 자원까지 다양하다.\n성능 측면에서 자원은 애플리케이션이 동작할 때 사용하며, 부족한 경우나 사용량 변화에 따라 성능에 영향을 미치는 요소를 의미한다.\n자원은 목표 성능을 달성할 수 있게 해주는 중요 기반요소로서, 성능 평가나 분석 시 자원 사용량도 모니터링해서 다양한 관점(적정성, 효율성, 안정성, 가용성, 확장성)에서 평가해야 한다.\n1.4.1 적정성 (Suitability) # (각각의)자원 사용량이 적절한지 확인한다.\n예를 들어, WAS 스레드 풀의 모든 스레드가 작업 중이라서 새로운 요청이 큐잉되고 있다고 하자.\n이때 단순히 스레드 풀의 자원을 늘리는 것은 좋은 해결 방법이 아니다. CPU, 메모리와 같은 인프라 자원 상태나 병목 여부 확인(애플리케이션 내 로직, DB 쿼리 등) 등 종합적으로 상태를 판단한 후 스레드 풀 자원을 늘릴지, 다른 방안을 모색할지 결정해야 한다.\n이미 CPU 사용량이 90% 이상이라면, 스레드 풀을 늘려봤자 소용이 없을 것이다. 오히려 스레드 풀을 줄여서 CPU가 70% 내외의 안정적인 범위에 있게 함으로써 성능을 개선할 수도 있다.\n또, 처리 시간이 긴 로직으로 인해 스레드 풀이 소진됐다면 이 부분을 개선하는 것이 먼저일 것이다.\n각 자원의 부족 여부를 판단할 때는 다른 자원과의 상관관계와 인과관계를 잘 파악해서 평가해야 한다.\n1.4.2 효율성 # 동일한 성능(TPS, 응답시간 등)을 수행하는 두 아키텍쳐가 있다고 가정하자.\n이때는 적은 자원(= 적은 비용)을 사용하는 아키텍쳐가 효율적인 것이다.\n성능 개선이라는 행위 자체가 시스템의 효율성을 높이려는 활동이다.\n효율성은 직접적인 비용에 영향을 미치는 요소로 BMT(Benchmark Test) 같은 성능 비교 평가에서 중요 평가지표가 된다.\n1.4.3 안정성 # 시스템 운영시간이 지남에 따라 성능이 저하되거나 장애가 발생하는 등의 문제가 발생하지 않아야 한다.\n메모리에 누수가 있다면 메모리가 부족해 장애가 발생할 것이다.\n처리하는 데이터가 꾸준히 증가한다면 언젠가 성능 저하로 사용에 불편을 느낄 것이다.\n이처럼 시간이 지나더라도 응답시간이나 자원 사용량이 일정하게 유지되는지 확인하는 것이 안정성 평가다.\n1.4.4 가용성 # 일정 기간(년, 월 등) 동안 시스템이 정상적으로 서비스된 시간 비율을 의미한다.\n이중화 구성, DR 구축 등의 키워드가 있을 것이다.\n이중화가 되어 있다고 가용성이 향상되는 것은 아니다. 일부 장비가 실제로 장애로 다운됐을 때, 정상적인 서비스가 이뤄지는 것이 중요하다.\n즉, 서비스 중 일부에 장애가 발생하더라도 사용자가 큰 불편 없이 서비스를 사용할 수 있는 수준이 돼야 한다.\n가용성 테스트를 할 때 서비스 중단시간과 서비스 안정성, 응답시간, TPS, 자원 사용량 변화와 같은 성능 지표도 함께 측정해서 평가한다.\n1.4.5 확장성 # 시스템 사용량 증가에 따라 시스템 증설이 필요할 때 각 자원이 얼마나 용이하게 증설될 수 있는지 평가하는 것이다.\n확장성은 크게 수직 확장(스케일-업), 수평 확장(스케일-아웃)으로 나눠 평가할 수 있다.\n보통 수직 확장은 수평 확장에 비해 확장성이 떨어지는 것으로 평가한다.\n"},{"id":246,"href":"/docs/BOOKS/%EA%B0%80%EC%83%81-%EB%A9%B4%EC%A0%91-%EC%82%AC%EB%A1%80%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88/10_%EC%95%8C%EB%A6%BC-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84/","title":"10. 알림 시스템 설계","section":"가상 면접 사례로 배우는 대규모 시스템 설계 기초","content":" 개요 # 앱(iOS, Android) 알림, SMS, Email 알림을 보내야 한다.\niOS 푸시 알림 # iOS에서 Push Notification(푸시 알림)을 보내기 위해서 3가지 컴포넌트가 필요하다.\n알림 제공자(Provider), APNS, iOS 단말기(Device)\n컴포넌트 설명 알림 제공자 (Provider) 알림 요청을 APNS에 요청하는 주체이다. 알림 요청을 생성하기 위해 단말 토큰(device token), 내용(payload) 가 필요하다고 한다. APNS (Apple Push Notification Service) 애플이 제공하는 원격 서비스이다. 푸시 알림을 iOS 단말기로 보내는 역할을 담당한다. iOS 단말기 사용자가 사용하는 단말기(장치)이다. 안드로이드 푸시 알림 # 안드로이드 Push Notification(푸시 알림)도 iOS와 비슷하다. APNS 대신 FCM을 사용한다는 점만 다르다.\n알림 제공자, FCM, 안드로이드 단말기\nSMS 메시지 # (보통의 경우)제 3사업자의 서비스를 이용해서 SMS 메시지를 보낼 수 있다.\n알림 제공자, SMS 서비스(사업자), SMS 수신 단말기\n이메일 # 고유 이메일 서버를 구축해도 좋고, 상용 이메일 서비스를 이용해도 된다.\n알림 제공자, Email 서비스, 이메일 수신 단말\n초안 (Ver1) # 서비스 1 -------------| | |--------- APNS ----- iOS 단말 | |--------- FCM ----- 안드로이드 단말 서비스 2 -------------|----------- 알림 시스템 ------------| | |--------- SMS 서비스 ----- SMS 단말 | |--------- Email 서비스 ----- Email 수신 단말 | 서비스 N -------------| 문제점\nSPOF : 알림 시스템 (한 대의 알림 시스템 서비스로 모든 알림을 처리하고 있다.) 확장성 : 한 대의 알림 시스템 서비스로 모든 알림을 처리하고 있어서 확장성이 떨어진다. 성능 병목 : 알림을 요청하는 것은 자원을 많이 필요로 하는 작업일 수도 있다. 하나의 서버(알림 시스템)에서 처리하면 과부하 상태에 빠질 수 있다. 개선 (Ver2) # 서비스 1 -------------| | |--- iOS Queue --- Worker(작업 서버) --- APNS --- iOS 단말 | |--- 안드로이드 Queue --- Worker(작업 서버) --- FCM --- 안드로이드 단말 서비스 2 -------------|----------- 알림 시스템 ------------| | 캐시 |--- SMS Queue --- Worker (작업 서버) --- SMS 서비스 --- SMS 단말 | DB |--- Email Queue --- Worker (작업 서버) --- Email 서비스 --- Email 단말 | 서비스 N -------------| * Worker 는 - 실패 시 재시도할 수 있다. (retry) - 로그(이력)을 저장/관리할 수 있다. 나는 처음에 서비스 - Queue - Worker 구조가 바로 떠올랐다. (즉, 위 그림에서 중간에 알림 시스템이 없는 것)\n위와 같이 설계하면,\n각 서비스에서 진행해야하는 분기 처리(어떤 Queue에 넣을 건지)를 알림 시스템에서 하게 될 거고 (역할 분리) (본인의 역할에 충실하게 되면서) 알림 시스템에서는 알림 시스템 용도의 DB(+ 캐시)를 통해 성능을 향상할 수 있을 것 같다. (성능 향상) Ver1 에 비해,\n작업(작업 서버)와 알림 시스템의 역할을 분리했다. 알림 시스템에서는 처리(work)하지 않는다. Event 만 발행하므로 과부하(병목) 상태를 방지할 수 있다. 캐시 사용 알림 시스템인 기본적인 검증(Verification) + Event 발행만 담당한다. 알림 시스템 \u0026lt;-\u0026gt; 알림 서비스(APNS, FCM, SMS 서비스, Email 서비스) 결합(의존성)을 분리했다. 서비스, 알림 시스템 입장에서는 알림 서비스를 더 이상 신경쓰지 않아도 된다. (확장성) 최종 (Ver3) # 조금 더 개선해본다. (안정성, 모니터링, 이벤트 추적, 처리율 제한, 알림 템플릿 등)\n기능 설명 알림 템플릿 알림은 대부분 Format이 동일하다. 따라서 고정된 포맷의 템플릿 적극 활용할 수 있다. (변수 값만 받아 처리한다.) Queue 모니터링 큐 사용 시 Lag은 중요한 메트릭이다. 꼭 모니터링한다. 이벤트 추적 알림 확인율, 클릭율, 실제 앱 사용 비율 등의 메트릭은 사용자를 이해하는데 중요하다. 데이터 분서 서비스(analytics)는 보통 이벤트 추적 기능도 제공한다. 보통 알림 시스템을 만들면 데이터 분석 서비스와도 통합해야 한다. 알림 서비스 + 데이터 분석 서비스(analytics) 조합을 기억하자.\n단순 # 전체 # "},{"id":247,"href":"/docs/BOOKS/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/1%EC%9E%A5-%EA%B0%9D%EC%B2%B4-%EC%84%A4%EA%B3%84/","title":"1장 객체, 설계","section":"오브젝트","content":" 1장 \u0026lsquo;객체, 설계\u0026rsquo;의 핵심 부분 정리해보기\n로버트 마틴 \u0026lsquo;클린 소프트웨어: 애자일 원칙과 패턴, 그리고 실천 방법\u0026rsquo; 에서 소프트웨어 모듈이 가져야 하는 세 가지 기능은 다음과 같다.\n실행 중에 제대로 동작한다. 변경을 위해 존재한다. 대부분의 모듈은 생명주기 동안 변경되기 때문에 간단하게 변경할 수 있어야 한다. 변경하기 어렵다면, 개선해야 한다. 코드를 읽는 사람과 의사소통한다. 개발자가 쉽게 읽고 이해할 수 있어야 한다. 읽는 사람과 의사소통할 수 없는 모듈은 개선되어야 한다. 객체 사이의 의존성을 완전히 없애는 것이 정답은 아니다. OOP는 객체끼리 서로 의존(협력)해야 한다. 다만, 중요한 포인트는 불필요한 의존성(결합도, coupling)을 제거하는 것이다. 객체들이 합당하게 의존한다면 결합도가 낮은 것으로 본다.\n결합도가 낮아야 하는 이유는 무엇일까? 결합도(의존성)은 변경에 취약하다. 변경에 취약하다는 것은 한 객체(부분)가 변경될 때 다른 부분도 변경됨을 의미한다.\n객체간의 불필요한 의존을 제거하기 위해 아래와 같이 개선해볼 수 있다.\n// 개선 전의 코드 class Theater { TicketSeller ticketSeller; public void enter(Audience audience) { if(audience.getBag().hasInvitation()) { Ticket ticket = ticketSeller.getTicketOffice().getTicket(); audience.getBag().setTicket(ticket); } else { Ticket ticket = ticketSeller.getTicketOffice().getTicket(); audience.getBag().minusAmount(ticket.getFee()); ticketSeller.getTicketOffice().plusAmount(ticket.getFee()); audience.getBag().setTicket(ticket); } } } // 개선 후의 코드 class Theater { TicketSeller ticketSeller; public void enter(Audience audience) { ticketSeller.sellTo(audience); } } class TicketSeller { TicketOffice ticketOffice; public void sellTo(Audience audience) { ticketOffice.sellTicketTo(audience); } } class TicketOffice { private Long amount; private List\u0026lt;Ticket\u0026gt; tickets; public void sellTicketTo(Audience audience) { plusAmount(audience.buy(getTicket())); } private Ticket getTicket() { return tickets.remove(0); } private void plusAmount(Long amount) { this.amount += amount; } } class Audience { Bag bag; public Long buy(Ticket ticket) { return bag.hold(ticket); } } class Bag { private Long amount; private Ticket ticket; private Invitation invitation; public Long hold(Ticket ticket) { setTicket(ticket); if(hasInvitation()) { return 0L; } minusAmount(ticket.getFee()); return ticket.getFee(); } private void setTicket(Ticket ticket) { ... } private boolean hasInviation() { ... } private void minusAmount(Long amount) { ... } } 여기서 주목해볼 점은, \u0026lsquo;캡슐화/객체의 독립성\u0026rsquo;이다. 객체는 각자 자신의 데이터(속성)에 대한 작업만 한다. 그 데이터가 다른 객체라면, 그 객체에 메시지를 던진다. 즉 그 객체의 인터페이스만 이용한다. 메시지를 받은 객체는 자신의 데이터(속성)에 대한 작업만 한다. 다른 객체의 데이터(속성)를 다루지 않는다.\n한 객체가 자신의 데이터만 다루게 되면 자연스럽게 응집도가 향상되고 결합도가 떨어진다. 그 결과 각각의 객체는 다른 객체와의 불필요한 협력을 제거하게 되고 자기 자신에게만 의존하는, 변경에 용이한 객체가 된다.\n이 행위는 \u0026lsquo;책임\u0026rsquo;과도 연관이 있다. A라는 객체가 다른 객체의 데이터를 사용한다는 것은 A라는 객체의 책임(결합도)가 높아짐을 의미한다. 객체는 자기 자신만을 책임질 수 있어야 한다.(이하 \u0026lsquo;객체의 독립성\u0026rsquo;, 책에서는 \u0026lsquo;자율성\u0026rsquo;이라고 표현함)\n위와 같이 개선을 하다보면 (TicketOffice 객체와 같이) TradeOff 가 발생하는 순간이 온다. 객체의 독립성 vs 객체의 의존성에 대한 TradeOff이다.\n예를 들어, 위의 TicketOffice 는 아래 코드 처럼 TicketSeller 에서 처리될 수 있었던 코드이다. 객체의 독립성을 위해 개선하면서 위와 같은 코드가 된 것이다. 위와 같은 코드가 되면서 TicketOffice 는 응집도가 향상되었지만 Audience 에 의존을 갖게 되었다. (책에서는 결국 아래 코드처럼 작성하기를 선택했다고 한다.) 포인트는 객체의 독립성(응집도)도 좋지만 적절하게 타협할 수도 있어야 한다는 것이다.\nclass TicketSeller { ... public void sellTo(Audience audience) { ticketOffice.plusAmount(audience.buy(ticketOffice.getTicket())); } } 또, 눈여겨볼 점은 \u0026lsquo;의인화\u0026rsquo;이다. 실생활에서는 Bag, TicketOffice 의 경우 수동적인 객체이다. 실생활을 생각한다면 Bag, TicketOffice는 로직을 가져서는 안된다.\n하지만 이러한 객체가 코드로써 표현될 때에는 능동적으로 동작해야 한다고 한다.\n\u0026quot; 비록 현실에서는 수동적인 존재라고 하더라도 일단 객체지향의 세계에 들어오면 모든 것이 능동적이고 자율적인 존재로 바뀌다. 레베카 워프스브록은 이처럼 능동적이고 자율적인 존재로 소프트웨어 객체를 설계하는 원칙을 의인화라고 부른다. \u0026quot;\n즉, 사물이나 사람과 같이 보지말고 하나의 객체로써 보면 될 것 같다.\n1장에서의 핵심 키워드(문장)를 정리해보면 다음과 같을 것 같다.\n변경에 용이해야 한다. 객체의 자율성(독립성) : 객체를 독립적으로 만든다. (객체를 자율적인 존재로 만들어라.) 의인화 : 모든 객체를 능동적인 존재로 생각한다. "},{"id":248,"href":"/docs/BOOKS/%EB%AA%A8%EB%8D%98-%EC%9E%90%EB%B0%94-%EC%9D%B8-%EC%95%A1%EC%85%98/1%EC%9E%A5-%EC%9E%90%EB%B0%94-891011-%EB%AC%B4%EC%8A%A8-%EC%9D%BC%EC%9D%B4-%EC%9D%BC%EC%96%B4%EB%82%98%EA%B3%A0-%EC%9E%88%EB%8A%94%EA%B0%80/","title":"1장. 자바 8,9,10,11 무슨 일이 일어나고 있는가?","section":"모던 자바 인 액션","content":" 자바 8,9,10,11 무슨 일이 일어나고 있는가? # 자바 역사를 통틀어 자바 8에서 가장 큰 변화가 일어났다.\n자바 8에서 제공하는 새로운 기술은 다음과 같다.\n스트림 API 메서드에 코드를 전달하는 것 (함수형 프로그래밍(?)) 인터페이스 Default 메서드 에러를 자주 일으키고 멀티코어 CPU를 이용하는 것보다 훨씬 비용이 비싼 synchrosized 키워드 대신에 Stream API 을 사용할 수 있다.\n또, Stream API 덕분에 메서드에 코드를 전달하는 것, 인터페이스의 Default 메서드 가 자연스럽게 탄생하게 되었다. (?)\n메서드에 코드를 전달하는 것 은 동작 파라미터화(behavior parameterization) 을 구현할 수 있음을 의미한다. 또한 함수형 프로그래밍(functional-style programming) 에서 위력을 발휘한다.\n자바 8에서 함수평 프로그래밍을 도입하면서 객체지향프로그래밍 과 함수형프로그래밍의 장점을 누릴 수 있게 되었다.\n자바 8 설계의 밑바탕을 이루는 세가지 프로그래밍 개념 # 스트림 API (Stream processing) # 첫 번째 중요 개념은 Stream 이다. 스트림이란, 한 번에 한 개씩 만들어지는 연속적인 데이터 항목들의 모임이다.\nStream API 란 ?\n동작(행위) 파라미터화 (behavior parameterization) # 두 번째 중요 개념은 코드를 파라미터로 전달할 수 있다는 것이다. (기존에는 익명함수를 사용하곤 했다.)\nStream API 의 연산에서 대개 함수형 인터페이스를 파라미터로 받는데, 이것이 바로 코드를 파라미터로 전달하는 개념인 것이다. (이것을 \u0026lsquo;동작 파라미터화\u0026rsquo; 라고 말한다.)\n병렬성 (공유 가변 데이터) # 세 번째 중요 개념은 병렬성을 쉽게 얻을 수 있다는 것이다. Stream API 의 연산에서 전달되는 코드(함수형 인터페이스)의 동작 방식을 조금 수정한다면, 병렬 처리를 할 수 있다.\n* Stream API 의 메서드로 전달되는 코드는 공유 가변 데이터에 대한 고려가 없어야 한다. 이러한 함수(코드)를 순수 함수(pure), 부작용 없는 함수(side-effect-free), 상태가 없는 함수(stateless) 라고 부른다.\n자바의 함수 # 일급 시민과 이급 시민 # 프로그래밍의 핵심은 \u0026lsquo;값을 바꾸는 것\u0026rsquo;이다. 전통적으로 프로그래밍언어에서는 이 값을 일급(first-class) 또는 시민(citizens) 라고 부른다.\n자바에서도 다양한 자료구조가 값을 표현하는데 사용되고 있다. 그러나 모든 자료구조(구조체)를 자유롭게 전달할 수 없는데, 이러한 자료구조(구조체)를 이급 시민이라고 한다.\n자바 8에서는 이급 시민을 일급 시민으로 바꿀 수 있는 기능을 추가했다. (* js와 같은 다양한 언어에서 이미 이러한 시도들을 해왔었다.)\n메서드, 람다 = 일급 시민 # File[] hiddenFiles = new File(\u0026#34;.\u0026#34;).listFiles(File::isHidden); (자바 8의 새로운 기능인)자바 메서드 참조(::)를 이용해서 메서드를 값으로 직접 전달할 수 있다.\n람다(또는 익명함수)를 포함하여 함수도 값으로 취급할 수 있다.\n프레디케이트(Predicate) 란? # 수학에서는 인수로 값을 받아 true, false 를 반환하는 함수를 \u0026lsquo;프레디케이트\u0026rsquo; 라고 한다.\n자바 8에서도 Function\u0026lt;Apple, Boolean\u0026gt; 과 같이 코드를 작성할 수 있지만, Predicate\u0026lt;Apple\u0026gt; 과 같이 사용하는 것이 더 표준적인 방식이다. (* boolean 을 Boolean 으로 변환하는 과정이 없어서 더 효율적이기도 하다.)\n이와 관련된 내용은 함수형 인터페이스 에 대해 조금 더 알아보자.\n메서드를 값으로 전달하는 것은 매우 유용하다. 다만 한 두번 사용할 메서드를 매번 정의하는 것은 비효율적일 수 있다. 이런 상황에서는 람다를 사용한다. (단, 익명 람다를 사용했는데 코드의 길이가 몇 줄 이상으로 길어진다면, 메서드로 분리하는 것이 바람직하다.)\n멀티 스레딩은 어렵다. # 컬렉션으로 처리하면서 발생했던 \u0026lsquo;반복적인 코드 사용 문제\u0026rsquo;와 \u0026lsquo;멀티 코어 활용의 어려움\u0026rsquo;의 문제를 모두 해결했다.\n컬렉션은 데이터를 어떻게 저장하고 접근할지에 중점을 둔다.\n스트림은 데이터에 어떤 계산을 할지에 중점을 둔다.\nDefault 메서드와 자바 모듈 # Default 메서드는 구현하지 않아도 되는 메서드이다.\n자바 8에서는 인터페이스를 쉽게 변경할 수 있도록 default 메서드를 지원한다.\ndefault 메서드는 특정 프로그램을 구현하는 데 도움을 주는 기능이 아니라, (미래에) 프로그램이 쉽게 변화할 수 있는 기능을 제공한다.\n이미 공개된 인터페이스의 기존 구현을 고치지 않고. 변경할 수 있도록 해준다.\n* 기존에는 인터페이스에 메서드가 추가되면 이를 구현하는 모든 구현체에서 메서드를 추가해야 했다.\nhttps://github.com/BAEKJungHo/modern-java-in-action/blob/master/01장(자바8%2C9%2C10%2C11).md\n"},{"id":249,"href":"/docs/BOOKS/%EB%AA%A8%EB%8D%98-%EC%9E%90%EB%B0%94-%EC%9D%B8-%EC%95%A1%EC%85%98/2%EC%9E%A5-%EB%8F%99%EC%9E%91-%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0%ED%99%94-%EC%BD%94%EB%93%9C-%EC%A0%84%EB%8B%AC%ED%95%98%EA%B8%B0/","title":"2장. 동작 파라미터화 코드 전달하기","section":"모던 자바 인 액션","content":" 동작 파라미터화 코드 전달하기 # 쉽게 말하면 메서드를 파라미터로 전달하는 것이다.\n동작 파라미터화란? 아직은 어떻게 실행할 것인지 결정하지 않은 코드블록이다. 코드블록은 나중에 프로그램에서 호출한다. 즉, 코드블록의 실행은 나중이다.\n예시코드 # 첫 번째 시도 # public static List\u0026lt;Apple\u0026gt; filterApple(List\u0026lt;Apple\u0026gt; apples) { List\u0026lt;Apple\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for(Apple apple : apples) { if(GREEN.equals(apple.getColor())) { result.add(apple); } } return result; } 여기서 조건(GREEN)이 변경(RED)되거나 추가(Weight)된다면 해당 메서드를 사용할 수 없다. (새로운 메서드를 생성할 것이다.) 새로운 메서드를 생성하면 조건 검사 로직 외에는 모두 중복코드이다. 따라서 해당 부분을 파라미터화 하여 개선해볼 수 있다.\n두 번째 시도 # public static List\u0026lt;Apple\u0026gt; filterGreenApple(List\u0026lt;Apple\u0026gt; apples, String color) { List\u0026lt;Apple\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for(Apple apple : apples) { if(color.equals(apple.getColor())) { result.add(apple); } } return result; } public static List\u0026lt;Apple\u0026gt; filterApple(List\u0026lt;Apple\u0026gt; apples, int weight) { List\u0026lt;Apple\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for(Apple apple : apples) { if(weight \u0026lt;= apple.getWeight()) { result.add(apple); } } return result; } 위의 코드로 \u0026lsquo;첫 번째 시도\u0026rsquo; 를 개선해보았다. 위의 코드는 다시 아래와 같이 수정해볼 수 있다.\n이는 소프트웨어 공학의 DRY(Don\u0026rsquo;t Repeat yourself) 같은 것을 반복하지말 것 원칙을 어기는 것이다. 이를 해결하기 위해서 색과 무게를 filter라는 메서드로 합치는 방법도 있다. 따라서 색이나 무게 중 어던 것을 기준으로 필터링할 지 가리키는 플래그를 추가할 수 있다. (하지만 실전에서는 절대 아래의 방법을 사용하지 말아야 한다.)\n세 번째 시도 # public static List\u0026lt;Apple\u0026gt; filterApple(List\u0026lt;Apple\u0026gt; apples, String color, int weight, boolean flag) { List\u0026lt;Apple\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for(Apple apple : apples) { if((flag \u0026amp;\u0026amp; color.equals(apple.getColor())) || (!flag \u0026amp;\u0026amp; weight \u0026lt;= apple.getWeight())) result.add(apple); } return result; } List\u0026lt;Apple\u0026gt; greenApples = filterApple(apples, \u0026#34;GREEN\u0026#34;, 100, true); List\u0026lt;Apple\u0026gt; heavyApples = filterApple(apples, \u0026#34;GREEN\u0026#34;, 100, false); 위와 같은 코드 방식은 절대 사용하지 말라고 권장된다. 과연 true/false 가 의미하는 것이 명확하다고 할 수 있을까라는 것이다. 또, 요구사항이 다시 변경된다면 의미가 없어진다. (예를 들어, 사과의 모양, 원산지 등으로 필터링 조건이 추가된다면..?)\n네 번째 시도 (동작 파라미터화) # public interface ApplePredicate { boolean test(Apple apple); } public class AppleHeavyWeightPredicate implements ApplePredicate { // 전략 public boolean test(Apple appe) { return apple.getWeight() \u0026gt; 150; } } public class AppleGreenColorPredicate implements ApplePredicate { // 전략 public boolean test(Apple apple) { return \u0026#34;GREEN\u0026#34;.equals(apple.getColor()); } } // 조건이 추가/변경될 때, 위와 같은 Predicate 만 생성해주고 적용하면 된다. public static List\u0026lt;Apple\u0026gt; filterApple(List\u0026lt;Apple\u0026gt; apples, ApplePredicate p) { List\u0026lt;Apple\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for(Apple apple : apples) { if(p.test(apple)) { result.add(apple); } } return result; } 위와 같은 방식을 전략 패턴이라고 한다. 전략(알고리즘)을 동적으로 선택한다.\n전략 디자인 패턴은 각 알고리즘(전략이라 부르는)을 캡슐화 하는 알고리즘 패밀리를 정의해둔 다음에 런타임에 알고리즘을 선택하는 기법이다.\n클라이언트는 다양한 전략들 중 한 개를 선택해서 생성하고, 컨텍스트에 주입한다. (사용한다.)\n다섯 번째 시도 (동적 파라미터 -\u0026gt; 익명 클래스 적용) # List\u0026lt;Apple\u0026gt; filteredApples = filterApple(apples, new ApplePredicate() { public boolean test(Apple apple) { return \u0026#34;GREEN\u0026#34;.eqauls(apple.getColor()); } }); Predicate 를 생성하기에는 애매할 때, 위와 같이 익명 클래스로 사용할 수 있다.\n다만 익명 클래스의 단점은 아직도 코드의 길이가 길다는 것이다. (또, 익숙하지 않다는 것도 있다.)\n여섯 번째 시도 (동적 파라미터 -\u0026gt; 익명 클래스 적용) # List\u0026lt;Apple\u0026gt; filteredApples = filterApple(apples, apple -\u0026gt; \u0026#34;GREEN\u0026#34;.eqauls(apple.getColor())); Predicate 를 생성하기에는 애매할 때, 위와 같이 람다표현식으로 사용할 수 있다. (익명 클래스보다 더 가독성이 뛰어나고 사용하기 쉽다.)\n위와 같이 자주 사용되는 Predicate, Function 등을 이미 자바에서 함수형 인터페이스로써 만들어두었다.\nList\u0026lt;Apple\u0026gt; filteredApples = apples.filter(apple -\u0026gt; \u0026#34;GREEN\u0026#34;.eqauls(apple.getColor())); 사실 위에서 만든 filterApple() 함수를 다른 List, Predicate 형식으로 추상화하면 자바에서 제공하는 filter() 가 된다.\npublic static List\u0026lt;T\u0026gt; filter(List\u0026lt;T\u0026gt; list, Predicate\u0026lt;T\u0026gt; p) { List\u0026lt;T\u0026gt; result = new ArrayList\u0026lt;\u0026gt;(); for(T el : list) { if(p.test(el)) { result.add(el); } } return result; } Comparator 로 정렬하기 # java.util.Comparator 객체를 이용하여 sort 에서 동작 파라미터를 사용할 수 있다.\npublic interface Comparator\u0026lt;T\u0026gt; { int compare(T o1, T o2); } apples.sort(new Comparator\u0026lt;Apple\u0026gt; { public int compare(Apple o1, Apple o2) { return o1.getWeight().compareTo(a2.getWeight()); } }) 이것은 최종적으로 아래와 같이 수정할 수 있다.\napples.sort((Apple o1, Apple o2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight())); "},{"id":250,"href":"/docs/BOOKS/%EB%AA%A8%EB%8D%98-%EC%9E%90%EB%B0%94-%EC%9D%B8-%EC%95%A1%EC%85%98/3%EC%9E%A5-%EB%9E%8C%EB%8B%A4%ED%91%9C%ED%98%84%EC%8B%9D/","title":"3장. 람다표현식","section":"모던 자바 인 액션","content":" 람다 표현식 # 람다? # 람다 표현식(이하 람다)는 메서드로 전달할 수 있는 익명함수를 단순화 한 것이다.\n람다 표현식(lambda expression)이란 간단히 말해 메소드를 하나의 식으로 표현한 것입니다.\n람다는 {parameters} {-\u0026gt;} {body} 의 형태로 작성된다.\n(Apple a1, Apple a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight()); 자바 8에서 지원하는 5 가지 람다 표현식의 예제 # 1. (String s) -\u0026gt; s.length() 2. (Apple a) -\u0026gt; a.getWeight() \u0026gt; 150 3. (int x, int y) -\u0026gt; { System.out.println(x, y); } 4. () -\u0026gt; 42 5. (Apple a1, Apple a2) -\u0026gt; a1.getWeight().compareTo(a2.getWeight()) 표현식이 한 개인데, return 문을 사용해야 한다면 블록{}으로 감싸야한다.\n(String s) -\u0026gt; return s + i; // X (String s) -\u0026gt; { return s + i; } // O 함수형 인터페이스 # 함수형 인터페이스는 오직 하나의 추상메서드만을 갖는 인터페이스 이다.\nPredicate, Compator, Runnable, Function 등이 있다.\n함수형 인터페이스를 활용한다는 것은, 람다 표현식을 적극 활용할 수 있다는 것이다. (다르게 말하면 람다의 표현식이 함수형 인터페이스의 인스턴스(함수형 인터페이스를 구현한 인스턴스)가 될 수 있다는 것이다.)\n람다 표현식이란?\n"},{"id":251,"href":"/docs/BOOKS/%EB%AA%A8%EB%8D%98-%EC%9E%90%EB%B0%94-%EC%9D%B8-%EC%95%A1%EC%85%98/4%EC%9E%A5-%EC%8A%A4%ED%8A%B8%EB%A6%BC-%EC%86%8C%EA%B0%9C/","title":"4장. 스트림 소개","section":"모던 자바 인 액션","content":"Stream 이란, \u0026lsquo;데이터 처리 연산을 지원하도록, source 에서 추출된 연속된 요소(sequence of elements)\u0026rsquo; 라고 한다.\n연속된 요소\n컬렉션과 마찬가지로 (특정 요소 형식으로 이루어진) 연속된 값 집합의 인터페이스를 제공한다.\n컬렉션은 자료구조(data structure)이므로, 시간/공간 복잡도에 대한 고려, 저장, 접근 연산이 주를 이룬다.\n반면, 스트림은 filter, sorted, map 과 같은 표현식(표현 계산식)이 주를 이룬다.\n즉, 컬렉션의 주제는 데이터(data)이고 스트림의 주제는 계산(operation, calculation)이다.\n소스(Source)\n스트림은 컬렉션, 배열, I/O 자원 등의 \u0026lsquo;데이터 소스\u0026rsquo;로부터 데이터를 소비한다.\n예를 들어, 정렬된 컬렉션으로 스트림을 생성하면 정렬이 유지되고 리스트로 스트림을 만들면 리스트의 요소와 같은 순서를 유지한다.\n데이터 처리 연산\n스트림은 \u0026ldquo;함수형 언어에서 (일반적으로)지원하는 연산 + 데이터베이스와 비슷한 연산\u0026rdquo; 을 지원한다.\n예를 들어, filter, map,, reduce, find, match, sort 등의 연산이 있다.\n이들을 순차적으로, 병렬적으로 실행할 수 있다.\n파이프라이닝(pipelining)\n(대부분의) 스트림 연산은 스트림 연산끼리 연결하여 커다란 파이프라인을 구성할 수 있다.\n* 커다란 파이프라인을 구성할 수 있도록 자기 자신을 반환한다.\n덕분에 Laziness(지연), Short-circuiting(쇼트 서킷) 과 같은 최적화도 얻을 수 있다고 한다.\n내부 반복\n반복자(iterator)를 이용해서 명시적으로 컬렉션을 순회하는 것과 달리, 스트림은 내부 반복을 지원한다.\n"},{"id":252,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-%EC%9E%85%EB%AC%B8%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%9E%90%EB%B0%94-%EA%B0%9D%EC%B2%B4-%EC%A7%80%ED%96%A5%EC%9D%98-%EC%9B%90%EB%A6%AC%EC%99%80-%EC%9D%B4%ED%95%B4/5%EC%9E%A5.-%EA%B0%9D%EC%B2%B4-%EC%A7%80%ED%96%A5-%EC%84%A4%EA%B3%84-5%EC%9B%90%EC%B9%99-SOLID/","title":"5장. 객체 지향 설계 5원칙 (SOLID)","section":"스프링 입문을 위한 자바 객체 지향의 원리와 이해","content":" 객체 지향 설계 5 원칙 - SOLID # * 주관적으로 해석될 수 있다.\n객체 지향의 특성을 올바르게 사용하는 방법, 즉 객체 지향 언어를 이용해 객체 지향 프로그램을 올바르게 설계해 나가는 방법/원칙에 대한 고민이 있었다.\n많은 Best Practice, 시행 착오 속에서 SOLID 개념이 탄생되었다.\n이들의 기본적인 원칙은 응집도(cohension)를 높이고, 결합도(coupling)는 낮추는 것에 있다.\n우리들의 프로그램(소프트웨어)에 녹여내야 하는 개념이다.\n디자인 패턴, 스프링 프레임워크의 뼈대이다.\n객체 지향 4대 특성을 제대로 활용하면 자연스럽게 SOLID 가 적용된다.\n단일 책임 원칙 (Single Responsibility Principle) 개방 폐쇄 원칙 (Open Closed Principle) 리스코프 치환 원칙 (Liskov Substitution Principle) 인터페이스 분리 원칙 (Interface Segregation Principle) 의존 역전 원칙 (Dependency Inversion Principle) 단일 책임 원칙 (Single Responsibility Principle) # 한 클래스는 하나의 책임(역할)을 가져야 한다.\n어떤 클래스를 변경해야 하는 이유는 오직 하나뿐이어야 한다.\n클래스뿐만 아니라, 속성, 메서드 패키지, 모듈, 컴포넌트, 프레임워크 등에서도 적용될 수 있는 개념이다.\n예시 1 (클래스)\n남자 클래스 남자친구 역할 아들 역할 사원 역할 군인 역할 위의 \u0026lsquo;남자\u0026rsquo; 클래스는 역할(책임)이 너무 많다. 이것을 분리할 수 있다.\n남자친구 클래스 아들 클래스 사원 클래스 군인 클래스 예시 2 (멤버 변수)\nclass 사람 { 성별; is남자; is여자; 군번; } (남자만 군번이라는 속성을 갖는다고 가정하에) 위의 \u0026lsquo;사람\u0026rsquo; 클래스는 \u0026lsquo;남자\u0026rsquo;, \u0026lsquo;여자\u0026rsquo; 역할을 다루고 있다. 여자 역할에서 군번 속성은 필요하지 않다. 따라서, 남자 클래스와 여자 클래스로 분리할 수 있다.\nclass 남자 { 군번; } class 여자 { } 예시 3 (메소드)\nclass 강아지 { 성별; is수컷 = true; is암컷 = false; ... void 소변보다() { if(수컷) { } else { } } } 위의 강아지 클래스는 수컷, 암컷을 모두 구현하려 하고 있다. 그 대가로 소변보다() 메소드에서 if 분기 처리가 발생하고 있다.\n수컷, 암컷 클래스로 분리할 수 있다.\nabstract class 강아지 { abstract void 소변보다(); } class 수컷 extends 강아지 { void 소변보다() { ... } } class 암컷 extends 강아지 { void 소변보다() { ... } } 개방 폐쇄 원칙 (Open Closed Principle) # 확장에 대해서는 열려 있어야 하고, 변경에 대해서는 닫혀 있어야 한다.\n자신의 확장에는 열려 있고, 주변의 변경에는 닫혀 있어야 한다.\n// 변경 전 운전자 ----\u0026gt; 쏘나타 수동 기어 조작() 창문 열기() // 변경 후 운전자 ----\u0026gt; 아반떼 자동 기어 조작() 창문 열기() 위의 예시에서는 운전자가 수동 기어 조작() 에서 자동 기어 조작() 으로 변경된 메소드를 사용하게 된다. 즉 운전자의 코드가 변경된다.\nOCP 에 어긋난다. 아래와 같이 개선할 수 있다.\n운전자 ----\u0026gt; 자동차 창문 열기() 기어 조작() | | | | 쏘나타 아반떼 창문열기() 창문열기() 기어조작() 기어조작() 위의 예시에서는 쏘나타에서 아반떼로, 아반떼에서 쏘나타로 변경되어도 운전자의 코드는 변경되지 않는다. 또 자동차는 무한히 확장 가능하다.\nOCP 가 잘 성립된다. (자동차의)확장에는 열려 있고, (운전자의)변경에는 닫혀 있다.\nOCP 를 통해 유연성, 재사용성, 유지보수성 등의 이점을 얻을 수 있다.\n리스코프 치환 원칙 (Liscov Substitution Principle) # 하위 타입은 언제나 자신의 기반 타입(상위 타입)으로 교체할 수 있어야 한다.\n하위 클래스의 인스턴스는 상위 객체 참조 변수에 대입해 상위 클래스의 인스턴스 역할을 하는데 문제가 없어야 한다.\n하위 클래스 is a kind of 상위 클래스 구현 클래스 is able to 인터페이스 위의 문장이 성립된다면, LSP 를 지키고 있는 것이다.\n// 잘못된 예시 아버지 춘향이 = new 딸(); // 잘된 예시 동물 뽀로로 = new 펭귄(); 객체 지향의 4대 특성 중 \u0026lsquo;상속\u0026rsquo; 개념이 잘 적용되어 있다면, LSP 도 자연스럽게 성립되지 않을까 생각한다.\n인터페이스 분리 원칙 (ISP) # 인터페이스를 분리한다.\n자동차 운전자 ----------- 자동차 인터페이스 ----------- 기어 조작() | 창문 열기() | | 만능 기계 | | | 비행기 운전자 ----------- 비행기 인터페이스 ----------- 이륙하기() ... 단일 책임 원칙(SRP) 와 인터페이스 분할 원칙(ISP)는 같은 문제에 대한 두 가지 다른 해결책이라고 볼 수 있다.\n책에서는 특별한 경우가 아니라면, SRP 를 적용하는 것을 추천하고 있다.\n인터페이스 최소주의 원칙 상위 클래스는 풍부할수록 좋고, 인터페이스(강제사항)는 작을수록 좋다. 위의 예시에서 만능 기계 는 기어조작(), 창문열기(), 이륙하기() 등 모두를 구현해야 한다. 의존 역전 원칙 (DIP) # 고차원 모듈(역할, 인터페이스, \u0026hellip;)은 저차원 모듈(구현, 구현 클래스, \u0026hellip;) 에 의존하면 안된다.\n추상화된 것은 구체적인 것에 의존하면 안된다.\n구체적인 것은 추상화된 것에 의존해야 한다.\n자주 변경되는 구체 클래스(구현)에 의존하지 말아야 한다.\n자신보다 변하기 쉬운 것에 의존하지 말아야 한다.\n// 스노우 타이어는 누구에게도 의존하지 않는다. 자동차 ----\u0026gt; 스노우 타이어 아래와 같이 개선할 수 있다.\n// 스노우 타이어는 타이어에 의존한다. 자동차 ----\u0026gt; 타이어 ^ ^ | | | | 일반타이어 스노우타이어 자동차가 구체 클래스(스노우 타이어, 일반 타이어)에 의존하지 않고, 추상화 클래스 혹은 인터페이스(타이어)에 의존하도록 수정했다.\n이제 자동차는 구체적인 타이어(스노우 타이어, 일반 타이어)가 변경되어도 영향을 받지 않는다.\n(여기까지는 OCP의 예시와 유사하다. 즉 하나의 원칙을 지키면 자연스럽게 다른 원칙까지 지켜지게 되는 경우가 많다.)\n여기서 눈여겨 볼 점은, 구체 클래스(스노우타이어)의 의존 방향(관계)이 역전되었다는 것이다.\n스노우 타이어는 누구에게도 의존하지 않다가 타이어라는 추상화된 것을 의존하기 시작했다. 즉 의존이 역전되었다.\n구체적인 것에 의존하던 것을 추상화된 인터페이스나 상위 클래스를 두어 변화에 영향받지 않게 하는 것이 의존 역전 원칙이다.\n"},{"id":253,"href":"/docs/BOOKS/%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%84%9C%EB%B9%84%EC%8A%A4%EB%A5%BC-%EC%A7%80%ED%83%B1%ED%95%98%EB%8A%94-%EA%B8%B0%EC%88%A0/5%EC%9E%A5_%EB%8C%80%EA%B7%9C%EB%AA%A8-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%B2%98%EB%A6%AC%EC%9D%98-%EC%96%B4%EB%A0%A4%EC%9A%B4-%EC%A0%90-%EB%A9%94%EB%AA%A8%EB%A6%AC%EC%99%80-%EB%94%94%EC%8A%A4%ED%81%AC/","title":"5장. 대규모 데이터 처리의 어려운 점 (메모리와 디스크)","section":"대규모 서비스를 지탱하는 기술","content":" (대규모 데이터 처리가 어려운 이유)메모리 내에서 처리(계산)할 수 없다. # 메모리에서 처리할 수 없으면 DISK 를 사용해야 한다. 메모리의 크기는 DISK에 비해 작기 때문에 데이터의 크기가 클 경우 메모리에서 모두 처리할 수 없게 된다. 메모리는 디스크에 비해 10^5(10만) ~ 10^6(100만) 배 빠르다. 메모리는 왜 디스크보다 빠를까? # 1. 물리적인 구조\n물리적인 구조가 그렇다. 메모리는 전기적인 부품이다. 데이터를 탐색하는 속도가 빠르다.\n반대로 DISK는 동축 상에 원반(disk)로 쌓여 있다. 원반 회전, 헤드의 이동 등의 물리적인 비용이 발생하고 이게 크다.\nSSD의 경우 물리적인 회전이 아니므로 탐색 비용이 빠르지만 버스 속도가 병목이 되거나 그 밖에 구조에 기인하는 면이 있어서 메모리에 비해서는 느리다.\n2. 전송 속도, 버스 속도\n아래는 책에서 나온 hdparm 측정한 전송 속도 예시이다. 약 100배 이상 차이가 난다.\nTiming cached reads : 7525.03 MB/sec (7.5 GB/초) - Memory 에서 읽어 CPU 까지 가는 비용이라고 보면 될 것 같다. Timing buffered disk reads : 58.37 MB/sec (58 MB/초) - Disk 에서 읽어 CPU 까지 가는 비용이라고 보면 될 것 같다. 단일 호스트의 부하 # 추측하지 말라, 계측하라 # 단일 호스트의 성능을 끌어내는 데에는 서버 리소스의 이용현황을 정확하게 파악할 필요가 있다. 즉, 부하가 어느 정도 걸리고 있는지 알아야 한다. 이런 계측작업이야 말로 단일 호스트의 부하를 줄이는 데 가장 중요한 작업이다.\n병목 규명 작업의 기본적인 흐름 # 병목을 규명하기 위한 작업을 크게 나누면 다음과 같다.\nLoad Average 확인 CPU, I/O 병목 원인 확인/조사 1. Load Average 확인\nLoad Average는 시스템 전체의 부하 상황을 나타내는 지표다. 다만, Load Average 만으로는 병목의 원인(구체적인 포인트)을 판단할 수 없다.\nLoad Average 값을 시작으로 병목에 대한 조사를 시작하는 것이다. Load Average는 낮은데 시스템의 전송량(처리량?)이 오르지 않는 경우도 가끔 있다. 이런 경우는 소프트웨어 설정, 오류, 네트워크, 원격 호스트 측에 원인이 없는지 살펴본다.\n2. CPU, I/O 병목 원인 확인/조사\nLoad Average 가 높은 경우 CPU, I/O 어느 쪽에 원인이 있는지를 조사한다.\nsar, vmstat 등으로 시간 경과에 따른 \u0026lsquo;CPU 사용률\u0026rsquo; 이나 \u0026lsquo;I/O 대기율\u0026rsquo; 의 추이를 확인할 수 있다.\n아래는 부하의 원인을 좁혀나갈 수 있는 기본적인 전략과 대응 방법이다.\n경우 병목 확인 병목 조치 CPU 부하가 높은 경우 1. 사용자 프로그램의 처리가 병목인지, 시스템 프로그램이 원인인지 확인한다. top, sar 등으로 확인할 수 있다. 2. ps로 볼 수 있는 프로세스 상태, CPU 사용 시간 등을 확인할 수 있다. 3. (문제로 보여지는) 프로세스를 찾았고 보다 상세하게 조사할 경우 strace, oprofile 등으로 프로파일링을 해서 병목 지점을 좁혀간다. 일반적으로 CPU에 부하가 걸리고 있는 경우는 다음 상황 중 하나이다. 1. disk, memory 용량 등 그 밖의 부분에서는 병목이 되지 않는, 말하자면 이상적인 상태 2. 프로그램이 폭주해서 CPU에 필요 이상의 부하가 걸리는 경우 1. 서버 증설 2. 프로그램 로직 / 알고리즘 개선 3. 오류 제거 I/O 부하가 높은 경우 프로그램으로부터 입출력이 많아서 부하가 높거나 스왑이 발생해서 디스크 액세스가 발생하고 있는 상황 중 하나인 경우가 대부분이다. sar, vmstat 등으로 스왑의 발생 상황을 확인해서 문제를 가려내 볼 수 있다. 스왑이 발생하고 있는 경우는 다음과 같이 조사해볼 수 있다.\n1. 특정 프로세스가 극단적으로 메모리를 많이 사용하고 있는지 ps 등으로 확인한다. 2. 프로그램의 오류로 메모리를 지나치게 사용하고 있는지 확인한다. 3. 탑재된 메모리가 부족한지 확인한다. (메모리를 증설하지 못하는 경우에는 분산을 검토한다.) 스왑이 발생하지 않고 디스크로의 입출력이 빈번하게 발생하고 있는 경우는 캐시에 필요한 메모리가 부족한 경우를 생각해볼 수 있다. 해당 서버가 저장하고 있는 데이터 용량과 증설 가능한 메모리 양을 비교해서 다음과 같이 나눠 검토한다. 1. 메모리 증설로 캐시 영역을 확대시킬 수 있는 경우는 메모리를 증설한다. 2. 메모리 증설로 대응할 수 없는 경우는 데이터 분산, 캐시 서버 도입 등을 검토한다. 3. 프로그램을 개선해서 I/O 빈도를 줄이는 것을 검토한다. 1. 프로그램 개선 2. 메모리 증설 or 분산 3. 캐시 서버 도입 OS 튜닝 (= 부하의 원인을 알고 이것을 제거하는 것) # 튜닝이라는 단어를 \u0026lsquo;본래 SW가 지니고 있는 성능을 2배, 3배, x배 이상으로 키워지기 위한 것\u0026rsquo;으로 이해하고 있을 수 있다. 이게 아니다.\n튜닝의 본래 의미는, \u0026lsquo;병목이 발견되면 이를 제거하는 작업\u0026rsquo;이다. 애초에 HW, SW가 지니고 있는 성능 이상의 성능을 내는 것은 불가능하다.\n우리가 할 수 있는 것은 본래 지닌 성능을 충분히 발휘할 수 있도록 문제가 될 만한 부분을 제거하는 것이다.\n최근의 OS, 미들웨어는 기본적으로 충분한 성능을 발휘할 수 있도록 설정되어 있다. 이렇게 기본 설정이 최적화 되어 있다면 아무리 설정을 변경하더라도 대부분의 경우에는 효과가 없다. (오히려 역효과가 날 수도 있을 것이다.)\n문제가 되는 부분(예를 들어, 10초 걸릴 작업이 100초가 걸리는 등)이 발견되면 아래와 같은 행동들을 통해 튜닝(병목 구간 제거)을 하는 것이다.\n(메모리 증설 확인) 캐시 영역을 확보함으로써 대응할 수 있는지 확인한다. (데이터 양 확인) 원래 데이터 양이 비정상적으로, 비효율적으로 많지는 않는지 확인한다. (I/O 관련 애플리케이션 알고리즘 확인) 애플리케이션 측의 I/O 알고리즘을 변경할 필요는 없는지 확인한다. 위 내용의 바탕이 되고 있는 \u0026lsquo;(24시간 365일) 서버/인프라를 지탱하는 기술\u0026rsquo;이라는 책이 있다. OS 내부 구조, 부하 계측 방법에 관한 기본적인 내용을 설명한다.\n"},{"id":254,"href":"/docs/BOOKS/%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%84%9C%EB%B9%84%EC%8A%A4%EB%A5%BC-%EC%A7%80%ED%83%B1%ED%95%98%EB%8A%94-%EA%B8%B0%EC%88%A0/6%EC%9E%A5_%EA%B7%9C%EB%AA%A8-%EC%A1%B0%EC%A0%95%EC%9D%98-%EC%9A%94%EC%86%8C/","title":"6장. 규모 조정의 요소","section":"대규모 서비스를 지탱하는 기술","content":" 규모 조정 # CPU 부하의 규모 조정은 간단하다. # 스케일 아웃 전략을 통해 대응한다. 보통 웹, API, 크롤러 등의 애플리케이션에 해당된다. I/O 부하의 규모 조정은 어렵다. # 보통 DB(with 대규모 데이터) 가 해당된다. 두 종류의 부하(CPU, I/O)와 웹 애플리케이션 # 일반적으로 웹 애플리케이션은 CPU 바운드 프로그램이다.\n반면, 일반적으로 디스크에 저장된 데이터를 찾아내는 프로그램(= DB)는 I/O 바운드 프로그램이다.\n멀티태스킹 OS와 부하 # (멀티 태스킹 환경에서) A가 CPU 를 점유하고 있는 동안 (CPU가 필요한)B, C 는 대기하게 된다. \u0026lsquo;처리하려고 해도 대기한다\u0026rsquo; 라는 대기 상태는 프로그램(태스크)의 실행 지연이다.\nLoad Average 는 단위 시간당 대기된 Task의 수, 즉 평균적으로 어느 정도의 task가 대기 상태로 있었는지를 보고하는 수치다.\nLoad Average 가 높은 상황은 그만큼 task 실행에 대기가 발생하고 있다는 표시이고, 지연이 되는(= 부하가 높은) 상황이라고 볼 수 있다.\nAverage가 보고하는 부하의 정체 # HW는 일정 주기로 CPU로 인터럽트(interrupt) 신호를 보낸다. (주기적으로 보내는 신호여서 Timer interrupt 라고 부르기도 한다.)\n예를 들어 CentOS 5 에서의 인터럽트 간격은 4ms 가 되도록 설정되어 있다.\n이 인터럽트를 통해 어떤 프로세스가 얼마만큼의 CPU를 사용하고 있는지, 시간을 얼마나 쓰고 있는지 등을 계산한다. (= Load Average 가 계산된다.)\n커널은 타이머 인터럽트가 발생했을 때 \u0026lsquo;실행 가능 상태 task\u0026rsquo; 와 \u0026lsquo;I/O 대기 상태 task\u0026rsquo; 개수를 세어둔다. 이 값을 단위 시간으로 나누면 Load Average 값이 된다.\n아마 이런 수식일 것이다.\nI/O 대기 상태 task / (실행 가능 상태 task + I/O 대기 상태 task)\n즉, Load Average가 의미하는 것은 아래와 같다.\n처리를 하려고 해도 실행할 수 없어 대기하고 있는 프로세스 수 CPU 점유를 대기하고 있는 프로세스 수 I/O가 완료되기를 기다리고 있는 프로세스 수 = CPU 부하, I/O 부하에 따라 (자연스럽게) Load Average 가 높아진다.\n"},{"id":255,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-%EC%9E%85%EB%AC%B8%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%9E%90%EB%B0%94-%EA%B0%9D%EC%B2%B4-%EC%A7%80%ED%96%A5%EC%9D%98-%EC%9B%90%EB%A6%AC%EC%99%80-%EC%9D%B4%ED%95%B4/6%EC%9E%A5.-%EC%8A%A4%ED%94%84%EB%A7%81%EC%9D%B4-%EC%82%AC%EB%9E%91%ED%95%9C-%EB%94%94%EC%9E%90%EC%9D%B8-%ED%8C%A8%ED%84%B4/","title":"6장. 스프링이 사랑한 디자인 패턴","section":"스프링 입문을 위한 자바 객체 지향의 원리와 이해","content":" 스프링이 사랑한 디자인 패턴 # 디자인 패턴이란?\n프로그램을 작성하다보면 비슷비슷한 상황에 직면하게 된다. 이러한 상황에서 이전의 많은 개발자들이 고민하고 정제한 (사실상의)표준 설계 패턴이다.\nDesign Pattern = 설계 패턴\n개발을 하면서 사용된 다양한 설계 패턴 중 많은 사람들이 인정한 Best Practice 를 정리한 것이다.\n\u0026lsquo;객체 지향의 4대 특성\u0026rsquo;과 \u0026lsquo;객체 지향의 설계 5 원칙\u0026rsquo;이 기반이 된다.\n디자인 패턴은 객체 지향의 특성 중 상속, 인터페이스, 합성(객체를 속성으로 사용하는 것)을 이용한다.\n어댑터 패턴 (Adapter Pattern) 프록시 패턴 (Proxy Pattern) 데코레이터 패턴 (Decorator Pattern) 싱클톤 패턴 (Singleton Pattern) 템플릿 메서드 패턴 (Template Method Pattern) 팩토리 메서드 패턴 (Factory Method Pattern) 전략 패턴 (Strategy Pattern) 템플릿 콜백 패턴 (Template Callback Pattern) 이 외 다양한 패턴들 어댑터 패턴 (Adapter Pattern) # 어댑터(adapter) 는 변환기(converter) 라고 할 수 있다.\n변환기는 서로 다른 두 인터페이스 사이에 통신(접근, 연결)이 가능하게 하는 것이다.\nOCP (개방 폐쇄 원칙) 을 활용한 디자인 패턴이다.\n어댑터 패턴은 합성(객체를 속성으로 만들어서 참조하는 것)을 이용한 디자인 패턴이다.\n호출당하는 쪽의 메서드를 호출하는 쪽의 코드에 대응하도록 중간에 변환기(converter)를 통해 호출하는 패턴이다.\n예시 1)\n핸드폰을 전원 콘센트에 직접 연결할 수 없다. \u0026lsquo;충전기\u0026rsquo; 라는 변환기를 통해 연결할 수 있다.\n예시 2)\n애플리케이션을 직접 데이터베이스로 연결하지 않고 ODBC, JDBC 라는 변환기를 통해 연결한다.\n// 어댑터 패턴을 적용하지 않은 코드 public class ServiceA { void runServiceA() { System.out.println(\u0026#34;ServiceA\u0026#34;); } } public class ServiceB { void runServiceB() { System.out.println(\u0026#34;ServiceB\u0026#34;); } } public class Main { public static void main(String[] args) { ServiceA serviceA = new ServiceA(); ServiceB serviceB = new ServiceB(); serviceA.runServiceA(); serviceB.runServiceB(); } } // 어댑터 패턴을 적용한 코드 public class ServiceA { void runServiceA() { System.out.println(\u0026#34;ServiceA\u0026#34;); } } public class ServiceB { void runServiceB() { System.out.println(\u0026#34;ServiceB\u0026#34;); } } public class AdapterA { Service serviceA = new ServiceA(); // \u0026#34; 어댑터 패턴은 합성(객체를 속성으로 만들어서 참조하는 것)을 이용한 디자인 패턴이다. \u0026#34; void runService() { serviceA.runServiceA(); } } public class AdapterB { Service serviceB = new ServiceB(); // \u0026#34; 어댑터 패턴은 합성(객체를 속성으로 만들어서 참조하는 것)을 이용한 디자인 패턴이다. \u0026#34; void runService() { serviceB.runServiceB(); } } public class Main { public static void main(String[] args) { // 호출당하는 쪽의 메서드를 호출하는 쪽의 코드에 대응하도록 중간에 변환기(converter)를 통해 호출하는 패턴이다. // ServiceA, ServiceB 의 코드(호출당하는 쪽)를 Main 의 코드(호출하는 쪽)에 맞춘다..? AdapterA adapterA = new AdapterA(); AdapterB adapterB = new AdapterB(); adapterA.runService(); \u0026lt;-- 메소드명을 통일시켰기에 인터페이스를 구현하게 해서 한 단계 더 개선시킬 수 있다. adapterB.runService(); \u0026lt;-- 메소드명을 통일시켰기에 인터페이스를 구현하게 해서 한 단계 더 개선시킬 수 있다. } } 비슷한 로직이지만 메소드명이 다른 경우가 있다. (처음부터 동일한 메소드명으로 작성이 되어 있고 인터페이스도 잘 설계되어 있다면 상관 없겠지만, 그렇지 않은 경우도 있을 것이다.)\n이러한 경우에 어댑터 패턴을 통해 리팩토링을 진행할 수 있는 것 같다.\n호출당하는 쪽의 메서드를 호출하는 쪽의 코드에 대응하도록 중간에 변환기(converter)를 통해 호출하는 패턴이다.\n프록시 패턴 (Proxy Pattern) # 프록시는 대리자(대리인, 대변인) 의 의미를 갖는다.\n대리자(대리인, 대변인)는 \u0026lsquo;다른 어떠한 것(누군가)이 그 역할을 대신 수행하는 것\u0026lsquo;이다.\n프록시 패턴은 실제 객체가 가진 메서드와 같은 이름의 메서드를 사용하고, 이것을 위해 인터페이스를 사용한다.\n인터페이스를 사용하면 실제 객체 대신 대리자 객체(이하 가짜 객체)를 주입할 수 있다. 클라이언트 쪽에서는 실제 객체를 이용하는 지, 가짜 객체를 이용하는지 모를 것이다.\nOCP(개방 폐쇄 원칙), DIP(의존 역전 원칙) 을 활용한 디자인 패턴이다.\n// 프록시 패턴을 적용하지 않은 코드 public class Service { public String run() { return \u0026#34;Hello\u0026#34;; } } public class Main { public static void main(String[] args) { Service service = new Service(); System.out.println(service.run()); } } // 프록시 패턴을 적용한 코드 public interface ServiceInterface { String run(); } public class Service implements ServiceInterface { public String run() { return \u0026#34;Hello\u0026#34;; } } public class ProxyService implements ServiceInterface { Service service; // 합성 (객체를 속성으로 이용한다.) public String run() { // 호출에 대한 흐름 제어가 주된 목적이다. 반환하는 값에 대한 변화/수정 없이 그대로 전달한다. // 실제 메서드가 호출 되기 전/후에 별도의 로직을 수행할 수도 있다. service = new Service(); return service.run(); // 실제 반환되는 결과값은 변환이나 수정 없이 그대로 전달한다. } } public class Main { public static void main(String[] args) { ServiceInterface service = new ProxyService(); System.out.println(service.run()); } } \u0026quot; 백악관 \u0026lsquo;대변인\u0026rsquo;은 해당 기관의 입장을 대변할 뿐, 그 입장에 자신의 입장을 가감하지 않는다. 프록시 패턴도 실제 메서드의 반환값에 가감하지 않는다. 단, 제어의 흐름을 변경하거나 추가적인 로직을 수행하기 위해 사용한다 \u0026quot;\n제어 흐름을 조정할 목적으로 중간에 대리자(프록시)를 두는 패턴이다.\n데코레이터 패턴 (Decorator Pattern) # 데코레이터는 장식자/도장/도배업자를 의미한다.\n원본(원본 값)에 장식을 더한다. 즉 원래 메서드의 반환 값에 어떠한 조작(장식)을 덧입힌다.\n프록시 패턴과 구현 방법이 동일하다.\n프록시 패턴은 (클라이언트가 받을)최종 반환 값에 어떠한 조작이 없지만, 데코레이터 패턴은 최종 반환 값에 어떠한 조작이 들어간다.\n데코레이터 패턴에 장식이 없다면 프록시 패턴과 동일하다.\nOCP(개방 폐쇄 원칙), DIP(의존 역전 원칙) 을 활용한 디자인 패턴이다.\n// 데코레이터 패턴을 적용한 코드 // 프록시 패턴의 코드 예제와 동일 (클래스명과 return 값만 다르다.) public interface ServiceInterface { String run(); } public class Service implements ServiceInterface { public String run() { return \u0026#34;Hello\u0026#34;; } } public class DecoratorService implements ServiceInterface { Service service; // 합성 (객체를 속성으로 이용한다.) public String run() { // 실제 메서드에 대한 장식이 주된 목적이다. // 실제 메서드가 호출 되기 전/후에 별도의 로직을 수행할 수도 있다. service = new Service(); return \u0026#34;Decorator: \u0026#34; + service.run(); // 실제 반환되는 결과값에 장식이 추가되었다. } } public class Main { public static void main(String[] args) { ServiceInterface service = new DecoratorService(); System.out.println(service.run()); } } 메서드 호출의 반환 값에 변화를 주기 위해 중간에 장식자(데코레이터)를 두는 패턴이다.\n싱글톤 패턴 (Singleton Pattern) # 인스턴스를 1개만 만들어 사용하는 패턴이다.\n커넥션 풀, 스레드 풀, 디바이스 설정 객체 등과 같은 인스턴스에 활용될 수 있다.\n인스턴스를 1개만 만들고, 그것을 계속해서 재사용한다.\n1개의 단일 객체로 공유되기 때문에 (쓰기 가능한)속성을 갖지 않는 것이 정석이다. 다만, 읽기 전용으로 갖는 것은 문제가 되지 않는다.\n구현하기 위한 방법은 다음과 같다.\nnew 생성자에 제약을 건다. (private 을 사용한다.) 만들어진 인스턴스를 반환해주는 메서드가 필요하다. 만들어진 인스턴스를 참조할 정적(static) 참조 변수가 필요하다. public class Singleton { static Singleton singletonObj; private Singleton() { } // private public static Singleton getInstance() { if(singletonObj == null) { singletonObj = new Singleton(); } return singletonObj; } } public class Main { public static void main(String[] args) { // private 생성자이므로 아래와 같이 생성할 수 없다. // Singleton singleton = new Singleton(); Singleton s1 = Singleton.getInstance(); Singleton s2 = Singleton.getInstance(); Singleton s3 = Singleton.getInstance(); } } Class 의 인스턴스, 즉 객체를 1개만 만들어서 사용하는 패턴이다.\n템플릿 메서드 패턴 (Template Method Pattern) # 상위 클래스에서 공통의 로직을 수행하는 템플릿 메서드와 하위 클래스에 오버라이딩을 강제하는 추상 메서드 or 선택적으로 오버라이딩 할 수 있는 Hook 메서드를 두는 패턴을 템플릿 메서드 패턴이라고 한다.\nDIP 를 활용한 패턴이다.\n// 템플릿 메서드 패턴을 적용하지 않는 코드 public class Dog { public void playWithOwner() { System.out.println(\u0026#34;놀이 시작\u0026#34;); System.out.println(\u0026#34;강아지\u0026#34;); \u0026lt;-- Cat 클래스의 playWithOwner 메서드와 이 부분만 다르다 System.out.println(\u0026#34;놀이 휴식\u0026#34;); System.out.println(\u0026#34;놀이 끝\u0026#34;); } } public class Cat { public void playWithOwner() { System.out.println(\u0026#34;놀이 시작\u0026#34;); System.out.println(\u0026#34;고양이\u0026#34;); \u0026lt;-- Dog 클래스의 playWithOwner 메서드와 이 부분만 다르다 System.out.println(\u0026#34;놀이 휴식\u0026#34;); System.out.println(\u0026#34;놀이 끝\u0026#34;); } } // 템플릿 메서드 패턴을 적용한 코드 public abstract class Animal { // 템플릿 메서드 (템플릿을 제공한다.) public void playWithOwner() { System.out.println(\u0026#34;놀이 시작\u0026#34;); play1(); play2(); System.out.println(\u0026#34;놀이 끝\u0026#34;); } abstract void play1(); // 추상 메서드 // Hook 메서드 void play2() { System.out.println(\u0026#34;놀이 휴식\u0026#34;); } } public class Dog extends Animal { @Override public void play1() { System.out.println(\u0026#34;강아지\u0026#34;); } @Override public void play2() { ~~ } } public class Cat extends Animal { @Override public void play1() { System.out.println(\u0026#34;고양이\u0026#34;); } @Override public void play2() { ~~ } } 상위 클래스의 템플릿 메서드에서 하위 클래스가 오버라이딩한 메서드를 호출하는 패턴이다.\n팩토리 메서드 패턴 (Factory Mathod Pattern) # 팩토리는 공장을 의미한다. 즉, 객체를 생성하는 공장을 의미한다.\n팩토리 메서드는 객체를 생성/반환하는 메서드를 의미한다.\n팩토리 메서드 패턴은 하위 클래스에서 팩토리 메서드를 오버라이딩해서 객체를 반환하게 하는 것을 의미한다. (\u0026hellip;?)\nDIP 를 활용한 패턴이다.\n// 팩토리 메서드 적용된 코드 예시 public abstract class AnimalToy { // 팩토리 메서드가 생성할 객체(DogToy, CatToy)의 상위 클래스 abstract void idenfity(); } public class DogToy extends AnimalToy { // 팩터리 메서드가 생성할 객체 public void identify() { ~~ } } public class CatToy extends AnimalToy { // 팩터리 메서드가 생성할 객체 public void identify() { ~~ } } public abstract class Animal { abstract AnimalToy getToy(); // (추상) 팩토리 메서드 } public class Dog extends Animal { @Override AnimalToy getToy() { // 팩토리 메서드 오버라이딩 return new DogToy(); // 객체 반환 } // 설명과 동일하게 팩토리 메서드를 오버라이딩해서 객체를 반환하고 있다. } public class Cat extends Animal { @Override AnimalToy getToy() { // 팩토리 메서드 오버라이딩 return new CatToy(); // 객체 반환 } // 설명과 동일하게 팩토리 메서드를 오버라이딩해서 객체를 반환하고 있다. } public class Main { public static void main(String[] args) { // 팩토리 메서드를 보유한 객체(bolt, kitty) Animal bolt = new Dog(); Animal kitty = new Cat(); // 팩토리 메서드가 객체를 반환 AnimalToy boltBall = bolt.getToy(); AnimalToy kittyTower = kitty.getToy(); } } 오버라이드된 메서드가 객체를 반환하는 패턴이다.\n전략 패턴 # 전략 패턴은 디자인 패턴의 꽃이라고 한다.\n다음의 3 요소를 꼭 기억해야 한다.\n전략 메서드를 가진 전략 객체 전략 객체를 사용하는 컨텍스트 (전략 객체의 사용자/소비자) 전략 객체를 생성해서 컨텍스트에 주입하는 클라이언트 (제 3자, 전략 객체의 공급자) ㅡㅡㅡㅡㅡㅡ 1. 전략 객체 생성 ㅡㅡㅡㅡㅡㅡ\u0026gt; 전략들 (전략1, 전략2, ..., 전략n) | 클라이언트 | ㅡㅡㅡㅡㅡㅡ 2. 전략 객체 주입 ㅡㅡㅡㅡㅡㅡ\u0026gt; 컨텍스트 클라이언트는 다양한 전략들 중 한개를 선택해서 생성하고, 컨텍스트에 주입한다.\nOCP, DIP 를 활용한 패턴이다.\npublic class Gun implements Strategy { // 전략 (총) @Override public void runStrategy() { ~~ } } public class Sword implements Strategy { // 전략 (검) @Override public void runStrategy() { ~~ } } public class Soldier { // 컨텍스트 (군인) void runContext(Strategy strategy) { // 이 부분이 템플릿 메서드 패턴과 유사하다. System.out.println(\u0026#34;전투 시작\u0026#34;); strategy.runStrategy(); System.out.println(\u0026#34;전투 종료\u0026#34;); } } public class Client { // 클라이언트 (보급 장교, 제 3자) public static void main(String[] args) { Strategy strategy; Soldier soldier = new Soldier(); strategy = new Gun(); // 전략 객체 생성 soldier.runContext(strategy); // 컨텍스트에 전략 주입 strategy = new Sword(); // 전략 객체 생성 soldier.runContext(strategy); // 컨텍스트에 전략 주입 } } \u0026quot; 템플릿 메서드 패턴과 유사하다는 느낌이 든다면, 정확히 본 것이다. \u0026quot;\n같은 문제에 대해, 템플릿 메서드는 상속을 이용한 해결책을 제시하고 전략 패턴은 객체 주입을 통해 해결책을 제시한다.\n클라이언트가 전략을 생성해 전략을 실행할 컨텍스트에 주입하는 패턴이다.\n템플릿 콜백 패턴 (Template Callback Pattern) # 전략 패턴의 변형이다. 스프링의 3대 프로그래밍 모델 중 하나인 DI(의존성 주입)에서 사용하는 특별한 형태의 전략 패턴이다.\n전략 패턴과 모든 것이 동일한데, 전략을 익명 내부 클래스로 정의해서 사용한다는 특징이 있따.\nOCP 와 DIP 가 활용된 패턴이다.\n// 위의 전략 패턴과 동일한 예시 public class Soldier { void runContext(Strategy strategy) { System.out.println(\u0026#34;전투 시작\u0026#34;); strategy.runStrategy(); System.out.println(\u0026#34;전투 종료\u0026#34;); } } public class Client { public static void main(String[] args) { Soldier soldier = new Soldier(); soldier.runContext(new Strategy() { @Override public void runStrategy() { ~~ } }); soldier.runContext(new Strategy() { @Override public void runStrategy() { ~~ } }); } } 전략을 익명 내부 클래스로 구현한 전략 패턴이다.\n스프링이 사랑한 다른 패턴들 # 위의 8가지 패턴 이 외에 스프링은 다양한 디자인 패턴을 활용한다.\n스프링 MVC의 경우에는 프론트 컨트롤러 패턴(Front Controller Pattern), MVC 패턴 을 활용한다.\n"},{"id":256,"href":"/docs/BOOKS/%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%84%9C%EB%B9%84%EC%8A%A4%EB%A5%BC-%EC%A7%80%ED%83%B1%ED%95%98%EB%8A%94-%EA%B8%B0%EC%88%A0/7%EC%9E%A5_%EB%8C%80%EA%B7%9C%EB%AA%A8-%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC-%EB%8B%A4%EB%A3%A8%EA%B8%B0-%EC%9C%84%ED%95%9C-%EA%B8%B0%EC%B4%88_%EC%A7%80%EC%8B%9D/","title":"7장. 대규모 데이터를 다루기 위한 기초 지식","section":"대규모 서비스를 지탱하는 기술","content":" 대규모 데이터를 다루는 세 가지 요령 # 1. 최대한 메모리에서 처리한다.\nex: disk seek 횟수 최소화 ex: 국소성 활용한 분산 실현 2. (데이터량에 따른) 효율적인 알고리즘/자료구조 사용\nex: 선형 탐색 -\u0026gt; 이분 탐색 3. 데이터 압축, 검색 기술과 같은 테크닉\nex: 데이터 압축(데이터 용량 ↓) = 메모리 처리 ↑ = seek 횟수 ↓ Load Average 다음은 CPU 사용률, I/O 대기율 # 과부하로 시스템의 성능이 떨어지는 원인은 대부분의 경우에 CPU, I/O에 있다.\nLoad Average 를 보고 대응이 필요하다고 판단한 경우, 다음 단계로 CPU, I/O 중 어느 쪽에 원인이 있는지를 조사해야 한다.\np.51 에 sar 명령어를 통해 cpu %, iowait % 를 확인하고, 설명하고 있다.\n경우 설명 Load Average 높음 \u0026amp; CPU 사용량 높음 부하 원인이 CPU(리소스 부족) 라고 판단할 수 있다. (100% 확정할 수는 없다.) Load Average 높음 \u0026amp; I/O 대기율 높음 부하 원인이 I/O 라고 판단할 수 있다. (100% 확정할 수는 없다.) \u0026quot; 멀티 코어 CPU, Disk 하나 인 경우 CPU 부하는 분산돼도 I/O 부하는 분산되지 않는다. 코어 별로 (I/O wait)지표 값을 확인해보면 확실하게 알 수 있다. 따라서 멀티 코어 환경에서는 지표 값을 코어 별로(개별적으로) 확인할 필요도 있다. \u0026ldquo;\n"},{"id":257,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-%EC%9E%85%EB%AC%B8%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%9E%90%EB%B0%94-%EA%B0%9D%EC%B2%B4-%EC%A7%80%ED%96%A5%EC%9D%98-%EC%9B%90%EB%A6%AC%EC%99%80-%EC%9D%B4%ED%95%B4/7%EC%9E%A5.-%EC%8A%A4%ED%94%84%EB%A7%81-%EC%82%BC%EA%B0%81%ED%98%95%EA%B3%BC-%EC%84%A4%EC%A0%95-%EC%A0%95%EB%B3%B4/","title":"7장. 스프링 삼각형과 설정 정보","section":"스프링 입문을 위한 자바 객체 지향의 원리와 이해","content":" 스프링 삼각형과 설정 정보 # 스프링을 이해하기 위해 스프링의 3대 프로그래밍 모델을 이해할 수 있어야 한다.\n스프링의 3대 프로그래밍 모델이란?\nIoC/DI AOP PSA * POJO 기반임을 기억하자.\nIoC/DI # 제어의 역전, 의존성 주입\n* 주입이란? 외부에서 라는 뜻을 내포하고 있다. 즉, 외부에서 생성되어 주입이 되는 것이다.\n다음과 같은 코드가 있다.\n// 운전자 public class Driver { public static void main(String[] args) { Car car = new Car(); } } // 자동차 public class Car { Tire tire; public Car() { tire = new KoreaTire(); } ... } // 타이어 (인터페이스) interface Tire { String getBrand(); } // 한국 타이어 public class KoreaTire implements Tire { public String getBrand() { return \u0026#34;한국 타이어!\u0026#34;; } } // 미국 타이어 public class AmericaTire implements Tire { public String getBrand() { return \u0026#34;미국 타이어!\u0026#34;; } } 위의 코드는 운전자 -\u0026gt; 자동차 -\u0026gt; 타이어 형태의 의존 관계가 맺어지고 있다.\n스프링 없이 의존성을 주입하기 1 (생성자 주입)\n운전자 클래스에서 타이어를 생산하고, 자동차 에 주입해준다.\npublic class Driver { public static void main(String[] args) { Tire tire = new KoreaTire(); Car car = new Car(tire); // 타이어 주입 } } // 이하 생략 기존의 코드는 자동차가 어떤 타이어를 사용할지 결정했다. 개선된 코드는 운전자가 어떤 타이어를 사용할지 결정한다. (유연성이 향상되었다고 볼 수 있다. 조금 더 객체 지향적이다.) 자동차의 입장에서는, Tire 에 대해 더 이상 알 필요가 없다. 그저 주입만 받으면 된다. 스프링 없이 의존성을 주입하기 2 (속성 주입)\npublic class Driver { public static void main(String[] args) { Tire tire = new KoreaTire(); Car car = new Car(); car.setTire(tire); // 타이어 주입 } } // 이하 생략 속성 주입을 통해, 자동차를 생성할 때만 타이어를 주입할 수 있는 문제가 해결되었다. 즉 언제든지 주입, 교체할 수 있다. 생성자 주입, 속성 주입 중 무엇이 더 나은지는 호불호가 갈릴 수 있다. 지금까지는 스프링을 사용하지 않고 의존성을 주입했다.\n스프링 통해 의존성을 주입하기 1 (XML 파일 사용, 소스 코드에서 주입)\n생성자 주입, 속성 주입 모두 가능하다.\n속성 주입을 예시로 하여, 의사 코드를 작성하면 다음과 같다.\n운전자가 종합 쇼핑몰에서 타이어를 구입한다.\n운전자가 종합 쇼핑몰에서 자동차를 구입한다.\n운전자가 자동차에 타이어를 장착한다.\n여기서 눈 여겨 볼 점은 종합 쇼핑몰이 생겼는데, 종합 쇼핑몰의 역할을 하는 것이 바로 스프링 프레임워크 다.\n현실 세계와 더 유사해졌다. (= 조금 더 객체 지향적이다.)\npublic class Driver { public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\u0026#34;~~.xml\u0026#34;); Car car = context.getBean(\u0026#34;car\u0026#34;, Car.class); // 자동차 구입 Tire tire = context.getBean(\u0026#34;tire\u0026#34;, Tire.class); // 타이어 구입 car.setTire(car); } } // 이하 생략 가장 큰 이점은 자동차의 타이어 브랜드(구현체 클래스)를 변경할 때 재컴파일/재배포가 이뤄지지 않아도 된다는 점이다. XML 파일만 변경하면 된다.\n즉, 타이어 브랜드가 변경되어도 소스 코드는 아무것도 변경되지 않는다. 스프링 통해 의존성을 주입하기 2 (XML 파일 사용, XML에서 주입)\n의사 코드는 다음과 같다.\n운전자가 종합 쇼핑몰에서 자동차를 구매한다.\n종합 쇼핑몰은 자동차를 생산한다.\n종합 쇼핑몰은 타이어를 생산한다.\n종합 쇼핑몰은 자동차에 타이어를 장착한다.\n운전자는 종합 쇼핑몰로부터 자동차를 전달받는다.\n\u0026lt;bean id=\u0026#34;koreaTire\u0026#34; class=\u0026#34;~~.KoreaTire\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;americaTire\u0026#34; class=\u0026#34;~~.AmericaTire\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;car\u0026#34; class=\u0026#34;~~.Car\u0026#34;\u0026gt; \u0026lt;property name=\u0026#34;tire\u0026#34; ref=\u0026#34;koreaTire\u0026#34;\u0026gt;\u0026lt;/property\u0026gt; \u0026lt;/bean\u0026gt; 스프링 통해 의존성을 주입하기 3 (@Autowired 주입)\n의사 코드는 이전과 동일하다.\n// xml 설정 추가 부분 생략 @Autowired Tire tire; 설정자 메소드(setter)를 사용하지 않고, 설정 파일(xml)을 통해 속성을 주입해준다.\n설정 파일을 보고 자동으로 속성의 설정자 메서드에 해당하는 역할을 해주겠다는 의미이다.\n즉, 이전 코드에서 보인 bean 의 propert 부분을 자동으로 설정해 주는 것이다. (자동 의존성 주입)\n스프링 통해 의존성을 주입하기 3 (@Resource 주입)\n의사 코드는 이전과 동일하다.\n// xml 설정 추가 부분 생략 @Resource Tire tire; 정리하면 다음과 같다.\n스프링을 통해 의존성을 주입하기 위해서는 아래와 같은 방법이 있다.\n\u0026lt;property\u0026gt; @Autowired @Resource @Autowired @Resource 스프링 어노테이션 자바 표준 어노테이션 type 우선순위 \u0026gt; id 우선순위 id 우선순위 \u0026gt; type 우선순위 책에서는 다음과 같은 순위로 사용을 권장한다.\n\u0026lt;property\u0026gt; \u0026gt; @Resource \u0026gt; @Autowired\n* 설정 파일(xml) 을 사용하는 가장 중요한 이유는 재컴파일/재배포 없이 변경할 수 있다는 것이다.\n"},{"id":258,"href":"/docs/BOOKS/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-for-beginners/Broker-Replication-ISR/","title":"Broker, Replication, ISR","section":"아파치 카프카 for beginners","content":"Kafka Broker : 카프카가 설치된 서버의 단위를 의미\n보통 브로커 3대 유지하기를 권장한다고 함 partition -\u0026gt; replication 의 수 만큼 복제 (단, 브로커 개수에 제한된다.)\nLeader partition (DB의 master 개념) producer의 데이터를 전달받는 주체 Follower parition (DB의 slave 개념) Leader partition(브로커) 죽었을 때 -\u0026gt; follower partition 이 Leader 가 되어 가용성 보장 ISR = Leader + Follower partition e.g. replciation 3 이라면, Leader partition 1, Follower partition 2 개 존재한다.\nProducer 의 ack 옵션\nack 0 : 데이터 전달 후 응답 받지 않는다. 데이터가 잘 전송되었는지 알 수 없다. ack 1 : 데이터 전달 후 Leader partition 에 대해서만 응답 값을 받는다. Leader partition 에 대해서는 데이터가 잘 전송되었는지 알 수 있다. 단, Leader partition 에 저장된 것이 Follower 에도 잘 저장된 것을 의미하지는 않는다. 즉, 데이터 유실 가능성은 아직도 있다. ack all : Leader, Follower 파티션 모두에 응답 값을 받는다. 데이터 유실 가능성은 없다. 다만 속도가 현저히 늦어진다. 데이터 유입량, 유지시간 등을 고려해 replication 수를 지정한다.\n3개 이상의 브로커를 사용할 때 replication 3 설정을 권장한다.\n"},{"id":259,"href":"/docs/BOOKS/PAPER-Mock-Roles-not-Objects/","title":"Mock Roles, not Objects","section":"BOOKS","content":" Mock Roles, not Objects # 4. MOCK OBJECTS IN PRACTICE # 시스템 설계가 약할 때(강한 결합, 잘못된 책임 등_), Mock 기반의 테스트 코드는 굉장히 복잡해지고, 많은 문제(problem)를 야기한다.\n예를 들어, 우리가 하나의 클래스에 너무 많은 역할을 부여하고 테스트 코드(with Mocking) 작성할 때 이상함을 느끼곤한다. (그러곤 이 부분에 대해 리팩토링을 하곤 한다.)\n이런 케이스도 위에서 말한 케이스에 포함되는 것 같다.\n한 가지 대응 방법은 \u0026lsquo;Mocking 사용\u0026rsquo;을 중단하는 것이다.\n\u0026lsquo;Mocking 사용\u0026rsquo;은 설계 개선(위에서 말한 \u0026lsquo;예시\u0026rsquo; 처럼)을 위한 목적으로 사용하는 것이 더 낫다고 생각한다.\n4.1 Only Mock Types You Own # Mocking Objects 는 설계 기법이므로 프로그래머들은 오직 그들이(프로그래머) 변경할 수 있는 타입들에 대해서만 mock을 사용해야 한다. (?)\n\u0026quot; Mock Objects is a design technique so programmers should only write mocks for types that they can change. \u0026ldquo;\n\u0026rdquo; Programmers should not write mocks for fixed types, such as those defined by the runtime or external libraries. \u0026ldquo; (?, 어떤 것을 의미하는 지 이해하지 못했다.)\n\u0026rdquo; Instead they should write thin wrappers to implement the application abstractions in terms of the underlying infrastructure. Those wrappers will have been defined as part of a need-driven test. \u0026ldquo;\n4.2 Don\u0026rsquo;t use getters # \u0026rdquo; Getters expose implementation, which increases coupling between objects and allows responsibilities to be left in the wrong module. \u0026ldquo;\n\u0026rdquo; Avoiding getters forces an emphasis on object behaviour, rather than state, which is one of the characteristics of ResponsibilityDriven Design. \u0026ldquo;\nGetter 는 구현체를 노출하는데, 이 구현체를 노출함으로써 결합(coupling)을 증가시키고, 책임(responsibilties)이 적절하지 않은 곳(모듈, 클래스)에 분배되게 한다.\nGetter 를 피하면 객체의 상태(state)보다 동작(behaviour)을 강조하게 되는데, 이것은 ResponsibilityDriven Design 특징 중 하나이다.\n내가 이해한 것은, \u0026ldquo;무분별하게 getter 를 사용하지 말자.\u0026rdquo; 이다.\n예를 들면 아래와 같을 것 같다. A 라는 클래스(객체)에 getter 를 사용하지 않으면, A 에서 처리할 수 있다. getter 를 사용하면, getter 를 사용하는 곳에 책임(로직)이 분배된다. (= 결합을 증가시킨다.) 4.3 Be explicit about things that should not happen # 전달하고자 한 의도를 파악한 것인지 모르겠다. (잘못된 해석일 수 있다.)\n\u0026rdquo; There are some conditions that are not made clear when they are simply left out of the test. \u0026ldquo;\n\u0026rdquo; A specification that a method should not be called, is not the same as a specification that doesn’t mention the method at all. \u0026ldquo;\n\u0026rdquo; In the latter case, it’s not clear to other readers whether a call to the method is an error. We often write tests that specify that methods should not be called, even where not necessary, just to make our intentions clear. \u0026ldquo;\n\u0026lsquo;should not happen\u0026rsquo; 케이스에 대해 명시해라.\n\u0026lsquo;should not happen\u0026rsquo; 케이스는 읽는 사람에게 우리의 의도를 명확하게 밝힐 수 있다.\n의도를 분명히 밝히기 위해, 우리는 필요하지 않은 경우에도 \u0026lsquo;should not happen\u0026rsquo; 테스트를 작성한다.\n4.4 Specify as little as possible in a test # 전달하고자 한 의도를 파악한 것인지 모르겠다. (잘못된 해석일 수 있다.)\n\u0026rdquo; When testing with Mock Objects it is important to find the right balance between an accurate specification of a unit\u0026rsquo;s required behaviour and a flexible test that allows easy evolution of the code base.\nOne of the risks with TDD is that tests become “brittle”, that is they fail when a programmer makes unrelated changes to the application code.\nThey have been over-specified to check features that are an artefact of the implementation, not an expression of some requirement in the object. A test suite that contains a lot of brittle tests will slow down development and inhibit refactoring.\nThe solution is to re-examine the code and see if either the specification should be weakened, or the object structure is wrong and should be changed.\nFollowing Einstein, a specification should be as precise as possible, but not more precise. \u0026ldquo;\n하나의 테스트는 가능한 작게 유지해라. (= 작은 범위만을 다뤄라.)\n하나의 명세(나는 구현/메소드/테스트로 이해했다.)가 많은 것(= 기능, 확인하려는 테스트 범위 등)을 다루면 점점 다루기 힘들어진다.\n예를 들어, 연관이 없다고 생각한 코드 혹은 논리적으로/기능적으로 관계가 먼 코드를 변경했을 때에도 영향을 받아 테스트가 실패할 수 있다.\n복잡한 테스트 코드는 결국 개발 생산성을 저하시킨다.\n이 경우 코드, 설계를 다시 확인하여 리팩토링해야 한다. (예를 들어, 강한 결합이나 낮은 응집도, 설계 등)\n\u0026quot; Following Einstein, a specification should be as precise as possible, but not more precise. \u0026quot;\n(작성 중)\n"},{"id":260,"href":"/docs/BOOKS/IOS-Android-%EC%95%B1-%EA%B0%9C%EB%B0%9C%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%8B%A4%EC%A0%84-React-Native-Basic/%EA%B8%B0%EB%B3%B8/","title":"기본","section":"IOS, Android 앱 개발을 위한 실전 React Native - Basic","content":" 기본 원리 # React Native # 1. Bundling\nJS 파일을 React N 이 번들링하여, 각 플랫폼에 제공(?)한다.\n2. Bridge\n(플랫폼 단에서) JS Thread 와 Native Threads 가 매끄럽게 이어질 수 있도록(?) Bridge 를 제공한다.\nBulding 종류 # 종류 장점 단점 Expo CLI 1. 개발 환경 구축이 쉽다. 2. 실제로 개발이 쉽고 편하다. 1. OS Layer 와 직접 상호작용 불가능하다. (Java, Kotlin, Object-C, Swift 로 추가 작성이 불가능하다.) 2. Expo에서 제공해주는 모듈만 사용 가능하다. 3. Expo Client 에서는 잘 동작하지만 실제 시뮬레이터/단말기에서는 잘 동작하지 않을 수 있다. 4. 개발 관점에서 자유도가 낮다. React Native CLI 1. (Expo로는 접근하지 못하는) Native 기능에 접근 가능하다. (Native 모듈 사용 자유도가 높다.) 2. 원하는 언어로 추가 작성 가능하다. (Custom Native 모듈 사용 가능하다.) 3. 필요한 기능이 있는 경우, 모듈을 직접 제작 가능하다. 4. OS Layer 와 직접적인 상호작용 가능하다. 1. 초기 개발환경 구축 / 실제 앱 개발에 다소 시간이 걸릴 수 있다. (Expo와 비교했을 때) Installation # node (nvm) ex : node: 10.15.1, npm : 6.13.7 "},{"id":261,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/%EB%B9%88-%EC%83%9D%EB%AA%85-%EC%A3%BC%EA%B8%B0/","title":"빈 생명 주기","section":"스프링 핵심 원리 (기본편)","content":"스프링 Bean 은 다음과 같은 라이프사이클\n(Bean) 객체 생성 의존관계 주입 스프링 컨테이너 생성 (ApplicationContext) 스프링 Bean 생성/등록 의존관계 주입 (DI) 초기화 콜백 : 빈 생성 / DI 이후 호출 사용 (개발자 코드 동작) 소멸(전) 콜백 : 빈 소멸 전 호출 스프링(스프링 컨테이너) 종료 생성자에서 하면 되는 것을, 왜(굳이) 초기화 콜백 사용??\n-\u0026gt; (권장!!) 객체의 생성 / 초기화 분리한다.\n책임 / 역할 분리 생성자 : 필수 정보 / 메모리 할당 등 \u0026lsquo;생성\u0026rsquo; 에 중점을 둔다. 초기화 : 생성 이후에 로직에 필요한 값 전에 \u0026lsquo;초기화\u0026rsquo; 에 중점을 둔다. 3가지 방법으로 \u0026lsquo;빈 생명주기 콜백\u0026rsquo; 을 지원 # 인터페이스 : InitializingBean, DisposableBean 설정 정보 : 초기화 메서드, 종료 메서드 지정 애노테이션 : @PostConstruct, @PreDestroy 1. 인터페이스 : InitializingBean, DisposableBean # 스프링 초기 시절에 많이 사용되었고, 현재는 많이 사용되고 있지는 않는다고 함\n스프링 전용 인터페이스 : 스프링에 의존한다. 애노테이션 등의 의존은 그렇다 쳐도, 코드 레벨의 의존은 조금 그렇다. 초기화, 소멸 메서드 이름을 변경할 수 없음 내가 작성한 코드가 아닌, (내가 고칠 수 없는)외부 코드/라이브러리에 적용할 수 없음 /** * Interface to be implemented by beans that need to react once all their properties have been set by a BeanFactory: * e.g. to perform custom initialization, or merely to check that all mandatory properties have been set. * * An alternative to implementing InitializingBean is specifying a custom init method, * for example in an XML bean definition. * * For a list of all bean lifecycle methods, see the BeanFactory javadocs. */ public interface InitializingBean { /** * Invoked by the containing BeanFactory after it has set all bean properties * and satisfied BeanFactoryAware, ApplicationContextAware etc. * This method allows the bean instance to perform validation of its overall * configuration and final initialization when all bean properties have been set. * * @throws Exception in the event of misconfiguration (such as failure to set an * essential property) or if initialization fails for any other reason */ void afterPropertiesSet() throws Exception; } /** * Interface to be implemented by beans that want to release resources on destruction. * A BeanFactory will invoke the destroy method on individual destruction of a scoped bean. * * An org.springframework.context.ApplicationContext is supposed to dispose all of its singletons on shutdown, driven by the application lifecycle. * * A Spring-managed bean may also implement Java\u0026#39;s AutoCloseable interface for the same purpose. * An alternative to implementing an interface is specifying a custom destroy method, for example in an XML bean definition. * * For a list of all bean lifecycle methods, see the BeanFactory javadocs. */ public interface DisposableBean { /** * Invoked by the containing BeanFactory on destruction of a bean. * * @throws Exception in case of shutdown errors. Exceptions will get logged * but not rethrown to allow other beans to release their resources as well. */ void destroy() throws Exception; } 2. 설정 정보 : 초기화 메서드, 종료 메서드 지정 # 메서드 이름 : 자유롭게 지정 스프링에 의존하지 않음 (설정 정보를 사용하기 때문에?)외부 라이브러리에도 적용 가능 @Bean 의 destroyMethod(default 값) : (inferred)\nclose, shutdown 등의 메서드가 있으면 자동으로 호출해준다. (추론) 추론 기능 사용하기 싫으면 destroyMethod = \u0026quot;\u0026quot; 와 같이 설정 @Bean(initMethod = \u0026#34;myInit\u0026#34;, destroyMethod = \u0026#34;myDestory\u0026#34;) public MyService myService() { return new MyService(); } class MyService { void myInit() { ... } void myDestroy() { ... } } 3. 애노테이션 : @PostConstruct, @PreDestroy # 가장 권장되는 방법\n스프링에서 권장 패키지 : package javax.annotation; 스프링에 종속 X 자바 표준 (JSR) 컴포넌트 스캔과 잘 어울림 (@Configuration, @Bean 사용이 아니니까) 외부 라이브러리에 적용 X 외부 라이브러리 적용이 필요하면 2번 방법(설정 정보 : 초기화 메서드, 종료 메서드 지정)을 이용 class MyService { @PostConstruct void myInit() { ... } @PreDestroy void myDestroy() { ... } } "},{"id":262,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/%EB%B9%88-%EC%8A%A4%EC%BD%94%ED%94%84/","title":"빈 스코프","section":"스프링 핵심 원리 (기본편)","content":" 빈 스코프 : 빈이 존재할 수 있는 범위 # 기본 값 : singleton (애플리케이션 시작 ~ 종료)\n즉, 스프링 컨테이너의 시작과 끝 (동일한 범위를 갖는다.)\n스코프 종류 # singleton, prototype, request 는 기억하고 넘어갈 것\nsingleton prototype 빈 생성 / 의존관계 / 초기화하여 반환하고 끝 (관리 X) 매우 짧은 범위의 스코프 request (웹 관련 scope) 웹 요청이 들어오고 나갈 때 까지의 스코프 session (웹 관련 scope) 웹 세션 생성 ~ 종료 스코프 application (웹 관련 scope) 웹 서플릿 컨텍스트와 같은 범위 웹스코프 (라이브러리 필요 : spring-boot-starter-web)\n웹 환경에서만 동작 해당 스코프의 종료시점까지 관리 (종료 메서드 호출) prototype 스코프 # [요약]\n1. PreDestroy 와 같은 종료 콜백 메서드 실행 X\n2. 매번 새롭게 Bean 생성\n빈을 요청하면 항상 새로운 Bean(인스턴스)를 생성/반환\n싱글톤 =\u0026gt; 스프링 컨테이너 띄워질 때 생성해놓고 관리 프로토타입 =\u0026gt; 조회/요청 시에 생성/반환 Bean 생성 -\u0026gt; 반환 -\u0026gt; 초기화 -\u0026gt; 끝 (더 이상 관리하지 않음) 관리의 주체 : Bean 을 받은 클라이언트 (싱글톤의 경우 -\u0026gt; 스프링 컨테이너)\n따라서, PreDestory 같은 종료 메서드 실행되지 않음 실무에서 거의 사용되지 않는다고함\n싱글톤 빈과 함께 사용할 때 주의할 점\n@Scope(\u0026#34;singleton\u0026#34;) class ClientBean { private final PrototypeBean prototypeBean; } @Scope(\u0026#34;prototype\u0026#34;) class PrototypeBean { } ClientBean 생성 / DI 시점에 PrototypeBean 이 프로토타입 형태로 주입 받음 이후에도 ClientBean 은 PrototypeBean 을 가지고 있고, 다시 주입받을 일이 없음. (요청할 일이 없음) 결론 =\u0026gt; PrototypeBean 싱글톤 느낌으로 동작하게 됨. prototype 의도한대로 하려면 아래와 같이 사용해야함 // 방법 1 : ApplicationContext 사용 // - 코드가 너무 지저분해짐 // - 단위 테스트 어렵고, 스프링 컨테이너(ApplicationContext)에 의존 @Scope(\u0026#34;singleton\u0026#34;) class ClientBean { private final ApplicationContext applicationContext; void add() { // DL(Dependency LookUp) : 의존관계를 직접 조회/찾음 (\u0026lt;-\u0026gt; DI) PrototypeBean prototypeBean = applicationContext.getBean(PrototypeBean.class); prototypeBean.addCount(); ... } } // 방법 2 : ObjectProvider 사용 (springframework 제공) // 위에서 DL 역할만 있으면 됨. @Scope(\u0026#34;singleton\u0026#34;) class ClientBean { private final ObjectProvider\u0026lt;PrototypeBean\u0026gt; prototypeBeanProvider; void add() { // DL(Dependency LookUp) : 의존관계를 직접 조회/찾음 (\u0026lt;-\u0026gt; DI) PrototypeBean prototypeBean = prototypeBeanProvider.getObject(); prototypeBean.addCount(); ... } } // 방법 3 : Provider 사용 (Java 표준, 의존성 추가 : javax.inject:javax.inject:1) @Scope(\u0026#34;singleton\u0026#34;) class ClientBean { private final Provider\u0026lt;PrototypeBean\u0026gt; prototypeBeanProvider; void add() { // DL(Dependency LookUp) : 의존관계를 직접 조회/찾음 (\u0026lt;-\u0026gt; DI) PrototypeBean prototypeBean = prototypeBeanProvider.get(); prototypeBean.addCount(); ... } } (주의할 점) ObjectProvider 는\nprototype 을 위해 만들어진게 아님 ApplicationContext LookUp 을 위해 사용하는 것 단, 스프링에 의존 (주의할 점) Provider 는\njava 표준 의존성 추가 request 스코프 (웹 스코프) # HTTP 요청 당 유지되는 스코프 (즉, HTTP 응답 나갈 때, 종료) 각각의 HTTP 요청 마다 Bean 생성/관리 e.g. 동시에 2 Client 가 요청하면, 각각 다른(다른 HTTP 요청이기이) 빈 생성\n(아마 아래 스코프도 동일할 듯) 아래와 같은 코드는 오류 발생\n이유 :\nMyService 는 웹 애플리케이션이 뜰 때 Bean 으로 등록된다. 이때, MyLog 를 주입받아야 하는데, MyLog 는 HTTP 요청이 없으니 Bean 으로 관리 X @Service class MyService { private final MyLog myLog; public void logic() { ... } } @Scope(\u0026#34;request\u0026#34;) class MyLog { ... } 방법 1 : Provider\nDL 은 여러 번 호출 되어도, 같은 생명주기 내에서는 동일한 Bean 보장\nController, Service 에서 myLogProvider.getObject() 호출 -\u0026gt; 동일한 Bean\n// 방법 1 : Provider 사용 @Service class MyService { private final ObjectProvider\u0026lt;MyLog\u0026gt; myLogProvider; public void logic() { // DL 은 여러 번 호출 되어도, 같은 생명주기 내에서는 동일한 Bean 보장 // e.g. Controller, Service 에서 myLogProvider.getObject() 호출 -\u0026gt; 동일한 Bean MyLog myLog = myLogProvider.getObject(); ... } } @Scope(\u0026#34;request\u0026#34;) class MyLog { ... } 방법 2 : 프록시\n싱글톤 빈을 띄울 때, 프록시 객체를 주입\n실제 동작 =\u0026gt; 프록시 메서드 내에서 DL 을 사용하거나 해서 동작할 것으로 예상\nproxyMode = ScopedProxyMode.TARGET_CLASS\n적용 대상 인터페이스 : INTERFACES 선택 적용 대상 인터페이스 X : TARGET_CLASS 선택 @Service class MyService { private final MyLog myLog; public void logic() { ... } } @Scope( value = \u0026#34;request\u0026#34;, proxyMode = ScopedProxyMode.TARGET_CLASS ) public class MyLog { } :star::star: Provider, 프록시 의 핵심 아이디어 : 지연 처리 (꼭 필요한 시점) (다형성 + DI 의 가장 큰 강점)\nsession 스코프 # HTTP Session 당 유지되는 스코프 application 스코프 # 서블릿컨텍스트(ServletContext) 와 동일한 생명 주기 websocket # 웹 소켓과 동일한 생명 주기 알아둘것 :star::star::star: # 프록시 개념 : 스프링의 핵심 개념\n클라이언트(개발자)의 코드 수정 없이 다양한 기능을 부여/조작할 수 있음 "},{"id":263,"href":"/docs/BOOKS/Spring-Cloud%EB%A1%9C-%EA%B0%9C%EB%B0%9C%ED%95%98%EB%8A%94-%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98/%EC%84%B9%EC%85%981-Service-Discovery/","title":"섹션1. Service Discovery","section":"Spring Cloud로 개발하는 마이크로서비스 애플리케이션","content":" Service Discovery(Eureka) 이해해보기\nPC 가 한 대라면 같은 IP/다른 PORT 형태로 여러 애플리케이션을 구성할 수 있다. PC 가 여러 대라면, 다른 IP/같은 PORT 형태로 여러 애플리케이션을 구성할 수 있다.\nService Discovery 란, 외부에서 내부의 마이크로서비스를 찾기 위해(검색) 사용된다. Key, Value 쌍으로 서비스를 등록하고 검색할 수 있다. 또, Netflix Eureka 는 Netfix 에서 만든 오픈소스를 아파치 재단에 등록한 것이다.\nLoad Balancer 혹은 API Gateway 에 요청이 들어왔을 때, 먼저 Service Discovery 에 해당 서비스가 어디 위치하고 있는지 조회하는 개념이다.\n기본적인 설정은 다음과 같이 할 수 있다.\nEureka Server\n127.0.0.1:9000 으로 Eureka Server 를 가동한다고 가정한다.\n@EnableEurekaServer // @EnableEurekaServer 어노테이션을 추가한다. @SpringBootApplication public class ServiceDiscoveryApplication { public static void main(String[] args) { SpringApplication.run(ServiceDiscoveryApplication.class, args); } } server: port: 9000 spring: application: name: service-discovery eureka: client: fetch-registry: false register-with-eureka: false Eureka Client\n@EnableDiscoveryClient // @EnableDiscoveryClient 어노테이션을 추가한다. @SpringBootApplication public class Demo1Application { public static void main(String[] args) { SpringApplication.run(Demo1Application.class, args); } } server: port: 8001 spring: application: name: demo1 eureka: instance: instance-id: ${spring.application.name}:${spring.cloud.client.hostname}:${server.port}:${spring.application.instance_id:${random.value}} # instance id 의 경우 자유롭게 설정하면 된다. 여기서는 instance id 가 중복되지 않도록 하기 위해 random.value 를 추가해주었다. client: register-with-eureka: true fetch-registry: true service-url: defaultZone: http://127.0.0.1:9000/eureka # Eureka Server 쪽을 향하도록 설정한다. 위와 같은 형태로 Eureka 서버, 데모1, 데모2, 게이트웨이 를 가동한다고 가정하면 아래와 같이 설정된 것을 볼 수 있다.\n"},{"id":264,"href":"/docs/BOOKS/Spring-Cloud%EB%A1%9C-%EA%B0%9C%EB%B0%9C%ED%95%98%EB%8A%94-%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98/%EC%84%B9%EC%85%982-API-Gateway/","title":"섹션2. API Gateway","section":"Spring Cloud로 개발하는 마이크로서비스 애플리케이션","content":" API Gateway # 외부에 노출되는 API 이다.\n내부의 API 들은 감추고, 외부에 노출하여 Proxy/Gateway 역할(즉 단일 진입점 역할)을 한다.\nClient 는 API Gateway(단일 API) 만 바라보고 작업할 수 있다.\nAPI Gateway 는 인증, 인가, LB, Routing, Logging, CircuitBreaker 의 역할을 한다. (?)\nNetflix Ribbon # Spring Cloud 에서 MSA 간 통신이 필요하다.\nResetTemplate : RestAPI 를 통해 통신한다. Feign Client : MicroService의 이름을 등록하고, 이름으로 호출한다. Ribbon : Client-Side Load Balancer\n서비스 이름으로 호출 Health checking * Spring Cloud Ribbon 은 Spring Boot 2.4에서 Maintenance 상태이다.\nNetflix Zuul # API Gateway library(fraemwork) 이다.\nclient \u0026lt;-\u0026gt; netflix zuul \u0026lt;-\u0026gt; msa1, msa2, ... * Spring Cloud Zuul 은 Spring Boot 2.4에서 Maintenance 상태이다.\n"},{"id":265,"href":"/docs/BOOKS/Spring-Cloud%EB%A1%9C-%EA%B0%9C%EB%B0%9C%ED%95%98%EB%8A%94-%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98/%EC%84%B9%EC%85%983-Spring-Configuration-Service/","title":"섹션3. Spring Configuration Service","section":"Spring Cloud로 개발하는 마이크로서비스 애플리케이션","content":"서버, 클라이언트 구성에 필요한 설정 정보(application.yml)를 외부 시스템에서 관리할 수 있다.\n하나의 중앙화 된 저장소(GIT Repository, Secure Valut, Secure File Storage 등)에서 관리할 수 있다.\n각 서비스를 다시 빌드하지 않고 바로 적용 가능하다.\n애플리케이션 배포 파이프라인을 통해 DEV-STAGE-PROD 환경에 맞는 구성 정보로 사용 가능하다.\n저장소로부터 Spring Cloud Config Server가 config 파일(값)을 가져와 각각의 service 에 전달해줄 수 있다.\nConfig Server # @SpringBootApplication @EnableConfigServer public class ConfigServiceApplication { ... } server: port: 8888 spring: application: name: config-service cloud: config: server: git: uri: file:///Users/leehyunjae/local-repository # spring.cloud.config.server.git.uri 에 로컬의 repository 경로를 작성할 수 있다. http://127.0.0.1:8888/ecommerce/default http://127.0.0.1:8888/ecommerce/dev http://127.0.0.1:8888/ecommerce/prod Config Client # Dependencies 추가\nspring-cloud-starter-config spring-cloud-starter-bootstrap (or spring.cloud.bootstrap.enabled=true) bootstrap.yml\nspring: cloud: config: uri: http://127.0.0.1:8888 # Config Server URI name: ecommerce bootstrap.yml 의 우선순위가 더 높다. (bootstrap.yml \u0026gt; application.yml)\napplication.yml 파일에 해당 내용을 작성해도 된다. 하지만 지금은 application.yml 을 config server 로 관리(즉, application.yml 을 갖고 있지 않을 예정)하고자 하기 때문에 bootstrap.yml 에 작성한다.\n"},{"id":266,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/%EC%9D%98%EC%A1%B4%EA%B4%80%EA%B3%84-%EC%A3%BC%EC%9E%85/","title":"의존관계 주입","section":"스프링 핵심 원리 (기본편)","content":" 주입 방법 # 생성자 주입 # final OK (누락 X) 변경 가능성 X 최초 1번 실행 보장 생성자 1개 =\u0026gt; @Autowired 생략 가능 여러 개, 생략 불가능 세터 주입 # 생성자 이후에 처리 (= final X)\n단점\nSetter Open 변경 가능성 final X 선택적 (null OK) 필드 주입 # 생성자 이후에 처리 (= final X)\nDI Framework 에 의존 테스트할 때, 주입해줄 수 없음. Setter 열어줘야함. final X 선택적 (null OK) * 단, 일부 테스트 코드에서는 OK 일반 메서드 주입 # 생성자 이후에 처리 (= final X)\n일반 메서드 통해 주입 OK\n잘 사용하지 않음 // 다른 주입과 동일하게, Bean 등록 시 알아서 주입해줌 @Autowired public void asdasd(MyRepository myRepository) { this.myRepository = myRepository; } @Autowired(required = false) # 주입 대상 있으면, 주입 주입 대상 없으면, 생략 @Autowired(required = false) public void setNoBean1(Member member) { System.out.println(member); // Member Bean 없으면 이 주입(메서드)는 실행 안됨 } ```java @Autowired(required = false) public void setNoBean2(Optional\u0026lt;Member\u0026gt; member) { System.out.println(member); // Optional.empty } // null 주입 @Autowired public void setNoBean3(@Nullable Member member) { System.out.println(member); // Member Bean 없으면 이 주입(메서드)는 실행 안됨 } @Primary, @Qualifier # @Qualifer 시 아래와 같이 사용자 어노테이션 만드는 방법도 있음\n무분별하게 사용, 만들지는 말 것\n@Qualifier(\u0026#34;myDetail1Service\u0026#34;) public @interface MyDetail1Service { } "},{"id":267,"href":"/docs/BOOKS/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-for-beginners/%EC%BB%A8%EC%8A%88%EB%A8%B8-%EB%9E%99Consumer-Lag/","title":"컨슈머 랙(Consumer Lag)","section":"아파치 카프카 for beginners","content":" 파티션에 데이터가 들어갈 때 offset 이라는 숫자가 붙게 된다. (0 부터 시작한다.)\n컨슈머의 상태를 추측할 수 있음 (모니터링 지표)\n각 파티션의 offset 기준으로, 컨슈머의 상태를 확인할 수 있도록 함 lag은 프로듀서 생산 속도(offset), 컨슈머 소비 속도(offset)의 차이를 기반으로 함\nlag은 여러개가 될 수 있음 (파티션별로) records-lag-max : lag 값 중 가장 큰 값 컨슈머가 느리거나, 정상적으로 동작하지 않으면 lag 이 필연적으로 발생한다고 한다.\n모니터링 애플리케이션, 카프카 버로우(Burrow) # 컨슈머 쪽에서 ELK, Grafana 쪽으로 데이터를 보내 확인할 수도 있으나, 컨슈머에 의존하게 되는 문제가 있다. 컨슈머가 비정상적으로 종료되거나, 모든 컨슈머에 이런 처리를 해줘야되는 문제가 있음\n컨슈머 lag 모니터링을 도와주는 독립적인(외부) 애플리케이션\n사용하는 것을 강력 권장한다. (사용하지 않을 이유가 없다고 한다.)\nMulti kafka cluster 지원 (Kafka 클러스터 여러 개를 지원) Sliding window 를 통한 컨슈머의 status(error, warning, ok) 확인할 수 있다. (?) HTTP API 제공한다. "},{"id":268,"href":"/docs/BOOKS/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-for-beginners/%ED%86%A0%ED%94%BD/","title":"토픽","section":"아파치 카프카 for beginners","content":" TOPIC # (DB)Table, (FileSystem)Directory 와 비슷한 개념\n\u0026lsquo;이름\u0026rsquo; 무슨 데이터를 갖는지 명확하게 네이밍 \u0026lsquo;파티션\u0026rsquo; consumer 가 partition 데이터를 읽어도 바로 삭제되지 않음 (중요) 데이터를 2번(혹은 여러 번) 소비해야할 때 유용, 중요한 특징 늘리는 것 가능 / 줄이는 것 불가능 파티션을 늘리고 컨슈머를 늘려 -\u0026gt; 데이터 처리를 분산 파티션 데이터 삭제 방식 일정 \u0026lsquo;시간\u0026rsquo; 이후 삭제 일정 \u0026lsquo;용량\u0026rsquo; 이후 삭제 "},{"id":269,"href":"/docs/BOOKS/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-for-beginners/%ED%8C%8C%ED%8B%B0%EC%85%94%EB%84%88/","title":"파티셔너","section":"아파치 카프카 for beginners","content":" 프로듀서가 데이터를 보냄 -\u0026gt; 파티셔너가 이를 처리\n어떤 파티션에 데이터를 저장할 지 결정 파티셔너 따로 설정하지 않는다면, UniformStickyPartioner 로 설정 (이 방식은 아래와 같이 동작)\n메시지 키가 있는 데이터에 대해서는 해쉬 값을 생성하여 파티션을 결정 동일한 메시지 키(해쉬 값)은 동일한 파티션에 들어감 메시지 키가 없는 레코드는 Round-Robin 다만 전통적인 RR 과 조금 다르다. Batch 단위로 동작한다(?) 사용자 지정 파티셔너도 사용 가능\nCustomPartitional 인터페이스를 제공한다고 함 예시 # 파티셔너, 파티션 결정이 중요한 이유는 아래와 같은 예시로 사용 가능\n파티션 10개 중 8개 -\u0026gt; VIP를 위해 배정 : VIP에 대해서 조금 더 빠른 데이터 처리 기대 "},{"id":270,"href":"/docs/AWS/OpenSearch/02.-%EB%82%B4%EB%B6%80-%EA%B5%AC%EC%A1%B0-%EC%84%B1%EB%8A%A5-%EC%B5%9C%EC%A0%81%ED%99%94-%EA%B7%B8%EB%A6%AC%EA%B3%A0-%EC%8A%A4%EC%BC%80%EC%9D%BC%EB%A7%81/","title":"02. 내부 구조, 성능 최적화 그리고 스케일링","section":"08. Opensearch","content":" OpenSearch 구조 # 파란색 부분(Index, Shard)에 대해서만 이해하고 있다면 일반적인 사용에서 문제가 없다. 초록색 부분(Lucene Index, Segment)는 깊은 사용, 성능 최적화 등을 위해 이해해야 하는 부분이다. Shard # 영상에서, 샤드 = 물리적인 노드 1대1 대응해서 설명하는 것 같다.\n즉, 아래 그림은 각각의 물리적인 노드 위에 각 샤드가 있는 것을 가정한다.\n샤드의 수 = 데이터 노드(or AZ) x N Replica 수 = AZ x N Index 디자인 # Index 패턴 # 패턴 설명 Rolling Index - 인덱스 기간, 보존 기간이 있고 계속적으로 데이터가 흘러 들어오는 경우 - 오래된 Index 는 보유 기간에 따라 Warm/Cold 계층으로 마이그레이션, 삭제 가능 - search-logs-2022, weblogs-2022-07, \u0026hellip; Long-Term Retention Index - 같은 Index에 소스 데이터 저장\n- 문서의 업데이트, 삭제가 필요한 경우가 많음 - movies, internal-docs, website-contents, \u0026hellip; Index 사이즈 관리 # 관리 설명 사이즈 기반 로테이션 - 크기 추정 불가 (특정 사이즈가 넘어가면 새로운 인덱스로 생성한다.)\n- \u0026lsquo;삭제\u0026rsquo;에 대한 요구사항 없음 - 동일한 shard(인덱스) 크기 유지 - index-A-000000, index-A-000001, \u0026hellip; 기간(시계열) 기반 로테이션 - 크기 추정 가능 - \u0026lsquo;삭제\u0026rsquo;에 대한 요구사항 있음 (특정 기간에 대한 삭제가 용이하다.) - 기간 기준 검색 요구사항 있음 - index-A-2022-09-01, index-A-2022-09-02, \u0026hellip; Index 로테이션 빈도에 따른 주의사항 # 매일마다 일정한 데이터 흐름 속도(양)으로 들어오더라도, 로테이션 빈도에 따라 Shard 구성이 달라질 수 있다.\n예를 들어, 일일 데이터 양 30GB가 유입되고, Shard 사이즈를 50GB라고 가정하자. (계산 편의를 위해 Primary 샤드만 고려한다.)\n경우 샤드 수 Daily rotation 30GB * 1.1 / 50GB = 0.66 = 1 Shard Weekly rotation 30GB * 1.1 * 7 / 50GB = 4.62 = 5 Shard Monthly rotation 30GB * 1.1 * 31 / 50GB = 20.46 = 21 Shard 즉, 한달 기준으로\ndaily로 인덱스를 생성하면, 30개의 샤드(인덱스)가 필요하다. monthly 인덱스 생성하면, 21개의 샤드(인덱스)가 필요하다. 적합한 Domain(= Cluster) 구성 예측 # Opensearch 사용을 시작하면 기본적으로 아래와 같은 형태와 같이 배포된다.\n처음 사용할 때는 각종 노드를 어느정도(인스턴스 타입)로 구성하고, 몇 개로 구성해야할 지 예상하는 것이 어렵다.\nDomain(= Cluster) 구성 예측 # 스토리지 크기 를 예측해본다. (1번을 기반으로) Shard 수 를 예측해본다. (1, 2번을 기반으로) vCPU / Memory 를 예측해본다. (3번을 기반으로) Data Nodes (인스턴스 타입) 을 예측해본다. (4번을 기반으로) Master Nodes (인스턴스 타입) 을 예측해본다. 말그래도 \u0026lsquo;예측\u0026rsquo;이다. 실제로 운영하면서 모니터링하고 수정해나가야 한다.\nDomain 구성 예측 1 - 스토리지 크기 # 구성 설명 Hot 검색 빈도 수가 높은 인덱스 노드의 볼륨에 저장한다. UltraWarm 검색 빈도 수가 중간 정도 되는 인덱스 데이터양은 많지만 낮은 비용으로 검색, 분석할 때 사용할 수 있다. 노드의 로컬 캐시 + S3 Bucket 를 사용한다. Cold 검색 빈도 수가 거의 없는 인덱스 S3에 저장한다. 인스턴스가 없으므로 검색할 수 없다. UltraWarm 으로 마이그레이션하여 검색하거나 S3 데이터를 다운로드 할 수만 있다. UltraWarm 노드 # 데이터양은 많지만 낮은 비용으로 데이터 검색, 분석하고 싶을 때 (이 구성으로)사용할 수 있다.\n다만, readonly 이므로 write 가 필요한 경우에는 hot 영역으로 마이그레이션해야 한다. (아래 이미지에 나와있는 API 통해 마이그레이션을 간단히 수행할 수 있다.)\n클라이언트가 검색할 때에는 Hot, UltraWarm 노드에서 데이터를 가져온다.\nStorage 크기 예측 (예시) # 기준 설명 Indexing Overhead 보통 10% 잡는다. 10%는 계산의 편의를 위해 보통 설정하는 기준이다. 정확한 계산을 위해서는 _cat/indices API 를 통해 실제 인덱스 사이즈를 확인할 수 있다. Replica (운영 환경 기준)보통 2개 잡는다. OS 예약공간 보통 5% 잡는다. 주요 프로세스를 위한 영역이다. Service Overhead 보통 20% 잡는다. 노드별 스토리지 용량의 20%를 확보한다. 구성에 따라 20%라는 값이 달라질 수 있다. (위 그림 참고) 큰 용량 x 적은 노드 수가 적은 overhead 를 갖는다. UltraWarm, Cold Storage 의 경우에는 인덱스가 S3에 저장되기 때문에 Indexing Overhead만 고려하면 된다.\nDomain 구성 예측 2 - Shard 수 예측 # 결론부터 말하면, 완벽한 수(구성)는 없다.\n샤드 수가 너무 적어도, 너무 많아도 문제다. 적절한 수를 찾아야한다.\n케이스 설명 작은 Shard x 많은 수 아래와 같은 문제가 발생할 수 있다. - 검색 성능 저하 - 높은 Heap 사용률 큰 Shard x 적은 수 아래와 같은 문제가 발생할 수 있다. - 검색 성능 저하 일반적으로 인덱스 사이즈는 위 그림(10GB ~ 30GB, 10GB ~ 50GB)에서 나온 것 처럼 구성(시작)되면 좋다.\nRolling Index 의 경우 새롭게 인덱스를 생성할 때 사이즈를 재조정 가능하므로, 깊게 고려하지 않아도 된다.\nPrimary Shard 수 # 예제\n매일 200GB 유입 각 Shard 크기 수 30GB 매일 Rolling 3 AZ 에 3개의 데이터 노드가 분산 Replica 수 2 계산\n샤드 계산 결론 Primary (200GB + 0) * (1 + 0.1) / 30GB x 1 day = 7 shard 6 or 9 shard (6개를 선택했다고 가정한다.) Replica primary shard(6, 9) x 2 12 or 18 shard per day Domain 구성 예측 3 - vCPU / Memory # vCPU 예측 # 일반적인 Workload : 일반적인 상황 고부하 워크로드 : 잦은 인덱싱, 검색 요청률 높음, 대용량 검색으로 인한 부하 높은 상황 Memory 예측 # JVM 에서는 32GB 이상으로 Heap 용량을 주면 오히려 성능이 저하되는 현상이 있음 (Compressed OOP 관련 이슈?)\nDomain 구성 예측 4 - Data Node # 최신 인스턴스 타입을 선택하는 것은 기본이다. (최신 인스턴스 일수록 성능이 좋고 비용이 저렴할 것이다.)\n일반적인 상황에서는 m6g 부터 시작해도 좋다고 한다. 어느정도 인스턴스인지 확인해보자.\n일반적인 상황에서는 gp3 를 사용하면 될 것이다.\n빠른 I/O 처리가 필요한 경우에는 NVMe SSD 를 사용할 수 있다.\nDomain 구성 예측 5 - Master Node # 데이터 노드와 같은 아키텍쳐(graviton or intel)인 인스턴스 타입을 사용해야한다.\n위 권장 타입은 최소한의 상황에 대한 타입이므로, 모니터링 후 적절한 타입을 선택해야 한다.\n마스터 노드는 1개로 동작한다. n개가 필요한 이유는 단지 \u0026lsquo;가용성\u0026rsquo;을 위함이다.\nAPI 요청 핸들링 (구조) # Queue 에 요청이 쌓이고, Thread Pool 의 thread 가 요청을 처리하는 구조이다.\nThread는 샤드별로 할당된다. 하나의 요청에 대해 n개의 thread 가 처리한다. Queue 에 요청이 꽉 찼다면, 429 Too Many Requests 응답된다.\nQueue, Thread Pool, vCPU 상관관계 # 검색 성능 최적화 (for Read) # File System Cache 메모리 증설 # File System Cache 메모리 증설하여 성능을 개선할 수 있다.\nNode Query Cache 재사용 (활용) # Filter 를 사용했을 때 응답 속도를 개선하기 위해 사용되는 캐시 (LRU)\nHeap 영역의 10%를 사용한다.\nInstance Store 사용 # 복잡한 Document 구조 피하기 # 1. (Nested) 중첩 필드 유형 등의 복잡한 구조는 피한다.\n일반 필드 유형보다 검색 요청을 처리하는데 몇 배 더 오래 걸릴 수 있다. 중첩 유형 하위에 여러 필드가 있고, 해당 필드로 검색하는 경우 오래 걸릴 수 있다. copy_to 를 사용하여 여러 필드를 결합하고 단일 필드로 복사하여 개선할 수 있다. 즉, n 개의 검색 조건을 주는 것보다 1 개의 필드로 만들어 단일 검색으로 쿼리하는 것을 말한다. (예를 들어, first, last field로 검색하던 것을 full field 로 만들어 검색한다.) 2. 조인 필드 유형으로 부모-자식 관계 사용하는 것을 최대한 피한다.\n일반 필드 유형보다 검색 요청을 처리하는데 몇 배 더 오래 걸릴 수 있다. 1:N 부모-자식 관계 외에는 사용하지 않는 것을 권장한다. 조인이 필요한 경우, 인덱싱 시점에 미리 전처리하여 저장하는 것이 검색 성능에 유리하다. Term 형태로 Range 를 미리 설정하는 것도 동일하다. (아래 그림 참고) 가능한 Script 피하기 # 검색 시 Script 사용하면 검색 성능이 저하된다.\n미리 전처리된 데이터를 사용해야 한다.\nKinesis, Lambda 등을 통해 전처리 후 데이터를 넣으면 이후 검색 성능 괜찮을 것이다. Index Sorting # 정렬 사용 시 인덱스 소팅을 사용하는 것이 좋다. (설명을 들어보니 DB 인덱스와 동일한 구조)\n큰 Result 는 Paging, Async 검색 활용 # 1. OpenSearch 는 단일 검색 요청에서 반환될 수 있는 Document 수에 제한이 있다.\n기본 limit : 10,000개 2. limit 수정은 index.max_result_window 업데이트 하면 된다. (?)\nlimit 을 늘릴 수 있지만, 큰 Heap 메모리가 필요하고 vCPU 사용률 증가할 수 있다. 3. search_after, size \u0026amp; from 함께 페이징 사용\nAPI 실행 당 검색되는 문서 수를 줄인다. 4. 비동기 검색 사용\n배치 프로세싱과 같이 오랫동안 실행되는 쿼리의 경우 비동기 검색을 고려하자. Index Roll-Up # 집계 비용을 절약할 수 있다.\n집계된 결과만을 볼 때 유용하게 사용할 수 있다.\n조금 더 찾아볼 것\n인덱싱 성능 최적화 (for Write) # _bulk API # bulk API를 통해 쓰기를 최적화할 수 있다.\n적절한 Payload 사이즈는 구성에 따라 다르다. 모니터링 필요하다.\n단일 샤드 기준 3MB ~ 5MB 설정하고 모니터링하면 좋다고 한다.\n새로고침 간격 (refresh interval) 조절 # 인덱싱 과정은 다음과 같다.\n메모리 Heap 영역의 버퍼로 쓰인다. (refersh 거친 후) File System Cache의 세그먼트 단위로 만들어진다. 이때부터 검색이 가능한 상태가 된다. (flush 거친 후) Disk에 세그먼트가 저장된다. (당연스럽게도) 세그먼트 생성 빈도를 줄이면 성능이 좋아진다. 다만 인덱싱을 늦게 함으로써 검색 가능한 시점이 늦어질 수 있다. 쓰기 ⇿ 검색 간격이 넓어도 된다면 고려할 수 있다. (tradeoff)\nReplica 비활성화 # 인덱싱 관점에서는 (복제 과정이 없어지기 때문에)Replica 를 비활성화하면 처리량이 향상된다.\nReplica 없이 운영하되 배치 형태로 스냅샷을 뜨거나 하면 괜찮을 수도 있다.\n자동으로 생성되는 ID 사용 # Document ID를 개발자가 지정하면, 인덱싱 과정에서 ID 충돌 검사가 들어간다.\n자동으로 생성되는 ID 를 사용하게 되면, 인덱싱 과정에서 ID 충돌 검사를 건너뛰기 때문에 인덱싱 성능이 좋아진다.\n인덱싱, 검색 워크로드 분리 # 하나의 Domain(= Cluster)에서 인덱싱, 검색을 동시에 수행하면 노드의 자원을 공유함으로 요청 간의 경쟁이 발생할 수 있다.\n클러스터 간 (자동)복제 기능을 통해 인덱싱, 검색 워크로드를 분리할 수 있다. (= 도메인 최적화)\n기타 유용한 팁 # 자동 튜닝(Auto-tune) 사용 # (자동으로) 성능을 분석해주고, 최적화된 값으로 설정해준다.\nJVM 관련 설정은 (재배포가 필요하기 때문에)Blue/Green 배포로 반영된다. 그 외 설정은 온라인 반영 가능하기 때문에 즉시 반영된다. 워크로드에 따른 클러스터 분리 # 같은 검색이더라도, 워크로드마다 특징이 다를 수 있다. 특징 별 최적의 리소스를 구성하여 사용할 수 있다.\n로그 분석 : 데이터량이 많고 높은 I/O 성능이 필요하다. Full-Text 검색 : 데이터 량 적지만 단위시간당 검색량이 많기 때문에 vCPU/Memory 성능이 많이 필요하다. 상호(= 도메인 = 클러스터) 참조 필요시 클러스터 간 검색을 통해 한번에 검색할 수도 있다.\n운영 환경에서는 T2, T3 인스턴스를 피한다. # 메모리 관련 이슈가 발생하기 쉽다.\n지속적으로 vCPU의 사용량이 (많이)요구되는 경우에는 EC2에서 처럼 CPUCreditBalance 가 고갈될 수 있다. (= 원래 인스턴스가 갖고 있던 vCPU 성능으로 되돌아가는 것 (하락되는 게 아님))\n인덱싱, 검색 요청 # 인덱싱(write) : 가장 마지막에 쓰인 인덱스에 요청한다. 검색 요청(read): 모든 인덱스에 요청한다. 스케일링 전략 # 일반적으로 Scale-Up이 더 효과적이다.\nScale-Out 은 노드가 갖고 있는 제한사항 극복하거나 가용성을 위해 사용할 수 있다.\n"},{"id":271,"href":"/docs/AWS/OpenSearch/03.-5xx-Error-with-Scaling/","title":"03. 5xx Error (With Scaling)","section":"08. Opensearch","content":" SysMemoryUtilization 값이 90%를 초과하는 것은 이슈가 있는 것은 아니고, FreeStorageSpace, JVMMemoryPressure, CPUUilization 값을 확인해보아야 한다.\n5xx 에러가 발생했을 경우 아래 부분을 의심해볼 수 있다.\n확인 사항 1. 스토리지 가용 공간 확인 # 아래에 해당되는 경우 (1) 인스턴스 타입을 변경하거나 (2) EBS 볼륨을 늘리거나 (3) 인스턴스를 추가할 수 있다.\n가용 공간이 노드 스토리지의 20% or 20GB 미만인지 확인한다. ISM 통해 스냅샷 저장 후 불필요한 데이터는 삭제한다. Lack of available storage space If one or more nodes in your cluster has less than 20% of available storage space, or less than 20 GB of storage space, basic write operations like adding documents and creating indexes can start to fail. Calculating storage requirements provides a summary of how OpenSearch Service uses disk space. To avoid issues, monitor the FreeStorageSpace metric in the OpenSearch Service console and create CloudWatch alarms to trigger when FreeStorageSpace drops below a certain threshold. GET /_cat/allocation?v also provides a useful summary of shard allocation and disk usage. To resolve issues associated with a lack of storage space, scale your OpenSearch Service domain to use larger instance types, more instances, or more EBS-based storage. 확인 사항 2. JVMMemoryPressure # 아래에 해당되는 경우 (1) 인스턴스 타입을 변경하거나 (2) 인스턴스를 추가할 수 있다.\n마스터, 데이터 노드의 JVMMemoryPressure 수치가 95% 이상인지 확인한다. (= 95% 이상인 경우 OOM 에러가 발생할 수 있다.)\n확인 사항 설명 JVMMemoryPressure maximum is \u0026gt;= 95% for 1 minute, 3 consecutive times OldGenJVMMemoryPressure maximum is \u0026gt;= 80% for 1 minute, 3 consecutive times The cluster could encounter out of memory errors if usage increases. Consider scaling vertically. OpenSearch Service uses half of an instance\u0026rsquo;s RAM for the Java heap, up to a heap size of 32 GiB. You can scale instances vertically up to 64 GiB of RAM, at which point you can scale horizontally by adding instances. MasterJVMMemoryPressure maximum is \u0026gt;= 95% for 1 minute, 3 consecutive times\nMasterOldGenJVMMemoryPressure maximum is \u0026gt;= 80% for 1 minute, 3 consecutive times Consider using larger instance types for your dedicated master nodes. Because of their role in cluster stability and blue/green deployments, dedicated master nodes should have lower CPU usage than data nodes. 확인 사항 3. CPUUtilization # 아래에 해당되는 경우 (1) 인스턴스 타입을 변경하거나 (2) 인스턴스를 추가할 수 있다.\n마스터 노드의 CPUUtilization 수치가 지속적으로 50% 이상인지 확인합니다. 데이터 노드의 CPUUtilization 수치가 지속적으로 80% 이상인지 확인합니다. 확인 사항 설명 CPUUtilization or WarmCPUUtilization maximum is \u0026gt;= 80% for 15 minutes, 3 consecutive times\t100% CPU utilization might occur sometimes, but sustained high usage is problematic. Consider using larger instance types or adding instances. MasterCPUUtilization maximum is \u0026gt;= 50% for 15 minutes, 3 consecutive times Consider using larger instance types for your dedicated master nodes. Because of their role in cluster stability and blue/green deployments, dedicated master nodes should have lower CPU usage than data nodes. 참고 # Why is the SysMemoryUtilization so high on my Amazon OpenSearch Service cluster? Recommended CloudWatch alarms for Amazon OpenSearch Service "},{"id":272,"href":"/docs/AWS/01.-API-Gateway/","title":"01. API Gateway","section":"AWS","content":" What is Amazon API Gateway? # Amazon API Gateway is an AWS service for creating, publishing, maintaining, monitoring, and securing REST, HTTP, and WebSocket APIs at any scale.\nAPI developers can create APIs that access AWS or other web services, as well as data stored in the AWS Cloud.\nAs an API Gateway API developer, you can create APIs for use in your own client applications. Or you can make your APIs available to third-party app developers.\nCustom Domain Names # API Gateway 는 기본적으로 아래 형태와 같은 HOSTNAME 을 갖는다.\nhttps://api-id.execute-api.region.amazonaws.com/stage # https://ab123cdef4.execute-api.ap-northeast-2.amazonaws.com/my-stage/my-api-path Custom Domain Names 를 사용할 수 있다.\n물론 정식으로 등록된, 소유하고 있는 domain 만 사용할 수 있다.\nYou must have a registered internet domain name in order to set up custom domain names for your APIs. If needed, you can register an internet domain using Amazon Route 53 or using a third-party domain registrar of your choice. An API\u0026rsquo;s custom domain name can be the name of a subdomain or the root domain (also known as \u0026ldquo;zone apex\u0026rdquo;) of a registered internet domain.\nAfter a custom domain name is created in API Gateway, you must create or update your DNS provider\u0026rsquo;s resource record to map to your API endpoint. Without such a mapping, API requests bound for the custom domain name cannot reach API Gateway.\nWith custom domain names, you can set up your API\u0026rsquo;s hostname, and choose a base path (for example, myservice) to map the alternative URL to your API. For example, a more user-friendly API base URL can become: https://api.example.com/myservice\nIf you don\u0026rsquo;t set any base mapping under a custom domain name, the resulting API\u0026rsquo;s base URL is the same as the custom domain (for example, https://api.example.com). In this case, the custom domain name can\u0026rsquo;t support more than one API.\nWith AWS Lambda # AWS Lambda Function을 호출하는 형태로 사용할 수도 있다.\nYou can create a web API with an HTTP endpoint for your Lambda function by using Amazon API Gateway.\n참고 # https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html https://docs.aws.amazon.com/lambda/latest/dg/services-apigateway.html "},{"id":273,"href":"/docs/AWS/02.-Batch/","title":"02. Batch","section":"AWS","content":" Launch Template # AWS Batch only updates the launch template with a new launch template version during infrastructure updates. For more information, see Updating compute environments.\nQ1. launch template 지정 시 해당 launch template 을 (직접적으로)사용하는 것인지 테스트 필요하다. (단순히 설정 정보를 읽어오는 정도(import)로만 사용하고, 별도 launch template 이 생성되는 건지)\nA1. launch template 을 지정해도, (batch 에 의해)별도 launch template 이 생성되는 것을 확인했다.\nLaunch template 버전 변경이 필요한 경우 # create-compute-environment 문서에 나와있다.\n새로운 launch template 을 사용하기 위해서, 새로운 compute environment 생성이 필요하다.\nJob Scheduling (w/ stuck) # The AWS Batch scheduler evaluates when, where, and how to run jobs that are submitted to a job queue. If you don’t specify a scheduling policy when you create a job queue, the AWS Batch job scheduler defaults to a first-in, first-out (FIFO) strategy. A FIFO strategy might cause important jobs to get “stuck” behind jobs that were submitted earlier. By specifying a different scheduling policy, you can allocate compute resources according to your specific needs.\nJobs stuck in a RUNNABLE status # "},{"id":274,"href":"/docs/AWS/03.-Cloud-Formation/","title":"03. Cloud Formation","section":"AWS","content":" What is AWS CloudFormation? # 요약: IaC를 위한 서비스다.\nAWS resources 를 관리(모델링, 셋업 등)할 수 있는 서비스이다.\n1. CloudFormation Template 을 생성한다.\n템플릿 : AWS 리소스 명시 Json, Yaml 포맷 지원 참고 2. CloudFormation 은 템플릿을 기반으로 리소스를 프로비저닝하고 구성한다.\nYou create a template that describes all the AWS resources that you want (like Amazon EC2 instances or Amazon RDS DB instances), and CloudFormation takes care of provisioning and configuring those resources for you.\nYou don\u0026rsquo;t need to individually create and configure AWS resources and figure out what\u0026rsquo;s dependent on what\n참고 # https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/Welcome.html "},{"id":275,"href":"/docs/AWS/04.-Elastic-Beanstalk/","title":"04. Elastic Beanstalk","section":"AWS","content":" Elastic Beanstalk 에 대한 기본 개념은 어렵지 않고 문서에 잘 설명이 되있어서 문서만 참고해도 좋을 듯 하다.\nWhat is AWS Elastic Beanstalk? # Elastic Beanstalk를 사용하면 애플리케이션을 실행하는 인프라에 대해 자세히 알지 못해도 AWS 클라우드에서 애플리케이션을 신속하게 배포하고 관리할 수 있습니다. Elastic Beanstalk를 사용하면 선택 또는 제어에 대한 제한 없이 관리 복잡성을 줄일 수 있습니다. 애플리케이션을 업로드하기만 하면 Elastic Beanstalk에서 용량 프로비저닝, 로드 밸런싱, 조정, 애플리케이션 상태 모니터링에 대한 세부 정보를 자동으로 처리합니다.\nElastic Beanstalk를 사용하려면 애플리케이션을 생성하고, 애플리케이션 소스 번들의 형태(예: Java .war 파일)로 애플리케이션 버전을 Elastic Beanstalk에 업로드하고, 애플리케이션에 대한 몇 가지 정보를 제공합니다. Elastic Beanstalk가 자동으로 환경을 실행하고 코드 실행에 필요한 AWS 리소스를 생성 및 구성합니다. 환경 실행 후에는 환경을 직접 관리하고 새로운 앱 버전을 배포할 수 있습니다. 다음 다이어그램은 Elastic Beanstalk의 워크플로를 보여 줍니다.\n[요약]\n애플리케이션 생성, 소스 번들 형태로 업로드 \u0026amp; 환경 설정 EB가 자동으로 환경을 구성하고 실행 애플리케이션을 생성 및 배포한 후에는 지표, 이벤트, 환경 상태 등의 애플리케이션 정보를 Elastic Beanstalk 콘솔, API 또는 통합된 AWS CLI를 비롯한 명령줄 인터페이스를 통해 확인할 수 있습니다.\n요약 # 애플리케이션 코드만 업로드하면 서버를 운영할 수 있다. 기타 인프라 설정(SG, ASG, EC2, LB, CloudWatch)은 자동으로 해준다. 비용 # Elastic Beanstalk 에 추가적인 비용은 없다. AWS Resource 에 대한 비용만 지불하면 된다.\n"},{"id":276,"href":"/docs/AWS/05.-Glue/","title":"05. Glue","section":"AWS","content":" What is AWS Glue? # 완전 관리형(=서버 리스) ETL(extract, transform, load) 서비스\n(데이터를) 카테고라이징, 정리, 보강 (데이터를) 다양한 data store, data stream 간 이동 Glue 구성 요소\nCentral metadata repository (= Data Catalog) ETL engine (= python, scala code 등을 자동으로 생성하는 ETL Engine) Scheduler (= 의존성을 핸들링하고, Job monitoring, retry 를 처리할 수 있는 유연한 스케줄러) Glue 특징\nsemi-structured data(반구조화된 데이터)와 함께 처리되도록 설계되었다. ETL 스크립트를 사용할 수 있는 dynamic frame(동적 프레임) 이라는 컴포넌트(?) Glue Console 을 이용해서 데이터를 발견(discover), 변환(transform), 검색/쿼리가 가능(make it available for search and querying)하게 할 수 있다. 마지막 문장인 \u0026ldquo;쿼리가 가능하게 할 수 있다.\u0026rdquo; 가 중요한 것 같다. 실제 데이터를 테이블에 삽입하는 방식이 아니라, \u0026ldquo;Data Store 에 있는 데이터를 검색할 수 있게 하는 것\u0026rdquo; 을 알려주는 것 같기 때문이다. 그 외 다양한 특징/이점은 AWS 공식문서를 살펴본다.\n다만 아래 내용은 중요하니, 참고하자.\nDynamic frame 이란? # (데이터를 row, column으로 구조화하기 위해 사용되는 데이터 추상화인)Apache Spark의 dataframe 과 유사하다. 각 레코드는 self-describing 하다는 것을 기반으로, 초기 데이터 스키마 설정/설계가 필요하지 않다. 예를 들어, json 데이터를 분석해, 분석한 스키마를 기반으로 테이블(파티션)을 생성하는 이 기법? 을 의미하는 단어인 것 가다. Dynamic frame \u0026lt;-\u0026gt; Spark dataframe 간에 컨버팅이 가능하다. Glue, Spark 모두 활용할 수 있는 이점이 있다. Crawler # Crawler 는 Data Stores(S3, \u0026hellip;) 를 분석한다.\n파티션, 스키마를 파악하여 (Data Catalog)Table 을 생성한다. Table 은 파티션 정보를 가지고 있는데, 이 파티션 정보가 중요하다. 데이터를 조회할 때 스캔한 파티션을 기반으로(?) 데이터 조회가 가능하다. 데이터를 조회할 때 스캐한 파티션을 기반으로, DataStore 를 조회 \u0026amp; 결과를 반환하는 것 같다. 따라서, 한번 스캔된 파티션(= DataStore 쪽에)에 데이터를 추가/삭제하면 바로바로 확인할 수 있다. [예시 : 스캔된 파티션]\nData Store(ex: S3의 Path A) 해당 파티션(Path)에 대해 이미 스캔되었다면, (해당 파티션, path 위치에)S3에 데이터를 삽입,삭제하면 바로바로 조회가 가능하다.\n[예시 : 스캔되지 않은 파티션]\n반면에 DataStore(ex: S3의 Path B) 해당 파티션(Path)에 대해 한번이라도 스캔되지 않았다면, 이는 크롤러에 의해 최초 한번은 스캔되어야 한다. 그렇지 않으면 사용할 수 없다.\nDeprecated # https://docs.aws.amazon.com/glue/latest/dg/crawler-configuration.html\n처음에는 위(DeleteBehavior)에서 언급한 \u0026lsquo;a deleted object\u0026rsquo; 가 S3의 object 인 줄 알았는데, Data Store 를 의미하는 것 같다.\nData Store 에 정상적으로 접근하지 못하는 경우를 의미하는 것 같다. (해당 Path 를 찾지 못해 접근하지 못하거나, 권한이 없을 때? 등의 상황이 있을 것 같다.)\n[예시: 로그]\n2022-01-01T00:00:00.000+09:00\t[0123456-7890-1234-5678-1234567890] BENCHMARK : Running Start Crawl for Crawler {크롤러명} 2022-01-01T00:00:00.000+09:00\t[0123456-7890-1234-5678-1234567890] BENCHMARK : Classification complete, writing results to database {DB명} 2022-01-01T00:00:00.000+09:00\t[0123456-7890-1234-5678-1234567890] INFO : Crawler configured with SchemaChangePolicy {\u0026#34;UpdateBehavior\u0026#34;:\u0026#34;LOG\u0026#34;,\u0026#34;DeleteBehavior\u0026#34;:\u0026#34;DEPRECATE_IN_DATABASE\u0026#34;}. 2022-01-01T00:00:00.000+09:00\t[0123456-7890-1234-5678-1234567890] INFO : Table {테이블명} is marked deprecated because a matching schema was not found at the table\u0026#39;s location. 2022-01-01T00:00:00.000+09:00\t[0123456-7890-1234-5678-1234567890] INFO : Found partition of table {테이블명} with partition values [1, A, C, 2] with no matching schema at the partition\u0026#39;s S3 location 2022-01-01T00:00:00.000+09:00\t[0123456-7890-1234-5678-1234567890] BENCHMARK : Finished writing to Catalog 2022-01-01T00:00:00.000+09:00\t[0123456-7890-1234-5678-1234567890] INFO : Run Summary For TABLE: 2022-01-01T00:00:00.000+09:00\t[0123456-7890-1234-5678-1234567890] INFO : UPDATE: 1 2022-01-01T00:00:00.000+09:00\t[0123456-7890-1234-5678-1234567890] BENCHMARK : Crawler has finished running and is in state READY Deprecated 참고\n(테스트 해보니)한번 Deprecated 마킹되면 정상적으로 돌아와도 마킹이 풀리지 않는 것 같다.\nhttps://docs.aws.amazon.com/glue/latest/dg/console-tables.html\nㄴ (깔끔하게 유지하기 위해서) 삭제 후 재생성하는 것도 방법이 될 수 있을 것 같다.\nWhen should I use AWS Glue? # 1. You can use AWS Glue to organize, cleanse, validate, and format data for storage in a data warehouse or data lake.\n2. You can use AWS Glue when you run serverless queries against your Amazon S3 data lake.\nAWS Glue 는 S3의 데이터를 카탈로그화 할 수 있다. 카탈로그화를 통해 Athena, Redshift Spectrum으로 쿼리(검색)가 가능하게 만들 수 있다.\n여기서 말하는 카탈로그화란, 데이터에 대한 메타데이터를 만드는 것으로 이해했다.\n\u0026quot; AWS Glue can catalog your Amazon Simple Storage Service (Amazon S3) data, making it available for querying with Amazon Athena and Amazon Redshift Spectrum. \u0026ldquo;\nGlue Crawler를 통해, 메타데이터가 계속해서 동기화될 수 있도록 할 수 있다.\nAthena, Redshift Spectrum 은 AWS Glue Data Catalog 를 통해 S3에 직접적으로 쿼리할 수 있게 된다.\n(위 방식과 같이) AWS Glue 를 사용하면 여러 DataStore 에 각각 로드하지 않고 하나의 인터페이스(예를 들어, Athena, Redshift Spectrum)를 통해 데이터를 검색/분석할 수 있게 된다.\n3. You can create event-driven ETL pipelines with AWS Glue.\n4. You can use AWS Glue to understand your data assets.\n내용 추가 (1) # 내용 추가 (2) # Glue -\u0026gt; S3 Access Denied 403 오류 발생 시, 아래 내용을 확인해볼 수 있다.\nAWS Glue 작업에서 403 Access Denied 오류가 반환되는 이유는 무엇입니까?\nAWS Identity and Access Management(IAM) 역할에 버킷 액세스에 필요한 권한이 없습니다. (IAM Role) Amazon S3 버킷 정책이 IAM 역할에 필요한 권한을 허용하지 않습니다. (Bucket Policy) S3 버킷 소유자가 객체 소유자와 다릅니다. (S3 ACLs) 객체가 AWS Key Management Service(AWS KMS)로 암호화되었고, AWS KMS 정책이 키 사용에 필요한 최소 권한을 IAM 역할에 부여하지 않습니다. (S3 Encryption) Amazon Virtual Private Cloud(Amazon VPC) 엔드포인트 정책에 S3 버킷 액세스에 필요한 권한이 없습니다. S3 버킷에 요청자 지불이 설정되어 있습니다. S3 버킷에 대한 액세스가 AWS Organizations 서비스 제어 정책에 의해 제한되었습니다. "},{"id":277,"href":"/docs/AWS/06.-IAM/","title":"06. IAM","section":"AWS","content":" IAM # AWS Identity and Access Management(IAM)는 AWS 리소스에 대한 access를 안전하게 제어할 수 있는 웹서비스이다.\nEntity(User, Group, Role)에 Policy를 적용해서 AWS 리소스(EC2, S3, RDS, \u0026hellip;) 에 대한 접근을 관리한다.\nKeyword : User, Group, Role, Policy\nTerms # IAM Resources # user, group, role, policy, identity provider objects\nIAM identities # identify(식별), group(그룹화)에 사용되는 IAM resource object\nIAM identity 에 policy(정책)을 연결(부여)할 수 있다. ex : users, groups, roles IAM Entities # authentication(인증)을 위해 사용하는 IAM resource object\nex : users and roles Principle # (AWS 리소스 사용을 위해) user(+ root user), role 를 사용하는 주체(person, application)\nex: federated users, assumed roles, \u0026hellip; IAM Role # 하나의 IAM role 은 하나의 IAM user 와 유사하다.\nRole 에 Permission, Policy 등을 설정하고, 사용한다. 해당 Role 이 필요한 곳에서 사용한다. 사용자(users), 애플리케이션(applications), 서비스(services)에게 AWS 리소스에 대한 권한을 위임할 수 있다. Roles terms and concepts # Roles\n특정한 권한(specific permission)을 갖는 IAM identity\n나머지는 위 내용(IAM Roles 내용)과 동일하다.\nAWS service role\n하나의 서비스(a service)가 작업(actions)을 수행하기 위해 role 을 사용할 수 있다.\nAWS service environments 를 셋업할 때, 우리는 서비스(service)가 사용할 role 을 정의해야한다.\n해당 서비스가 사용/접근할 AWS resources 에 대한 모든 권한이 정의되어있어야 한다. AWS service role for an EC2 instance\nAWS service role 중 EC2 서비스를 위한 특별한 service role 이다. (EC2만을 위해 명시적으로 하나 더 있다고 보면 될 것 같다.)\n이 role 은 EC2 인스턴스가 시작될 때(be launched), 할당된다.\nFor details about using a service role for an EC2 instance, see Using an IAM role to grant permissions to applications running on Amazon EC2 instances.\nAWS service-linked role\nRole chaining\nRole A 가 Role B와 연결되어 있을 때(Role A가 Role B를 필요로 할 때?) Role chaining 을 통해 연결된 Role 까지 사용할 수 있도록 할 수 있다.\n다만, Role chaining 을 사용하면 credential(session) 정보는 최대 1시간으로 제한된다.\nDelegation\n두 계정(accounts)간에 신뢰(trust)를 설정하여, 접근 권한을 부여할 수 있다.\nThe first is the account that owns the resource (the trusting account). The second is the account that contains the users that need to access the resource (the trusted account). Trusted/Trusting 계정은 다음 중 하나이다.\n동일 계정 Organization 하위의 다른 계정 다른 Organization 의 다른 계정 To delegate permission to access a resource, you create an IAM role in the trusting account that has two policies attached. The permissions policy grants the user of the role the needed permissions to carry out the intended tasks on the resource. The trust policy specifies which trusted account members are allowed to assume the role.\nWhen you create a trust policy, you cannot specify a wildcard (*) as a principal. The trust policy is attached to the role in the trusting account, and is one-half of the permissions. The other half is a permissions policy attached to the user in the trusted account that allows that user to switch to, or assume the role. A user who assumes a role temporarily gives up his or her own permissions and instead takes on the permissions of the role. When the user exits, or stops using the role, the original user permissions are restored. An additional parameter called external ID helps ensure secure use of roles between accounts that are not controlled by the same organization.\nFederation\nFederated user\nTrust policy\n신뢰하는 보안 주체(principals) 를 정의한 JSON policy document 이다.\nA role trust policy는 IAM role 에 연결된 필수적인 resource-based policy 이다.\n보안 주체(principals)는 사용자(users), 역할(roles), 계정(accounts), 서비스(services) 중에서 지정되는 값이다.\n좀 더 찾아볼 것\nPermissions policy\n하나의 permissions document 는 해당 role 이 수행할 수 있는 actions, resources access 를 정의한다.\n즉, 접근 권한, 수행 권한을 정의하는 문서이다. The document is written according to the rules of the IAM policy language.\nPermissions boundary\n\u0026quot; An advanced feature in which you use policies to limit the maximum permissions that an identity-based policy can grant to a role. \u0026quot;\nmaximum permissions 를 제한(limit)할 수 있는 고급 기능(an advanced feature)이다.\n\u0026quot; You cannot apply a permissions boundary to a service-linked role. \u0026quot;\nPrincipal\nactions, access resources 를 수행할 수 있는 하나의 엔티티(an entity)이다.\n다음 종류 중 하나가 된다.\nAWS account root user IAM user IAM role Role for cross-account access\n"},{"id":278,"href":"/docs/AWS/07.-VPC/","title":"07. VPC","section":"AWS","content":" https://www.44bits.io/ko/post/understanding_aws_vpc 내용입니다.\n\u0026quot; Amazon Virtual Private Cloud(VPC)를 사용하면 AWS 클라우드에서 논리적으로 격리된 공간을 프로비저닝하여 고객이 정의하는 가상 네트워크에서 AWS 리소스를 시작할 수 있습니다. IP 주소 범위 선택, 서브넷 생성, 라우팅 테이블 및 네트워크 게이트웨이 구성 등 가상 네트워킹 환경을 완벽하게 제어할 수 있습니다. VPC에서 IPv4와 IPv6를 모두 사용하여 리소스와 애플리케이션에 안전하고 쉽게 액세스할 수 있습니다. – 아마존 버추얼 프라이빗 클라우드(Amazon Virtual Private Cloud) \u0026ldquo;\nAWS에서는 AWS계정을 생성할 때 리전 별로 기본 VPC를 함께 생성해준다. 즉, 내 계정의 기본 VPC이다. 리소스를 생성할 때 VPC를 설정하지 않으면 이 기본 VPC가 설정된다.\n\u0026rdquo; 이 화면의 중간 쯤에 네트워크(Network)라는 항목이 보입니다. 바로 이 네트워크 속성이 EC2 인스턴스를 실행할 VPC를 선택하는 항목입니다. VPC를 지정하지 않는 방법은 없습니다. 반드시 인스턴스가 속할 하나의 VPC를 지정해야만 합니다. 서브넷은 VPC에 속해있는 리소스이며, 하나의 인스턴스는 반드시 하나의 서브넷에 속해야합니다. 단, 기본값을 사용한다면 기본 VPC에서 인스턴스가 생성될 것입니다. \u0026ldquo;\n즉, AWS 리소스에는 VPC, 서브넷 설정이 반드시 필요하다.\n\u0026rdquo; VPC 그 자체가 리소스의 이름입니다. 하지만 동시에 버추얼 프라이빗 클라우드(VPC)를 구축하기 위한 일체의 리소스를 제공하는 서비스의 이름이기도 합니다. 웹 콘솔 메뉴에서 VPC를 찾아보면 VPC 대시보드에 접속할 수 있습니다. \u0026ldquo;\nVPC도 SaaS와 같은 리소스/서비스이다.\nVPC 구성 요소 # 계정을 처음 만들었을 때 리전 별로 (해당 계정을 위한)VPC가 생성된다고 했다. 이때 만들어지는 리소스 항목은 다음과 같다.\n1 VPC n 서브넷 (Subnet, n은 사용할 수 있는 가용존의 개수) 1 라우팅 테이블 (Route Table) 1 네트워크 ACL (Network ACL) 1 시큐리티 그룹 (Security Group) 1 인터넷 게이트웨이 (Internet Gateway) 1 DHCP 옵션 세트 (DHCP options set) VPC # 논리적인 독립 네트워크를 구성하는 리소스\n이름, IPv4 CIDR 블록을 필수로 갖는다. "},{"id":279,"href":"/docs/SPRING/SPRING-Spring-Cache/","title":"[SPRING] Spring Cache","section":"SPRING","content":" 참고 # https://docs.spring.io/spring-framework/docs/6.0.4/reference/html/integration.html#cache https://docs.spring.io/spring-boot/docs/current/reference/html/io.html Caching (from spring-boot docs) # \u0026quot; You can also use the standard JSR-107 (JCache) annotations (such as @CacheResult) transparently. However, we strongly advise you to not mix and match the Spring Cache and JCache annotations. \u0026quot;\nSpring Cache 어노테이션과 JCache 어노테이션을 혼합하여 사용하지 않는다.\n\u0026quot; If you do not add any specific cache library, Spring Boot auto-configures a simple provider that uses concurrent maps in memory. When a cache is required (such as piDecimals in the preceding example), this provider creates it for you. The simple provider is not really recommended for production usage \u0026hellip; \u0026quot;\n기본적으로 concurrent map 기반의 캐시 프로파이더가 사용되는데, 실제 운영 환경에서는 사용하지 않도록 한다.\n캐시 추상화(cache abstraction)은 캐시 프로바이더(실질적인 캐시 저장소)를 제공하지 않는다.\n\u0026quot; If you have not defined a bean of type CacheManager or a CacheResolver named cacheResolver (see CachingConfigurer), Spring Boot tries to detect the following providers (in the indicated order): \u0026ldquo;\nGeneric JCache (JSR-107) (EhCache 3, Hazelcast, Infinispan, and others) Hazelcast Infinispan Couchbase Redis Caffeine Cache2k Simple CacheManagerCustomizer # CacheManager 빈이 완전히 설정되기 전에 CacheManagerCustomizer 를 통해 추가적인 설정이 가능하다.\n@Configuration(proxyBeanMethods = false) class MyCacheManagerConfiguration { @Bean fun cacheManagerCustomizer(): CacheManagerCustomizer\u0026lt;ConcurrentMapCacheManager\u0026gt; { return CacheManagerCustomizer { cacheManager -\u0026gt; cacheManager.isAllowNullValues = false } } } Generic # \u0026rdquo; Generic caching is used if the context defines at least one org.springframework.cache.Cache bean. A CacheManager wrapping all beans of that type is created. \u0026ldquo;\nSimple # \u0026rdquo; If none of the other providers can be found, a simple implementation using a ConcurrentHashMap as the cache store is configured. By default, caches are created as needed, but you can restrict the list of available caches by setting the cache-names property. For instance, if you want only cache1 and cache2 caches, set the cache-names property as follows: \u0026ldquo;\nspring.cache.cache-names=cache1,cache2 None # \u0026rdquo; When @EnableCaching is present in your configuration, a suitable cache configuration is expected as well. If you need to disable caching altogether in certain environments, force the cache type to none to use a no-op implementation, as shown in the following example: \u0026ldquo;\nspring.cache.type=none spring.cache.type=none 설정을 통해 캐시를 비활성화할 수 있다.\n"},{"id":280,"href":"/docs/AWS/OpenSearch/","title":"08. Opensearch","section":"AWS","content":""},{"id":281,"href":"/docs/AWS/","title":"AWS","section":"Docs","content":""},{"id":282,"href":"/docs/DEV/AWS-Community-Day-2022/","title":"AWS Community Day 2022","section":"DEV","content":""},{"id":283,"href":"/docs/BOOKS/","title":"BOOKS","section":"Docs","content":""},{"id":284,"href":"/docs/LANGUAGES/CPP/","title":"CPP","section":"LANGUAGES","content":""},{"id":285,"href":"/docs/DB/","title":"DB","section":"Docs","content":""},{"id":286,"href":"/docs/DEV/","title":"DEV","section":"Docs","content":""},{"id":287,"href":"/docs/","title":"Docs","section":"thisandthat","content":""},{"id":288,"href":"/docs/ETC/","title":"ETC","section":"Docs","content":""},{"id":289,"href":"/docs/DEV/ifkakaodev-2022/","title":"If Kakao 2022","section":"DEV","content":""},{"id":290,"href":"/docs/BOOKS/IOS-Android-%EC%95%B1-%EA%B0%9C%EB%B0%9C%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%8B%A4%EC%A0%84-React-Native-Basic/","title":"IOS, Android 앱 개발을 위한 실전 React Native - Basic","section":"BOOKS","content":""},{"id":291,"href":"/docs/LANGUAGES/JAVA/","title":"JAVA","section":"LANGUAGES","content":""},{"id":292,"href":"/docs/KAFKA/","title":"KAFKA","section":"Docs","content":""},{"id":293,"href":"/docs/LANGUAGES/KOTLIN/","title":"KOTLIN","section":"LANGUAGES","content":""},{"id":294,"href":"/docs/LANGUAGES/","title":"LANGUAGES","section":"Docs","content":""},{"id":295,"href":"/docs/LINUX/","title":"LINUX","section":"Docs","content":""},{"id":296,"href":"/docs/NETWORK/","title":"NETWORK","section":"Docs","content":""},{"id":297,"href":"/docs/NUXT/","title":"NUXT","section":"Docs","content":""},{"id":298,"href":"/docs/OS/","title":"OS","section":"Docs","content":""},{"id":299,"href":"/docs/LANGUAGES/PHP/","title":"PHP","section":"LANGUAGES","content":""},{"id":300,"href":"/docs/BOOKS/Real-Mysql-8.0/","title":"Real Mysql 8.0","section":"BOOKS","content":""},{"id":301,"href":"/docs/REDIS/","title":"REDIS","section":"Docs","content":""},{"id":302,"href":"/docs/SPRING/","title":"SPRING","section":"Docs","content":""},{"id":303,"href":"/docs/BOOKS/Spring-Cloud%EB%A1%9C-%EA%B0%9C%EB%B0%9C%ED%95%98%EB%8A%94-%EB%A7%88%EC%9D%B4%ED%81%AC%EB%A1%9C%EC%84%9C%EB%B9%84%EC%8A%A4-%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98/","title":"Spring Cloud로 개발하는 마이크로서비스 애플리케이션","section":"BOOKS","content":""},{"id":304,"href":"/docs/WEB/","title":"WEB","section":"Docs","content":""},{"id":305,"href":"/docs/BOOKS/%EA%B0%80%EC%83%81-%EB%A9%B4%EC%A0%91-%EC%82%AC%EB%A1%80%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%A4%EA%B3%84-%EA%B8%B0%EC%B4%88/","title":"가상 면접 사례로 배우는 대규모 시스템 설계 기초","section":"BOOKS","content":""},{"id":306,"href":"/docs/BOOKS/%EB%8C%80%EA%B7%9C%EB%AA%A8-%EC%84%9C%EB%B9%84%EC%8A%A4%EB%A5%BC-%EC%A7%80%ED%83%B1%ED%95%98%EB%8A%94-%EA%B8%B0%EC%88%A0/","title":"대규모 서비스를 지탱하는 기술","section":"BOOKS","content":""},{"id":307,"href":"/docs/BOOKS/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%ED%81%B4%EB%A6%B0-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/","title":"만들면서 배우는 클린 아키텍처","section":"BOOKS","content":""},{"id":308,"href":"/docs/BOOKS/%EB%AA%A8%EB%8D%98-%EC%9E%90%EB%B0%94-%EC%9D%B8-%EC%95%A1%EC%85%98/","title":"모던 자바 인 액션","section":"BOOKS","content":""},{"id":309,"href":"/docs/BOOKS/%EB%AA%A8%EB%93%A0-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-HTTP-%EC%9B%B9-%EA%B8%B0%EB%B3%B8-%EC%A7%80%EC%8B%9D/","title":"모든 개발자를 위한 HTTP 웹 기본 지식","section":"BOOKS","content":""},{"id":310,"href":"/docs/BOOKS/IOS-Android-%EC%95%B1-%EA%B0%9C%EB%B0%9C%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%8B%A4%EC%A0%84-React-Native-Basic/%EC%8A%A4%ED%83%80%EC%9D%BC-1/","title":"스타일 (1)","section":"IOS, Android 앱 개발을 위한 실전 React Native - Basic","content":" Style 방식 # 1. inline\n\u0026lt;View style={{...}}\u0026gt; ... \u0026lt;/View\u0026gt; 2. StyleSheet\n\u0026lt;View style={styles.mainView}\u0026gt; ... \u0026lt;/View\u0026gt; ... const styles = StyleSheet.create({ mainView: { .... } }) "},{"id":311,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-5-%EB%A0%88%EC%8B%9C%ED%94%BC/","title":"스프링 5 레시피","section":"BOOKS","content":""},{"id":312,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-%EC%9E%85%EB%AC%B8%EC%9D%84-%EC%9C%84%ED%95%9C-%EC%9E%90%EB%B0%94-%EA%B0%9D%EC%B2%B4-%EC%A7%80%ED%96%A5%EC%9D%98-%EC%9B%90%EB%A6%AC%EC%99%80-%EC%9D%B4%ED%95%B4/","title":"스프링 입문을 위한 자바 객체 지향의 원리와 이해","section":"BOOKS","content":""},{"id":313,"href":"/docs/BOOKS/%EC%8A%A4%ED%94%84%EB%A7%81-%ED%95%B5%EC%8B%AC-%EC%9B%90%EB%A6%AC-%EA%B8%B0%EB%B3%B8%ED%8E%B8/","title":"스프링 핵심 원리 (기본편)","section":"BOOKS","content":""},{"id":314,"href":"/docs/BOOKS/%EC%8B%A4%EB%AC%B4%EB%A1%9C-%EB%B0%B0%EC%9A%B0%EB%8A%94-%EC%8B%9C%EC%8A%A4%ED%85%9C-%EC%84%B1%EB%8A%A5-%EC%B5%9C%EC%A0%81%ED%99%94/","title":"실무로 배우는 시스템 성능 최적화","section":"BOOKS","content":""},{"id":315,"href":"/docs/BOOKS/%EC%95%84%ED%8C%8C%EC%B9%98-%EC%B9%B4%ED%94%84%EC%B9%B4-for-beginners/","title":"아파치 카프카 for beginners","section":"BOOKS","content":""},{"id":316,"href":"/docs/BOOKS/%EC%98%A4%EB%B8%8C%EC%A0%9D%ED%8A%B8/","title":"오브젝트","section":"BOOKS","content":""},{"id":317,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%EC%BD%94%ED%8B%80%EB%A6%B0/","title":"이펙티브 코틀린","section":"BOOKS","content":""},{"id":318,"href":"/docs/BOOKS/%EC%9D%B4%ED%8E%99%ED%8B%B0%EB%B8%8C-%ED%83%80%EC%9E%85%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8/","title":"이펙티브 타입스크립트","section":"BOOKS","content":""},{"id":319,"href":"/docs/BOOKS/%EC%9E%90%EB%B0%94-ORM-%ED%91%9C%EC%A4%80-JPA-%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%B0%8D/","title":"자바 ORM 표준 JPA 프로그래밍","section":"BOOKS","content":""},{"id":320,"href":"/docs/BOOKS/%EC%BD%94%ED%8B%80%EB%A6%B0-%EC%9D%B8-%EC%95%A1%EC%85%98/","title":"코틀린 인 액션","section":"BOOKS","content":""}]